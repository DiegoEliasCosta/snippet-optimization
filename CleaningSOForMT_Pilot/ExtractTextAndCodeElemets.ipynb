{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    text1 = removeSpecialChars(text1)\n",
    "    text2 = removeSpecialChars(text2)\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "def removeSpecialChars(text):\n",
    "    return re.sub(\"[^a-zA-Z0-9]\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Converting a Pandas GroupBy object to DataFrame Python Pandas - Re-ordering columns in a dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove all tokens that are not alphabetic. Special Characters\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # stemming of words\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    processed_text = (' ').join(stemmed)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Class to extract method as well as attribute calls. Each token after '.' is called attribute \n",
    "# be it function call or anything else\n",
    "\n",
    "class AttributeVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "        self._pos = -1 \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @property\n",
    "    def lineno(self):\n",
    "        return self._pos\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._pos = node.lineno # line number\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._pos = node.lineno # line number\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_all_calls(tree):\n",
    "    all_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Attribute):\n",
    "            callvisitor = AttributeVisitor()\n",
    "            callvisitor.visit(node)\n",
    "            all_calls.append(callvisitor.name)\n",
    "    return all_calls\n",
    "\n",
    "# Visitin method calls only\n",
    "class FunctionCallVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "        self._pos = -1 \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @property\n",
    "    def lineno(self):\n",
    "        return self._pos\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._pos = node.lineno # line number\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._pos = node.lineno # line number\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_func_calls(tree):\n",
    "    func_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            callvisitor = FunctionCallVisitor()\n",
    "            callvisitor.visit(node.func)\n",
    "            func_calls.append((callvisitor.name, callvisitor.lineno))\n",
    "    return func_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_dump_processed_file = '../data/stack-overflow/pandas-preprocessedcode-dataset-part3'\n",
    "dataset ='../data/stack-overflow/Dataset - Pandas.csv'\n",
    "api_doc_file = '../code/data-import/build_api_doc_base/api_doc.csv'\n",
    "id_col = 'Id' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stackoverflow_df = pd.read_pickle(so_dump_processed_file)\n",
    "api_df = pd.read_csv(api_doc_file, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "dataset_df = pd.read_csv(dataset, encoding='ISO-8859-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.to_csv('api_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get API description with fully qualified name for a method from API doc and build the context\n",
    "def buildAPIDictionary(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        \n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['Description']\n",
    "            tokens = row['FullyQualifiedName'].split('.')\n",
    "        \n",
    "            for token in tokens:\n",
    "                methodContext = str(methodContext)+' '+token\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return api_dict\n",
    "        \n",
    "## Get AnswerId and Question Text combo from dataset to build the context\n",
    "def buildAnswerIdQuestionTextDict(dataset_df):\n",
    "    dataset_answerId_QText_Dict = dict()\n",
    "    try:\n",
    "        for idx, row in dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                dataset_answerId_QText_Dict[answerId] = process_text(row['QuestionText'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return dataset_answerId_QText_Dict\n",
    "\n",
    "api_dict = buildAPIDictionary(api_df)\n",
    "dataset_answerId_QText_Dict = buildAnswerIdQuestionTextDict(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContext(method_name):\n",
    "    if method_name in api_dict.keys():\n",
    "        return api_dict[method_name]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def getSOContext(answerId):\n",
    "    return dataset_answerId_QText_Dict[int(answerId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'AcceptedAnswerId', 'AnswerCount', 'Body',\n",
       "       'ClosedDate', 'CommentCount', 'CommunityOwnedDate', 'CreationDate',\n",
       "       'FavoriteCount', 'Id', 'LastActivityDate', 'LastEditDate',\n",
       "       'LastEditorDisplayName', 'LastEditorUserId', 'OwnerDisplayName',\n",
       "       'OwnerUserId', 'ParentId', 'PostTypeId', 'Score', 'Tags', 'Title',\n",
       "       'ViewCount', 'Code', 'PreprocessedCode', 'PreprocessedCode2',\n",
       "       'PreprocessedCode2_1', 'PreprocessedCode3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_stackoverflow_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df = pd.DataFrame(columns=['title', 'all_calls'])\n",
    "for index, row in processed_stackoverflow_df.iterrows():\n",
    "    try:\n",
    "        if row.PostTypeId !=1:\n",
    "            tile = getSOContext(row.Id)\n",
    "            code_snippet = row.PreprocessedCode3\n",
    "            tree = ast.parse(code_snippet)\n",
    "            all_calls = get_all_calls(tree)\n",
    "            if(len(all_calls) !=0):\n",
    "                title_codeElement_pair_df.loc[index] = [tile, all_calls]\n",
    "            \n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "1209      panda datafram find row valu column maxim   \n",
       "1211          convert panda groupbi object datafram   \n",
       "1213            redefin index panda datafram object   \n",
       "1232  python panda column datafram base column name   \n",
       "1238                             databas like mysql   \n",
       "\n",
       "                                              all_calls  \n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                      [df.reindex_axis, df.columns]  \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H1(df):\n",
    "    all_calls = df['all_calls']\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if lookUpAPIDocForContext(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h1_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h1 = title_codeElement_pair_df.apply(filter_code_elements_using_H1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                  [df.reindex_axis]  \n",
       "1238                         [pd.read_sql, pd.read_sql]  \n",
       "...                                                 ...  \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAPIDictionaryForH2(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        \n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['SubCategory']\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print('Error in method buildAPIDictionary',e)\n",
    "    return api_dict\n",
    "\n",
    "api_dict_H2 = buildAPIDictionaryForH2(api_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContextH2(method_name):\n",
    "    try:\n",
    "        if method_name in api_dict_H2.keys() and api_dict_H2[method_name] == \"Constructor\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print('Error in method lookUpAPIDocForContext', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H2(df):\n",
    "    all_calls = df['all_calls']\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if not lookUpAPIDocForContextH2(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h2_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h2 = title_codeElement_pair_df_after_h1.apply(filter_code_elements_using_H2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                      [df.reindex_axis, df.columns]  \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...  \n",
       "...                                                 ...  \n",
       "2856                               [df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H1H2(df):\n",
    "    # H1 filtered call\n",
    "    h1_filtered_calls = df['h1_filtered_calls']\n",
    "    len_h1 = len(h1_filtered_calls)\n",
    "    filtered_calls = []\n",
    "    for call in h1_filtered_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if not lookUpAPIDocForContextH2(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h1h2_filtered_calls'] = filtered_calls\n",
    "    len_h1h2 = len(filtered_calls)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h1h2 = title_codeElement_pair_df_after_h2.apply(filter_code_elements_using_H1H2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, df.str.split, upper_lower_df.st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                  [df.reindex_axis]  \n",
       "1238                         [pd.read_sql, pd.read_sql]  \n",
       "...                                                 ...  \n",
       "2856                               [df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split, df.str.split, upper_lower_df.st...  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h1h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_M1(df, cosine_sim_threshould):\n",
    "    all_calls = df['all_calls']\n",
    "    len_all = len(all_calls)\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        api_context = lookUpAPIDocForContext(method_name)\n",
    "        if api_context == \"\":\n",
    "            cos_score = -1\n",
    "        else:\n",
    "            cos_score = cosine_sim(api_context, df['title'])\n",
    "        if cos_score > cosine_sim_threshould:\n",
    "            filtered_calls.append(call)\n",
    "    df['m1_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_m1 = title_codeElement_pair_df_after_h1h2.apply(filter_code_elements_using_M1, args=(0.1,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "      <th>m1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[pandas.DataFrame, dfrm.idxmax, dfrm.idxmax]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.add_suffix.reset_index, df1.groupby.size.D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, df.str.split, upper_lower_df.st...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, df.str.split, upper_lower_df.st...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      m1_filtered_calls  \n",
       "1209       [pandas.DataFrame, dfrm.idxmax, dfrm.idxmax]  \n",
       "1211  [g1.add_suffix.reset_index, df1.groupby.size.D...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                                 []  \n",
       "1238                                                 []  \n",
       "...                                                 ...  \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]  \n",
       "2859                             [df3.index.duplicated]  \n",
       "2951                                                 []  \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_text(df, columns):\n",
    "    for col in columns:\n",
    "        list_ = df[col]\n",
    "        df[col] = \" \".join(list_)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['all_calls', 'h1_filtered_calls', 'h2_filtered_calls', 'h1h2_filtered_calls', 'm1_filtered_calls']\n",
    "title_codeElement_pair = title_codeElement_pair_df_after_m1.apply(list_to_text, args=(list_columns,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "      <th>m1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>pandas.DataFrame df.argmax df.argmax df.argmax...</td>\n",
       "      <td>pandas.DataFrame df.argmax df.argmax df.argmax...</td>\n",
       "      <td>df.argmax df.argmax df.argmax dfrm.idxmax dfrm...</td>\n",
       "      <td>df.argmax df.argmax df.argmax dfrm.idxmax dfrm...</td>\n",
       "      <td>pandas.DataFrame dfrm.idxmax dfrm.idxmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.add_suffix.reset_index df1.groupby.size.Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>df.reindex_axis df.columns</td>\n",
       "      <td>df.reindex_axis</td>\n",
       "      <td>df.reindex_axis df.columns</td>\n",
       "      <td>df.reindex_axis</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>cx_Oracle.connect pd.read_sql ora_conn.close M...</td>\n",
       "      <td>pd.read_sql pd.read_sql</td>\n",
       "      <td>cx_Oracle.connect pd.read_sql ora_conn.close M...</td>\n",
       "      <td>pd.read_sql pd.read_sql</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "      <td>df.drop_duplicates</td>\n",
       "      <td>df.drop_duplicates</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>df.str.split.str df.str.split.str df.str.split...</td>\n",
       "      <td>df.str.split pd.DataFrame df.str.split pd.Data...</td>\n",
       "      <td>df.str.split.str df.str.split.str df.str.split...</td>\n",
       "      <td>df.str.split df.str.split upper_lower_df.str.l...</td>\n",
       "      <td>df.str.split pd.DataFrame df.str.split pd.Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  pandas.DataFrame df.argmax df.argmax df.argmax...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                         df.reindex_axis df.columns   \n",
       "1238  cx_Oracle.connect pd.read_sql ora_conn.close M...   \n",
       "...                                                 ...   \n",
       "2856                    pd.DataFrame df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split.str df.str.split.str df.str.split...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  pandas.DataFrame df.argmax df.argmax df.argmax...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                                    df.reindex_axis   \n",
       "1238                            pd.read_sql pd.read_sql   \n",
       "...                                                 ...   \n",
       "2856                    pd.DataFrame df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split pd.DataFrame df.str.split pd.Data...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  df.argmax df.argmax df.argmax dfrm.idxmax dfrm...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                         df.reindex_axis df.columns   \n",
       "1238  cx_Oracle.connect pd.read_sql ora_conn.close M...   \n",
       "...                                                 ...   \n",
       "2856                                 df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split.str df.str.split.str df.str.split...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \\\n",
       "1209  df.argmax df.argmax df.argmax dfrm.idxmax dfrm...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                                    df.reindex_axis   \n",
       "1238                            pd.read_sql pd.read_sql   \n",
       "...                                                 ...   \n",
       "2856                                 df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split df.str.split upper_lower_df.str.l...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      m1_filtered_calls  \n",
       "1209           pandas.DataFrame dfrm.idxmax dfrm.idxmax  \n",
       "1211  g1.add_suffix.reset_index df1.groupby.size.Dat...  \n",
       "1213                                     data.set_index  \n",
       "1232                                                     \n",
       "1238                                                     \n",
       "...                                                 ...  \n",
       "2856                    pd.DataFrame df.drop_duplicates  \n",
       "2859                               df3.index.duplicated  \n",
       "2951                                                     \n",
       "3060  df.str.split pd.DataFrame df.str.split pd.Data...  \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...  \n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'all_calls', 'h1_filtered_calls', 'h2_filtered_calls',\n",
       "       'h1h2_filtered_calls', 'm1_filtered_calls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair.to_csv('corpus/title.txt', columns = ['title'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/all_calls_code.txt', columns = ['all_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h1_filtered_calls_code.txt', columns = ['h1_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h2_filtered_calls_code.txt', columns = ['h2_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h1h2_filtered_calls_code.txt', columns = ['h1h2_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/m1_filtered_calls_code.txt', columns = ['m1_filtered_calls'], index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
