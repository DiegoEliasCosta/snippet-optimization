{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    text1 = removeSpecialChars(text1)\n",
    "    text2 = removeSpecialChars(text2)\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "def removeSpecialChars(text):\n",
    "    return re.sub(\"[^a-zA-Z0-9]\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def process_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove all tokens that are not alphabetic. Special Characters\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # stemming of words\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    processed_text = (' ').join(stemmed)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Class to extract method as well as attribute calls. Each token after '.' is called attribute \n",
    "# be it function call or anything else\n",
    "\n",
    "class AttributeVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "        self._pos = -1 \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @property\n",
    "    def lineno(self):\n",
    "        return self._pos\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._pos = node.lineno # line number\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._pos = node.lineno # line number\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_all_calls(tree):\n",
    "    all_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Attribute):\n",
    "            callvisitor = AttributeVisitor()\n",
    "            callvisitor.visit(node)\n",
    "            all_calls.append(callvisitor.name)\n",
    "    return all_calls\n",
    "\n",
    "# Visitin method calls only\n",
    "class FunctionCallVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "        self._pos = -1 \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @property\n",
    "    def lineno(self):\n",
    "        return self._pos\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._pos = node.lineno # line number\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._pos = node.lineno # line number\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_func_calls(tree):\n",
    "    func_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            callvisitor = FunctionCallVisitor()\n",
    "            callvisitor.visit(node.func)\n",
    "            func_calls.append((callvisitor.name, callvisitor.lineno))\n",
    "    return func_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_dump_processed_file = '../data/stack-overflow/pandas-preprocessedcode-dataset-part3'\n",
    "dataset ='../data/stack-overflow/Dataset - Pandas.csv'\n",
    "api_doc_file = '../code/data-import/build_api_doc_base/api_doc.csv'\n",
    "id_col = 'Id' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stackoverflow_df = pd.read_pickle(so_dump_processed_file)\n",
    "api_df = pd.read_csv(api_doc_file, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "dataset_df = pd.read_csv(dataset, encoding='ISO-8859-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df.to_csv('api_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get API description with fully qualified name for a method from API doc and build the context\n",
    "def buildAPIDictionary(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        \n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['Description']\n",
    "            tokens = row['FullyQualifiedName'].split('.')\n",
    "        \n",
    "            for token in tokens:\n",
    "                methodContext = str(methodContext)+' '+token\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return api_dict\n",
    "        \n",
    "## Get AnswerId and Question Text combo from dataset to build the context\n",
    "def buildAnswerIdQuestionTextDict(dataset_df):\n",
    "    dataset_answerId_QText_Dict = dict()\n",
    "    try:\n",
    "        for idx, row in dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                dataset_answerId_QText_Dict[answerId] = process_text(row['QuestionText'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return dataset_answerId_QText_Dict\n",
    "\n",
    "api_dict = buildAPIDictionary(api_df)\n",
    "dataset_answerId_QText_Dict = buildAnswerIdQuestionTextDict(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContext(method_name):\n",
    "    if method_name in api_dict.keys():\n",
    "        return api_dict[method_name]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def getSOContext(answerId):\n",
    "    return dataset_answerId_QText_Dict[int(answerId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'AcceptedAnswerId', 'AnswerCount', 'Body',\n",
       "       'ClosedDate', 'CommentCount', 'CommunityOwnedDate', 'CreationDate',\n",
       "       'FavoriteCount', 'Id', 'LastActivityDate', 'LastEditDate',\n",
       "       'LastEditorDisplayName', 'LastEditorUserId', 'OwnerDisplayName',\n",
       "       'OwnerUserId', 'ParentId', 'PostTypeId', 'Score', 'Tags', 'Title',\n",
       "       'ViewCount', 'Code', 'PreprocessedCode', 'PreprocessedCode2',\n",
       "       'PreprocessedCode2_1', 'PreprocessedCode3', 'BodyText', 'BodyTextRake',\n",
       "       'TitleRake'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_stackoverflow_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df = pd.DataFrame(columns=['title', 'body_text', 'body_text_rake', 'all_calls'])\n",
    "for index, row in processed_stackoverflow_df.iterrows():\n",
    "    try:\n",
    "        if row.PostTypeId !=1:\n",
    "            tile = getSOContext(row.Id)\n",
    "            #title_rake = process_text(row.TitleRake)\n",
    "            body_text = row.BodyText\n",
    "            body_text_rake = process_text(row.BodyTextRake)\n",
    "            code_snippet = row.PreprocessedCode3\n",
    "            tree = ast.parse(code_snippet)\n",
    "            all_calls = get_all_calls(tree)\n",
    "            if(len(all_calls) !=0):\n",
    "                title_codeElement_pair_df.loc[index] = [tile, body_text, body_text_rake, all_calls]\n",
    "            \n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "1209      panda datafram find row valu column maxim   \n",
       "1211          convert panda groupbi object datafram   \n",
       "1213            redefin index panda datafram object   \n",
       "1232  python panda column datafram base column name   \n",
       "1238                             databas like mysql   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "\n",
       "                                              all_calls  \n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                      [df.reindex_axis, df.columns]  \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H1(df):\n",
    "    all_calls = df['all_calls']\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if lookUpAPIDocForContext(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h1_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h1 = title_codeElement_pair_df.apply(filter_code_elements_using_H1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>This is much easier in pandas now with drop_du...</td>\n",
       "      <td>much easier keep paramet panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>I would suggest using the duplicated method on...</td>\n",
       "      <td>current accept answer slightli less perform sa...</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>When reading to and from your csv file include...</td>\n",
       "      <td>csv file includ argument index csv read read p...</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>TL;DR version:\\nFor the simple case of:\\n\\nI h...</td>\n",
       "      <td>python tupl unpack first two paramet plain pyt...</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>2017 Answer - pandas 0.20: .ix is deprecated. ...</td>\n",
       "      <td>loc use label base index loc see loc includ lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "...                                                 ...   \n",
       "2856  This is much easier in pandas now with drop_du...   \n",
       "2859  I would suggest using the duplicated method on...   \n",
       "2951  When reading to and from your csv file include...   \n",
       "3060  TL;DR version:\\nFor the simple case of:\\n\\nI h...   \n",
       "3186  2017 Answer - pandas 0.20: .ix is deprecated. ...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "...                                                 ...   \n",
       "2856                     much easier keep paramet panda   \n",
       "2859  current accept answer slightli less perform sa...   \n",
       "2951  csv file includ argument index csv read read p...   \n",
       "3060  python tupl unpack first two paramet plain pyt...   \n",
       "3186  loc use label base index loc see loc includ lo...   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                  [df.reindex_axis]  \n",
       "1238                         [pd.read_sql, pd.read_sql]  \n",
       "...                                                 ...  \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAPIDictionaryForH2(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        \n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['SubCategory']\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print('Error in method buildAPIDictionary',e)\n",
    "    return api_dict\n",
    "\n",
    "api_dict_H2 = buildAPIDictionaryForH2(api_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContextH2(method_name):\n",
    "    try:\n",
    "        if method_name in api_dict_H2.keys() and api_dict_H2[method_name] == \"Constructor\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print('Error in method lookUpAPIDocForContext', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H2(df):\n",
    "    all_calls = df['all_calls']\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if not lookUpAPIDocForContextH2(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h2_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h2 = title_codeElement_pair_df_after_h1.apply(filter_code_elements_using_H2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>This is much easier in pandas now with drop_du...</td>\n",
       "      <td>much easier keep paramet panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>I would suggest using the duplicated method on...</td>\n",
       "      <td>current accept answer slightli less perform sa...</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>When reading to and from your csv file include...</td>\n",
       "      <td>csv file includ argument index csv read read p...</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>TL;DR version:\\nFor the simple case of:\\n\\nI h...</td>\n",
       "      <td>python tupl unpack first two paramet plain pyt...</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>2017 Answer - pandas 0.20: .ix is deprecated. ...</td>\n",
       "      <td>loc use label base index loc see loc includ lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "...                                                 ...   \n",
       "2856  This is much easier in pandas now with drop_du...   \n",
       "2859  I would suggest using the duplicated method on...   \n",
       "2951  When reading to and from your csv file include...   \n",
       "3060  TL;DR version:\\nFor the simple case of:\\n\\nI h...   \n",
       "3186  2017 Answer - pandas 0.20: .ix is deprecated. ...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "...                                                 ...   \n",
       "2856                     much easier keep paramet panda   \n",
       "2859  current accept answer slightli less perform sa...   \n",
       "2951  csv file includ argument index csv read read p...   \n",
       "3060  python tupl unpack first two paramet plain pyt...   \n",
       "3186  loc use label base index loc see loc includ lo...   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                      [df.reindex_axis, df.columns]  \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...  \n",
       "...                                                 ...  \n",
       "2856                               [df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_H1H2(df):\n",
    "    # H1 filtered call\n",
    "    h1_filtered_calls = df['h1_filtered_calls']\n",
    "    len_h1 = len(h1_filtered_calls)\n",
    "    filtered_calls = []\n",
    "    for call in h1_filtered_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        if not lookUpAPIDocForContextH2(method_name):\n",
    "            filtered_calls.append(call)\n",
    "    df['h1h2_filtered_calls'] = filtered_calls\n",
    "    len_h1h2 = len(filtered_calls)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_h1h2 = title_codeElement_pair_df_after_h2.apply(filter_code_elements_using_H1H2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>This is much easier in pandas now with drop_du...</td>\n",
       "      <td>much easier keep paramet panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>I would suggest using the duplicated method on...</td>\n",
       "      <td>current accept answer slightli less perform sa...</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>When reading to and from your csv file include...</td>\n",
       "      <td>csv file includ argument index csv read read p...</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>TL;DR version:\\nFor the simple case of:\\n\\nI h...</td>\n",
       "      <td>python tupl unpack first two paramet plain pyt...</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, df.str.split, upper_lower_df.st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>2017 Answer - pandas 0.20: .ix is deprecated. ...</td>\n",
       "      <td>loc use label base index loc see loc includ lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "...                                                 ...   \n",
       "2856  This is much easier in pandas now with drop_du...   \n",
       "2859  I would suggest using the duplicated method on...   \n",
       "2951  When reading to and from your csv file include...   \n",
       "3060  TL;DR version:\\nFor the simple case of:\\n\\nI h...   \n",
       "3186  2017 Answer - pandas 0.20: .ix is deprecated. ...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "...                                                 ...   \n",
       "2856                     much easier keep paramet panda   \n",
       "2859  current accept answer slightli less perform sa...   \n",
       "2951  csv file includ argument index csv read read p...   \n",
       "3060  python tupl unpack first two paramet plain pyt...   \n",
       "3186  loc use label base index loc see loc includ lo...   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                  [df.reindex_axis]  \n",
       "1238                         [pd.read_sql, pd.read_sql]  \n",
       "...                                                 ...  \n",
       "2856                               [df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split, df.str.split, upper_lower_df.st...  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_h1h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code_elements_using_M1(df, cosine_sim_threshould):\n",
    "    all_calls = df['all_calls']\n",
    "    len_all = len(all_calls)\n",
    "    filtered_calls = []\n",
    "    for call in all_calls:\n",
    "        tokens = call.split('.')\n",
    "        method_name = tokens[len(tokens)-1]\n",
    "        api_context = lookUpAPIDocForContext(method_name)\n",
    "        if api_context == \"\":\n",
    "            cos_score = -1\n",
    "        else:\n",
    "            cos_score = cosine_sim(api_context, df['title'])\n",
    "        if cos_score > cosine_sim_threshould:\n",
    "            filtered_calls.append(call)\n",
    "    df['m1_filtered_calls'] = filtered_calls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair_df_after_m1 = title_codeElement_pair_df_after_h1h2.apply(filter_code_elements_using_M1, args=(0.0,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "      <th>m1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[df.argmax, df.argmax, df.argmax, dfrm.idxmax,...</td>\n",
       "      <td>[pandas.DataFrame, df.argmax, df.argmax, df.ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "      <td>[g1.index, g1.add_suffix.reset_index, df1.grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "      <td>[data.set_index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis, df.columns]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "      <td>[df.reindex_axis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[cx_Oracle.connect, pd.read_sql, ora_conn.clos...</td>\n",
       "      <td>[pd.read_sql, pd.read_sql]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>This is much easier in pandas now with drop_du...</td>\n",
       "      <td>much easier keep paramet panda</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[df.drop_duplicates]</td>\n",
       "      <td>[pd.DataFrame, df.drop_duplicates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>I would suggest using the duplicated method on...</td>\n",
       "      <td>current accept answer slightli less perform sa...</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "      <td>[df3.index.duplicated, df3.index]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>When reading to and from your csv file include...</td>\n",
       "      <td>csv file includ argument index csv read read p...</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "      <td>[df.read_csv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>TL;DR version:\\nFor the simple case of:\\n\\nI h...</td>\n",
       "      <td>python tupl unpack first two paramet plain pyt...</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "      <td>[df.str.split.str, df.str.split.str, df.str.sp...</td>\n",
       "      <td>[df.str.split, df.str.split, upper_lower_df.st...</td>\n",
       "      <td>[df.str.split, pd.DataFrame, df.str.split, pd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>2017 Answer - pandas 0.20: .ix is deprecated. ...</td>\n",
       "      <td>loc use label base index loc see loc includ lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "      <td>[df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "...                                                 ...   \n",
       "2856  This is much easier in pandas now with drop_du...   \n",
       "2859  I would suggest using the duplicated method on...   \n",
       "2951  When reading to and from your csv file include...   \n",
       "3060  TL;DR version:\\nFor the simple case of:\\n\\nI h...   \n",
       "3186  2017 Answer - pandas 0.20: .ix is deprecated. ...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "...                                                 ...   \n",
       "2856                     much easier keep paramet panda   \n",
       "2859  current accept answer slightli less perform sa...   \n",
       "2951  csv file includ argument index csv read read p...   \n",
       "3060  python tupl unpack first two paramet plain pyt...   \n",
       "3186  loc use label base index loc see loc includ lo...   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                      [df.reindex_axis, df.columns]   \n",
       "1238  [cx_Oracle.connect, pd.read_sql, ora_conn.clos...   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split.str, df.str.split.str, df.str.sp...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \\\n",
       "1209  [df.argmax, df.argmax, df.argmax, dfrm.idxmax,...   \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...   \n",
       "1213                                   [data.set_index]   \n",
       "1232                                  [df.reindex_axis]   \n",
       "1238                         [pd.read_sql, pd.read_sql]   \n",
       "...                                                 ...   \n",
       "2856                               [df.drop_duplicates]   \n",
       "2859                  [df3.index.duplicated, df3.index]   \n",
       "2951                                      [df.read_csv]   \n",
       "3060  [df.str.split, df.str.split, upper_lower_df.st...   \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...   \n",
       "\n",
       "                                      m1_filtered_calls  \n",
       "1209  [pandas.DataFrame, df.argmax, df.argmax, df.ar...  \n",
       "1211  [g1.index, g1.add_suffix.reset_index, df1.grou...  \n",
       "1213                                   [data.set_index]  \n",
       "1232                                  [df.reindex_axis]  \n",
       "1238                                                 []  \n",
       "...                                                 ...  \n",
       "2856                 [pd.DataFrame, df.drop_duplicates]  \n",
       "2859                  [df3.index.duplicated, df3.index]  \n",
       "2951                                      [df.read_csv]  \n",
       "3060  [df.str.split, pd.DataFrame, df.str.split, pd....  \n",
       "3186  [df.loc, df.loc, df.loc, df.loc, df.loc, df.lo...  \n",
       "\n",
       "[111 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair_df_after_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_text(df, columns):\n",
    "    for col in columns:\n",
    "        list_ = df[col]\n",
    "        df[col] = \" \".join(list_)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['all_calls', 'h1_filtered_calls', 'h2_filtered_calls', 'h1h2_filtered_calls', 'm1_filtered_calls']\n",
    "title_codeElement_pair = title_codeElement_pair_df_after_m1.apply(list_to_text, args=(list_columns,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_rake</th>\n",
       "      <th>all_calls</th>\n",
       "      <th>h1_filtered_calls</th>\n",
       "      <th>h2_filtered_calls</th>\n",
       "      <th>h1h2_filtered_calls</th>\n",
       "      <th>m1_filtered_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>panda datafram find row valu column maxim</td>\n",
       "      <td>You just need the argmax() (now called idxmax)...</td>\n",
       "      <td>go drop mani hour worth system suddenli get us...</td>\n",
       "      <td>pandas.DataFrame df.argmax df.argmax df.argmax...</td>\n",
       "      <td>pandas.DataFrame df.argmax df.argmax df.argmax...</td>\n",
       "      <td>df.argmax df.argmax df.argmax dfrm.idxmax dfrm...</td>\n",
       "      <td>df.argmax df.argmax df.argmax dfrm.idxmax dfrm...</td>\n",
       "      <td>pandas.DataFrame df.argmax df.argmax df.argmax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>convert panda groupbi object datafram</td>\n",
       "      <td>g1 here is a DataFrame. It has a hierarchical ...</td>\n",
       "      <td>want someth like someth like hierarch index th...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "      <td>g1.index g1.add_suffix.reset_index df1.groupby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>redefin index panda datafram object</td>\n",
       "      <td>Why don't you simply use set_index method?\\n\\n</td>\n",
       "      <td>simpli use method</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "      <td>data.set_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>python panda column datafram base column name</td>\n",
       "      <td>\\nThis assumes that sorting the column names w...</td>\n",
       "      <td>want column column name sort lexicograph sort ...</td>\n",
       "      <td>df.reindex_axis df.columns</td>\n",
       "      <td>df.reindex_axis</td>\n",
       "      <td>df.reindex_axis df.columns</td>\n",
       "      <td>df.reindex_axis</td>\n",
       "      <td>df.reindex_axis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>databas like mysql</td>\n",
       "      <td>As Wes says, io/sql's read_sql will do it, onc...</td>\n",
       "      <td>two short exampl use databas connect use dbi c...</td>\n",
       "      <td>cx_Oracle.connect pd.read_sql ora_conn.close M...</td>\n",
       "      <td>pd.read_sql pd.read_sql</td>\n",
       "      <td>cx_Oracle.connect pd.read_sql ora_conn.close M...</td>\n",
       "      <td>pd.read_sql pd.read_sql</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>drop duplic row python panda</td>\n",
       "      <td>This is much easier in pandas now with drop_du...</td>\n",
       "      <td>much easier keep paramet panda</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "      <td>df.drop_duplicates</td>\n",
       "      <td>df.drop_duplicates</td>\n",
       "      <td>pd.DataFrame df.drop_duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>remov row duplic indic panda datafram timeseri</td>\n",
       "      <td>I would suggest using the duplicated method on...</td>\n",
       "      <td>current accept answer slightli less perform sa...</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "      <td>df3.index.duplicated df3.index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>remov index column panda</td>\n",
       "      <td>When reading to and from your csv file include...</td>\n",
       "      <td>csv file includ argument index csv read read p...</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "      <td>df.read_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>how split column two column</td>\n",
       "      <td>TL;DR version:\\nFor the simple case of:\\n\\nI h...</td>\n",
       "      <td>python tupl unpack first two paramet plain pyt...</td>\n",
       "      <td>df.str.split.str df.str.split.str df.str.split...</td>\n",
       "      <td>df.str.split pd.DataFrame df.str.split pd.Data...</td>\n",
       "      <td>df.str.split.str df.str.split.str df.str.split...</td>\n",
       "      <td>df.str.split df.str.split upper_lower_df.str.l...</td>\n",
       "      <td>df.str.split pd.DataFrame df.str.split pd.Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>how take datafram panda</td>\n",
       "      <td>2017 Answer - pandas 0.20: .ix is deprecated. ...</td>\n",
       "      <td>loc use label base index loc see loc includ lo...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "      <td>df.loc df.loc df.loc df.loc df.loc df.loc df.l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1209       panda datafram find row valu column maxim   \n",
       "1211           convert panda groupbi object datafram   \n",
       "1213             redefin index panda datafram object   \n",
       "1232   python panda column datafram base column name   \n",
       "1238                              databas like mysql   \n",
       "...                                              ...   \n",
       "2856                    drop duplic row python panda   \n",
       "2859  remov row duplic indic panda datafram timeseri   \n",
       "2951                        remov index column panda   \n",
       "3060                     how split column two column   \n",
       "3186                         how take datafram panda   \n",
       "\n",
       "                                              body_text  \\\n",
       "1209  You just need the argmax() (now called idxmax)...   \n",
       "1211  g1 here is a DataFrame. It has a hierarchical ...   \n",
       "1213     Why don't you simply use set_index method?\\n\\n   \n",
       "1232  \\nThis assumes that sorting the column names w...   \n",
       "1238  As Wes says, io/sql's read_sql will do it, onc...   \n",
       "...                                                 ...   \n",
       "2856  This is much easier in pandas now with drop_du...   \n",
       "2859  I would suggest using the duplicated method on...   \n",
       "2951  When reading to and from your csv file include...   \n",
       "3060  TL;DR version:\\nFor the simple case of:\\n\\nI h...   \n",
       "3186  2017 Answer - pandas 0.20: .ix is deprecated. ...   \n",
       "\n",
       "                                         body_text_rake  \\\n",
       "1209  go drop mani hour worth system suddenli get us...   \n",
       "1211  want someth like someth like hierarch index th...   \n",
       "1213                                  simpli use method   \n",
       "1232  want column column name sort lexicograph sort ...   \n",
       "1238  two short exampl use databas connect use dbi c...   \n",
       "...                                                 ...   \n",
       "2856                     much easier keep paramet panda   \n",
       "2859  current accept answer slightli less perform sa...   \n",
       "2951  csv file includ argument index csv read read p...   \n",
       "3060  python tupl unpack first two paramet plain pyt...   \n",
       "3186  loc use label base index loc see loc includ lo...   \n",
       "\n",
       "                                              all_calls  \\\n",
       "1209  pandas.DataFrame df.argmax df.argmax df.argmax...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                         df.reindex_axis df.columns   \n",
       "1238  cx_Oracle.connect pd.read_sql ora_conn.close M...   \n",
       "...                                                 ...   \n",
       "2856                    pd.DataFrame df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split.str df.str.split.str df.str.split...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      h1_filtered_calls  \\\n",
       "1209  pandas.DataFrame df.argmax df.argmax df.argmax...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                                    df.reindex_axis   \n",
       "1238                            pd.read_sql pd.read_sql   \n",
       "...                                                 ...   \n",
       "2856                    pd.DataFrame df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split pd.DataFrame df.str.split pd.Data...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      h2_filtered_calls  \\\n",
       "1209  df.argmax df.argmax df.argmax dfrm.idxmax dfrm...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                         df.reindex_axis df.columns   \n",
       "1238  cx_Oracle.connect pd.read_sql ora_conn.close M...   \n",
       "...                                                 ...   \n",
       "2856                                 df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split.str df.str.split.str df.str.split...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                    h1h2_filtered_calls  \\\n",
       "1209  df.argmax df.argmax df.argmax dfrm.idxmax dfrm...   \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...   \n",
       "1213                                     data.set_index   \n",
       "1232                                    df.reindex_axis   \n",
       "1238                            pd.read_sql pd.read_sql   \n",
       "...                                                 ...   \n",
       "2856                                 df.drop_duplicates   \n",
       "2859                     df3.index.duplicated df3.index   \n",
       "2951                                        df.read_csv   \n",
       "3060  df.str.split df.str.split upper_lower_df.str.l...   \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...   \n",
       "\n",
       "                                      m1_filtered_calls  \n",
       "1209  pandas.DataFrame df.argmax df.argmax df.argmax...  \n",
       "1211  g1.index g1.add_suffix.reset_index df1.groupby...  \n",
       "1213                                     data.set_index  \n",
       "1232                                    df.reindex_axis  \n",
       "1238                                                     \n",
       "...                                                 ...  \n",
       "2856                    pd.DataFrame df.drop_duplicates  \n",
       "2859                     df3.index.duplicated df3.index  \n",
       "2951                                        df.read_csv  \n",
       "3060  df.str.split pd.DataFrame df.str.split pd.Data...  \n",
       "3186  df.loc df.loc df.loc df.loc df.loc df.loc df.l...  \n",
       "\n",
       "[111 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'body_text', 'body_text_rake', 'all_calls',\n",
       "       'h1_filtered_calls', 'h2_filtered_calls', 'h1h2_filtered_calls',\n",
       "       'm1_filtered_calls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_codeElement_pair.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(title_codeElement_pair)) < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "train = title_codeElement_pair[msk]\n",
    "test = title_codeElement_pair[~msk]\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('corpus/title_train.en', columns = ['title'], index=False, header=False)\n",
    "train.to_csv('corpus/body_text_train.en', columns = ['body_text'], index=False, header=False)\n",
    "train.to_csv('corpus/body_text_rake_train.en', columns = ['body_text_rake'], index=False, header=False)\n",
    "train.to_csv('corpus/all_calls_code_train.cd', columns = ['all_calls'], index=False, header=False)\n",
    "train.to_csv('corpus/h1_filtered_calls_code_train.cd', columns = ['h1_filtered_calls'], index=False, header=False)\n",
    "train.to_csv('corpus/h2_filtered_calls_code_train.cd', columns = ['h2_filtered_calls'], index=False, header=False)\n",
    "train.to_csv('corpus/h1h2_filtered_calls_code_train.cd', columns = ['h1h2_filtered_calls'], index=False, header=False)\n",
    "train.to_csv('corpus/m1_filtered_calls_code_train.cd', columns = ['m1_filtered_calls'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('corpus/title_test.en', columns = ['title'], index=False, header=False)\n",
    "test.to_csv('corpus/body_text_test.en', columns = ['body_text'], index=False, header=False)\n",
    "test.to_csv('corpus/body_text_rake_test.en', columns = ['body_text_rake'], index=False, header=False)\n",
    "test.to_csv('corpus/all_calls_code_test.cd', columns = ['all_calls'], index=False, header=False)\n",
    "test.to_csv('corpus/h1_filtered_calls_code_test.cd', columns = ['h1_filtered_calls'], index=False, header=False)\n",
    "test.to_csv('corpus/h2_filtered_calls_code_test.cd', columns = ['h2_filtered_calls'], index=False, header=False)\n",
    "test.to_csv('corpus/h1h2_filtered_calls_code_test.cd', columns = ['h1h2_filtered_calls'], index=False, header=False)\n",
    "test.to_csv('corpus/m1_filtered_calls_code_test.cd', columns = ['m1_filtered_calls'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_codeElement_pair.to_csv('corpus/title.txt', columns = ['title'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/body_text.txt', columns = ['body_text'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/body_text_rake.txt', columns = ['body_text_rake'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/all_calls_code.txt', columns = ['all_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h1_filtered_calls_code.txt', columns = ['h1_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h2_filtered_calls_code.txt', columns = ['h2_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/h1h2_filtered_calls_code.txt', columns = ['h1h2_filtered_calls'], index=False, header=False)\n",
    "title_codeElement_pair.to_csv('corpus/m1_filtered_calls_code.txt', columns = ['m1_filtered_calls'], index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
