AnswerId,preprocessed_code,h1,h2,h1h2,m1tfidf,m1doc2vec
7779260,,[],[''],[],[],[]
7837947,"pct_change = close[1:]/close[:-1]
pct_change = []
for row in close:
    pct_change.append(...)",['    pct_change.append(...)'],"['pct_change = close[1:]/close[:-1]', 'pct_change = []', 'for row in close:', '    pct_change.append(...)']",['    pct_change.append(...)'],,
7849789,"for date, row in df.T.iteritems():
    n = len(dates)","['for date, row in df.T.iteritems():']","['for date, row in df.T.iteritems():', '    n = len(dates)']","['for date, row in df.T.iteritems():']",,
8916746,"df
df[(df.values > 1.5).any(1)]
df[(df['A'] > 1) | (df['B'] < -1)]",['df[(df.values > 1.5).any(1)]'],"['df', 'df[(df.values > 1.5).any(1)]', ""df[(df['A'] > 1) | (df['B'] < -1)]""]",['df[(df.values > 1.5).any(1)]'],,
8992714,,[],[''],[],[],[]
8997908,,[],[''],[],[],[]
9555766,,[],[''],[],[],[]
9557319,,[],[''],[],[],[]
9558852,,[],[''],[],[],[]
9577305,,[],[''],[],[],[]
9620832,"category,value
AB,100.00
AB,200.00
AC,150.00
AD,500.00
import pandas
data_2010 = pandas.read_csv(""/path/to/2010.csv"")
data_2010.groupby(""category"").agg([len, sum])
category            ","['data_2010 = pandas.read_csv(""/path/to/2010.csv"")', 'data_2010.groupby(""category"").agg([len, sum])']","['category,value', 'AB,100.00', 'AB,200.00', 'AC,150.00', 'AD,500.00', 'import pandas', 'data_2010 = pandas.read_csv(""/path/to/2010.csv"")', 'data_2010.groupby(""category"").agg([len, sum])', 'category            ']","['data_2010 = pandas.read_csv(""/path/to/2010.csv"")', 'data_2010.groupby(""category"").agg([len, sum])']",,
9623878,"df
df.pivot_table(rows='category', aggfunc=[len, np.sum])
df
df.pivot_table(rows='category', aggfunc=[len, np.sum])
category                              ","[""df.pivot_table(rows='category', aggfunc=[len, np.sum])"", ""df.pivot_table(rows='category', aggfunc=[len, np.sum])""]","['df', ""df.pivot_table(rows='category', aggfunc=[len, np.sum])"", 'df', ""df.pivot_table(rows='category', aggfunc=[len, np.sum])"", 'category                              ']","[""df.pivot_table(rows='category', aggfunc=[len, np.sum])"", ""df.pivot_table(rows='category', aggfunc=[len, np.sum])""]",,
9652858,"DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\t')
DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\t', header=0)","[""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t')"", ""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t', header=0)""]","[""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t')"", ""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t', header=0)""]","[""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t')"", ""DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\t', header=0)""]",,
9656288,,[],[''],[],[],[]
9677723,,[],[''],[],[],[]
9762084,"subset = data_set[['data_date', 'data_1', 'data_2']]
tuples = [tuple(x) for x in subset.values]",['tuples = [tuple(x) for x in subset.values]'],"[""subset = data_set[['data_date', 'data_1', 'data_2']]"", 'tuples = [tuple(x) for x in subset.values]']",['tuples = [tuple(x) for x in subset.values]'],,
9772031,,[],[''],[],[],[]
9794891,"df2
df1
df2.comb
df2.combine_first(df1)",['df2.combine_first(df1)'],"['df2', 'df1', 'df2.comb', 'df2.combine_first(df1)']",['df2.combine_first(df1)'],,
10114652,"right
merge(left, right)
merge(left, right, on='ST_NAME', sort=False)",[],"['right', 'merge(left, right)', ""merge(left, right, on='ST_NAME', sort=False)""]",[],[],[]
10182172,import pandas,[],['import pandas'],[],[],[]
10202789,"import pandas
import numpy as np
df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])
df
df['A'].argmax()
3
df['B'].argmax()
4
df['C'].argmax()
1
dfrm
dfrm['A'].idxmax()
dfrm.ix[dfrm['A'].idxmax()]","[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","['import pandas', 'import numpy as np', 'df', ""df['A'].argmax()"", '3', ""df['B'].argmax()"", '4', ""df['C'].argmax()"", '1', 'dfrm', ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]"
10213167,"df = pandas.DataFrame(np.random.randn(10,3),columns=['A','B','C'])
df
df.idxmax()
df.ix[df['A'].idxmax()]","[""df = pandas.DataFrame(np.random.randn(10,3),columns=['A','B','C'])"", 'df.idxmax()', ""df.ix[df['A'].idxmax()]""]","['df', 'df.idxmax()', ""df.ix[df['A'].idxmax()]""]","['df.idxmax()', ""df.ix[df['A'].idxmax()]""]",,
10374456,"type(g1)
g1.index
g1.add_suffix('_Count').reset_index()
DataFrame({'count' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['type(g1)', 'g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']"
10377863,,[],[''],[],[],[]
10458386,"In : col = ['a','b','c']
In : data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)
In : data
In : data2 = data.set_index('a')
In : data2
a","[""In : data2 = data.set_index('a')""]","[""In : col = ['a','b','c']"", 'In : data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)', 'In : data', ""In : data2 = data.set_index('a')"", 'In : data2', 'a']","[""In : data2 = data.set_index('a')""]","[""In : data2 = data.set_index('a')""]","[""In : data2 = data.set_index('a')""]"
10465162,"In : df = pandas.DataFrame(numpy.random.randn(5,3), index=['a','c','d','e','g'])
In : df
In : df2 = df.reindex(['a','b','c','d','e','f','g'])
In : df2
In : df2.apply(pandas.Series.interpolate)","[""In : df = pandas.DataFrame(numpy.random.randn(5,3), index=['a','c','d','e','g'])"", ""In : df2 = df.reindex(['a','b','c','d','e','f','g'])"", 'In : df2.apply(pandas.Series.interpolate)']","['In : df', ""In : df2 = df.reindex(['a','b','c','d','e','f','g'])"", 'In : df2']","[""In : df2 = df.reindex(['a','b','c','d','e','f','g'])"", 'In : df2.apply(pandas.Series.interpolate)']",,
10511230,plt.show(),[],['plt.show()'],[],[],[]
10511545,,[],[''],[],[],[]
10565742,"from datetime import datetime as dt
dr = p.DateRange(dt(2009,1,1),dt(2010,12,31), offset=p.datetools.Hour())
hr = dr.map(lambda x: x.hour)
dt = p.DataFrame(rand(len(dr),2), dr)
dt 
dt[(hr >= 10) & (hr <=16)]
dtypes: float64(2)","['hr = dr.map(lambda x: x.hour)', 'dt = p.DataFrame(rand(len(dr),2), dr)']","['from datetime import datetime as dt', 'dr = p.DateRange(dt(2009,1,1),dt(2010,12,31), offset=p.datetools.Hour())', 'hr = dr.map(lambda x: x.hour)', 'dt ', 'dt[(hr >= 10) & (hr <=16)]', 'dtypes: float64(2)']",['hr = dr.map(lambda x: x.hour)'],,
10567298,"hour = ts.index.hour
selector = ((10 <= hour) & (hour <= 13)) | ((20 <= hour) & (hour <= 23))
data = ts[selector]",['hour = ts.index.hour'],"['hour = ts.index.hour', 'selector = ((10 <= hour) & (hour <= 13)) | ((20 <= hour) & (hour <= 23))', 'data = ts[selector]']",['hour = ts.index.hour'],,
10666301,"data = pandas.DataFrame(np.random.rand(10,5), columns = list('abcde'))
data_ab = data[list('ab')]
data_cde = data[list('cde')]","[""data = pandas.DataFrame(np.random.rand(10,5), columns = list('abcde'))""]","[""data_ab = data[list('ab')]"", ""data_cde = data[list('cde')]""]",[],,
10677896,"df = DataFrame(np.random.rand(4,5), columns = list('abcde'))
df.ix[:,'b':]",[],"[""df = DataFrame(np.random.rand(4,5), columns = list('abcde'))"", ""df.ix[:,'b':]""]",[],[],[]
10716007,,[],[''],[],[],[]
10726275,"df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])","[""df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])""]","[""df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])""]","[""df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])""]",,
10739432,,[],[''],[],[],[]
10762516,"return pandas.Series({'pvalue': pvalue, 'mean_ratio': mean_ratio})","[""return pandas.Series({'pvalue': pvalue, 'mean_ratio': mean_ratio})""]",[],[],,
10781413,df.phone = df.phone.astype(str),['df.phone = df.phone.astype(str)'],['df.phone = df.phone.astype(str)'],['df.phone = df.phone.astype(str)'],,
10859883,"Definition: DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None)
Parameters
axis : {0, 1}
how : {'any', 'all'}
subset : array-like
Returns
dropped : DataFrame
df=df.dropna(axis=1,how='all')","[""Definition: DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None)"", ""df=df.dropna(axis=1,how='all')""]","[""Definition: DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None)"", 'Parameters', 'axis : {0, 1}', ""how : {'any', 'all'}"", 'subset : array-like', 'Returns', 'dropped : DataFrame', ""df=df.dropna(axis=1,how='all')""]","[""Definition: DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None)"", ""df=df.dropna(axis=1,how='all')""]",,
10943545,,[],[''],[],[],[]
10964938,"grouped = df.groupby(keys)
def wavg(group):
    d = group['data']
    w = group['weights']
    return (d * w).sum() / w.sum()
grouped.apply(wavg)","['grouped = df.groupby(keys)', '    return (d * w).sum() / w.sum()', 'grouped.apply(wavg)']","['grouped = df.groupby(keys)', 'def wavg(group):', ""    d = group['data']"", ""    w = group['weights']"", '    return (d * w).sum() / w.sum()', 'grouped.apply(wavg)']","['grouped = df.groupby(keys)', '    return (d * w).sum() / w.sum()', 'grouped.apply(wavg)']",,
10972557,"pandas.concat([df['foo'].dropna(), df['bar'].dropna()]).reindex_like(df)","[""pandas.concat([df['foo'].dropna(), df['bar'].dropna()]).reindex_like(df)""]","[""pandas.concat([df['foo'].dropna(), df['bar'].dropna()]).reindex_like(df)""]","[""pandas.concat([df['foo'].dropna(), df['bar'].dropna()]).reindex_like(df)""]",,
10982198,"a
a.x2 = a.x2.shift(1)
a",['a.x2 = a.x2.shift(1)'],"['a', 'a.x2 = a.x2.shift(1)', 'a']",['a.x2 = a.x2.shift(1)'],,
11005208,,[],[''],[],[],[]
11067072,"df.reindex_axis(sorted(df.columns), axis=1)","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']"
11073962,"df.groupby(df.index.map(lambda t: t.minute))
df.groupby([df.index.map(lambda t: t.minute), 'Source'])
df.groupby([df['Source'],pd.TimeGrouper(freq='Min')])","['df.groupby(df.index.map(lambda t: t.minute))', ""df.groupby([df.index.map(lambda t: t.minute), 'Source'])"", ""df.groupby([df['Source'],pd.TimeGrouper(freq='Min')])""]","['df.groupby(df.index.map(lambda t: t.minute))', ""df.groupby([df.index.map(lambda t: t.minute), 'Source'])"", ""df.groupby([df['Source'],pd.TimeGrouper(freq='Min')])""]","['df.groupby(df.index.map(lambda t: t.minute))', ""df.groupby([df.index.map(lambda t: t.minute), 'Source'])"", ""df.groupby([df['Source'],pd.TimeGrouper(freq='Min')])""]",,
11077060,,[],[''],[],[],[]
11077215,,[],[''],[],[],[]
11107627,"(x.reindex_like(y).fillna(0) + y.fillna(0)).fillna(0)
x
y",['(x.reindex_like(y).fillna(0) + y.fillna(0)).fillna(0)'],"['(x.reindex_like(y).fillna(0) + y.fillna(0)).fillna(0)', 'x', 'y']",['(x.reindex_like(y).fillna(0) + y.fillna(0)).fillna(0)'],,
11112419,"import pandas as pd
df1 = pd.DataFrame([(1,2),(3,4),(5,6)], columns=['a','b'])
df2 = pd.DataFrame([(100,200),(300,400),(500,600)], columns=['a','b'])
df_add = df1.add(df2, fill_value=0)","[""df1 = pd.DataFrame([(1,2),(3,4),(5,6)], columns=['a','b'])"", ""df2 = pd.DataFrame([(100,200),(300,400),(500,600)], columns=['a','b'])"", 'df_add = df1.add(df2, fill_value=0)']","['import pandas as pd', 'df_add = df1.add(df2, fill_value=0)']","['df_add = df1.add(df2, fill_value=0)']",,
11138275,"import pandas as pd
import cx_Oracle
ora_conn = cx_Oracle.connect('your_connection_string')
df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    
ora_conn.close()
import MySQLdb
mysql_cn= MySQLdb.connect(host='myhost', 
                port=3306,user='myusername', passwd='mypassword', 
                db='information_schema')
df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    
mysql_cn.close()","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","['import pandas as pd', 'import cx_Oracle', ""ora_conn = cx_Oracle.connect('your_connection_string')"", ""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", 'ora_conn.close()', 'import MySQLdb', ""mysql_cn= MySQLdb.connect(host='myhost', "", ""                port=3306,user='myusername', passwd='mypassword', "", ""                db='information_schema')"", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    "", 'mysql_cn.close()']","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]"
11287278,"df1 = df[['a','b']]
df1 = df.ix[:,0:2] 
df1 = df.ix[0,0:2].copy() ","['df1 = df.ix[0,0:2].copy() ']","[""df1 = df[['a','b']]"", 'df1 = df.ix[:,0:2] ', 'df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']"
11346337,"df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})
df.columns = ['a', 'b']
df","[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]","[""df.columns = ['a', 'b']"", 'df']",[],"[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]","[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]"
11354850,"df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})
OR
df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", 'OR', ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]"
11362056,"paramdata.columns
paramdata.index",['paramdata.index'],"['paramdata.columns', 'paramdata.index']",['paramdata.index'],['paramdata.index'],['paramdata.index']
11366429,,[],[''],[],[],[]
11366706,"def stringSearchColumn_DataFrame(df, colName, regex):
    newdf = DataFrame()
    for idx, record in df[colName].iteritems():
        if re.search(regex, record):
            newdf = concat([df[df[colName] == record], newdf], ignore_index=True)
    return newdf","['    for idx, record in df[colName].iteritems():']","['def stringSearchColumn_DataFrame(df, colName, regex):', '    newdf = DataFrame()', '    for idx, record in df[colName].iteritems():', '        if re.search(regex, record):', '            newdf = concat([df[df[colName] == record], newdf], ignore_index=True)', '    return newdf']","['    for idx, record in df[colName].iteritems():']",,
11384667,"ax = x.plot(kind='bar', legend=False)
patches, labels = ax.get_legend_handles_labels()
ax.legend(patches, labels, loc='best')","[""ax = x.plot(kind='bar', legend=False)""]","[""ax = x.plot(kind='bar', legend=False)"", 'patches, labels = ax.get_legend_handles_labels()', ""ax.legend(patches, labels, loc='best')""]","[""ax = x.plot(kind='bar', legend=False)""]",,
11385335,"df
df1 = df[['b', 'c']]
df1",[],"['df', ""df1 = df[['b', 'c']]"", 'df1']",[],[],[]
11385780,,[],[''],[],[],[]
11395193,data.groupby(lambda x: data['date'][x].year),"[""data.groupby(lambda x: data['date'][x].year)""]","[""data.groupby(lambda x: data['date'][x].year)""]","[""data.groupby(lambda x: data['date'][x].year)""]",,
11397052,data.groupby(data['date'].map(lambda x: x.year)),"[""data.groupby(data['date'].map(lambda x: x.year))""]","[""data.groupby(data['date'].map(lambda x: x.year))""]","[""data.groupby(data['date'].map(lambda x: x.year))""]",,
11415882,"pandas.DataFrame(initialload, columns=list_of_column_names)","['pandas.DataFrame(initialload, columns=list_of_column_names)']",[],[],,
11420594,"df
mask = (np.sin(df.velocity) / df.ix[:, 0:2].prod(axis=1)) > 0
mask
df[mask]","['mask = (np.sin(df.velocity) / df.ix[:, 0:2].prod(axis=1)) > 0']","['df', 'mask = (np.sin(df.velocity) / df.ix[:, 0:2].prod(axis=1)) > 0', 'mask', 'df[mask]']","['mask = (np.sin(df.velocity) / df.ix[:, 0:2].prod(axis=1)) > 0']",,
11475486,"df = pandas.DataFrame(np.random.randn(5, 3), columns=['a', 'b', 'c'])
df
df[df.apply(lambda x: x['b'] > x['c'], axis=1)]","[""df = pandas.DataFrame(np.random.randn(5, 3), columns=['a', 'b', 'c'])"", ""df[df.apply(lambda x: x['b'] > x['c'], axis=1)]""]","['df', ""df[df.apply(lambda x: x['b'] > x['c'], axis=1)]""]","[""df[df.apply(lambda x: x['b'] > x['c'], axis=1)]""]",,
11495086,,[],[''],[],[],[]
11531402,"df[df['A'].str.contains(""hello"")]","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']"
11548224,,[],[''],[],[],[]
11589000,"for elem in dfrm['Category'].unique():
    dfrm[str(elem)] = dfrm['Category'] == elem
cat_names = {1:'Some_Treatment', 2:'Full_Treatment', 3:'Control'}
for elem in dfrm['Category'].unique():
    dfrm[cat_names[elem]] = dfrm['Category'] == elem","[""for elem in dfrm['Category'].unique():"", ""for elem in dfrm['Category'].unique():""]","[""for elem in dfrm['Category'].unique():"", ""    dfrm[str(elem)] = dfrm['Category'] == elem"", ""cat_names = {1:'Some_Treatment', 2:'Full_Treatment', 3:'Control'}"", ""for elem in dfrm['Category'].unique():"", ""    dfrm[cat_names[elem]] = dfrm['Category'] == elem""]","[""for elem in dfrm['Category'].unique():"", ""for elem in dfrm['Category'].unique():""]",,
11603242,"frame.resample('1H').agg({'radiation': np.sum, 'tamb': np.mean})
frame.resample('1H', how={'radiation': np.sum, 'tamb': np.mean})","[""frame.resample('1H').agg({'radiation': np.sum, 'tamb': np.mean})"", ""frame.resample('1H', how={'radiation': np.sum, 'tamb': np.mean})""]","[""frame.resample('1H').agg({'radiation': np.sum, 'tamb': np.mean})"", ""frame.resample('1H', how={'radiation': np.sum, 'tamb': np.mean})""]","[""frame.resample('1H').agg({'radiation': np.sum, 'tamb': np.mean})"", ""frame.resample('1H', how={'radiation': np.sum, 'tamb': np.mean})""]",,
11617194,,[],[''],[],[],[]
11617682,"from datetime import datetime
import pandas as pd
parse = lambda x: datetime.strptime(x, '%Y%m%d %H')
pd.read_csv(""..\\file.csv"",  parse_dates = [['YYYYMMDD', 'HH']], 
            index_col = 0, 
            date_parser=parse)","[""parse = lambda x: datetime.strptime(x, '%Y%m%d %H')"", 'pd.read_csv(""..\\\\file.csv"",  parse_dates = [[\'YYYYMMDD\', \'HH\']], ']","['from datetime import datetime', 'import pandas as pd', ""parse = lambda x: datetime.strptime(x, '%Y%m%d %H')"", 'pd.read_csv(""..\\\\file.csv"",  parse_dates = [[\'YYYYMMDD\', \'HH\']], ', '            index_col = 0, ', '            date_parser=parse)']","[""parse = lambda x: datetime.strptime(x, '%Y%m%d %H')"", 'pd.read_csv(""..\\\\file.csv"",  parse_dates = [[\'YYYYMMDD\', \'HH\']], ']",,
11622769,,[],[''],[],[],[]
11637456,3 -0.876146 -1.955199 -0.155030,[],['3 -0.876146 -1.955199 -0.155030'],[],[],[]
11639358,"left
right
left.join(right)",['left.join(right)'],"['left', 'right', 'left.join(right)']",['left.join(right)'],,
11643893,"import matplotlib.pyplot as plt
import numpy as np
from pandas import DataFrame
df = DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])
fig, ax = plt.subplots()
ax2, ax3 = ax.twinx(), ax.twinx()
rspine = ax3.spines['right']
rspine.set_position(('axes', 1.25))
ax3.set_frame_on(True)
ax3.patch.set_visible(False)
fig.subplots_adjust(right=0.75)
df.A.plot(ax=ax, style='b-')
df.B.plot(ax=ax2, style='r-', secondary_y=True)
df.C.plot(ax=ax3, style='g-')","[""df.A.plot(ax=ax, style='b-')"", ""df.B.plot(ax=ax2, style='r-', secondary_y=True)"", ""df.C.plot(ax=ax3, style='g-')""]","['import matplotlib.pyplot as plt', 'import numpy as np', 'from pandas import DataFrame', ""df = DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])"", 'fig, ax = plt.subplots()', 'ax2, ax3 = ax.twinx(), ax.twinx()', ""rspine = ax3.spines['right']"", ""rspine.set_position(('axes', 1.25))"", 'ax3.set_frame_on(True)', 'ax3.patch.set_visible(False)', 'fig.subplots_adjust(right=0.75)', ""df.A.plot(ax=ax, style='b-')"", ""df.B.plot(ax=ax2, style='r-', secondary_y=True)"", ""df.C.plot(ax=ax3, style='g-')""]","[""df.A.plot(ax=ax, style='b-')"", ""df.B.plot(ax=ax2, style='r-', secondary_y=True)"", ""df.C.plot(ax=ax3, style='g-')""]",,
11706782,,[],[''],[],[],[]
11707706,,[],[''],[],[],[]
11708610,,[],[''],[],[],[]
11708664,"df.describe()
pd.set_printoptions(precision=2)
df.describe()
df.describe()
pd.set_option('display.precision', 2)
df.describe()","['df.describe()', 'df.describe()', 'df.describe()', ""pd.set_option('display.precision', 2)"", 'df.describe()']","['df.describe()', 'pd.set_printoptions(precision=2)', 'df.describe()', 'df.describe()', ""pd.set_option('display.precision', 2)"", 'df.describe()']","['df.describe()', 'df.describe()', 'df.describe()', ""pd.set_option('display.precision', 2)"", 'df.describe()']",,
11711637,"import pandas as pd
pd.set_option('display.height', 1000)
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
Parameters
Returns
None
Raises
float or None
boolean
boolean
str/unicode
boolean
callable
int
int
int
int
int
int or None
int
int or None
bool
boolean
boolean
int
int
int
boolean
boolean","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","['import pandas as pd', ""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)"", 'Parameters', 'Returns', 'None', 'Raises', 'float or None', 'boolean', 'boolean', 'str/unicode', 'boolean', 'callable', 'int', 'int', 'int', 'int', 'int', 'int or None', 'int', 'int or None', 'bool', 'boolean', 'boolean', 'int', 'int', 'int', 'boolean', 'boolean']","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]"
11811425,,[],[''],[],[],[]
11856979,"df.set_index(['d'], append=True)","[""df.set_index(['d'], append=True)""]","[""df.set_index(['d'], append=True)""]","[""df.set_index(['d'], append=True)""]",,
11858532,,[],[''],[],[],[]
11872393,"df
df[(df.A == 1) & (df.D == 6)]",[],"['df', 'df[(df.A == 1) & (df.D == 6)]']",[],[],[]
11874590,"df.apply(lambda x:'%s is %s' % (x['bar'],x['foo']),axis=1)","[""df.apply(lambda x:'%s is %s' % (x['bar'],x['foo']),axis=1)""]","[""df.apply(lambda x:'%s is %s' % (x['bar'],x['foo']),axis=1)""]","[""df.apply(lambda x:'%s is %s' % (x['bar'],x['foo']),axis=1)""]",,
11882354,"df
rows
df.drop(rows)
df[~((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]
df.ix[rows]
df[((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]",['df.drop(rows)'],"['df', 'rows', 'df.drop(rows)', 'df[~((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]', 'df.ix[rows]', 'df[((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]']",['df.drop(rows)'],,
11893375,"def mask(df, f):
  return df[f(df)]
df.mask(lambda x: x[0] < 0).mask(lambda x: x[1] > 0)",['df.mask(lambda x: x[0] < 0).mask(lambda x: x[1] > 0)'],"['def mask(df, f):', '  return df[f(df)]', 'df.mask(lambda x: x[0] < 0).mask(lambda x: x[1] > 0)']",['df.mask(lambda x: x[0] < 0).mask(lambda x: x[1] > 0)'],,
11927922,"from matplotlib import pyplot as plt
from itertools import cycle, islice
import pandas, numpy as np  
x = [{i:np.random.randint(1,5)} for i in range(10)]
df = pandas.DataFrame(x)
my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(df)))
df.plot(kind='bar', stacked=True, color=my_colors)
my_colors = ['g', 'b']*5 
my_colors = [(0.5,0.4,0.5), (0.75, 0.75, 0.25)]*5 
my_colors = [(x/10.0, x/20.0, 0.75) for x in range(len(df))] ","['df = pandas.DataFrame(x)', ""df.plot(kind='bar', stacked=True, color=my_colors)""]","['from matplotlib import pyplot as plt', 'from itertools import cycle, islice', 'import pandas, numpy as np  ', 'x = [{i:np.random.randint(1,5)} for i in range(10)]', ""my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(df)))"", ""df.plot(kind='bar', stacked=True, color=my_colors)"", ""my_colors = ['g', 'b']*5 "", 'my_colors = [(0.5,0.4,0.5), (0.75, 0.75, 0.25)]*5 ', 'my_colors = [(x/10.0, x/20.0, 0.75) for x in range(len(df))] ']","[""df.plot(kind='bar', stacked=True, color=my_colors)""]",,
11941772,"df.ix['a']
df.ix['a'].ix['c']
df.swaplevel(0,1).ix['c']","[""df.swaplevel(0,1).ix['c']""]","[""df.ix['a']"", ""df.ix['a'].ix['c']"", ""df.swaplevel(0,1).ix['c']""]","[""df.swaplevel(0,1).ix['c']""]",,
11942697,"df.xs('a', level=0)
df.xs('c', level='group2')
group1                ","[""df.xs('a', level=0)"", ""df.xs('c', level='group2')""]","[""df.xs('a', level=0)"", ""df.xs('c', level='group2')"", 'group1                ']","[""df.xs('a', level=0)"", ""df.xs('c', level='group2')""]",,
11982843,"a.reset_index().merge(b, how=""left"").set_index('index')
index","['a.reset_index().merge(b, how=""left"").set_index(\'index\')']","['a.reset_index().merge(b, how=""left"").set_index(\'index\')', 'index']","['a.reset_index().merge(b, how=""left"").set_index(\'index\')']",,
12022003,df2 = df.head(10),['df2 = df.head(10)'],['df2 = df.head(10)'],['df2 = df.head(10)'],,
12022047,"data = read_table('sample.txt', skiprows=3, header=None, sep=r""\s*"")
data
data.ix[:,20:]",[],"['data = read_table(\'sample.txt\', skiprows=3, header=None, sep=r""\\s*"")', 'data', 'data.ix[:,20:]']",[],[],[]
12025395,,[],[''],[],[],[]
12036847,"df  = read_csv(filename, index_col = 0,header = 0)
self.datatable = QtGui.QTableWidget(parent=self)
self.datatable.setColumnCount(len(df.columns))
self.datatable.setRowCount(len(df.index))
for i in range(len(df.index)):
    for j in range(len(df.columns)):
        self.datatable.setItem(i,j,QtGui.QTableWidgetItem(str(df.iget_value(i, j))))","['self.datatable.setRowCount(len(df.index))', 'for i in range(len(df.index)):']","['df  = read_csv(filename, index_col = 0,header = 0)', 'self.datatable = QtGui.QTableWidget(parent=self)', 'self.datatable.setColumnCount(len(df.columns))', 'self.datatable.setRowCount(len(df.index))', 'for i in range(len(df.index)):', '    for j in range(len(df.columns)):', '        self.datatable.setItem(i,j,QtGui.QTableWidgetItem(str(df.iget_value(i, j))))']","['self.datatable.setRowCount(len(df.index))', 'for i in range(len(df.index)):']",,
12056933,"import decimal
import pydobc
import numpy as np
import pandas
cnn, cur = myConnectToDBfunction()
cmd = ""SELECT * FROM myTable""
cur.execute(cmd)
dataframe = __processCursor(cur, dataframe=True)
def __processCursor(cur, dataframe=False, index=None):
    datatypes = []
    colinfo = cur.description
    for col in colinfo:
        if col[1] == unicode:
            datatypes.append((col[0], 'U%d' % col[3]))
        elif col[1] == str:
            datatypes.append((col[0], 'S%d' % col[3]))
        elif col[1] in [float, decimal.Decimal]:
            datatypes.append((col[0], 'f4'))
        elif col[1] == datetime.datetime:
            datatypes.append((col[0], 'O4'))
        elif col[1] == int:
            datatypes.append((col[0], 'i4'))
    data = []
    for row in cur:
        data.append(tuple(row))
    array = np.array(data, dtype=datatypes)
    if dataframe:
        output = pandas.DataFrame.from_records(array)
        if index is not None:
            output = output.set_index(index)
    else:
        output = array
    return output","[""            datatypes.append((col[0], 'U%d' % col[3]))"", ""            datatypes.append((col[0], 'S%d' % col[3]))"", ""            datatypes.append((col[0], 'f4'))"", ""            datatypes.append((col[0], 'O4'))"", ""            datatypes.append((col[0], 'i4'))"", '        data.append(tuple(row))', '        output = pandas.DataFrame.from_records(array)', '            output = output.set_index(index)']","['import decimal', 'import pydobc', 'import numpy as np', 'import pandas', 'cnn, cur = myConnectToDBfunction()', 'cmd = ""SELECT * FROM myTable""', 'cur.execute(cmd)', 'dataframe = __processCursor(cur, dataframe=True)', 'def __processCursor(cur, dataframe=False, index=None):', '    datatypes = []', '    colinfo = cur.description', '    for col in colinfo:', '        if col[1] == unicode:', ""            datatypes.append((col[0], 'U%d' % col[3]))"", '        elif col[1] == str:', ""            datatypes.append((col[0], 'S%d' % col[3]))"", '        elif col[1] in [float, decimal.Decimal]:', ""            datatypes.append((col[0], 'f4'))"", '        elif col[1] == datetime.datetime:', ""            datatypes.append((col[0], 'O4'))"", '        elif col[1] == int:', ""            datatypes.append((col[0], 'i4'))"", '    data = []', '    for row in cur:', '        data.append(tuple(row))', '    array = np.array(data, dtype=datatypes)', '    if dataframe:', '        if index is not None:', '            output = output.set_index(index)', '    else:', '        output = array', '    return output']","[""            datatypes.append((col[0], 'U%d' % col[3]))"", ""            datatypes.append((col[0], 'S%d' % col[3]))"", ""            datatypes.append((col[0], 'f4'))"", ""            datatypes.append((col[0], 'O4'))"", ""            datatypes.append((col[0], 'i4'))"", '        data.append(tuple(row))', '        output = pandas.DataFrame.from_records(array)', '            output = output.set_index(index)']",,
12060886,"from pandas import DataFrame
df = DataFrame(resoverall.fetchall())
df.columns = resoverall.keys()",[],"['from pandas import DataFrame', 'df = DataFrame(resoverall.fetchall())', 'df.columns = resoverall.keys()']",[],[],[]
12065904,,[],[''],[],[],[]
12077782,,[],[''],[],[],[]
12098586,"df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})
df
df[df['A'].isin([3, 6])]","[""df[df['A'].isin([3, 6])]""]","[""df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})"", 'df', ""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]"
12100543,"M
M.ix[0]
M.ix[0,0]
M.ix[0,0] = 1.0
M
M.ix[(0,1),(0,1)] = 1
M
M.ix[""a"":""c"",""one""] = 2.0
M",[],"['M', 'M.ix[0]', 'M.ix[0,0]', 'M.ix[0,0] = 1.0', 'M', 'M.ix[(0,1),(0,1)] = 1', 'M', 'M.ix[""a"":""c"",""one""] = 2.0', 'M']",[],[],[]
12117333,"import numpy as np
import pandas
x = pandas.read_csv('weird.csv')
x.dtypes
datatypes = [('int_field','i4'),('floatlike','S10'),('strfield','S10')]
y_np = np.loadtxt('weird.csv', dtype=datatypes, delimiter=',', skiprows=1)
y_np
y_pandas = pandas.DataFrame.from_records(y_np)
y_pandas.dtypes","[""x = pandas.read_csv('weird.csv')"", 'x.dtypes', 'y_pandas = pandas.DataFrame.from_records(y_np)', 'y_pandas.dtypes']","['import numpy as np', 'import pandas', ""x = pandas.read_csv('weird.csv')"", 'x.dtypes', ""datatypes = [('int_field','i4'),('floatlike','S10'),('strfield','S10')]"", ""y_np = np.loadtxt('weird.csv', dtype=datatypes, delimiter=',', skiprows=1)"", 'y_np', 'y_pandas.dtypes']","[""x = pandas.read_csv('weird.csv')"", 'x.dtypes', 'y_pandas = pandas.DataFrame.from_records(y_np)', 'y_pandas.dtypes']",,
12133235,,[],[''],[],[],[]
12152759,"df = DataFrame({1: [2,3,4], 2: [3,4,5]})
df
df[2]
df[2].replace(4, 17)
df[2].replace(4, 17, inplace=True)
df
df[1]
df[1] == 4
df[1][df[1] == 4]
df[1][df[1] == 4] = 19
df","['df[2].replace(4, 17)', 'df[2].replace(4, 17, inplace=True)']","['df = DataFrame({1: [2,3,4], 2: [3,4,5]})', 'df', 'df[2]', 'df[2].replace(4, 17)', 'df[2].replace(4, 17, inplace=True)', 'df', 'df[1]', 'df[1] == 4', 'df[1][df[1] == 4]', 'df[1][df[1] == 4] = 19', 'df']","['df[2].replace(4, 17)', 'df[2].replace(4, 17, inplace=True)']",,
12169357,"import pandas as pd
df = pd.DataFrame({""A"": [1,2,3], ""B"": [-2, 8, 1]})
df
df[[""A"", ""B""]]
df[[""A"", ""B""]].max(axis=1)
df[""C""] = df[[""A"", ""B""]].max(axis=1)
df
df[""C""] = df.max(axis=1)","['df = pd.DataFrame({""A"": [1,2,3], ""B"": [-2, 8, 1]})', 'df[[""A"", ""B""]].max(axis=1)', 'df[""C""] = df[[""A"", ""B""]].max(axis=1)', 'df[""C""] = df.max(axis=1)']","['import pandas as pd', 'df', 'df[[""A"", ""B""]]', 'df[[""A"", ""B""]].max(axis=1)', 'df[""C""] = df[[""A"", ""B""]].max(axis=1)', 'df', 'df[""C""] = df.max(axis=1)']","['df[[""A"", ""B""]].max(axis=1)', 'df[""C""] = df[[""A"", ""B""]].max(axis=1)', 'df[""C""] = df.max(axis=1)']",,
12170403,"df['new_col'] = range(1, len(df) + 1)
df = df.reset_index()",['df = df.reset_index()'],"[""df['new_col'] = range(1, len(df) + 1)"", 'df = df.reset_index()']",['df = df.reset_index()'],,
12183507,"import functools
import operator
add_3 = functools.partial(operator.add,3)
add_3(2)
5
add_3(7)
10
my_series.apply((lambda x: your_func(a,b,c,d,...,x)))
my_series.apply(your_function, args=(2,3,4), extra_kw=1)","['add_3 = functools.partial(operator.add,3)', 'my_series.apply((lambda x: your_func(a,b,c,d,...,x)))', 'my_series.apply(your_function, args=(2,3,4), extra_kw=1)']","['import functools', 'import operator', 'add_3 = functools.partial(operator.add,3)', 'add_3(2)', '5', 'add_3(7)', '10', 'my_series.apply((lambda x: your_func(a,b,c,d,...,x)))', 'my_series.apply(your_function, args=(2,3,4), extra_kw=1)']","['add_3 = functools.partial(operator.add,3)', 'my_series.apply((lambda x: your_func(a,b,c,d,...,x)))', 'my_series.apply(your_function, args=(2,3,4), extra_kw=1)']",,
12184679,,[],[''],[],[],[]
12192021,"import pandas
import random
df = pandas.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))
rows = random.sample(df.index, 10)
df_10 = df.ix[rows]
df_90 = df.drop(rows)","[""df = pandas.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))"", 'rows = random.sample(df.index, 10)', 'df_90 = df.drop(rows)']","['import pandas', 'import random', 'rows = random.sample(df.index, 10)', 'df_10 = df.ix[rows]', 'df_90 = df.drop(rows)']","['rows = random.sample(df.index, 10)', 'df_90 = df.drop(rows)']",,
12193309,"from pandas import *
tp = read_csv('large_dataset.csv', iterator=True, chunksize=1000)  
df = concat(tp, ignore_index=True)  ",[],"['from pandas import *', ""tp = read_csv('large_dataset.csv', iterator=True, chunksize=1000)  "", 'df = concat(tp, ignore_index=True)  ']",[],[],[]
12201723,"df = pandas.DataFrame({'month': np.random.randint(0,11, 100), 'A': np.random.randn(100), 'B': np.random.randn(100)})
df.join(df.groupby('month')['A'].sum(), on='month', rsuffix='_r')","[""df = pandas.DataFrame({'month': np.random.randint(0,11, 100), 'A': np.random.randn(100), 'B': np.random.randn(100)})"", ""df.join(df.groupby('month')['A'].sum(), on='month', rsuffix='_r')""]","[""df.join(df.groupby('month')['A'].sum(), on='month', rsuffix='_r')""]","[""df.join(df.groupby('month')['A'].sum(), on='month', rsuffix='_r')""]",,
12204428,"import pandas
A = pandas.DataFrame({
    'val' :  ['aaaaa', 'acaca', 'ddddd', 'zzzzz'],
    'extra' : range(10,14),
})
A = A.reset_index(drop=True)
A = A.reset_index(drop=True)
A = A.reset_index(drop=True)","['A = pandas.DataFrame({', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)']","['import pandas', ""    'val' :  ['aaaaa', 'acaca', 'ddddd', 'zzzzz'],"", ""    'extra' : range(10,14),"", '})', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)']","['A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)']",,
12207352,"import pandas
my_series = pandas.Series([1,2,2,3,3,3, ""fred"", 1.8, 1.8])
my_series
counts = my_series.value_counts()
counts
len(counts)
5
sum(counts)
9
counts[""fred""]
1
dict(counts)
{1.8: 2, 2: 2, 3: 3, 1: 1, 'fred': 1}","['my_series = pandas.Series([1,2,2,3,3,3, ""fred"", 1.8, 1.8])', 'counts = my_series.value_counts()']","['import pandas', 'my_series', 'counts = my_series.value_counts()', 'counts', 'len(counts)', '5', 'sum(counts)', '9', 'counts[""fred""]', '1', 'dict(counts)', ""{1.8: 2, 2: 2, 3: 3, 1: 1, 'fred': 1}""]",['counts = my_series.value_counts()'],,
12250416,"import xlrd
xls = xlrd.open_workbook(r'<path_to_your_excel_file>', on_demand=True)",[],"['import xlrd', ""xls = xlrd.open_workbook(r'<path_to_your_excel_file>', on_demand=True)""]",[],[],[]
12286958,"import numpy as np 
from pandas import DataFrame
import matplotlib.pyplot as plt
Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']
Cols = ['A', 'B', 'C', 'D']
df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)
plt.pcolor(df)
plt.yticks(np.arange(0.5, len(df.index), 1), df.index)
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)
plt.show()","['plt.yticks(np.arange(0.5, len(df.index), 1), df.index)']","['import numpy as np ', 'from pandas import DataFrame', 'import matplotlib.pyplot as plt', ""Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']"", ""Cols = ['A', 'B', 'C', 'D']"", 'df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)', 'plt.pcolor(df)', 'plt.yticks(np.arange(0.5, len(df.index), 1), df.index)', 'plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)', 'plt.show()']","['plt.yticks(np.arange(0.5, len(df.index), 1), df.index)']",,
12307162,"df.ix[df.A==0, 'B'] = np.nan
df.ix[df.A==0, 'B'] = df.ix[df.A==0, 'B'] / 2",[],"[""df.ix[df.A==0, 'B'] = np.nan"", ""df.ix[df.A==0, 'B'] = df.ix[df.A==0, 'B'] / 2""]",[],[],[]
12322877,"df = pandas.DataFrame({'b':[2,2,4,5], 'c': [3,3,0,9]}, index=[1,1,3,7])
df_unique = df.groupby(level=0).first()
df
df_unique","[""df = pandas.DataFrame({'b':[2,2,4,5], 'c': [3,3,0,9]}, index=[1,1,3,7])"", 'df_unique = df.groupby(level=0).first()']","['df_unique = df.groupby(level=0).first()', 'df', 'df_unique']",['df_unique = df.groupby(level=0).first()'],,
12323599,df.drop_duplicates(),['df.drop_duplicates()'],['df.drop_duplicates()'],['df.drop_duplicates()'],,
12326113,df1.apply(lambda x: x.asof(df2.index)),['df1.apply(lambda x: x.asof(df2.index))'],['df1.apply(lambda x: x.asof(df2.index))'],['df1.apply(lambda x: x.asof(df2.index))'],,
12329993,"def set_column_sequence(dataframe, seq, front=True):
    cols = seq[:] 
    for x in dataframe.columns:
        if x not in cols:
            if front: 
                cols.append(x)
            else:
                cols.insert(0, x)
return dataframe[cols]","['                cols.append(x)', '                cols.insert(0, x)']","['def set_column_sequence(dataframe, seq, front=True):', '    cols = seq[:] ', '    for x in dataframe.columns:', '        if x not in cols:', '            if front: ', '                cols.append(x)', '            else:', '                cols.insert(0, x)', 'return dataframe[cols]']","['                cols.append(x)', '                cols.insert(0, x)']",,
12332974,df,[],['df'],[],[],[]
12335016,,[],[''],[],[],[]
12336039,"quotes
trades
ordered_merge(quotes, trades)
ordered_merge(quotes, trades, fill_method='ffill')",[],"['quotes', 'trades', 'ordered_merge(quotes, trades)', ""ordered_merge(quotes, trades, fill_method='ffill')""]",[],[],[]
12342180,,[],[''],[],[],[]
12356541,from pandas import *,[],['from pandas import *'],[],[],[]
12358601,"new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]
df[new_columns]
df = pd.DataFrame(np.random.randn(6, 4), columns=['ddd', 'fff', 'aaa', 'ppp'])
df
last_row = df.ix[df.last_valid_index()]
last_row.argsort()
df[last_row.argsort()]","['new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]', ""df = pd.DataFrame(np.random.randn(6, 4), columns=['ddd', 'fff', 'aaa', 'ppp'])"", 'last_row = df.ix[df.last_valid_index()]', 'last_row.argsort()', 'df[last_row.argsort()]']","['new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]', 'df[new_columns]', 'df', 'last_row = df.ix[df.last_valid_index()]', 'last_row.argsort()', 'df[last_row.argsort()]']","['new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]', 'last_row = df.ix[df.last_valid_index()]', 'last_row.argsort()', 'df[last_row.argsort()]']",,
12377080,"def is_hammer(rOpen,rLow,rClose,rHigh):
    return lower_wick_at_least_twice_real_body(rOpen,rLow,rClose) \
       and closed_in_top_half_of_range(rHigh,rLow,rClose)
df[""isHammer""] = map(is_hammer, df[""Open""], df[""Low""], df[""Close""], df[""High""])",[],"['def is_hammer(rOpen,rLow,rClose,rHigh):', '    return lower_wick_at_least_twice_real_body(rOpen,rLow,rClose) \\', '       and closed_in_top_half_of_range(rHigh,rLow,rClose)', 'df[""isHammer""] = map(is_hammer, df[""Open""], df[""Low""], df[""Close""], df[""High""])']",[],[],[]
12377083,"d
d.A > d.C
d.apply(lambda row: min([row['A'], row['B']])-row['C'], axis=1)
2   -3
3   -3
4   -7
d['A'][:-1] < d['C'][1:]
d['A'][1:] < d['C'][:-1]","[""d.apply(lambda row: min([row['A'], row['B']])-row['C'], axis=1)""]","['d', 'd.A > d.C', ""d.apply(lambda row: min([row['A'], row['B']])-row['C'], axis=1)"", '2   -3', '3   -3', '4   -7', ""d['A'][:-1] < d['C'][1:]"", ""d['A'][1:] < d['C'][:-1]""]","[""d.apply(lambda row: min([row['A'], row['B']])-row['C'], axis=1)""]",,
12394122,df,[],['df'],[],[],[]
12407691,"test[""x""][5:10].plot()","['test[""x""][5:10].plot()']","['test[""x""][5:10].plot()']","['test[""x""][5:10].plot()']",,
12433236,"import urllib
base_url = ""http://ichart.finance.yahoo.com/table.csv?s=""
def make_url(ticker_symbol):
    return base_url + ticker_symbol
output_path = ""C:/path/to/output/directory""
def make_filename(ticker_symbol, directory=""S&P""):
    return output_path + ""/"" + directory + ""/"" + ticker_symbol + "".csv""
def pull_historical_data(ticker_symbol, directory=""S&P""):
    try:
        urllib.urlretrieve(make_url(ticker_symbol), make_filename(ticker_symbol, directory))
    except urllib.ContentTooShortError as e:
        outfile = open(make_filename(ticker_symbol, directory), ""w"")
        outfile.write(e.content)
        outfile.close()",[],"['import urllib', 'base_url = ""http://ichart.finance.yahoo.com/table.csv?s=""', 'def make_url(ticker_symbol):', '    return base_url + ticker_symbol', 'output_path = ""C:/path/to/output/directory""', 'def make_filename(ticker_symbol, directory=""S&P""):', '    return output_path + ""/"" + directory + ""/"" + ticker_symbol + "".csv""', 'def pull_historical_data(ticker_symbol, directory=""S&P""):', '    try:', '        urllib.urlretrieve(make_url(ticker_symbol), make_filename(ticker_symbol, directory))', '    except urllib.ContentTooShortError as e:', '        outfile = open(make_filename(ticker_symbol, directory), ""w"")', '        outfile.write(e.content)', '        outfile.close()']",[],[],[]
12449785,"plot(test['x'][5:10].values)
plot(test['x'][5:10].reset_index(drop=True))
test[5:10].set_index('x')['y'].plot()","[""plot(test['x'][5:10].values)"", ""plot(test['x'][5:10].reset_index(drop=True))"", ""test[5:10].set_index('x')['y'].plot()""]","[""plot(test['x'][5:10].values)"", ""plot(test['x'][5:10].reset_index(drop=True))"", ""test[5:10].set_index('x')['y'].plot()""]","[""plot(test['x'][5:10].values)"", ""plot(test['x'][5:10].reset_index(drop=True))"", ""test[5:10].set_index('x')['y'].plot()""]",,
12497577,df.groupby(['A']).max(),"[""df.groupby(['A']).max()""]","[""df.groupby(['A']).max()""]","[""df.groupby(['A']).max()""]",,
12504527,"import pandas as pd
Sr1 = pd.Series([1,2,3,4], index = ['A', 'B', 'C', 'D'])
Sr2 = pd.Series([5,6], index = ['A', 'C'])
Sr1+Sr2
Sr1.add(Sr2, fill_value=0)","[""Sr1 = pd.Series([1,2,3,4], index = ['A', 'B', 'C', 'D'])"", ""Sr2 = pd.Series([5,6], index = ['A', 'C'])"", 'Sr1.add(Sr2, fill_value=0)']","['import pandas as pd', 'Sr1+Sr2', 'Sr1.add(Sr2, fill_value=0)']","['Sr1.add(Sr2, fill_value=0)']",,
12505031,"Mode           : backup
Timestamping   : False
State          : active
x = 1
quit()
ipython -log /tmp/session.log 
Filename       : ipython_log.py
...
x
Out[1]: 1",[],"['Mode           : backup', 'Timestamping   : False', 'State          : active', 'x = 1', 'quit()', 'ipython -log /tmp/session.log ', 'Filename       : ipython_log.py', '...', 'x', 'Out[1]: 1']",[],[],[]
12505089,"import pandas as pd
d1 = pd.DataFrame({'ticker' : ['spx 5/25/2001 p500', 'spx 5/25/2001 p600', 'spx 5/25/2001 p700']})
d1.ticker.str.split().tolist()","[""d1 = pd.DataFrame({'ticker' : ['spx 5/25/2001 p500', 'spx 5/25/2001 p600', 'spx 5/25/2001 p700']})"", 'd1.ticker.str.split().tolist()']","['import pandas as pd', 'd1.ticker.str.split().tolist()']",['d1.ticker.str.split().tolist()'],,
12510334,"from pandas.io.data import DataReader
from datetime import datetime
ibm = DataReader('IBM',  'yahoo', datetime(2000, 1, 1), datetime(2012, 1, 1))
print(ibm['Adj Close'])
import pandas_datareader as pdr
from datetime import datetime
ibm = pdr.get_data_yahoo(symbols='IBM', start=datetime(2000, 1, 1), end=datetime(2012, 1, 1))
print(ibm['Adj Close'])",[],"['from pandas.io.data import DataReader', 'from datetime import datetime', ""ibm = DataReader('IBM',  'yahoo', datetime(2000, 1, 1), datetime(2012, 1, 1))"", ""print(ibm['Adj Close'])"", 'import pandas_datareader as pdr', 'from datetime import datetime', ""ibm = pdr.get_data_yahoo(symbols='IBM', start=datetime(2000, 1, 1), end=datetime(2012, 1, 1))"", ""print(ibm['Adj Close'])""]",[],[],[]
12525836,"df
df_norm = (df - df.mean()) / (df.max() - df.min())
df_norm
df_norm.mean()
df_norm.max() - df_norm.min()","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df', 'df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']"
12555491,"df1['e'] = np.random.randn(sLength)
df1['e'] = df1['a'].map(lambda x: np.random.random())","[""df1['e'] = df1['a'].map(lambda x: np.random.random())""]","[""df1['e'] = np.random.randn(sLength)"", ""df1['e'] = df1['a'].map(lambda x: np.random.random())""]","[""df1['e'] = df1['a'].map(lambda x: np.random.random())""]",,
12555510,"df1['e'] = Series(np.random.randn(sLength), index=df1.index)
sLength = len(df1['a'])
df1
df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)
df1
p.version.short_version
'0.16.1'
df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)
df1
df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""sLength = len(df1['a'])"", 'df1', 'df1', 'p.version.short_version', ""'0.16.1'"", 'df1']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']"
12570410,"from pandas import *
P1Channels = data.filter(regex=""P1"")
P1Sum = P1Channels.sum(axis=1)","['P1Channels = data.filter(regex=""P1"")', 'P1Sum = P1Channels.sum(axis=1)']","['from pandas import *', 'P1Channels = data.filter(regex=""P1"")', 'P1Sum = P1Channels.sum(axis=1)']","['P1Channels = data.filter(regex=""P1"")', 'P1Sum = P1Channels.sum(axis=1)']",,
12605055,"df['Date'].str[-4:].astype(int)
df['Date'].str.extract('(?P<year>\d{4})').astype(int)
df['Date'] = df['Date'].apply(lambda x: int(str(x)[-4:]))
df['Date'] = df['Date'].apply(convert_to_year)","[""df['Date'].str[-4:].astype(int)"", ""df['Date'].str.extract('(?P<year>\\d{4})').astype(int)"", ""df['Date'] = df['Date'].apply(lambda x: int(str(x)[-4:]))"", ""df['Date'] = df['Date'].apply(convert_to_year)""]","[""df['Date'].str[-4:].astype(int)"", ""df['Date'].str.extract('(?P<year>\\d{4})').astype(int)"", ""df['Date'] = df['Date'].apply(lambda x: int(str(x)[-4:]))"", ""df['Date'] = df['Date'].apply(convert_to_year)""]","[""df['Date'].str[-4:].astype(int)"", ""df['Date'].str.extract('(?P<year>\\d{4})').astype(int)"", ""df['Date'] = df['Date'].apply(lambda x: int(str(x)[-4:]))"", ""df['Date'] = df['Date'].apply(convert_to_year)""]",,
12607018,,[],[''],[],[],[]
12627465,"df
cond = df['A'].str.contains('a') & (df['B'] == 20)
df.drop(df[cond].index.values)","[""cond = df['A'].str.contains('a') & (df['B'] == 20)"", 'df.drop(df[cond].index.values)']","['df', ""cond = df['A'].str.contains('a') & (df['B'] == 20)"", 'df.drop(df[cond].index.values)']","[""cond = df['A'].str.contains('a') & (df['B'] == 20)"", 'df.drop(df[cond].index.values)']",,
12681217,"pd.concat([Series(row['var2'], row['var1'].split(','))              
                    for _, row in a.iterrows()]).reset_index()","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']"
12707465,,[],[''],[],[],[]
12726468,"import pandas as pd
source = pd.DataFrame({'A': ['foo', 'bar'], 'B': [1, 2], 'C': [(1,2), (3,4)]})
source
source._get_numeric_data()","[""source = pd.DataFrame({'A': ['foo', 'bar'], 'B': [1, 2], 'C': [(1,2), (3,4)]})""]","['import pandas as pd', 'source', 'source._get_numeric_data()']",[],,
12727919,,[],[''],[],[],[]
12741168,,[],[''],[],[],[]
12834193,"import pyodbc
import pandas.io.sql as psql
cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=servername;DATABASE=mydb;UID=username;PWD=password') 
cursor = cnxn.cursor()
sql = (""""""select * from mytable"""""")
df = psql.frame_query(sql, cnxn)
cnxn.close()",[],"['import pyodbc', 'import pandas.io.sql as psql', ""cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=servername;DATABASE=mydb;UID=username;PWD=password') "", 'cursor = cnxn.cursor()', 'sql = (""""""select * from mytable"""""")', 'df = psql.frame_query(sql, cnxn)', 'cnxn.close()']",[],[],[]
12846154,"data
dtypes: object(360)",[],"['data', 'dtypes: object(360)']",[],[],[]
12850453,"bigdata = data1.append(data2, ignore_index=True)","['bigdata = data1.append(data2, ignore_index=True)']","['bigdata = data1.append(data2, ignore_index=True)']","['bigdata = data1.append(data2, ignore_index=True)']",,
12862196,"df2.pivot_table(values='X', rows='Y', cols='Z', 
                         aggfunc=lambda x: len(x.unique()))
Y             ","[""df2.pivot_table(values='X', rows='Y', cols='Z', "", '                         aggfunc=lambda x: len(x.unique()))']","[""df2.pivot_table(values='X', rows='Y', cols='Z', "", '                         aggfunc=lambda x: len(x.unique()))', 'Y             ']","[""df2.pivot_table(values='X', rows='Y', cols='Z', "", '                         aggfunc=lambda x: len(x.unique()))']",,
12874054,df = male_trips.groupby('start_station_id').size(),"[""df = male_trips.groupby('start_station_id').size()""]","[""df = male_trips.groupby('start_station_id').size()""]","[""df = male_trips.groupby('start_station_id').size()""]",,
12874135,"count_series = male_trips.start_station_id.value_counts()
count_series = (
                male_trips[male_trips.start_station_id.isin(stations.id.values)]
                    .start_station_id
                    .value_counts()
               )","['count_series = male_trips.start_station_id.value_counts()', '                male_trips[male_trips.start_station_id.isin(stations.id.values)]']","['count_series = male_trips.start_station_id.value_counts()', 'count_series = (', '                male_trips[male_trips.start_station_id.isin(stations.id.values)]', '                    .start_station_id', '                    .value_counts()', '               )']","['count_series = male_trips.start_station_id.value_counts()', '                male_trips[male_trips.start_station_id.isin(stations.id.values)]']",,
12882439,"df.to_csv('pandasfile.csv', float_format='%.3f')
df.to_csv('pandasfile.csv', float_format='%g')
Bob,0.085
Alice,0.005","[""df.to_csv('pandasfile.csv', float_format='%.3f')"", ""df.to_csv('pandasfile.csv', float_format='%g')""]","[""df.to_csv('pandasfile.csv', float_format='%.3f')"", ""df.to_csv('pandasfile.csv', float_format='%g')"", 'Bob,0.085', 'Alice,0.005']","[""df.to_csv('pandasfile.csv', float_format='%.3f')"", ""df.to_csv('pandasfile.csv', float_format='%g')""]",,
12961158,,[],[''],[],[],[]
12975518,,[],[''],[],[],[]
12992260,,[],[''],[],[],[]
13003524,"df.ix[:, df.columns - to_excl].hist()",[],"['df.ix[:, df.columns - to_excl].hist()']",[],[],[]
13020027,"from pandas.tseries.offsets import *
s
s.asfreq(BDay())
x=datetime(2011, 1, 5)
y=datetime(2011, 1, 9)
s.ix[x:y]
s.ix[x:y].asfreq(BDay())
s.ix[x:y].asfreq(BDay()).count()
Out[191]: 3","['s.asfreq(BDay())', 's.ix[x:y].asfreq(BDay())', 's.ix[x:y].asfreq(BDay()).count()']","['from pandas.tseries.offsets import *', 's', 's.asfreq(BDay())', 'x=datetime(2011, 1, 5)', 'y=datetime(2011, 1, 9)', 's.ix[x:y]', 's.ix[x:y].asfreq(BDay())', 's.ix[x:y].asfreq(BDay()).count()', 'Out[191]: 3']","['s.asfreq(BDay())', 's.ix[x:y].asfreq(BDay())', 's.ix[x:y].asfreq(BDay()).count()']",,
13021797,"df = DataFrame({""pear"": [1,2,3], ""apple"": [2,3,4], ""orange"": [3,4,5]})
df.columns
df.columns.get_loc(""pear"")
Out[47]: 2","['df.columns.get_loc(""pear"")']","['df = DataFrame({""pear"": [1,2,3], ""apple"": [2,3,4], ""orange"": [3,4,5]})', 'df.columns', 'df.columns.get_loc(""pear"")', 'Out[47]: 2']","['df.columns.get_loc(""pear"")']",,
13036844,,[],[''],[],[],[]
13036848,"grouped = df3.groupby(level=0)
df4 = grouped.last()
df4
import numpy as np
import pandas
idx = pandas.MultiIndex.from_tuples([('a', letter) for letter in list('abcde')])
df1 = pandas.DataFrame(np.random.normal(size=(5,2)), index=idx, columns=['colA', 'colB'])
df1.index.names = ['iA', 'iB']
df1 = df1.append(df1.select(lambda idx: idx[1] in ['c', 'e']))
df1
groups = df1.groupby(level=df1.index.names)  
groups.last() ","['grouped = df3.groupby(level=0)', 'df4 = grouped.last()', ""idx = pandas.MultiIndex.from_tuples([('a', letter) for letter in list('abcde')])"", ""df1 = pandas.DataFrame(np.random.normal(size=(5,2)), index=idx, columns=['colA', 'colB'])"", ""df1.index.names = ['iA', 'iB']"", ""df1 = df1.append(df1.select(lambda idx: idx[1] in ['c', 'e']))"", 'groups = df1.groupby(level=df1.index.names)  ', 'groups.last() ']","['grouped = df3.groupby(level=0)', 'df4 = grouped.last()', 'df4', 'import numpy as np', 'import pandas', ""idx = pandas.MultiIndex.from_tuples([('a', letter) for letter in list('abcde')])"", ""df1.index.names = ['iA', 'iB']"", ""df1 = df1.append(df1.select(lambda idx: idx[1] in ['c', 'e']))"", 'df1', 'groups = df1.groupby(level=df1.index.names)  ', 'groups.last() ']","['grouped = df3.groupby(level=0)', 'df4 = grouped.last()', ""idx = pandas.MultiIndex.from_tuples([('a', letter) for letter in list('abcde')])"", ""df1.index.names = ['iA', 'iB']"", ""df1 = df1.append(df1.select(lambda idx: idx[1] in ['c', 'e']))"", 'groups = df1.groupby(level=df1.index.names)  ', 'groups.last() ']",,
13052373,"def f(group):
    row = group.irow(0)
    return DataFrame({'class': [row['class']] * row['count']})
df.groupby('class', group_keys=False).apply(f)
df.groupby('class', group_keys=False).apply(f)","[""df.groupby('class', group_keys=False).apply(f)"", ""df.groupby('class', group_keys=False).apply(f)""]","['def f(group):', '    row = group.irow(0)', ""    return DataFrame({'class': [row['class']] * row['count']})"", ""df.groupby('class', group_keys=False).apply(f)"", ""df.groupby('class', group_keys=False).apply(f)""]","[""df.groupby('class', group_keys=False).apply(f)"", ""df.groupby('class', group_keys=False).apply(f)""]",,
13053267,"temp2.str[-1]
Name: ticker",[],"['temp2.str[-1]', 'Name: ticker']",[],[],[]
13053381,"import numpy as np
ax0.yaxis.set_ticks(np.arange(70000,80000,2500))",[],"['import numpy as np', 'ax0.yaxis.set_ticks(np.arange(70000,80000,2500))']",[],[],[]
13053967,"import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
max_yticks = 100
yloc = plt.MaxNLocator(max_yticks)
ax.yaxis.set_major_locator(yloc)
plt.show()",[],"['import matplotlib.pyplot as plt', 'fig = plt.figure()', 'ax = fig.add_subplot(1, 1, 1)', 'max_yticks = 100', 'yloc = plt.MaxNLocator(max_yticks)', 'ax.yaxis.set_major_locator(yloc)', 'plt.show()']",[],[],[]
13059751,"df.drop_duplicates(subset='A', keep=""last"")
df.groupby('A', group_keys=False).apply(lambda x: x.ix[x.B.idxmax()])
A       ","['df.drop_duplicates(subset=\'A\', keep=""last"")', ""df.groupby('A', group_keys=False).apply(lambda x: x.ix[x.B.idxmax()])""]","['df.drop_duplicates(subset=\'A\', keep=""last"")', ""df.groupby('A', group_keys=False).apply(lambda x: x.ix[x.B.idxmax()])"", 'A       ']","['df.drop_duplicates(subset=\'A\', keep=""last"")', ""df.groupby('A', group_keys=False).apply(lambda x: x.ix[x.B.idxmax()])""]",,
13070405,"from random import random,randint
def gen_weights(a,N):
    ws = list()
    for i in range(N):
        w = a * ((1-a)**i)
        ws.append(w)
    return ws
def weighted(data,ws):
    wt = list()
    for i,x in enumerate(data):
        wt.append(x*ws[i])
    return wt
N = 10
a = 0.5
ws = gen_weights(a,N)
data = [randint(0,100) for r in xrange(N)]
weighted_data = weighted(data,ws)","['        ws.append(w)', '        wt.append(x*ws[i])']","['from random import random,randint', 'def gen_weights(a,N):', '    ws = list()', '    for i in range(N):', '        w = a * ((1-a)**i)', '        ws.append(w)', '    return ws', 'def weighted(data,ws):', '    wt = list()', '    for i,x in enumerate(data):', '        wt.append(x*ws[i])', '    return wt', 'N = 10', 'a = 0.5', 'ws = gen_weights(a,N)', 'data = [randint(0,100) for r in xrange(N)]', 'weighted_data = weighted(data,ws)']","['        ws.append(w)', '        wt.append(x*ws[i])']",,
13086305,,[],[''],[],[],[]
13115473,"data
data.set_index('Date').diff()
Date                        ","[""data.set_index('Date').diff()""]","['data', ""data.set_index('Date').diff()"", 'Date                        ']","[""data.set_index('Date').diff()""]",,
13130357,"import numpy as np
count, division = np.histogram(series)
count, division = np.histogram(series, bins = [-201,-149,949,1001])
series.hist(bins=division)",[],"['import numpy as np', 'count, division = np.histogram(series)', 'count, division = np.histogram(series, bins = [-201,-149,949,1001])', 'series.hist(bins=division)']",[],[],[]
13148611,"df
cols = df.columns.tolist()
cols
cols = cols[-1:] + cols[:-1]
cols
df = df[cols]  
df",['cols = df.columns.tolist()'],"['df', 'cols = df.columns.tolist()', 'cols', 'cols = cols[-1:] + cols[:-1]', 'cols', 'df = df[cols]  ', 'df']",['cols = df.columns.tolist()'],[],['cols = df.columns.tolist()']
13165753,newdf = df[df.columns[2:4]] ,[],['newdf = df[df.columns[2:4]] '],[],[],[]
13181960,"pd.concat([group for _, group in grouped if len(group) > 1])","['pd.concat([group for _, group in grouped if len(group) > 1])']","['pd.concat([group for _, group in grouped if len(group) > 1])']","['pd.concat([group for _, group in grouped if len(group) > 1])']",,
13193256,"df
df.index.dtype
df.to_records()
df.to_records().dtype
df.index = df.index.astype('i8')
df.to_records().view([('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])
rec.array([(1, nan, 0.2, nan), (2, nan, nan, 0.5), (3, nan, 0.2, 0.5),
       (4, 0.1, 0.2, nan), (5, 0.1, 0.2, 0.5), (6, 0.1, nan, 0.5),
       (7, 0.1, nan, nan)], 
      dtype=[('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])","['df.index.dtype', 'df.to_records()', 'df.to_records().dtype', ""df.index = df.index.astype('i8')"", ""df.to_records().view([('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])""]","['df', 'df.index.dtype', 'df.to_records()', 'df.to_records().dtype', ""df.index = df.index.astype('i8')"", ""df.to_records().view([('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])"", 'rec.array([(1, nan, 0.2, nan), (2, nan, nan, 0.5), (3, nan, 0.2, 0.5),', '       (4, 0.1, 0.2, nan), (5, 0.1, 0.2, 0.5), (6, 0.1, nan, 0.5),', '       (7, 0.1, nan, nan)], ', ""      dtype=[('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])""]","['df.index.dtype', 'df.to_records()', 'df.to_records().dtype', ""df.index = df.index.astype('i8')"", ""df.to_records().view([('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])""]",,
13216688,"In[2]: df = pd.DataFrame(np.arange(40.).reshape((8, 5)), columns=list('abcde')); df
In[3]: ser = pd.Series(np.arange(8) * 10); ser
In[4]: func = lambda x: np.asarray(x) * np.asarray(ser)
In[5]: df.apply(func)
In[6]: ser2 = pd.Series(np.arange(5) *5); ser2
In[7]: func2 = lambda x: np.asarray(x) * np.asarray(ser2)
In[8]: df.apply(func2, axis=1)
In[9]: df.apply(lambda x: np.asarray(x) * np.asarray(ser))
In[10]: df.apply(lambda x: np.asarray(x) * np.asarray(ser2), axis=1)","[""In[2]: df = pd.DataFrame(np.arange(40.).reshape((8, 5)), columns=list('abcde')); df"", 'In[3]: ser = pd.Series(np.arange(8) * 10); ser', 'In[5]: df.apply(func)', 'In[6]: ser2 = pd.Series(np.arange(5) *5); ser2', 'In[8]: df.apply(func2, axis=1)', 'In[9]: df.apply(lambda x: np.asarray(x) * np.asarray(ser))', 'In[10]: df.apply(lambda x: np.asarray(x) * np.asarray(ser2), axis=1)']","['In[4]: func = lambda x: np.asarray(x) * np.asarray(ser)', 'In[5]: df.apply(func)', 'In[7]: func2 = lambda x: np.asarray(x) * np.asarray(ser2)', 'In[8]: df.apply(func2, axis=1)', 'In[9]: df.apply(lambda x: np.asarray(x) * np.asarray(ser))', 'In[10]: df.apply(lambda x: np.asarray(x) * np.asarray(ser2), axis=1)']","['In[5]: df.apply(func)', 'In[8]: df.apply(func2, axis=1)', 'In[9]: df.apply(lambda x: np.asarray(x) * np.asarray(ser))', 'In[10]: df.apply(lambda x: np.asarray(x) * np.asarray(ser2), axis=1)']",,
13226352,"import pandas as pd
import numpy as np
np.arrays = [['one','one','one','two','two','two'],[1,2,3,1,2,3]]
df = pd.DataFrame(np.random.randn(6,2),index=pd.MultiIndex.from_tuples(list(zip(*np.arrays))),columns=['A','B'])
df  
df.ndim
2
df.ix[""one""]
df.ix[""one""].ix[1]
df.ix[""one""].ix[1][""A""]
df.xs('one')
df.xs('B', axis=1)
Name: B","[""df = pd.DataFrame(np.random.randn(6,2),index=pd.MultiIndex.from_tuples(list(zip(*np.arrays))),columns=['A','B'])"", 'df.ndim', ""df.xs('one')"", ""df.xs('B', axis=1)""]","['import pandas as pd', 'import numpy as np', ""np.arrays = [['one','one','one','two','two','two'],[1,2,3,1,2,3]]"", 'df  ', 'df.ndim', '2', 'df.ix[""one""]', 'df.ix[""one""].ix[1]', 'df.ix[""one""].ix[1][""A""]', ""df.xs('one')"", ""df.xs('B', axis=1)"", 'Name: B']","[""df = pd.DataFrame(np.random.randn(6,2),index=pd.MultiIndex.from_tuples(list(zip(*np.arrays))),columns=['A','B'])"", 'df.ndim', ""df.xs('one')"", ""df.xs('B', axis=1)""]",,
13237914,"pandas.set_option('display.max_columns', 7)
pandas.set_option('display.max_columns', None)","[""pandas.set_option('display.max_columns', 7)"", ""pandas.set_option('display.max_columns', None)""]","[""pandas.set_option('display.max_columns', 7)"", ""pandas.set_option('display.max_columns', None)""]","[""pandas.set_option('display.max_columns', 7)"", ""pandas.set_option('display.max_columns', None)""]",,
13252767,,[],[''],[],[],[]
13257677,"df = pd.DataFrame({'A':[1,1,2,2],'B':[1,2,1,2],'values':np.arange(10,30,5)})
df
df['sum_values_A'] = df.groupby('A')['values'].transform(np.sum)
df","[""df = pd.DataFrame({'A':[1,1,2,2],'B':[1,2,1,2],'values':np.arange(10,30,5)})"", ""df['sum_values_A'] = df.groupby('A')['values'].transform(np.sum)""]","['df', ""df['sum_values_A'] = df.groupby('A')['values'].transform(np.sum)"", 'df']","[""df['sum_values_A'] = df.groupby('A')['values'].transform(np.sum)""]",,
13270110,"from pandas import DataFrame, merge
df1 = DataFrame({'key':[1,1], 'col1':[1,2],'col2':[3,4]})
df2 = DataFrame({'key':[1,1], 'col3':[5,6]})
merge(df1, df2,on='key')[['col1', 'col2', 'col3']]",[],"['from pandas import DataFrame, merge', ""df1 = DataFrame({'key':[1,1], 'col1':[1,2],'col2':[3,4]})"", ""df2 = DataFrame({'key':[1,1], 'col3':[5,6]})"", ""merge(df1, df2,on='key')[['col1', 'col2', 'col3']]""]",[],[],[]
13295801,"df
df.fillna(0)
df[1].fillna(0, inplace=True)
df","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df', 'df.fillna(0)', 'df[1].fillna(0, inplace=True)', 'df']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']"
13315962,"result = dataframe.mul(series, axis=0)","['result = dataframe.mul(series, axis=0)']","['result = dataframe.mul(series, axis=0)']","['result = dataframe.mul(series, axis=0)']",,
13316001,"df.insert(0, 'mean', df.mean(1))","[""df.insert(0, 'mean', df.mean(1))""]","[""df.insert(0, 'mean', df.mean(1))""]","[""df.insert(0, 'mean', df.mean(1))""]",,
13332682,"x = p.Series()
N = 4
for i in xrange(N):
   x = x.set_value(i, i**2)","['x = p.Series()', '   x = x.set_value(i, i**2)']","['N = 4', 'for i in xrange(N):', '   x = x.set_value(i, i**2)']","['   x = x.set_value(i, i**2)']",,
13337376,df,[],['df'],[],[],[]
13371090,"date_index = pd.DatetimeIndex([pd.datetime(2003,6,24), pd.datetime(2003,8,13),
        pd.datetime(2003,8,19), pd.datetime(2003,8,22), pd.datetime(2003,8,24)])
ts = pd.Series([2,1,2,1,5], index=date_index)
ts.reindex(pd.date_range(min(date_index), max(date_index)))","['ts = pd.Series([2,1,2,1,5], index=date_index)', 'ts.reindex(pd.date_range(min(date_index), max(date_index)))']","['date_index = pd.DatetimeIndex([pd.datetime(2003,6,24), pd.datetime(2003,8,13),', '        pd.datetime(2003,8,19), pd.datetime(2003,8,22), pd.datetime(2003,8,24)])', 'ts.reindex(pd.date_range(min(date_index), max(date_index)))']","['ts.reindex(pd.date_range(min(date_index), max(date_index)))']",,
13384494,"read_csv('sample.csv', dtype={'ID': object})",[],"[""read_csv('sample.csv', dtype={'ID': object})""]",[],[],[]
13385921,,[],[''],[],[],[]
13386025,"import pandas as pd
def strip(text):
    try:
        return text.strip()
    except AttributeError:
        return text
def make_int(text):
    return int(text.strip('"" '))
table = pd.read_table(""data.csv"", sep=r',',
                      names=[""Year"", ""Make"", ""Model"", ""Description""],
                      converters = {'Description' : strip,
                                    'Model' : strip,
                                    'Make' : strip,
                                    'Year' : make_int})
print(table)","['        return text.strip()', '    return int(text.strip(\'"" \'))', 'table = pd.read_table(""data.csv"", sep=r\',\',']","['import pandas as pd', 'def strip(text):', '    try:', '        return text.strip()', '    except AttributeError:', '        return text', 'def make_int(text):', '    return int(text.strip(\'"" \'))', 'table = pd.read_table(""data.csv"", sep=r\',\',', '                      names=[""Year"", ""Make"", ""Model"", ""Description""],', ""                      converters = {'Description' : strip,"", ""                                    'Model' : strip,"", ""                                    'Make' : strip,"", ""                                    'Year' : make_int})"", 'print(table)']","['        return text.strip()', '    return int(text.strip(\'"" \'))', 'table = pd.read_table(""data.csv"", sep=r\',\',']",,
13389808,"s.loc[('b', slice(2, 10))]
s.loc[(slice('a', 'b'), slice(2, 10))]
dtype: float64
s.ix[1:10, ""b""]
s[""b""].iloc[1:10]","[""s.loc[('b', slice(2, 10))]"", ""s.loc[(slice('a', 'b'), slice(2, 10))]"", 's[""b""].iloc[1:10]']","[""s.loc[('b', slice(2, 10))]"", ""s.loc[(slice('a', 'b'), slice(2, 10))]"", 'dtype: float64', 's.ix[1:10, ""b""]', 's[""b""].iloc[1:10]']","[""s.loc[('b', slice(2, 10))]"", ""s.loc[(slice('a', 'b'), slice(2, 10))]"", 's[""b""].iloc[1:10]']",,
13413842,"from scipy.stats import ttest_ind
cat1 = my_data[my_data['Category']=='cat1']
cat2 = my_data[my_data['Category']=='cat2']
ttest_ind(cat1['values'], cat2['values'])",[],"['from scipy.stats import ttest_ind', ""cat1 = my_data[my_data['Category']=='cat1']"", ""cat2 = my_data[my_data['Category']=='cat2']"", ""ttest_ind(cat1['values'], cat2['values'])""]",[],[],[]
13413845,df = df[np.isfinite(df['EPS'])],[],"[""df = df[np.isfinite(df['EPS'])]""]",[],[],[]
13415772,"df = DataFrame([[1, 2, 3], [4, 5, 6]])
df[1]",[],"['df = DataFrame([[1, 2, 3], [4, 5, 6]])', 'df[1]']",[],[],[]
13434501,"df = pd.DataFrame(np.random.randn(10,3))
df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;
df
df.dropna()     
df.dropna(how='all')     
df.dropna(thresh=2)   
df.dropna(subset=[1])   ","['df = pd.DataFrame(np.random.randn(10,3))', 'df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df = pd.DataFrame(np.random.randn(10,3))', 'df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df = pd.DataFrame(np.random.randn(10,3))', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']"
13445630,"d = d.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)","['d = d.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)']","['d = d.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)']","['d = d.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)']",,
13446268,"pd.date_range(start, end, freq='M').shift(15, freq=pd.datetools.day)","[""pd.date_range(start, end, freq='M').shift(15, freq=pd.datetools.day)""]","[""pd.date_range(start, end, freq='M').shift(15, freq=pd.datetools.day)""]","[""pd.date_range(start, end, freq='M').shift(15, freq=pd.datetools.day)""]",,
13447176,"data[data.groupby('tag').pid.transform(len) > 1]
import pandas
import numpy as np
data = pandas.DataFrame(
    {'pid' : [1,1,1,2,2,3,3,3],
     'tag' : [23,45,62,24,45,34,25,62],
     })
bytag = data.groupby('tag').aggregate(np.count_nonzero)
tags = bytag[bytag.pid >= 2].index
print(data[data['tag'].isin(tags)])","[""data[data.groupby('tag').pid.transform(len) > 1]"", 'data = pandas.DataFrame(', ""bytag = data.groupby('tag').aggregate(np.count_nonzero)"", 'tags = bytag[bytag.pid >= 2].index', ""print(data[data['tag'].isin(tags)])""]","[""data[data.groupby('tag').pid.transform(len) > 1]"", 'import pandas', 'import numpy as np', ""    {'pid' : [1,1,1,2,2,3,3,3],"", ""     'tag' : [23,45,62,24,45,34,25,62],"", '     })', ""bytag = data.groupby('tag').aggregate(np.count_nonzero)"", 'tags = bytag[bytag.pid >= 2].index', ""print(data[data['tag'].isin(tags)])""]","[""data[data.groupby('tag').pid.transform(len) > 1]"", ""bytag = data.groupby('tag').aggregate(np.count_nonzero)"", 'tags = bytag[bytag.pid >= 2].index', ""print(data[data['tag'].isin(tags)])""]",,
13456432,"test.append(pd.Series(200, index=[101]))","['test.append(pd.Series(200, index=[101]))']",[],"['test.append(pd.Series(200, index=[101]))']",,
13485766,,[],[''],[],[],[]
13581730,"user_dict = {12: {'Category 1': {'att_1': 1, 'att_2': 'whatever'},
                  'Category 2': {'att_1': 23, 'att_2': 'another'}},
             15: {'Category 1': {'att_1': 10, 'att_2': 'foo'},
                  'Category 2': {'att_1': 30, 'att_2': 'bar'}}}
pd.DataFrame.from_dict({(i,j): user_dict[i][j] 
                           for i in user_dict.keys() 
                           for j in user_dict[i].keys()},
                       orient='index')
user_ids = []
frames = []
for user_id, d in user_dict.iteritems():
    user_ids.append(user_id)
    frames.append(pd.DataFrame.from_dict(d, orient='index'))
pd.concat(frames, keys=user_ids)","['pd.DataFrame.from_dict({(i,j): user_dict[i][j] ', 'for user_id, d in user_dict.iteritems():', '    user_ids.append(user_id)', ""    frames.append(pd.DataFrame.from_dict(d, orient='index'))"", 'pd.concat(frames, keys=user_ids)']","[""user_dict = {12: {'Category 1': {'att_1': 1, 'att_2': 'whatever'},"", ""                  'Category 2': {'att_1': 23, 'att_2': 'another'}},"", ""             15: {'Category 1': {'att_1': 10, 'att_2': 'foo'},"", ""                  'Category 2': {'att_1': 30, 'att_2': 'bar'}}}"", '                           for i in user_dict.keys() ', '                           for j in user_dict[i].keys()},', ""                       orient='index')"", 'user_ids = []', 'frames = []', 'for user_id, d in user_dict.iteritems():', '    user_ids.append(user_id)', 'pd.concat(frames, keys=user_ids)']","['pd.DataFrame.from_dict({(i,j): user_dict[i][j] ', 'for user_id, d in user_dict.iteritems():', '    user_ids.append(user_id)', ""    frames.append(pd.DataFrame.from_dict(d, orient='index'))"", 'pd.concat(frames, keys=user_ids)']",,
13583024,,[],[''],[],[],[]
13592901,"df.groupby(""dummy"").agg({""returns"": [np.mean, np.sum]})
df.groupby('dummy').agg({'returns':
                                  {'Mean': np.mean, 'Sum': np.sum}})
dummy                    ","['df.groupby(""dummy"").agg({""returns"": [np.mean, np.sum]})', ""df.groupby('dummy').agg({'returns':"", ""                                  {'Mean': np.mean, 'Sum': np.sum}})""]","['df.groupby(""dummy"").agg({""returns"": [np.mean, np.sum]})', ""df.groupby('dummy').agg({'returns':"", ""                                  {'Mean': np.mean, 'Sum': np.sum}})"", 'dummy                    ']","['df.groupby(""dummy"").agg({""returns"": [np.mean, np.sum]})', ""df.groupby('dummy').agg({'returns':"", ""                                  {'Mean': np.mean, 'Sum': np.sum}})""]",,
13593882,"import pandas.io.data as web
nab = web.get_data_yahoo('NAB.AX', start='2009-05-25',
                                   end='2009-06-05')[['Close', 'Volume']]
cba = web.get_data_yahoo('CBA.AX', start='2009-05-26',
                                   end='2009-06-08')[['Close', 'Volume']]
nab
cba
keys = ['CBA.AX','NAB.AX']
pd.concat([cba, nab], axis=1, keys=keys)
Date                                          ","['pd.concat([cba, nab], axis=1, keys=keys)']","['import pandas.io.data as web', ""nab = web.get_data_yahoo('NAB.AX', start='2009-05-25',"", ""                                   end='2009-06-05')[['Close', 'Volume']]"", ""cba = web.get_data_yahoo('CBA.AX', start='2009-05-26',"", ""                                   end='2009-06-08')[['Close', 'Volume']]"", 'nab', 'cba', ""keys = ['CBA.AX','NAB.AX']"", 'pd.concat([cba, nab], axis=1, keys=keys)', 'Date                                          ']","['pd.concat([cba, nab], axis=1, keys=keys)']",,
13616382,"df.loc[df['col1'] >= 1, 'col1']
df[df['col1'] >= 1]
df[(df['col1'] >= 1) & (df['col1'] <=1 )]
def b(x, col, op, n): 
             return op(x[col],n)
def f(x, *b):
             return x[(np.logical_and(*b))]
b1 = b(df, 'col1', ge, 1)
b2 = b(df, 'col1', le, 1)
f(df, b1, b2)
df.query('col1 <= 1 & 1 <= col1')","[""df.loc[df['col1'] >= 1, 'col1']"", ""df.query('col1 <= 1 & 1 <= col1')""]","[""df.loc[df['col1'] >= 1, 'col1']"", ""df[df['col1'] >= 1]"", ""df[(df['col1'] >= 1) & (df['col1'] <=1 )]"", 'def b(x, col, op, n): ', '             return op(x[col],n)', 'def f(x, *b):', '             return x[(np.logical_and(*b))]', ""b1 = b(df, 'col1', ge, 1)"", ""b2 = b(df, 'col1', le, 1)"", 'f(df, b1, b2)', ""df.query('col1 <= 1 & 1 <= col1')""]","[""df.loc[df['col1'] >= 1, 'col1']"", ""df.query('col1 <= 1 & 1 <= col1')""]",,
13653490,"iter_csv = pandas.read_csv('file.csv', iterator=True, chunksize=1000)
df = pd.concat([chunk[chunk['field'] > constant] for chunk in iter_csv])","[""iter_csv = pandas.read_csv('file.csv', iterator=True, chunksize=1000)"", ""df = pd.concat([chunk[chunk['field'] > constant] for chunk in iter_csv])""]","[""iter_csv = pandas.read_csv('file.csv', iterator=True, chunksize=1000)"", ""df = pd.concat([chunk[chunk['field'] > constant] for chunk in iter_csv])""]","[""iter_csv = pandas.read_csv('file.csv', iterator=True, chunksize=1000)"", ""df = pd.concat([chunk[chunk['field'] > constant] for chunk in iter_csv])""]",,
13655271,"import pandas as pd
pd.to_datetime('2008-02-27')
Out[2]: datetime.datetime(2008, 2, 27, 0, 0)
df.index = pd.to_datetime(df.index)
df['date_col'] = df['date_col'].apply(pd.to_datetime)","[""pd.to_datetime('2008-02-27')"", 'df.index = pd.to_datetime(df.index)', ""df['date_col'] = df['date_col'].apply(pd.to_datetime)""]","['import pandas as pd', ""pd.to_datetime('2008-02-27')"", 'Out[2]: datetime.datetime(2008, 2, 27, 0, 0)', 'df.index = pd.to_datetime(df.index)', ""df['date_col'] = df['date_col'].apply(pd.to_datetime)""]","[""pd.to_datetime('2008-02-27')"", 'df.index = pd.to_datetime(df.index)', ""df['date_col'] = df['date_col'].apply(pd.to_datetime)""]",,
13659944,"d.groupby(['ip', 'useragent']).count()","[""d.groupby(['ip', 'useragent']).count()""]","[""d.groupby(['ip', 'useragent']).count()""]","[""d.groupby(['ip', 'useragent']).count()""]",,
13665099,,[],[''],[],[],[]
13674286,"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import matplotlib.dates as dates
idx = pd.date_range('2011-05-01', '2011-07-01')
s = pd.Series(np.random.randn(len(idx)), index=idx)
fig, ax = plt.subplots()
ax.plot_date(idx.to_pydatetime(), s, 'v-')
ax.xaxis.set_minor_locator(dates.WeekdayLocator(byweekday=(1),
                                                interval=1))
ax.xaxis.set_minor_formatter(dates.DateFormatter('%d\n%a'))
ax.xaxis.grid(True, which=""minor"")
ax.yaxis.grid()
ax.xaxis.set_major_locator(dates.MonthLocator())
ax.xaxis.set_major_formatter(dates.DateFormatter('\n\n\n%b\n%Y'))
plt.tight_layout()
plt.show()","[""idx = pd.date_range('2011-05-01', '2011-07-01')"", 's = pd.Series(np.random.randn(len(idx)), index=idx)', ""ax.plot_date(idx.to_pydatetime(), s, 'v-')""]","['import numpy as np', 'import pandas as pd', 'import matplotlib.pyplot as plt ', 'import matplotlib.dates as dates', ""idx = pd.date_range('2011-05-01', '2011-07-01')"", 'fig, ax = plt.subplots()', ""ax.plot_date(idx.to_pydatetime(), s, 'v-')"", 'ax.xaxis.set_minor_locator(dates.WeekdayLocator(byweekday=(1),', '                                                interval=1))', ""ax.xaxis.set_minor_formatter(dates.DateFormatter('%d\\n%a'))"", 'ax.xaxis.grid(True, which=""minor"")', 'ax.yaxis.grid()', 'ax.xaxis.set_major_locator(dates.MonthLocator())', ""ax.xaxis.set_major_formatter(dates.DateFormatter('\\n\\n\\n%b\\n%Y'))"", 'plt.tight_layout()', 'plt.show()']","[""idx = pd.date_range('2011-05-01', '2011-07-01')"", ""ax.plot_date(idx.to_pydatetime(), s, 'v-')""]",,
13680953,"import difflib 
difflib.get_close_matches
df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])
df2
df1.join(df2)
df1 = DataFrame([[1,'one'],[2,'two'],[3,'three'],[4,'four'],[5,'five']], columns=['number', 'name'])
df2 = DataFrame([['a','one'],['b','too'],['c','three'],['d','fours'],['e','five']], columns=['letter', 'name'])
df2['name'] = df2['name'].apply(lambda x: difflib.get_close_matches(x, df1['name'])[0])
df1.merge(df2)","['df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])', 'df1.join(df2)', ""df2['name'] = df2['name'].apply(lambda x: difflib.get_close_matches(x, df1['name'])[0])"", 'df1.merge(df2)']","['import difflib ', 'difflib.get_close_matches', 'df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])', 'df2', 'df1.join(df2)', ""df1 = DataFrame([[1,'one'],[2,'two'],[3,'three'],[4,'four'],[5,'five']], columns=['number', 'name'])"", ""df2 = DataFrame([['a','one'],['b','too'],['c','three'],['d','fours'],['e','five']], columns=['letter', 'name'])"", ""df2['name'] = df2['name'].apply(lambda x: difflib.get_close_matches(x, df1['name'])[0])"", 'df1.merge(df2)']","['df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])', 'df1.join(df2)', ""df2['name'] = df2['name'].apply(lambda x: difflib.get_close_matches(x, df1['name'])[0])"", 'df1.merge(df2)']",,
13682381,data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC')),"[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]"
13688105,"df['result'].str.lstrip('+-').str.rstrip('aAbBcC')
Name: result","[""df['result'].str.lstrip('+-').str.rstrip('aAbBcC')""]","[""df['result'].str.lstrip('+-').str.rstrip('aAbBcC')"", 'Name: result']","[""df['result'].str.lstrip('+-').str.rstrip('aAbBcC')""]",,
13703721,"str(dt64)
pd.to_datetime(str(dt64))
pd.to_datetime(str(dt64)).replace(tzinfo=None)
dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100')
pd.to_datetime(str(dt64)).replace(tzinfo=None)
Out[22]: datetime.datetime(2002, 6, 28, 1, 0)","['pd.to_datetime(str(dt64))', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)']","['str(dt64)', 'pd.to_datetime(str(dt64))', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)', ""dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100')"", 'pd.to_datetime(str(dt64)).replace(tzinfo=None)', 'Out[22]: datetime.datetime(2002, 6, 28, 1, 0)']","['pd.to_datetime(str(dt64))', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)']",,
13703930,"dt64.tolist()
datetime.datetime(2012, 5, 1, 0, 0)",['dt64.tolist()'],"['dt64.tolist()', 'datetime.datetime(2012, 5, 1, 0, 0)']",['dt64.tolist()'],,
13704307,"from datetime import datetime
import numpy as np
dt = datetime.utcnow()
dt
datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)
dt64 = np.datetime64(dt)
ts = (dt64 - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')
ts
1354650685.3624549
datetime.utcfromtimestamp(ts)
datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)
np.__version__
'1.8.0.dev-7b75899'
np.datetime64(datetime.utcnow()).astype(datetime)
datetime.datetime(2012, 12, 4, 13, 34, 52, 827542)
from datetime import datetime
import numpy 
numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)
datetime.datetime(2002, 6, 28, 0, 0)
numpy.__version__
'1.6.2' 
from datetime import datetime
import numpy
numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)
numpy.__version__
'1.8.0.dev-7b75899'
dt64.dtype
dtype('<M8[ns]')
ns = 1e-9 
datetime.utcfromtimestamp(dt64.astype(int) * ns)
datetime.datetime(2002, 6, 28, 0, 0)
dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100', 's')
dt64.dtype
dtype('<M8[s]')
datetime.utcfromtimestamp(dt64.astype(int))
datetime.datetime(2002, 6, 28, 0, 0)","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']","['from datetime import datetime', 'import numpy as np', 'dt = datetime.utcnow()', 'dt', 'datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)', 'dt64 = np.datetime64(dt)', ""ts = (dt64 - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')"", 'ts', '1354650685.3624549', 'datetime.utcfromtimestamp(ts)', 'datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)', 'np.__version__', ""'1.8.0.dev-7b75899'"", 'np.datetime64(datetime.utcnow()).astype(datetime)', 'datetime.datetime(2012, 12, 4, 13, 34, 52, 827542)', 'from datetime import datetime', 'import numpy ', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'datetime.datetime(2002, 6, 28, 0, 0)', 'numpy.__version__', ""'1.6.2' "", 'from datetime import datetime', 'import numpy', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'numpy.__version__', ""'1.8.0.dev-7b75899'"", 'dt64.dtype', ""dtype('<M8[ns]')"", 'ns = 1e-9 ', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'datetime.datetime(2002, 6, 28, 0, 0)', ""dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100', 's')"", 'dt64.dtype', ""dtype('<M8[s]')"", 'datetime.utcfromtimestamp(dt64.astype(int))', 'datetime.datetime(2002, 6, 28, 0, 0)']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'datetime.utcfromtimestamp(dt64.astype(int))']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']"
13713475,,[],[''],[],[],[]
13731128,[tuple(x) for x in data_set.to_records(index=False)],['[tuple(x) for x in data_set.to_records(index=False)]'],['[tuple(x) for x in data_set.to_records(index=False)]'],['[tuple(x) for x in data_set.to_records(index=False)]'],,
13741439,"data['weekday'] = data['my_dt'].apply(lambda x: x.weekday())
weekdays_only = data[data['weekday'] < 5 ]","[""data['weekday'] = data['my_dt'].apply(lambda x: x.weekday())""]","[""data['weekday'] = data['my_dt'].apply(lambda x: x.weekday())"", ""weekdays_only = data[data['weekday'] < 5 ]""]","[""data['weekday'] = data['my_dt'].apply(lambda x: x.weekday())""]",,
13753918,"Timestamp(numpy.datetime64('2012-05-01T01:00:00.000000'))
pandas.to_datetime('2012-05-01T01:00:00.000000+0100')
Out[24]: datetime.datetime(2012, 5, 1, 1, 0, tzinfo=tzoffset(None, 3600))","[""pandas.to_datetime('2012-05-01T01:00:00.000000+0100')""]","[""Timestamp(numpy.datetime64('2012-05-01T01:00:00.000000'))"", ""pandas.to_datetime('2012-05-01T01:00:00.000000+0100')"", 'Out[24]: datetime.datetime(2012, 5, 1, 1, 0, tzinfo=tzoffset(None, 3600))']","[""pandas.to_datetime('2012-05-01T01:00:00.000000+0100')""]",,
13758846,"df1 = pandas.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],
             'dat a1': range(7)})
df1['dat a1']","[""df1 = pandas.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],""]","[""             'dat a1': range(7)})"", ""df1['dat a1']""]",[],,
13786327,"import datetime
import pandas as pd
import numpy as np
todays_date = datetime.datetime.now().date()
index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')
columns = ['A','B', 'C']
df_ = pd.DataFrame(index=index, columns=columns)
df_ = df_.fillna(0) 
data = np.array([np.arange(10)]*3).T
df = pd.DataFrame(data, index=index, columns=columns)
df","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']","['import datetime', 'import pandas as pd', 'import numpy as np', 'todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", ""columns = ['A','B', 'C']"", 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']"
13788301,"np.round(dtindex_or_datetime_col.astype(np.int64), -9).astype('datetime64[ns]')
from pandas.lib import Timestamp
t1 = Timestamp('2012-1-1 00:00:00')
t2 = Timestamp('2012-1-1 00:00:00.000333')
t1
t2
t2.microsecond
t1.value
t2.value
long(round(t2.value, -9)) 
Timestamp(long(round(t2.value, -9)))
def to_the_second(ts):
    return Timestamp(long(round(ts.value, -9)))
dtindex.map(to_the_second)","[""np.round(dtindex_or_datetime_col.astype(np.int64), -9).astype('datetime64[ns]')"", 't2.microsecond', 't1.value', 't2.value', 'long(round(t2.value, -9)) ', 'Timestamp(long(round(t2.value, -9)))', '    return Timestamp(long(round(ts.value, -9)))', 'dtindex.map(to_the_second)']","[""np.round(dtindex_or_datetime_col.astype(np.int64), -9).astype('datetime64[ns]')"", 'from pandas.lib import Timestamp', ""t1 = Timestamp('2012-1-1 00:00:00')"", ""t2 = Timestamp('2012-1-1 00:00:00.000333')"", 't1', 't2', 't2.microsecond', 't1.value', 't2.value', 'long(round(t2.value, -9)) ', 'Timestamp(long(round(t2.value, -9)))', 'def to_the_second(ts):', '    return Timestamp(long(round(ts.value, -9)))', 'dtindex.map(to_the_second)']","[""np.round(dtindex_or_datetime_col.astype(np.int64), -9).astype('datetime64[ns]')"", 't2.microsecond', 't1.value', 't2.value', 'long(round(t2.value, -9)) ', 'Timestamp(long(round(t2.value, -9)))', '    return Timestamp(long(round(ts.value, -9)))', 'dtindex.map(to_the_second)']",,
13833239,"df.drop_duplicates(['foo','bar'])
df.pivot('foo','bar','baz')","[""df.drop_duplicates(['foo','bar'])"", ""df.pivot('foo','bar','baz')""]","[""df.drop_duplicates(['foo','bar'])"", ""df.pivot('foo','bar','baz')""]","[""df.drop_duplicates(['foo','bar'])"", ""df.pivot('foo','bar','baz')""]",,
13839029,"df['m'] = pd.Categorical(df['m'], [""March"", ""April"", ""Dec""])
df  
df.sort(""m"")
df.set_index(s.index).sort()
s = df['m'].replace({'March':0, 'April':1, 'Dec':3})","['df.set_index(s.index).sort()', ""s = df['m'].replace({'March':0, 'April':1, 'Dec':3})""]","['df[\'m\'] = pd.Categorical(df[\'m\'], [""March"", ""April"", ""Dec""])', 'df  ', 'df.sort(""m"")', 'df.set_index(s.index).sort()', ""s = df['m'].replace({'March':0, 'April':1, 'Dec':3})""]","['df.set_index(s.index).sort()', ""s = df['m'].replace({'March':0, 'April':1, 'Dec':3})""]",,
13842286,"df.xs('C')['x']=10
df['x']['C'] = 10
df.xs('C', copy = False)['x']=10","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df['x']['C'] = 10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]"
13843741,,[],[''],[],[],[]
13851602,df[df['column name'].map(len) < 2],"[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]"
13854901,,[],[''],[],[],[]
13866073,"songs.sort_index(by=['Peak', 'Weeks'], ascending=[True, False])","[""songs.sort_index(by=['Peak', 'Weeks'], ascending=[True, False])""]","[""songs.sort_index(by=['Peak', 'Weeks'], ascending=[True, False])""]","[""songs.sort_index(by=['Peak', 'Weeks'], ascending=[True, False])""]",,
13873014,"ax = df1.plot()
df2.plot(ax=ax)","['ax = df1.plot()', 'df2.plot(ax=ax)']","['ax = df1.plot()', 'df2.plot(ax=ax)']","['ax = df1.plot()', 'df2.plot(ax=ax)']",,
13876784,"df
df.groupby(['Month','Year']).mean().unstack()
Month             
df.groupby(['Month','Year']).mean().unstack().plot()","[""df.groupby(['Month','Year']).mean().unstack()"", ""df.groupby(['Month','Year']).mean().unstack().plot()""]","['df', ""df.groupby(['Month','Year']).mean().unstack()"", 'Month             ', ""df.groupby(['Month','Year']).mean().unstack().plot()""]","[""df.groupby(['Month','Year']).mean().unstack()"", ""df.groupby(['Month','Year']).mean().unstack().plot()""]",,
13888546,"df
df.index.levels[1]
Out[12]: Index([one, two], dtype=object)",['df.index.levels[1]'],"['df', 'df.index.levels[1]', 'Out[12]: Index([one, two], dtype=object)']",['df.index.levels[1]'],,
13893632,"prices
orders
prices.lookup(orders.Date, orders.ticker)
array([ 339.44,  342.64,  143.92,  616.5 ,   79.46,   79.68,  609.56,
        158.73,  160.97,  167.84,  323.03,  606.77,  606.77,  392.46])","['prices.lookup(orders.Date, orders.ticker)']","['prices', 'orders', 'prices.lookup(orders.Date, orders.ticker)', 'array([ 339.44,  342.64,  143.92,  616.5 ,   79.46,   79.68,  609.56,', '        158.73,  160.97,  167.84,  323.03,  606.77,  606.77,  392.46])']","['prices.lookup(orders.Date, orders.ticker)']",,
13921674,,[],[''],[],[],[]
13937141,"df[(df.one == 1) | (df.two == 7)]
df[(df.one.isin(checkList)) | (df.two.isin(checkList))]",['df[(df.one.isin(checkList)) | (df.two.isin(checkList))]'],"['df[(df.one == 1) | (df.two == 7)]', 'df[(df.one.isin(checkList)) | (df.two.isin(checkList))]']",['df[(df.one.isin(checkList)) | (df.two.isin(checkList))]'],,
13938831,"from pandas import DataFrame
df = DataFrame({""A"": [8,9,5,4], ""B"": [3,4,4,8], ""C"": [5,0,3,5], ""D"": [8,4,8,1]})
df.max()",['df.max()'],"['from pandas import DataFrame', 'df = DataFrame({""A"": [8,9,5,4], ""B"": [3,4,4,8], ""C"": [5,0,3,5], ""D"": [8,4,8,1]})', 'df.max()']",['df.max()'],,
13977244,"import pandas as pd
import numpy as np
from pandas.io.pytables import Term
index = pd.date_range('1/1/2000', periods=8)
df = pd.DataFrame( np.random.randn(8,3), index=index, columns=list('ABC'))  
store = pd.HDFStore('mydata.h5')
store.append('df_cols', df, axes='columns')
store.select('df_cols', [Term('columns', '=', 'A')])
df","[""index = pd.date_range('1/1/2000', periods=8)"", ""df = pd.DataFrame( np.random.randn(8,3), index=index, columns=list('ABC'))  "", ""store.append('df_cols', df, axes='columns')"", ""store.select('df_cols', [Term('columns', '=', 'A')])""]","['import pandas as pd', 'import numpy as np', 'from pandas.io.pytables import Term', ""index = pd.date_range('1/1/2000', periods=8)"", ""store = pd.HDFStore('mydata.h5')"", ""store.append('df_cols', df, axes='columns')"", ""store.select('df_cols', [Term('columns', '=', 'A')])"", 'df']","[""index = pd.date_range('1/1/2000', periods=8)"", ""store.append('df_cols', df, axes='columns')"", ""store.select('df_cols', [Term('columns', '=', 'A')])""]",,
13998600,"df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)
df.groupby('id')['x'].cumsum()","[""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].cumsum()""]","[""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].cumsum()""]","[""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].cumsum()""]",,
13999234,"store.select('df', [ Term('index', '>', Timestamp('20010105')), 
                     Term('columns', '=', ['A','B']) ])
df.reindex(columns = ['A','B'])","[""store.select('df', [ Term('index', '>', Timestamp('20010105')), "", ""df.reindex(columns = ['A','B'])""]","[""store.select('df', [ Term('index', '>', Timestamp('20010105')), "", ""                     Term('columns', '=', ['A','B']) ])"", ""df.reindex(columns = ['A','B'])""]","[""store.select('df', [ Term('index', '>', Timestamp('20010105')), "", ""df.reindex(columns = ['A','B'])""]",,
14000420,"df['date'] = df['datetime'].apply(lambda x: x.strftime('%d%m%Y'))
df['time'] = df['datetime'].apply(lambda x: x.strftime('%H%M%S'))
df[['date', 'time', ... ]].to_csv('df.csv')","[""df['date'] = df['datetime'].apply(lambda x: x.strftime('%d%m%Y'))"", ""df['time'] = df['datetime'].apply(lambda x: x.strftime('%H%M%S'))"", ""df[['date', 'time', ... ]].to_csv('df.csv')""]","[""df['date'] = df['datetime'].apply(lambda x: x.strftime('%d%m%Y'))"", ""df['time'] = df['datetime'].apply(lambda x: x.strftime('%H%M%S'))"", ""df[['date', 'time', ... ]].to_csv('df.csv')""]","[""df['date'] = df['datetime'].apply(lambda x: x.strftime('%d%m%Y'))"", ""df['time'] = df['datetime'].apply(lambda x: x.strftime('%H%M%S'))"", ""df[['date', 'time', ... ]].to_csv('df.csv')""]",,
14016590,"import numpy as np
index = df['b'].index[df['b'].apply(np.isnan)]
df['a'].ix[index[0]]
1.452354
df_index = df.index.values.tolist()
[df_index.index(i) for i in index]","[""index = df['b'].index[df['b'].apply(np.isnan)]"", 'df_index = df.index.values.tolist()', '[df_index.index(i) for i in index]']","['import numpy as np', ""index = df['b'].index[df['b'].apply(np.isnan)]"", ""df['a'].ix[index[0]]"", '1.452354', 'df_index = df.index.values.tolist()', '[df_index.index(i) for i in index]']","[""index = df['b'].index[df['b'].apply(np.isnan)]"", 'df_index = df.index.values.tolist()', '[df_index.index(i) for i in index]']",,
14033137,"df
pd.isnull(df).any(1).nonzero()[0]
Out[10]: array([3, 6])",['pd.isnull(df).any(1).nonzero()[0]'],"['df', 'pd.isnull(df).any(1).nonzero()[0]', 'Out[10]: array([3, 6])']",['pd.isnull(df).any(1).nonzero()[0]'],,
14058892,"s = pd.Series(np.arange(10.0))
x = range(4, 8)
mask = np.logical_not(s.isin(x))
s[mask]
s[-s.isin(x)]","['s = pd.Series(np.arange(10.0))', 'mask = np.logical_not(s.isin(x))', 's[-s.isin(x)]']","['x = range(4, 8)', 'mask = np.logical_not(s.isin(x))', 's[mask]', 's[-s.isin(x)]']","['mask = np.logical_not(s.isin(x))', 's[-s.isin(x)]']",,
14059783,"order_df['Value'] = order_df.apply(lambda row: (row['Prices']*row['Amount']
                                               if row['Action']=='Sell'
                                               else -row['Prices']*row['Amount']),
                                   axis=1)","[""order_df['Value'] = order_df.apply(lambda row: (row['Prices']*row['Amount']""]","[""order_df['Value'] = order_df.apply(lambda row: (row['Prices']*row['Amount']"", ""                                               if row['Action']=='Sell'"", ""                                               else -row['Prices']*row['Amount']),"", '                                   axis=1)']","[""order_df['Value'] = order_df.apply(lambda row: (row['Prices']*row['Amount']""]",,
14060360,"paste
from pandas import DataFrame
f = DataFrame({'a': ['1','2','3'], 'b': ['2','3','4']})
f.columns = [['level1 item1', 'level1 item2'],['', 'level2 item2'], ['level3 item1', 'level3 item2']]
f
f['level1 item1']",[],"['paste', 'from pandas import DataFrame', ""f = DataFrame({'a': ['1','2','3'], 'b': ['2','3','4']})"", ""f.columns = [['level1 item1', 'level1 item2'],['', 'level2 item2'], ['level3 item1', 'level3 item2']]"", 'f', ""f['level1 item1']""]",[],[],[]
14060625,"orders_df['C'] = orders_df.Action.apply(
               lambda x: (1 if x == 'Sell' else -1))
orders_df   
orders_df['Value'] = orders_df.Prices * orders_df.Amount * orders_df.C
orders_df   ","[""orders_df['C'] = orders_df.Action.apply(""]","[""orders_df['C'] = orders_df.Action.apply("", ""               lambda x: (1 if x == 'Sell' else -1))"", 'orders_df   ', ""orders_df['Value'] = orders_df.Prices * orders_df.Amount * orders_df.C"", 'orders_df   ']","[""orders_df['C'] = orders_df.Action.apply(""]",,
14063022,"import pandas as pd
from datetime import datetime
dr = pd.date_range(datetime(2009,1,1),datetime(2010,12,31),freq='H')
dt = pd.DataFrame(rand(len(dr),2),dr)
hour = dt.index.hour
selector = ((10 <= hour) & (hour <= 13)) | ((20<=hour) & (hour<=23))
data = dt[selector]","[""dr = pd.date_range(datetime(2009,1,1),datetime(2010,12,31),freq='H')"", 'dt = pd.DataFrame(rand(len(dr),2),dr)', 'hour = dt.index.hour']","['import pandas as pd', 'from datetime import datetime', ""dr = pd.date_range(datetime(2009,1,1),datetime(2010,12,31),freq='H')"", 'hour = dt.index.hour', 'selector = ((10 <= hour) & (hour <= 13)) | ((20<=hour) & (hour<=23))', 'data = dt[selector]']","[""dr = pd.date_range(datetime(2009,1,1),datetime(2010,12,31),freq='H')"", 'hour = dt.index.hour']",,
14071265,"values = df.Prices * df.Amount
df['Values'] = values.where(df.Action == 'Sell', other=-values)
df","[""df['Values'] = values.where(df.Action == 'Sell', other=-values)""]","['values = df.Prices * df.Amount', ""df['Values'] = values.where(df.Action == 'Sell', other=-values)"", 'df']","[""df['Values'] = values.where(df.Action == 'Sell', other=-values)""]",,
14110955,"import pandas as pd
import io
df = pd.read_csv(io.BytesIO(text), delimiter = ' ', 
                 converters = {0:str})
df.set_index(['STK_ID','RPT_Date'], inplace = True)
index = df.index
names = index.names
index = [('000999','20121231')] + df.index.tolist()[1:]
df.index = pd.MultiIndex.from_tuples(index, names = names)
print(df)
df.reset_index(inplace = True)
df.ix[0, ['STK_ID', 'RPT_Date']] = ('000999','20121231')
df = df.set_index(['STK_ID','RPT_Date'])
print(df)","[""df = pd.read_csv(io.BytesIO(text), delimiter = ' ', "", ""df.set_index(['STK_ID','RPT_Date'], inplace = True)"", 'index = df.index', ""index = [('000999','20121231')] + df.index.tolist()[1:]"", 'df.index = pd.MultiIndex.from_tuples(index, names = names)', 'df.reset_index(inplace = True)', ""df = df.set_index(['STK_ID','RPT_Date'])""]","['import pandas as pd', 'import io', ""df = pd.read_csv(io.BytesIO(text), delimiter = ' ', "", '                 converters = {0:str})', ""df.set_index(['STK_ID','RPT_Date'], inplace = True)"", 'index = df.index', 'names = index.names', ""index = [('000999','20121231')] + df.index.tolist()[1:]"", 'df.index = pd.MultiIndex.from_tuples(index, names = names)', 'print(df)', 'df.reset_index(inplace = True)', ""df.ix[0, ['STK_ID', 'RPT_Date']] = ('000999','20121231')"", ""df = df.set_index(['STK_ID','RPT_Date'])"", 'print(df)']","[""df = pd.read_csv(io.BytesIO(text), delimiter = ' ', "", ""df.set_index(['STK_ID','RPT_Date'], inplace = True)"", 'index = df.index', ""index = [('000999','20121231')] + df.index.tolist()[1:]"", 'df.index = pd.MultiIndex.from_tuples(index, names = names)', 'df.reset_index(inplace = True)', ""df = df.set_index(['STK_ID','RPT_Date'])""]",,
14148511,,[],[''],[],[],[]
14163174,"x = np.array([1, np.nan, 3])
y = np.where(np.isnan(x), None, x)","['y = np.where(np.isnan(x), None, x)']","['x = np.array([1, np.nan, 3])', 'y = np.where(np.isnan(x), None, x)']","['y = np.where(np.isnan(x), None, x)']",,
14163209,"df1 = df.where((pd.notnull(df)), None)
df = pd.DataFrame([1, np.nan])
df
df1 = df.where((pd.notnull(df)), None)
df1
df1 = df.astype(object).replace(np.nan, 'None')","['df1 = df.where((pd.notnull(df)), None)', 'df = pd.DataFrame([1, np.nan])', 'df1 = df.where((pd.notnull(df)), None)', ""df1 = df.astype(object).replace(np.nan, 'None')""]","['df1 = df.where((pd.notnull(df)), None)', 'df', 'df1 = df.where((pd.notnull(df)), None)', 'df1', ""df1 = df.astype(object).replace(np.nan, 'None')""]","['df1 = df.where((pd.notnull(df)), None)', 'df1 = df.where((pd.notnull(df)), None)', ""df1 = df.astype(object).replace(np.nan, 'None')""]",,
14179954,"import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
testdataframe = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])
styles = ['bs-','ro-','y^-']
linewidths = [2, 1, 4]
fig, ax = plt.subplots()
for col, style, lw in zip(testdataframe.columns, styles, linewidths):
    testdataframe[col].plot(style=style, lw=lw, ax=ax)
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
testdataframe1 = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])
testdataframe2 = pd.DataFrame(np.random.normal(size=(4,3)), columns=['D', 'E', 'F'])
styles1 = ['bs-','ro-','y^-']
styles2 = ['rs-','go-','b^-']
fig, ax = plt.subplots()
testdataframe1.plot(style=styles1, ax=ax)
testdataframe2.plot(style=styles2, ax=ax)","[""testdataframe = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])"", '    testdataframe[col].plot(style=style, lw=lw, ax=ax)', ""testdataframe1 = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])"", ""testdataframe2 = pd.DataFrame(np.random.normal(size=(4,3)), columns=['D', 'E', 'F'])"", 'testdataframe1.plot(style=styles1, ax=ax)', 'testdataframe2.plot(style=styles2, ax=ax)']","['import numpy as np', 'import matplotlib.pyplot as plt', 'import pandas as pd', ""styles = ['bs-','ro-','y^-']"", 'linewidths = [2, 1, 4]', 'fig, ax = plt.subplots()', 'for col, style, lw in zip(testdataframe.columns, styles, linewidths):', '    testdataframe[col].plot(style=style, lw=lw, ax=ax)', 'import numpy as np', 'import matplotlib.pyplot as plt', 'import pandas as pd', ""styles1 = ['bs-','ro-','y^-']"", ""styles2 = ['rs-','go-','b^-']"", 'fig, ax = plt.subplots()', 'testdataframe1.plot(style=styles1, ax=ax)', 'testdataframe2.plot(style=styles2, ax=ax)']","['    testdataframe[col].plot(style=style, lw=lw, ax=ax)', 'testdataframe1.plot(style=styles1, ax=ax)', 'testdataframe2.plot(style=styles2, ax=ax)']",,
14189912,"levels = df.columns.levels
labels = df.columns.labels
df.columns = levels[1][labels[1]]
import pandas as pd
columns = pd.MultiIndex.from_arrays([['basic_amt']*4,
                                     ['NSW','QLD','VIC','All']])
index = pd.Index(['All', 'Full Time', 'Part Time'], name = 'Faculty')
df = pd.DataFrame([(1,1,2,4),
                   (1,0,2,3)])
df.columns = columns
df.index = index
print(df)
Faculty                            
levels = df.columns.levels
labels = df.columns.labels
df.columns = levels[1][labels[1]]
print(df)
Faculty                      ","[""columns = pd.MultiIndex.from_arrays([['basic_amt']*4,"", 'df = pd.DataFrame([(1,1,2,4),', 'df.index = index']","['levels = df.columns.levels', 'labels = df.columns.labels', 'df.columns = levels[1][labels[1]]', 'import pandas as pd', ""columns = pd.MultiIndex.from_arrays([['basic_amt']*4,"", ""                                     ['NSW','QLD','VIC','All']])"", ""index = pd.Index(['All', 'Full Time', 'Part Time'], name = 'Faculty')"", '                   (1,0,2,3)])', 'df.columns = columns', 'df.index = index', 'print(df)', 'Faculty                            ', 'levels = df.columns.levels', 'labels = df.columns.labels', 'df.columns = levels[1][labels[1]]', 'print(df)', 'Faculty                      ']","[""columns = pd.MultiIndex.from_arrays([['basic_amt']*4,"", 'df.index = index']",,
14193170,,[],[''],[],[],[]
14224489,"df1.sort(axis=1) == df2.sort(axis=1)
def my_equal(df1, df2):
    from pandas.util.testing import assert_frame_equal",[],"['df1.sort(axis=1) == df2.sort(axis=1)', 'def my_equal(df1, df2):', '    from pandas.util.testing import assert_frame_equal']",[],[],[]
14225838,"from pandas import ExcelWriter
from pandas.io.parsers import ExcelWriter
def save_xls(list_dfs, xls_path):
    writer = ExcelWriter(xls_path)
    for n, df in enumerate(list_dfs):
        df.to_excel(writer,'sheet%s' % n)
    writer.save()","[""        df.to_excel(writer,'sheet%s' % n)""]","['from pandas import ExcelWriter', 'from pandas.io.parsers import ExcelWriter', 'def save_xls(list_dfs, xls_path):', '    writer = ExcelWriter(xls_path)', '    for n, df in enumerate(list_dfs):', ""        df.to_excel(writer,'sheet%s' % n)"", '    writer.save()']","[""        df.to_excel(writer,'sheet%s' % n)""]",,
14247708,"df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])
df.isnull()
df.isnull().any(axis=1)
dtype: bool
df[df.isnull().any(axis=1)]
df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])
df
pd.isnull(df)
pd.isnull(df).any(axis=1)
df[pd.isnull(df).any(axis=1)]","['df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])', 'df.isnull()', 'df.isnull().any(axis=1)', 'df[df.isnull().any(axis=1)]', 'df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])', 'pd.isnull(df)', 'pd.isnull(df).any(axis=1)', 'df[pd.isnull(df).any(axis=1)]']","['df.isnull()', 'df.isnull().any(axis=1)', 'dtype: bool', 'df[df.isnull().any(axis=1)]', 'df', 'pd.isnull(df)', 'pd.isnull(df).any(axis=1)', 'df[pd.isnull(df).any(axis=1)]']","['df.isnull()', 'df.isnull().any(axis=1)', 'df[df.isnull().any(axis=1)]', 'pd.isnull(df)', 'pd.isnull(df).any(axis=1)', 'df[pd.isnull(df).any(axis=1)]']",,
14248948,"ser.value_counts()
ser.value_counts().reindex(ser[:3])","['ser.value_counts()', 'ser.value_counts().reindex(ser[:3])']","['ser.value_counts()', 'ser.value_counts().reindex(ser[:3])']","['ser.value_counts()', 'ser.value_counts().reindex(ser[:3])']",,
14268804,"import numpy as np
import pandas as pd
store = pd.HDFStore('mystore.h5')
group_map = dict(
    REPORTING_ONLY = dict(fields = ['field_1000','field_1001',...], dc = []),
)
group_map_inverted = dict()
for g, v in group_map.items():
    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))
for f in files:
   for chunk in pd.read_table(f, chunksize=50000):
       for g, v in group_map.items():
             frame = chunk.reindex(columns = v['fields'], copy = False)    
             store.append(g, frame, index=False, data_columns = v['dc'])
frame = store.select(group_that_I_want)
new_frame = cool_function_on_frame(frame)
store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)
store.select(group, where = ['field_1000=foo', 'field_1001>0'])","[""    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))"", '   for chunk in pd.read_table(f, chunksize=50000):', ""             frame = chunk.reindex(columns = v['fields'], copy = False)    "", ""             store.append(g, frame, index=False, data_columns = v['dc'])"", 'frame = store.select(group_that_I_want)', 'store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)', ""store.select(group, where = ['field_1000=foo', 'field_1001>0'])""]","['import numpy as np', 'import pandas as pd', ""store = pd.HDFStore('mystore.h5')"", 'group_map = dict(', ""    REPORTING_ONLY = dict(fields = ['field_1000','field_1001',...], dc = []),"", ')', 'group_map_inverted = dict()', 'for g, v in group_map.items():', ""    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))"", 'for f in files:', '   for chunk in pd.read_table(f, chunksize=50000):', '       for g, v in group_map.items():', ""             frame = chunk.reindex(columns = v['fields'], copy = False)    "", ""             store.append(g, frame, index=False, data_columns = v['dc'])"", 'frame = store.select(group_that_I_want)', 'new_frame = cool_function_on_frame(frame)', 'store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)', ""store.select(group, where = ['field_1000=foo', 'field_1001>0'])""]","[""    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))"", '   for chunk in pd.read_table(f, chunksize=50000):', ""             frame = chunk.reindex(columns = v['fields'], copy = False)    "", ""             store.append(g, frame, index=False, data_columns = v['dc'])"", 'frame = store.select(group_that_I_want)', 'store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)', ""store.select(group, where = ['field_1000=foo', 'field_1001>0'])""]",,
14287518,"aCollection.insert((a[1].to_dict() for a in df.iterrows()))
pd.DataFrame(list(mongoCollection.find({'anAttribute':{'$gt':2887000, '$lt':2889000}})))
aJoinDF = pandas.DataFrame(list(mongoCollection.find({'anAttribute':{'$in':Att_Keys}})))
df = pandas.merge(df, aJoinDF, on=aKey, how='left')
collection.update({primarykey:foo},{key:change})","['aCollection.insert((a[1].to_dict() for a in df.iterrows()))', ""pd.DataFrame(list(mongoCollection.find({'anAttribute':{'$gt':2887000, '$lt':2889000}})))"", ""aJoinDF = pandas.DataFrame(list(mongoCollection.find({'anAttribute':{'$in':Att_Keys}})))"", ""df = pandas.merge(df, aJoinDF, on=aKey, how='left')"", 'collection.update({primarykey:foo},{key:change})']","['aCollection.insert((a[1].to_dict() for a in df.iterrows()))', ""df = pandas.merge(df, aJoinDF, on=aKey, how='left')"", 'collection.update({primarykey:foo},{key:change})']","['aCollection.insert((a[1].to_dict() for a in df.iterrows()))', ""pd.DataFrame(list(mongoCollection.find({'anAttribute':{'$gt':2887000, '$lt':2889000}})))"", ""aJoinDF = pandas.DataFrame(list(mongoCollection.find({'anAttribute':{'$in':Att_Keys}})))"", ""df = pandas.merge(df, aJoinDF, on=aKey, how='left')"", 'collection.update({primarykey:foo},{key:change})']",,
14306902,"df = pd.DataFrame(np.random.randn(10,2), columns=['col1','col2'])
df['col3'] = np.arange(len(df))**2 * 100 + 100
df
plt.scatter(df.col1, df.col2, s=df.col3)
df.plot(kind='scatter', x='col1', y='col2', s=df.col3)
colors = np.where(df.col3 > 300, 'r', 'k')
plt.scatter(df.col1, df.col2, s=120, c=colors)
df.plot(kind='scatter', x='col1', y='col2', s=120, c=colors)
cond = df.col3 > 300
subset_a = df[cond].dropna()
subset_b = df[~cond].dropna()
plt.scatter(subset_a.col1, subset_a.col2, s=120, c='b', label='col3 > 300')
plt.scatter(subset_b.col1, subset_b.col2, s=60, c='r', label='col3 <= 300') 
plt.legend()
df['subset'] = np.select([df.col3 < 150, df.col3 < 400, df.col3 < 600],
                         [0, 1, 2], -1)
for color, label in zip('bgrm', [0, 1, 2, -1]):
    subset = df[df.subset == label]
    plt.scatter(subset.col1, subset.col2, s=120, c=color, label=str(label))
plt.legend()","[""df = pd.DataFrame(np.random.randn(10,2), columns=['col1','col2'])"", ""df.plot(kind='scatter', x='col1', y='col2', s=df.col3)"", ""colors = np.where(df.col3 > 300, 'r', 'k')"", ""df.plot(kind='scatter', x='col1', y='col2', s=120, c=colors)"", 'subset_a = df[cond].dropna()', 'subset_b = df[~cond].dropna()', ""df['subset'] = np.select([df.col3 < 150, df.col3 < 400, df.col3 < 600],""]","[""df['col3'] = np.arange(len(df))**2 * 100 + 100"", 'df', 'plt.scatter(df.col1, df.col2, s=df.col3)', ""df.plot(kind='scatter', x='col1', y='col2', s=df.col3)"", ""colors = np.where(df.col3 > 300, 'r', 'k')"", 'plt.scatter(df.col1, df.col2, s=120, c=colors)', ""df.plot(kind='scatter', x='col1', y='col2', s=120, c=colors)"", 'cond = df.col3 > 300', 'subset_a = df[cond].dropna()', 'subset_b = df[~cond].dropna()', ""plt.scatter(subset_a.col1, subset_a.col2, s=120, c='b', label='col3 > 300')"", ""plt.scatter(subset_b.col1, subset_b.col2, s=60, c='r', label='col3 <= 300') "", 'plt.legend()', ""df['subset'] = np.select([df.col3 < 150, df.col3 < 400, df.col3 < 600],"", '                         [0, 1, 2], -1)', ""for color, label in zip('bgrm', [0, 1, 2, -1]):"", '    subset = df[df.subset == label]', '    plt.scatter(subset.col1, subset.col2, s=120, c=color, label=str(label))', 'plt.legend()']","[""df.plot(kind='scatter', x='col1', y='col2', s=df.col3)"", ""colors = np.where(df.col3 > 300, 'r', 'k')"", ""df.plot(kind='scatter', x='col1', y='col2', s=120, c=colors)"", 'subset_a = df[cond].dropna()', 'subset_b = df[~cond].dropna()', ""df['subset'] = np.select([df.col3 < 150, df.col3 < 400, df.col3 < 600],""]",,
14306921,"df.set_index(['Name', 'Destination'])","[""df.set_index(['Name', 'Destination'])""]","[""df.set_index(['Name', 'Destination'])""]","[""df.set_index(['Name', 'Destination'])""]",,
14307460,df,[],['df'],[],[],[]
14307961,"def rollBy(what, basis, window, func):
    def applyToWindow(val):
        chunk = what[(val<=basis) & (basis<val+window)]
        return func(chunk)
    return basis.apply(applyToWindow)
rollBy(d.ToRoll, d.RollBasis, 5, sum)
0    -4
1    -4
2    -4
3    -4
4    -6
5    -2
6   -15
7   -20
8    -7
9    -5
Name: RollBasis",['    return basis.apply(applyToWindow)'],"['def rollBy(what, basis, window, func):', '    def applyToWindow(val):', '        chunk = what[(val<=basis) & (basis<val+window)]', '        return func(chunk)', '    return basis.apply(applyToWindow)', 'rollBy(d.ToRoll, d.RollBasis, 5, sum)', '0    -4', '1    -4', '2    -4', '3    -4', '4    -6', '5    -2', '6   -15', '7   -20', '8    -7', '9    -5', 'Name: RollBasis']",['    return basis.apply(applyToWindow)'],,
14345875,"misc['product_desc'] = misc['product_desc'].str.replace('\n', '')","[""misc['product_desc'] = misc['product_desc'].str.replace('\\n', '')""]","[""misc['product_desc'] = misc['product_desc'].str.replace('\\n', '')""]","[""misc['product_desc'] = misc['product_desc'].str.replace('\\n', '')""]",,
14349645,,[],[''],[],[],[]
14349766,"import numpy as np
import matplotlib.pyplot as plt
import seaborn
seaborn.set(style='ticks')
X = np.random.randn(256)
fig = plt.figure(figsize=(8,6), dpi=72, facecolor=""white"")
axes = plt.subplot(111)
heights, positions, patches = axes.hist(X, color='white')
seaborn.despine(ax=axes, offset=10, trim=True)
fig.tight_layout()
plt.show()
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
X = np.random.randn(256)
fig = plt.figure(figsize=(8,6), dpi=72, facecolor=""white"")
axes = plt.subplot(111)
heights, positions, patches = axes.hist(X, color='white')
axes.spines['right'].set_color('none')
axes.spines['top'].set_color('none')
axes.xaxis.set_ticks_position('bottom')
was: axes.spines['bottom'].set_position(('data',1.1*X.min()))
axes.spines['bottom'].set_position(('axes', -0.05))
axes.yaxis.set_ticks_position('left')
axes.spines['left'].set_position(('axes', -0.05))
axes.set_xlim([np.floor(positions.min()), np.ceil(positions.max())])
axes.set_ylim([0,70])
axes.xaxis.grid(False)
axes.yaxis.grid(False)
fig.tight_layout()
plt.show()","[""was: axes.spines['bottom'].set_position(('data',1.1*X.min()))"", 'axes.set_xlim([np.floor(positions.min()), np.ceil(positions.max())])']","['import numpy as np', 'import matplotlib.pyplot as plt', 'import seaborn', ""seaborn.set(style='ticks')"", 'X = np.random.randn(256)', 'fig = plt.figure(figsize=(8,6), dpi=72, facecolor=""white"")', 'axes = plt.subplot(111)', ""heights, positions, patches = axes.hist(X, color='white')"", 'seaborn.despine(ax=axes, offset=10, trim=True)', 'fig.tight_layout()', 'plt.show()', 'import numpy as np', 'import matplotlib', 'import matplotlib.pyplot as plt', 'X = np.random.randn(256)', 'fig = plt.figure(figsize=(8,6), dpi=72, facecolor=""white"")', 'axes = plt.subplot(111)', ""heights, positions, patches = axes.hist(X, color='white')"", ""axes.spines['right'].set_color('none')"", ""axes.spines['top'].set_color('none')"", ""axes.xaxis.set_ticks_position('bottom')"", ""was: axes.spines['bottom'].set_position(('data',1.1*X.min()))"", ""axes.spines['bottom'].set_position(('axes', -0.05))"", ""axes.yaxis.set_ticks_position('left')"", ""axes.spines['left'].set_position(('axes', -0.05))"", 'axes.set_xlim([np.floor(positions.min()), np.ceil(positions.max())])', 'axes.set_ylim([0,70])', 'axes.xaxis.grid(False)', 'axes.yaxis.grid(False)', 'fig.tight_layout()', 'plt.show()']","[""was: axes.spines['bottom'].set_position(('data',1.1*X.min()))"", 'axes.set_xlim([np.floor(positions.min()), np.ceil(positions.max())])']",,
14351567,"def customaxis(ax, c_left='k', c_bottom='k', c_right='none', c_top='none',
               lw=3, size=20, pad=8):
    for c_spine, spine in zip([c_left, c_bottom, c_right, c_top],
                              ['left', 'bottom', 'right', 'top']):
        if c_spine != 'none':
            ax.spines[spine].set_color(c_spine)
            ax.spines[spine].set_linewidth(lw)
        else:
            ax.spines[spine].set_color('none')
    if (c_bottom == 'none') & (c_top == 'none'): 
        ax.xaxis.set_ticks_position('none')
    elif (c_bottom != 'none') & (c_top != 'none'): 
        ax.tick_params(axis='x', direction='out', width=lw, length=7,
                      color=c_bottom, labelsize=size, pad=pad)
    elif (c_bottom != 'none') & (c_top == 'none'): 
        ax.xaxis.set_ticks_position('bottom')
        ax.tick_params(axis='x', direction='out', width=lw, length=7,
                       color=c_bottom, labelsize=size, pad=pad)
    elif (c_bottom == 'none') & (c_top != 'none'): 
        ax.xaxis.set_ticks_position('top')
        ax.tick_params(axis='x', direction='out', width=lw, length=7,
                       color=c_top, labelsize=size, pad=pad)
    if (c_left == 'none') & (c_right == 'none'): 
        ax.yaxis.set_ticks_position('none')
    elif (c_left != 'none') & (c_right != 'none'): 
        ax.tick_params(axis='y', direction='out', width=lw, length=7,
                       color=c_left, labelsize=size, pad=pad)
    elif (c_left != 'none') & (c_right == 'none'): 
        ax.yaxis.set_ticks_position('left')
        ax.tick_params(axis='y', direction='out', width=lw, length=7,
                       color=c_left, labelsize=size, pad=pad)
    elif (c_left == 'none') & (c_right != 'none'): 
        ax.yaxis.set_ticks_position('right')
        ax.tick_params(axis='y', direction='out', width=lw, length=7,
                       color=c_right, labelsize=size, pad=pad)
def adjust_spines(ax,spines):
    for loc, spine in ax.spines.items():
        if loc in spines:
            spine.set_position(('outward',10)) 
            spine.set_smart_bounds(True)
        else:
            spine.set_color('none') 
import numpy as np
import matplotlib.pyplot as plt
fig,(ax1,ax2) = plt.subplots(figsize=(8,5), ncols=2)
ax1.plot(np.random.rand(20), np.random.rand(20), 'ok')
ax2.plot(np.random.rand(20), np.random.rand(20), 'ok')
customaxis(ax2) 
adjust_spines(ax2, ['left', 'bottom']) 
plt.show()","[""ax1.plot(np.random.rand(20), np.random.rand(20), 'ok')"", ""ax2.plot(np.random.rand(20), np.random.rand(20), 'ok')""]","[""def customaxis(ax, c_left='k', c_bottom='k', c_right='none', c_top='none',"", '               lw=3, size=20, pad=8):', '    for c_spine, spine in zip([c_left, c_bottom, c_right, c_top],', ""                              ['left', 'bottom', 'right', 'top']):"", ""        if c_spine != 'none':"", '            ax.spines[spine].set_color(c_spine)', '            ax.spines[spine].set_linewidth(lw)', '        else:', ""            ax.spines[spine].set_color('none')"", ""    if (c_bottom == 'none') & (c_top == 'none'): "", ""        ax.xaxis.set_ticks_position('none')"", ""    elif (c_bottom != 'none') & (c_top != 'none'): "", ""        ax.tick_params(axis='x', direction='out', width=lw, length=7,"", '                      color=c_bottom, labelsize=size, pad=pad)', ""    elif (c_bottom != 'none') & (c_top == 'none'): "", ""        ax.xaxis.set_ticks_position('bottom')"", ""        ax.tick_params(axis='x', direction='out', width=lw, length=7,"", '                       color=c_bottom, labelsize=size, pad=pad)', ""    elif (c_bottom == 'none') & (c_top != 'none'): "", ""        ax.xaxis.set_ticks_position('top')"", ""        ax.tick_params(axis='x', direction='out', width=lw, length=7,"", '                       color=c_top, labelsize=size, pad=pad)', ""    if (c_left == 'none') & (c_right == 'none'): "", ""        ax.yaxis.set_ticks_position('none')"", ""    elif (c_left != 'none') & (c_right != 'none'): "", ""        ax.tick_params(axis='y', direction='out', width=lw, length=7,"", '                       color=c_left, labelsize=size, pad=pad)', ""    elif (c_left != 'none') & (c_right == 'none'): "", ""        ax.yaxis.set_ticks_position('left')"", ""        ax.tick_params(axis='y', direction='out', width=lw, length=7,"", '                       color=c_left, labelsize=size, pad=pad)', ""    elif (c_left == 'none') & (c_right != 'none'): "", ""        ax.yaxis.set_ticks_position('right')"", ""        ax.tick_params(axis='y', direction='out', width=lw, length=7,"", '                       color=c_right, labelsize=size, pad=pad)', 'def adjust_spines(ax,spines):', '    for loc, spine in ax.spines.items():', '        if loc in spines:', ""            spine.set_position(('outward',10)) "", '            spine.set_smart_bounds(True)', '        else:', ""            spine.set_color('none') "", 'import numpy as np', 'import matplotlib.pyplot as plt', 'fig,(ax1,ax2) = plt.subplots(figsize=(8,5), ncols=2)', ""ax1.plot(np.random.rand(20), np.random.rand(20), 'ok')"", ""ax2.plot(np.random.rand(20), np.random.rand(20), 'ok')"", 'customaxis(ax2) ', ""adjust_spines(ax2, ['left', 'bottom']) "", 'plt.show()']","[""ax1.plot(np.random.rand(20), np.random.rand(20), 'ok')"", ""ax2.plot(np.random.rand(20), np.random.rand(20), 'ok')""]",,
14359211,"a = np.array([3,3,3,3,3,4,4,4,4,4,1,1,1,1,4,4,12,12,12])
prev = 0
splits = np.append(np.where(np.diff(a) != 0)[0],len(a)+1)+1
for split in splits:
    prev = split","['splits = np.append(np.where(np.diff(a) != 0)[0],len(a)+1)+1']","['a = np.array([3,3,3,3,3,4,4,4,4,4,1,1,1,1,4,4,12,12,12])', 'prev = 0', 'splits = np.append(np.where(np.diff(a) != 0)[0],len(a)+1)+1', 'for split in splits:', '    prev = split']","['splits = np.append(np.where(np.diff(a) != 0)[0],len(a)+1)+1']",,
14360423,"df.reset_index().groupby('A')['index'].apply(np.array)
import numpy as np
from pandas import *
df = DataFrame([3]*4+[4]*4+[1]*4, columns=['A'])
df
df.reset_index().groupby('A')['index'].apply(np.array)
grp = df.groupby('A')
grp.indices
grp.indices[3]
df['block'] = (df.A.shift(1) != df.A).astype(int).cumsum()
df
df.reset_index().groupby(['A','block'])['index'].apply(np.array)","[""df.reset_index().groupby('A')['index'].apply(np.array)"", ""df.reset_index().groupby('A')['index'].apply(np.array)"", ""grp = df.groupby('A')"", 'grp.indices', 'grp.indices[3]', ""df['block'] = (df.A.shift(1) != df.A).astype(int).cumsum()"", ""df.reset_index().groupby(['A','block'])['index'].apply(np.array)""]","[""df.reset_index().groupby('A')['index'].apply(np.array)"", 'import numpy as np', 'from pandas import *', ""df = DataFrame([3]*4+[4]*4+[1]*4, columns=['A'])"", 'df', ""df.reset_index().groupby('A')['index'].apply(np.array)"", ""grp = df.groupby('A')"", 'grp.indices', 'grp.indices[3]', ""df['block'] = (df.A.shift(1) != df.A).astype(int).cumsum()"", 'df', ""df.reset_index().groupby(['A','block'])['index'].apply(np.array)""]","[""df.reset_index().groupby('A')['index'].apply(np.array)"", ""df.reset_index().groupby('A')['index'].apply(np.array)"", ""grp = df.groupby('A')"", 'grp.indices', 'grp.indices[3]', ""df['block'] = (df.A.shift(1) != df.A).astype(int).cumsum()"", ""df.reset_index().groupby(['A','block'])['index'].apply(np.array)""]",,
14363721,"from pandas import *
df = DataFrame(dict(x=[0,0,1,0,1], y=[1,0,1,1,0], z=[0,0,1,0,1]))
df
df = df.drop(['x','y'], axis=1)
df","[""df = df.drop(['x','y'], axis=1)""]","['from pandas import *', 'df = DataFrame(dict(x=[0,0,1,0,1], y=[1,0,1,1,0], z=[0,0,1,0,1]))', 'df', ""df = df.drop(['x','y'], axis=1)"", 'df']","[""df = df.drop(['x','y'], axis=1)""]",,
14363758,"df
df = df[['x','z']]                                                                
df
df.columns
df[df.columns[1:]]
df.drop(df.columns[1:], axis=1)","['df.drop(df.columns[1:], axis=1)']","['df', ""df = df[['x','z']]                                                                "", 'df', 'df.columns', 'df[df.columns[1:]]', 'df.drop(df.columns[1:], axis=1)']","['df.drop(df.columns[1:], axis=1)']",,
14365647,import pandas as pd,[],['import pandas as pd'],[],[],[]
14366084,"import csv
from pprint import pprint
with open('foo.csv', 'rb') as f:
    reader = csv.reader(f)
    headers = reader.next()
    column = {h:[] for h in headers}
    for row in reader:
        for h, v in zip(headers, row):
            column[h].append(v)
    pprint(column)    
{'Date': ['2012-06-11',
          '2012-06-12',
          '2012-06-13',
          '2012-06-14',
          '2012-06-15',
          '2012-06-16',
          '2012-06-17'],
 'factor_1': ['1.255', '1.258', '1.249', '1.253', '1.258', '1.263', '1.264'],
 'factor_2': ['1.548', '1.554', '1.552', '1.556', '1.552', '1.558', '1.572'],
 'price': ['1600.20',
           '1610.02',
           '1618.07',
           '1624.40',
           '1626.15',
           '1626.15',
           '1626.15']}",['            column[h].append(v)'],"['import csv', 'from pprint import pprint', ""with open('foo.csv', 'rb') as f:"", '    reader = csv.reader(f)', '    headers = reader.next()', '    column = {h:[] for h in headers}', '    for row in reader:', '        for h, v in zip(headers, row):', '            column[h].append(v)', '    pprint(column)    ', ""{'Date': ['2012-06-11',"", ""          '2012-06-12',"", ""          '2012-06-13',"", ""          '2012-06-14',"", ""          '2012-06-15',"", ""          '2012-06-16',"", ""          '2012-06-17'],"", "" 'factor_1': ['1.255', '1.258', '1.249', '1.253', '1.258', '1.263', '1.264'],"", "" 'factor_2': ['1.548', '1.554', '1.552', '1.556', '1.552', '1.558', '1.572'],"", "" 'price': ['1600.20',"", ""           '1610.02',"", ""           '1618.07',"", ""           '1624.40',"", ""           '1626.15',"", ""           '1626.15',"", ""           '1626.15']}""]",['            column[h].append(v)'],,
14383654,"df = pd.DataFrame(np.random.random((5, 5)))
df","['df = pd.DataFrame(np.random.random((5, 5)))']",['df'],[],,
14407329,,[],[''],[],[],[]
14428450,,[],[''],[],[],[]
14432914,"price2 = price.reset_index()
price2
p
dtypes: float64(2)",['price2 = price.reset_index()'],"['price2 = price.reset_index()', 'price2', 'p', 'dtypes: float64(2)']",['price2 = price.reset_index()'],,
14451264,"import pandas as pd
import numpy as np
df = pd.DataFrame(range(50), columns  = ['filtercol'])
w = 0
x = 5
y = 17
z = 33
filter_values = [w, x, y, z]
out = pd.cut(df.filtercol, bins = filter_values)
counts = pd.value_counts(out)
print(counts)
counts.reindex(out.cat.categories)","[""df = pd.DataFrame(range(50), columns  = ['filtercol'])"", 'out = pd.cut(df.filtercol, bins = filter_values)', 'counts = pd.value_counts(out)', 'counts.reindex(out.cat.categories)']","['import pandas as pd', 'import numpy as np', 'w = 0', 'x = 5', 'y = 17', 'z = 33', 'filter_values = [w, x, y, z]', 'out = pd.cut(df.filtercol, bins = filter_values)', 'counts = pd.value_counts(out)', 'print(counts)', 'counts.reindex(out.cat.categories)']","['out = pd.cut(df.filtercol, bins = filter_values)', 'counts = pd.value_counts(out)', 'counts.reindex(out.cat.categories)']",,
14487936,"import pandas as pd
df = pd.read_sql(sql, cnxn)
import pyodbc
import pandas.io.sql as psql
cnxn = pyodbc.connect(connection_info) 
cursor = cnxn.cursor()
sql = ""SELECT * FROM TABLE""
df = psql.frame_query(sql, cnxn)
cnxn.close()","['df = pd.read_sql(sql, cnxn)']","['import pandas as pd', 'df = pd.read_sql(sql, cnxn)', 'import pyodbc', 'import pandas.io.sql as psql', 'cnxn = pyodbc.connect(connection_info) ', 'cursor = cnxn.cursor()', 'sql = ""SELECT * FROM TABLE""', 'df = psql.frame_query(sql, cnxn)', 'cnxn.close()']","['df = pd.read_sql(sql, cnxn)']",,
14508355,"df.columns = df.columns.get_level_values(0)
df.columns = [' '.join(col).strip() for col in df.columns.values]
[' '.join(col).strip() for col in df.columns.values]
['USAF',
 'WBAN',
 'day',
 'month',
 's_CD sum',
 's_CL sum',
 's_CNT sum',
 's_PC sum',
 'tempf amax',
 'tempf amin',
 'year']","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]"", ""['USAF',"", "" 'WBAN',"", "" 'day',"", "" 'month',"", "" 's_CD sum',"", "" 's_CL sum',"", "" 's_CNT sum',"", "" 's_PC sum',"", "" 'tempf amax',"", "" 'tempf amin',"", "" 'year']""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]"
14508639,"df
mi = df.columns
mi
mi.tolist()
ind = pd.Index([e[0] + e[1] for e in mi.tolist()])
ind
df.columns = ind
df","['mi.tolist()', 'ind = pd.Index([e[0] + e[1] for e in mi.tolist()])']","['df', 'mi = df.columns', 'mi', 'mi.tolist()', 'ind = pd.Index([e[0] + e[1] for e in mi.tolist()])', 'ind', 'df.columns = ind', 'df']","['mi.tolist()', 'ind = pd.Index([e[0] + e[1] for e in mi.tolist()])']",,
14530027,"df
f = {'A':['sum','mean'], 'B':['prod']}
df.groupby('GRP').agg(f)
f = {'A':['sum','mean'], 'B':['prod'], 'D': lambda g: df.ix[g.index].E.sum()}
df.groupby('GRP').agg(f)
cust = lambda g: g[df.ix[g.index]['C'] < 0.5].sum()
f = {'A':['sum','mean'], 'B':['prod'], 'D': {'my name': cust}}
df.groupby('GRP').agg(f)
GRP","[""df.groupby('GRP').agg(f)"", ""f = {'A':['sum','mean'], 'B':['prod'], 'D': lambda g: df.ix[g.index].E.sum()}"", ""df.groupby('GRP').agg(f)"", ""cust = lambda g: g[df.ix[g.index]['C'] < 0.5].sum()"", ""df.groupby('GRP').agg(f)""]","['df', ""f = {'A':['sum','mean'], 'B':['prod']}"", ""df.groupby('GRP').agg(f)"", ""f = {'A':['sum','mean'], 'B':['prod'], 'D': lambda g: df.ix[g.index].E.sum()}"", ""df.groupby('GRP').agg(f)"", ""cust = lambda g: g[df.ix[g.index]['C'] < 0.5].sum()"", ""f = {'A':['sum','mean'], 'B':['prod'], 'D': {'my name': cust}}"", ""df.groupby('GRP').agg(f)"", 'GRP']","[""df.groupby('GRP').agg(f)"", ""f = {'A':['sum','mean'], 'B':['prod'], 'D': lambda g: df.ix[g.index].E.sum()}"", ""df.groupby('GRP').agg(f)"", ""cust = lambda g: g[df.ix[g.index]['C'] < 0.5].sum()"", ""df.groupby('GRP').agg(f)""]",,
14540509,"ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]
ts.ix[ts.index.indexer_between_time(datetime.time(18), datetime.time(9),
                                    include_start=False, include_end=False)]
rng = pd.date_range('1/1/2000', periods=24, freq='H')
ts = pd.Series(pd.np.random.randn(len(rng)), index=rng)
ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))] 
df = pd.DataFrame(ts)
df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]","['ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]', 'ts.ix[ts.index.indexer_between_time(datetime.time(18), datetime.time(9),', ""rng = pd.date_range('1/1/2000', periods=24, freq='H')"", 'ts = pd.Series(pd.np.random.randn(len(rng)), index=rng)', 'ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))] ', 'df = pd.DataFrame(ts)', 'df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]']","['ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]', 'ts.ix[ts.index.indexer_between_time(datetime.time(18), datetime.time(9),', '                                    include_start=False, include_end=False)]', ""rng = pd.date_range('1/1/2000', periods=24, freq='H')"", 'ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))] ', 'df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]']","['ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]', 'ts.ix[ts.index.indexer_between_time(datetime.time(18), datetime.time(9),', ""rng = pd.date_range('1/1/2000', periods=24, freq='H')"", 'ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))] ', 'df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]']",,
14568392,,[],[''],[],[],[]
14630250,,[],[''],[],[],[]
14657511,"import pandas as pd
df = pd.read_csv(""dup.csv"")
ids = df[""ID""]
df[ids.isin(ids[ids.duplicated()])].sort(""ID"")
pd.concat(g for _, g in df.groupby(""ID"") if len(g) > 1)","['df = pd.read_csv(""dup.csv"")', 'df[ids.isin(ids[ids.duplicated()])].sort(""ID"")', 'pd.concat(g for _, g in df.groupby(""ID"") if len(g) > 1)']","['import pandas as pd', 'df = pd.read_csv(""dup.csv"")', 'ids = df[""ID""]', 'df[ids.isin(ids[ids.duplicated()])].sort(""ID"")', 'pd.concat(g for _, g in df.groupby(""ID"") if len(g) > 1)']","['df = pd.read_csv(""dup.csv"")', 'df[ids.isin(ids[ids.duplicated()])].sort(""ID"")', 'pd.concat(g for _, g in df.groupby(""ID"") if len(g) > 1)']",,
14661768,"df
df.drop(df.index[[1,3]])","['df.drop(df.index[[1,3]])']","['df', 'df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']"
14669654,"df.iloc[-3:]
pd.__version__
'0.12.0'
df = pd.DataFrame([{""a"": 1}, {""a"": 2}])
df.iloc[-5:]
...
df.tail(5)
df1.irow(slice(-3, None))","['df.iloc[-3:]', 'df = pd.DataFrame([{""a"": 1}, {""a"": 2}])', 'df.iloc[-5:]', 'df.tail(5)']","['df.iloc[-3:]', 'pd.__version__', ""'0.12.0'"", 'df.iloc[-5:]', '...', 'df.tail(5)', 'df1.irow(slice(-3, None))']","['df.iloc[-3:]', 'df.iloc[-5:]', 'df.tail(5)']",,
14688398,"import pandas as pd
df = pd.DataFrame([])
df.instrument_name = 'Binky'",['df = pd.DataFrame([])'],"['import pandas as pd', ""df.instrument_name = 'Binky'""]",[],,
14688529,,[],[''],[],[],[]
14714452,"df
df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')
df['desired_output'] = df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')
df","[""df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')"", ""df['desired_output'] = df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')""]","['df', ""df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')"", ""df['desired_output'] = df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')"", 'df']","[""df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')"", ""df['desired_output'] = df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')""]",,
14717374,"df = pandas.DataFrame([1,2,3,4], columns=[""data""])
df
df[""desired""] = df[""data""] > 2.5
df","['df = pandas.DataFrame([1,2,3,4], columns=[""data""])']","['df', 'df[""desired""] = df[""data""] > 2.5', 'df']",[],,
14717761,df['desired_output'] = df.le(2.5),"[""df['desired_output'] = df.le(2.5)""]","[""df['desired_output'] = df.le(2.5)""]","[""df['desired_output'] = df.le(2.5)""]",,
14734148,"df.sort([('Group1', 'C')], ascending=False)",[],"[""df.sort([('Group1', 'C')], ascending=False)""]",[],[],[]
14734627,"gb.get_group('foo')
gb[[""A"", ""B""]].get_group(""foo"")
gb[""C""].get_group(""foo"")","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']"
14745484,"import pandas as pd
df
df = pd.DataFrame(df.row.str.split(' ',1).tolist(),
                                   columns = ['flips','row'])
df","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","['import pandas as pd', 'df', ""                                   columns = ['flips','row'])"", 'df']","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]"
14746845,"df['Firstlevel'] = 'Foo'
df.set_index('Firstlevel', append=True, inplace=True)
df.reorder_levels(['Firstlevel', 'A', 'B'])","[""df.set_index('Firstlevel', append=True, inplace=True)"", ""df.reorder_levels(['Firstlevel', 'A', 'B'])""]","[""df['Firstlevel'] = 'Foo'"", ""df.set_index('Firstlevel', append=True, inplace=True)"", ""df.reorder_levels(['Firstlevel', 'A', 'B'])""]","[""df.set_index('Firstlevel', append=True, inplace=True)"", ""df.reorder_levels(['Firstlevel', 'A', 'B'])""]",,
14760930,,[],[''],[],[],[]
14762651,"r.plot([1,2,3],[1,2,3], xlab=""X"", ylab=""Y"")
deparse(substitute(c(1,2,3)))
r.assign('testX', df.A)
r.assign('testY', df.B)
rdf = com.convert_to_r_dataframe(df)
r.assign('bob', rdf)","['r.plot([1,2,3],[1,2,3], xlab=""X"", ylab=""Y"")', ""r.assign('testX', df.A)"", ""r.assign('testY', df.B)"", ""r.assign('bob', rdf)""]","['r.plot([1,2,3],[1,2,3], xlab=""X"", ylab=""Y"")', 'deparse(substitute(c(1,2,3)))', ""r.assign('testX', df.A)"", ""r.assign('testY', df.B)"", 'rdf = com.convert_to_r_dataframe(df)', ""r.assign('bob', rdf)""]","['r.plot([1,2,3],[1,2,3], xlab=""X"", ylab=""Y"")', ""r.assign('testX', df.A)"", ""r.assign('testY', df.B)"", ""r.assign('bob', rdf)""]",,
14789513,"from collections import OrderedDict
py2ri_orig = rpy2.robjects.conversion.py2ri
def conversion_pydataframe(obj):
    if isinstance(obj, pandas.core.frame.DataFrame):
        od = OrderedDict()
        for name, values in obj.iteritems():
            if values.dtype.kind == 'O':
                od[name] = rpy2.robjects.vectors.StrVector(values)
            else:
                od[name] = rpy2.robjects.conversion.py2ri(values)
        return rpy2.robjects.vectors.DataFrame(od)
    elif isinstance(obj, pandas.core.series.Series):
        res = py2ri_orig(obj) 
        if obj.ndim == 1:
            res.names = ListVector({'x': ro.conversion.py2ri(obj.index)})
        else:
            res.dimnames = ListVector(ro.conversion.py2ri(obj.index))
        return res
    else:
        return py2ri_orig(obj) 
rpy2.robjects.conversion.py2ri = conversion_pydataframe
r.plot(rpy2.robjects.Formula('c3~c2'), data)
p = ggplot2.ggplot(rpy2.robjects.conversion.py2ri(data)) +\
    ggplot2.geom_histogram(ggplot2.aes_string(x = 'c3'))
p.plot()","['    if isinstance(obj, pandas.core.frame.DataFrame):', '        for name, values in obj.iteritems():', ""            if values.dtype.kind == 'O':"", '        return rpy2.robjects.vectors.DataFrame(od)', '    elif isinstance(obj, pandas.core.series.Series):', '        if obj.ndim == 1:', ""            res.names = ListVector({'x': ro.conversion.py2ri(obj.index)})"", '            res.dimnames = ListVector(ro.conversion.py2ri(obj.index))', ""r.plot(rpy2.robjects.Formula('c3~c2'), data)"", 'p.plot()']","['from collections import OrderedDict', 'py2ri_orig = rpy2.robjects.conversion.py2ri', 'def conversion_pydataframe(obj):', '        od = OrderedDict()', '        for name, values in obj.iteritems():', ""            if values.dtype.kind == 'O':"", '                od[name] = rpy2.robjects.vectors.StrVector(values)', '            else:', '                od[name] = rpy2.robjects.conversion.py2ri(values)', '        res = py2ri_orig(obj) ', '        if obj.ndim == 1:', ""            res.names = ListVector({'x': ro.conversion.py2ri(obj.index)})"", '        else:', '            res.dimnames = ListVector(ro.conversion.py2ri(obj.index))', '        return res', '    else:', '        return py2ri_orig(obj) ', 'rpy2.robjects.conversion.py2ri = conversion_pydataframe', ""r.plot(rpy2.robjects.Formula('c3~c2'), data)"", 'p = ggplot2.ggplot(rpy2.robjects.conversion.py2ri(data)) +\\', ""    ggplot2.geom_histogram(ggplot2.aes_string(x = 'c3'))"", 'p.plot()']","['        for name, values in obj.iteritems():', ""            if values.dtype.kind == 'O':"", '        if obj.ndim == 1:', ""            res.names = ListVector({'x': ro.conversion.py2ri(obj.index)})"", '            res.dimnames = ListVector(ro.conversion.py2ri(obj.index))', ""r.plot(rpy2.robjects.Formula('c3~c2'), data)"", 'p.plot()']",,
14809026,import pandas as pd,[],['import pandas as pd'],[],[],[]
14809149,"if isinstance(obj, basestring):
    i_am_string(obj)",[],"['if isinstance(obj, basestring):', '    i_am_string(obj)']",[],[],[]
14813733,"data = np.zeros((2,2))
data
from pandas import DataFrame
df  = DataFrame(data, index = ['first', 'second'], columns=['c1','c2'])
df
i = df.index
c = df.columns
df  = DataFrame(np.random.rand(2,2), index=i, columns=c)
df",['i = df.index'],"['data = np.zeros((2,2))', 'data', 'from pandas import DataFrame', ""df  = DataFrame(data, index = ['first', 'second'], columns=['c1','c2'])"", 'df', 'i = df.index', 'c = df.columns', 'df  = DataFrame(np.random.rand(2,2), index=i, columns=c)', 'df']",['i = df.index'],,
14814282,"import pandas as pd
pd.DataFrame(preprocessing.scale(data), index = data.index, columns = data.columns) ","['pd.DataFrame(preprocessing.scale(data), index = data.index, columns = data.columns) ']",['import pandas as pd'],"['pd.DataFrame(preprocessing.scale(data), index = data.index, columns = data.columns) ']",,
14822703,"import pandas as pd
s = pd.Series([0,1,8,9], name = 'BayFail')
s.tolist()","[""s = pd.Series([0,1,8,9], name = 'BayFail')"", 's.tolist()']","['import pandas as pd', 's.tolist()']",['s.tolist()'],,
14843650,"df = pd.DataFrame(np.random.random((6, 5)) * 10,               
                        index=list('abcdef'), columns=list('ABCDE'))
df
ax = df.plot(kind='bar', stacked=True, align='center')
for container in ax.containers:
              plt.setp(container, width=1)
x0, x1 = ax.get_xlim()
ax.set_xlim(x0 -0.5, x1 + 0.25)
plt.tight_layout()","['df = pd.DataFrame(np.random.random((6, 5)) * 10,               ', ""ax = df.plot(kind='bar', stacked=True, align='center')""]","[""                        index=list('abcdef'), columns=list('ABCDE'))"", 'df', ""ax = df.plot(kind='bar', stacked=True, align='center')"", 'for container in ax.containers:', '              plt.setp(container, width=1)', 'x0, x1 = ax.get_xlim()', 'ax.set_xlim(x0 -0.5, x1 + 0.25)', 'plt.tight_layout()']","[""ax = df.plot(kind='bar', stacked=True, align='center')""]",,
14861132,"sample.resample('60Min', how=conversion, base=30)","[""sample.resample('60Min', how=conversion, base=30)""]","[""sample.resample('60Min', how=conversion, base=30)""]","[""sample.resample('60Min', how=conversion, base=30)""]",,
14887119,"import numpy 
import pandas
from  matplotlib import pyplot
import seaborn
seaborn.set(style='ticks')
numpy.random.seed(0)
N = 37
_genders= ['Female', 'Male', 'Non-binary', 'No Response']
df = pandas.DataFrame({
    'Height (cm)': numpy.random.uniform(low=130, high=200, size=N),
    'Weight (kg)': numpy.random.uniform(low=30, high=100, size=N),
    'Gender': numpy.random.choice(_genders, size=N)
})
fg = seaborn.FacetGrid(data=df, hue='Gender', hue_order=_genders, aspect=1.61)
fg.map(pyplot.scatter, 'Weight (kg)', 'Height (cm)').add_legend()
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
def dfScatter(df, xcol='Height', ycol='Weight', catcol='Gender'):
    fig, ax = plt.subplots()
    categories = np.unique(df[catcol])
    colors = np.linspace(0, 1, len(categories))
    colordict = dict(zip(categories, colors))  
    df[""Color""] = df[catcol].apply(lambda x: colordict[x])
    ax.scatter(df[xcol], df[ycol], c=df.Color)
    return fig
if 1:
    df = pd.DataFrame({'Height':np.random.normal(size=10),
                       'Weight':np.random.normal(size=10),
                       'Gender': [""Male"",""Male"",""Unknown"",""Male"",""Male"",
                                  ""Female"",""Did not respond"",""Unknown"",""Female"",""Female""]})    
    fig = dfScatter(df)
    fig.savefig('fig1.png')","['df = pandas.DataFrame({', ""fg.map(pyplot.scatter, 'Weight (kg)', 'Height (cm)').add_legend()"", '    categories = np.unique(df[catcol])', '    df[""Color""] = df[catcol].apply(lambda x: colordict[x])', ""    df = pd.DataFrame({'Height':np.random.normal(size=10),""]","['import numpy ', 'import pandas', 'from  matplotlib import pyplot', 'import seaborn', ""seaborn.set(style='ticks')"", 'numpy.random.seed(0)', 'N = 37', ""_genders= ['Female', 'Male', 'Non-binary', 'No Response']"", ""    'Height (cm)': numpy.random.uniform(low=130, high=200, size=N),"", ""    'Weight (kg)': numpy.random.uniform(low=30, high=100, size=N),"", ""    'Gender': numpy.random.choice(_genders, size=N)"", '})', ""fg = seaborn.FacetGrid(data=df, hue='Gender', hue_order=_genders, aspect=1.61)"", ""fg.map(pyplot.scatter, 'Weight (kg)', 'Height (cm)').add_legend()"", 'import numpy as np', 'import matplotlib.pyplot as plt', 'import pandas as pd', ""def dfScatter(df, xcol='Height', ycol='Weight', catcol='Gender'):"", '    fig, ax = plt.subplots()', '    categories = np.unique(df[catcol])', '    colors = np.linspace(0, 1, len(categories))', '    colordict = dict(zip(categories, colors))  ', '    df[""Color""] = df[catcol].apply(lambda x: colordict[x])', '    ax.scatter(df[xcol], df[ycol], c=df.Color)', '    return fig', 'if 1:', ""                       'Weight':np.random.normal(size=10),"", '                       \'Gender\': [""Male"",""Male"",""Unknown"",""Male"",""Male"",', '                                  ""Female"",""Did not respond"",""Unknown"",""Female"",""Female""]})    ', '    fig = dfScatter(df)', ""    fig.savefig('fig1.png')""]","[""fg.map(pyplot.scatter, 'Weight (kg)', 'Height (cm)').add_legend()"", '    categories = np.unique(df[catcol])', '    df[""Color""] = df[catcol].apply(lambda x: colordict[x])']",,
14900065,"df4 = df3.drop_duplicates(subset='rownum', keep='last')
df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')
df3 = df3.sort()","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')"", 'df3 = df3.sort()']","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]"
14917572,"df = pandas.DataFrame({""s1_x"": scipy.randn(10), ""s1_y"": scipy.randn(10), ""s2_x"": scipy.randn(10), ""s2_y"": scipy.randn(10)})
df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])
df.stack(0).reset_index(1)
df
id = df.ix[:, ['names']]
df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])
pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)
df
df = df.set_index('names')
df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])
df.stack(0).reset_index(1)
names                            ","['df = pandas.DataFrame({""s1_x"": scipy.randn(10), ""s1_y"": scipy.randn(10), ""s2_x"": scipy.randn(10), ""s2_y"": scipy.randn(10)})', ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)', ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)', ""df = df.set_index('names')"", ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)']","[""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)', 'df', ""id = df.ix[:, ['names']]"", ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)', 'df', ""df = df.set_index('names')"", ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)', 'names                            ']","[""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)', ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)', ""df = df.set_index('names')"", ""df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])"", 'df.stack(0).reset_index(1)']",,
14941170,"df
df.ix[:, 2]
2   -1.560583
4   -2.184617
Name: C
df[df.columns[2]]
2   -1.560583
4   -2.184617
Name: C",[],"['df', 'df.ix[:, 2]', '2   -1.560583', '4   -2.184617', 'Name: C', 'df[df.columns[2]]', '2   -1.560583', '4   -2.184617', 'Name: C']",[],[],[]
14942625,"sum_B_over_A = df.groupby('A').sum().B
sum_B_over_A
df
df.sort(['sum_B_over_A', 'A', 'B'])
df.sort(['sum_B_over_A', 'A', 'B']).drop('sum_B_over_A', axis=1)","[""sum_B_over_A = df.groupby('A').sum().B"", ""df.sort(['sum_B_over_A', 'A', 'B']).drop('sum_B_over_A', axis=1)""]","[""sum_B_over_A = df.groupby('A').sum().B"", 'sum_B_over_A', 'df', ""df.sort(['sum_B_over_A', 'A', 'B'])"", ""df.sort(['sum_B_over_A', 'A', 'B']).drop('sum_B_over_A', axis=1)""]","[""sum_B_over_A = df.groupby('A').sum().B"", ""df.sort(['sum_B_over_A', 'A', 'B']).drop('sum_B_over_A', axis=1)""]",,
14946246,"grp = df.groupby('A')
grp[['B']].transform(sum).sort('B')
sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]
sort1
f = lambda x: x.sort('C', ascending=False)
sort2 = sort1.groupby('A', sort=False).apply(f)
sort2
sort2.reset_index(0, drop=True)","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", 'sort1', ""f = lambda x: x.sort('C', ascending=False)"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2', 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)""]"
14964637,"df.xs(('B',), level='Alpha')
df.xs(('B', False), level=('Alpha', 'Bool'))
ix_vals = set(i for _, i, _ in df.index if i % 2 == 0)
ix = df.index.get_level_values('Int').isin(ix_vals)
df[ix]","[""df.xs(('B',), level='Alpha')"", ""df.xs(('B', False), level=('Alpha', 'Bool'))"", 'ix_vals = set(i for _, i, _ in df.index if i % 2 == 0)', ""ix = df.index.get_level_values('Int').isin(ix_vals)""]","[""df.xs(('B',), level='Alpha')"", ""df.xs(('B', False), level=('Alpha', 'Bool'))"", 'ix_vals = set(i for _, i, _ in df.index if i % 2 == 0)', ""ix = df.index.get_level_values('Int').isin(ix_vals)"", 'df[ix]']","[""df.xs(('B',), level='Alpha')"", ""df.xs(('B', False), level=('Alpha', 'Bool'))"", 'ix_vals = set(i for _, i, _ in df.index if i % 2 == 0)', ""ix = df.index.get_level_values('Int').isin(ix_vals)""]",,
14985695,"vals = np.random.randint(0,20, (4,3))
df = pd.DataFrame(np.hstack([vals, vals]), columns=['Time', 'H1', 'N2', 'Time Relative', 'N2', 'Time'] )
df.T.drop_duplicates().T
df2 = pd.read_table('dummy.csv')
df2.T.drop_duplicates().T
df2 = pd.read_table('dummy.csv', header=None)
from collections import defaultdict
cols = []
df2.columns = cols
df2
df2.T.drop_duplicates().T","[""df = pd.DataFrame(np.hstack([vals, vals]), columns=['Time', 'H1', 'N2', 'Time Relative', 'N2', 'Time'] )"", 'df.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv')"", 'df2.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv', header=None)"", 'df2.T.drop_duplicates().T']","['vals = np.random.randint(0,20, (4,3))', 'df.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv')"", 'df2.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv', header=None)"", 'from collections import defaultdict', 'cols = []', 'df2.columns = cols', 'df2', 'df2.T.drop_duplicates().T']","['df.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv')"", 'df2.T.drop_duplicates().T', ""df2 = pd.read_table('dummy.csv', header=None)"", 'df2.T.drop_duplicates().T']",,
14988913,"Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData))
Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData), ignore_index=True)","['Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData))', 'Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData), ignore_index=True)']",[],"['Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData))', 'Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData), ignore_index=True)']",,
14989047,"import numpy as np
import pandas as pd
dates = np.asarray(pd.date_range('1/1/2000', periods=8))
df1 = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])
df2 = df1.copy()
df = df1.append(df2)","[""dates = np.asarray(pd.date_range('1/1/2000', periods=8))"", ""df1 = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])"", 'df2 = df1.copy()', 'df = df1.append(df2)']","['import numpy as np', 'import pandas as pd', ""dates = np.asarray(pd.date_range('1/1/2000', periods=8))"", 'df2 = df1.copy()', 'df = df1.append(df2)']","[""dates = np.asarray(pd.date_range('1/1/2000', periods=8))"", 'df2 = df1.copy()', 'df = df1.append(df2)']",,
14992237,"df2.dropna(subset=['three', 'four', 'five'], how='all')
subset=df2.columns[-k:]
subset=filter(lambda x: len(x) > 3, df2.columns)","[""df2.dropna(subset=['three', 'four', 'five'], how='all')""]","[""df2.dropna(subset=['three', 'four', 'five'], how='all')"", 'subset=df2.columns[-k:]', 'subset=filter(lambda x: len(x) > 3, df2.columns)']","[""df2.dropna(subset=['three', 'four', 'five'], how='all')""]",,
15002718,"grouped.agg(lambda x: x.iloc[0])
df = pd.DataFrame([[1, 2], [3, 4]])
g = df.groupby(0)
g.first()
g.agg(lambda x: x.iloc[0])
0   
g.agg({1: lambda x: x.iloc[0]})
g.nth(0)  
g.nth(-1)  
grouped['D'].agg({'result1' : ""sum"", 'result2' : ""mean""})","['grouped.agg(lambda x: x.iloc[0])', 'df = pd.DataFrame([[1, 2], [3, 4]])', 'g = df.groupby(0)', 'g.first()', 'g.agg(lambda x: x.iloc[0])', 'g.agg({1: lambda x: x.iloc[0]})', 'g.nth(0)  ', 'g.nth(-1)  ']","['grouped.agg(lambda x: x.iloc[0])', 'g = df.groupby(0)', 'g.first()', 'g.agg(lambda x: x.iloc[0])', '0   ', 'g.agg({1: lambda x: x.iloc[0]})', 'g.nth(0)  ', 'g.nth(-1)  ', 'grouped[\'D\'].agg({\'result1\' : ""sum"", \'result2\' : ""mean""})']","['grouped.agg(lambda x: x.iloc[0])', 'g = df.groupby(0)', 'g.first()', 'g.agg(lambda x: x.iloc[0])', 'g.agg({1: lambda x: x.iloc[0]})', 'g.nth(0)  ', 'g.nth(-1)  ']",,
15006495,"df = pd.DataFrame({""A"": range(1000), ""B"": range(1000)})
df
dtypes: int64(2)
df[:5]
df = pd.DataFrame({i: range(1000) for i in range(100)})
df.ix[:5, :10]","['df = pd.DataFrame({""A"": range(1000), ""B"": range(1000)})', 'df = pd.DataFrame({i: range(1000) for i in range(100)})']","['df', 'dtypes: int64(2)', 'df[:5]', 'df.ix[:5, :10]']",[],,
15009160,"import pandas as pd
len(z)",[],"['import pandas as pd', 'len(z)']",[],[],[]
15026839,import pandas as pd,[],['import pandas as pd'],[],[],[]
15030455,"import pandas as pd
from StringIO import StringIO
csv = """"""dummy,date,loc,x
bar,20090101,a,1
bar,20090102,a,3
bar,20090103,a,5
bar,20090101,b,1
bar,20090102,b,3
bar,20090103,b,5
""""""
df = pd.read_csv(StringIO(csv),
        index_col=[0,1],
        usecols=[1,2,3], 
        parse_dates=[0],
        header=0,
        names=[""date"", ""loc"", """", ""x""])","['df = pd.read_csv(StringIO(csv),']","['import pandas as pd', 'from StringIO import StringIO', 'csv = """"""dummy,date,loc,x', 'bar,20090101,a,1', 'bar,20090102,a,3', 'bar,20090103,a,5', 'bar,20090101,b,1', 'bar,20090102,b,3', 'bar,20090103,b,5', '""""""', 'df = pd.read_csv(StringIO(csv),', '        index_col=[0,1],', '        usecols=[1,2,3], ', '        parse_dates=[0],', '        header=0,', '        names=[""date"", ""loc"", """", ""x""])']","['df = pd.read_csv(StringIO(csv),']",,
15070110,"df
def f1(x):
    return 'blah_%1.2f' % x
def f2(x):
    return 'f2_%1.2f' % x",[],"['df', 'def f1(x):', ""    return 'blah_%1.2f' % x"", 'def f2(x):', ""    return 'f2_%1.2f' % x""]",[],[],[]
15073977,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(5, 10))
df[list(df.columns[:2]) + [7]]
df[col_[:2, ""col5"", 3:6]]","['df = pd.DataFrame(np.random.randn(5, 10))']","['import pandas as pd', 'import numpy as np', 'df[list(df.columns[:2]) + [7]]', 'df[col_[:2, ""col5"", 3:6]]']",[],,
15074395,"df = pd.DataFrame({'Name': ['foo', 'bar'] * 3,
                   'Rank': np.random.randint(0,3,6),
                   'Val': np.random.rand(6)})
grouped = df.groupby([""Name"", ""Rank""])
grouped.grouper.groups            
df[""GroupId""] = df.groupby([""Name"", ""Rank""]).grouper.group_info[0]
df","[""df = pd.DataFrame({'Name': ['foo', 'bar'] * 3,"", 'grouped = df.groupby([""Name"", ""Rank""])', 'grouped.grouper.groups            ', 'df[""GroupId""] = df.groupby([""Name"", ""Rank""]).grouper.group_info[0]']","[""                   'Rank': np.random.randint(0,3,6),"", ""                   'Val': np.random.rand(6)})"", 'grouped = df.groupby([""Name"", ""Rank""])', 'grouped.grouper.groups            ', 'df[""GroupId""] = df.groupby([""Name"", ""Rank""]).grouper.group_info[0]', 'df']","['grouped = df.groupby([""Name"", ""Rank""])', 'grouped.grouper.groups            ', 'df[""GroupId""] = df.groupby([""Name"", ""Rank""]).grouper.group_info[0]']",,
15097125,"import pandas as pd
import sqlite3
with sqlite3.connect(""whatever.sqlite"") as con:
    sql = ""SELECT * FROM table_name""
    df = pd.read_sql_query(sql, con)","['    df = pd.read_sql_query(sql, con)']","['import pandas as pd', 'import sqlite3', 'with sqlite3.connect(""whatever.sqlite"") as con:', '    sql = ""SELECT * FROM table_name""', '    df = pd.read_sql_query(sql, con)']","['    df = pd.read_sql_query(sql, con)']",,
15100193,"import pandas as pd
from StringIO import StringIO
csv = r""""""dummy,date,loc,x
bar,20090101,a,1
bar,20090102,a,3
bar,20090103,a,5
bar,20090101,b,1
bar,20090102,b,3
bar,20090103,b,5""""""
df = pd.read_csv(StringIO(csv),
        index_col=[""date"", ""loc""], 
        usecols=[""dummy"", ""date"", ""loc"", ""x""],
        parse_dates=[""date""],
        header=0,
        names=[""dummy"", ""date"", ""loc"", ""x""])
del df['dummy']","['df = pd.read_csv(StringIO(csv),']","['import pandas as pd', 'from StringIO import StringIO', 'csv = r""""""dummy,date,loc,x', 'bar,20090101,a,1', 'bar,20090102,a,3', 'bar,20090103,a,5', 'bar,20090101,b,1', 'bar,20090102,b,3', 'bar,20090103,b,5""""""', 'df = pd.read_csv(StringIO(csv),', '        index_col=[""date"", ""loc""], ', '        usecols=[""dummy"", ""date"", ""loc"", ""x""],', '        parse_dates=[""date""],', '        header=0,', '        names=[""dummy"", ""date"", ""loc"", ""x""])', ""del df['dummy']""]","['df = pd.read_csv(StringIO(csv),']",,
15112264,df.values.T.tolist(),['df.values.T.tolist()'],['df.values.T.tolist()'],['df.values.T.tolist()'],,
15125793,"def calculate(s):
    a = s['path'] + 2*s['row'] 
    b = s['path'] * 0.153
    return pd.Series(dict(col1=a, col2=b))
st.ix[i]['a'] = a
st.ix[i, 'a'] = a","['    return pd.Series(dict(col1=a, col2=b))']","['def calculate(s):', ""    a = s['path'] + 2*s['row'] "", ""    b = s['path'] * 0.153"", ""st.ix[i]['a'] = a"", ""st.ix[i, 'a'] = a""]",[],,
15139677,,[],[''],[],[],[]
15144847,"import pandas as pd
import numpy as np
df = pd.DataFrame({'A':[9,10]*6,
                   'B':range(23,35),
                   'C':range(-6,6)})
print(df)
idx = (df['C']!=0) & (df['A']==10) & (df['B']<30)
df.loc[idx, 'A'] += df.loc[idx, 'B'] * df.loc[idx, 'C']
print(df)","[""df = pd.DataFrame({'A':[9,10]*6,"", ""df.loc[idx, 'A'] += df.loc[idx, 'B'] * df.loc[idx, 'C']""]","['import pandas as pd', 'import numpy as np', ""                   'B':range(23,35),"", ""                   'C':range(-6,6)})"", 'print(df)', ""idx = (df['C']!=0) & (df['A']==10) & (df['B']<30)"", ""df.loc[idx, 'A'] += df.loc[idx, 'B'] * df.loc[idx, 'C']"", 'print(df)']","[""df.loc[idx, 'A'] += df.loc[idx, 'B'] * df.loc[idx, 'C']""]",,
15203886,"[t.value // 10 ** 9 for t in tsframe.index]
t = pd.Timestamp('2000-02-11 00:00:00')
t
t.value
time.mktime(t.timetuple())
Out[4]: 950227200.0
tsframe.index.astype(np.int64) // 10 ** 9","['[t.value // 10 ** 9 for t in tsframe.index]', ""t = pd.Timestamp('2000-02-11 00:00:00')"", 't.value', 'time.mktime(t.timetuple())', 'tsframe.index.astype(np.int64) // 10 ** 9']","['[t.value // 10 ** 9 for t in tsframe.index]', ""t = pd.Timestamp('2000-02-11 00:00:00')"", 't', 't.value', 'time.mktime(t.timetuple())', 'Out[4]: 950227200.0', 'tsframe.index.astype(np.int64) // 10 ** 9']","['[t.value // 10 ** 9 for t in tsframe.index]', ""t = pd.Timestamp('2000-02-11 00:00:00')"", 't.value', 'time.mktime(t.timetuple())', 'tsframe.index.astype(np.int64) // 10 ** 9']",,
15204235,"import numpy as np
import pandas as pd
from datetime import datetime
dates = [datetime(2012, 5, 1), datetime(2012, 5, 2), datetime(2012, 5, 3)]
index.astype(np.int64)
index.astype(np.int64) // 10**9
Out[6]: array([1335830400, 1335916800, 1336003200], dtype=int64)","['index.astype(np.int64)', 'index.astype(np.int64) // 10**9']","['import numpy as np', 'import pandas as pd', 'from datetime import datetime', 'dates = [datetime(2012, 5, 1), datetime(2012, 5, 2), datetime(2012, 5, 3)]', 'index.astype(np.int64)', 'index.astype(np.int64) // 10**9', 'Out[6]: array([1335830400, 1335916800, 1336003200], dtype=int64)']","['index.astype(np.int64)', 'index.astype(np.int64) // 10**9']",,
15213171,"df[columns] = df[columns].convert_objects(convert_numeric=True)
x = pd.read_csv(StringIO.StringIO(data), dtype={'a': np.float32}, delim_whitespace=True)
x
x.dtypes
pd.__version__
quit()","['df[columns] = df[columns].convert_objects(convert_numeric=True)', ""x = pd.read_csv(StringIO.StringIO(data), dtype={'a': np.float32}, delim_whitespace=True)"", 'x.dtypes']","['df[columns] = df[columns].convert_objects(convert_numeric=True)', ""x = pd.read_csv(StringIO.StringIO(data), dtype={'a': np.float32}, delim_whitespace=True)"", 'x', 'x.dtypes', 'pd.__version__', 'quit()']","['df[columns] = df[columns].convert_objects(convert_numeric=True)', ""x = pd.read_csv(StringIO.StringIO(data), dtype={'a': np.float32}, delim_whitespace=True)"", 'x.dtypes']",,
15220374,"df.a.dtype = pd.np.float32
df.a.dtype
Out[23]: dtype('float32')","['df.a.dtype = pd.np.float32', 'df.a.dtype']","['df.a.dtype = pd.np.float32', 'df.a.dtype', ""Out[23]: dtype('float32')""]","['df.a.dtype = pd.np.float32', 'df.a.dtype']",,
15222976,"source.groupby(['Country','City']).agg(lambda x: stats.mode(x)[0][0])","[""source.groupby(['Country','City']).agg(lambda x: stats.mode(x)[0][0])""]","[""source.groupby(['Country','City']).agg(lambda x: stats.mode(x)[0][0])""]","[""source.groupby(['Country','City']).agg(lambda x: stats.mode(x)[0][0])""]",,
15223034,"import pandas as pd
source = pd.DataFrame({'Country' : ['USA', 'USA', 'Russia','USA'], 
                  'City' : ['New-York', 'New-York', 'Sankt-Petersburg', 'New-York'],
                  'Short name' : ['NY','New','Spb','NY']})
source.groupby(['Country','City']).agg(lambda x:x.value_counts().index[0])","[""source = pd.DataFrame({'Country' : ['USA', 'USA', 'Russia','USA'], "", ""source.groupby(['Country','City']).agg(lambda x:x.value_counts().index[0])""]","['import pandas as pd', ""                  'City' : ['New-York', 'New-York', 'Sankt-Petersburg', 'New-York'],"", ""                  'Short name' : ['NY','New','Spb','NY']})"", ""source.groupby(['Country','City']).agg(lambda x:x.value_counts().index[0])""]","[""source.groupby(['Country','City']).agg(lambda x:x.value_counts().index[0])""]",,
15244074,"import pandas as pd
df = pd.DataFrame()
with open(filepath, 'r') as f:
    for line in f:
        df = pd.concat( [df, pd.DataFrame([tuple(line.strip().split(','))])], ignore_index=True )","['df = pd.DataFrame()', ""        df = pd.concat( [df, pd.DataFrame([tuple(line.strip().split(','))])], ignore_index=True )""]","['import pandas as pd', ""with open(filepath, 'r') as f:"", '    for line in f:']","[""        df = pd.concat( [df, pd.DataFrame([tuple(line.strip().split(','))])], ignore_index=True )""]",,
15248239,"import pandas as pd
p1 = {'name': 'willy', 'age': 10}
p2 = {'name': 'willy', 'age': 11}
p3 = {'name': 'zoe', 'age': 10}
df = pd.DataFrame([p1, p2, p3])
df
df.duplicated('name')","['df = pd.DataFrame([p1, p2, p3])', ""df.duplicated('name')""]","['import pandas as pd', ""p1 = {'name': 'willy', 'age': 10}"", ""p2 = {'name': 'willy', 'age': 11}"", ""p3 = {'name': 'zoe', 'age': 10}"", 'df', ""df.duplicated('name')""]","[""df.duplicated('name')""]",,
15252012,"1,2,3
1,2,3,4
1,2,3,4,5
1,2
1,2,3,4
my_cols = [""A"", ""B"", ""C"", ""D"", ""E""]
pd.read_csv(""ragged.csv"", names=my_cols, engine='python')","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['1,2,3', '1,2,3,4', '1,2,3,4,5', '1,2', '1,2,3,4', 'my_cols = [""A"", ""B"", ""C"", ""D"", ""E""]', 'pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']"
15262146,"df.groupby('A_id').apply(lambda x: pd.Series(dict(
    sum_up=(x.B == 'up').sum(),
    sum_down=(x.B == 'down').sum(),
    over_200_up=((x.B == 'up') & (x.C > 200)).sum()
)))
A_id                               ","[""df.groupby('A_id').apply(lambda x: pd.Series(dict("", ""    sum_up=(x.B == 'up').sum(),"", ""    sum_down=(x.B == 'down').sum(),"", ""    over_200_up=((x.B == 'up') & (x.C > 200)).sum()""]","[""    sum_up=(x.B == 'up').sum(),"", ""    sum_down=(x.B == 'down').sum(),"", ""    over_200_up=((x.B == 'up') & (x.C > 200)).sum()"", ')))', 'A_id                               ']","[""df.groupby('A_id').apply(lambda x: pd.Series(dict("", ""    sum_up=(x.B == 'up').sum(),"", ""    sum_down=(x.B == 'down').sum(),"", ""    over_200_up=((x.B == 'up') & (x.C > 200)).sum()""]",,
15300930,"import pandas as pd
grouper = pd.TimeGrouper(""1M"")
df['normed'] = df.groupby(grouper).transform(lambda x: x/x.mean())","[""df['normed'] = df.groupby(grouper).transform(lambda x: x/x.mean())""]","['import pandas as pd', 'grouper = pd.TimeGrouper(""1M"")', ""df['normed'] = df.groupby(grouper).transform(lambda x: x/x.mean())""]","[""df['normed'] = df.groupby(grouper).transform(lambda x: x/x.mean())""]",,
15315507,"import pandas as pd
from random import randint
df = pd.DataFrame({'A': [randint(1, 9) for x in xrange(10)],
                   'B': [randint(1, 9)*10 for x in xrange(10)],
                   'C': [randint(1, 9)*100 for x in xrange(10)]})
df
df[""B""] > 50
Name: B
df[""A""][(df[""B""] > 50) & (df[""C""] == 900)]
df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""]
df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""].values
array([5, 8], dtype=int64)
df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""] *= 1000
df","[""df = pd.DataFrame({'A': [randint(1, 9) for x in xrange(10)],"", 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""]', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""].values', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""] *= 1000']","['import pandas as pd', 'from random import randint', ""                   'B': [randint(1, 9)*10 for x in xrange(10)],"", ""                   'C': [randint(1, 9)*100 for x in xrange(10)]})"", 'df', 'df[""B""] > 50', 'Name: B', 'df[""A""][(df[""B""] > 50) & (df[""C""] == 900)]', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""]', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""].values', 'array([5, 8], dtype=int64)', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""] *= 1000', 'df']","['df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""]', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""].values', 'df.loc[(df[""B""] > 50) & (df[""C""] == 900), ""A""] *= 1000']",,
15322715,"idx = df.groupby('word')['count'].idxmax()
print(idx)
word
Name: count
print(df.loc[idx, ['word', 'tag']])
import pandas as pd
df = pd.DataFrame({'word':'a the a an the'.split(),
                   'tag': list('SSTTT'),
                   'count': [30, 20, 60, 5, 10]})
print(df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))
word
N = 10000
df = pd.DataFrame({'word':'a the a an the'.split()*N,
                   'tag': list('SSTTT')*N,
                   'count': [30, 20, 60, 5, 10]*N})
def using_apply(df):
    return (df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))
def using_idxmax_loc(df):
    idx = df.groupby('word')['count'].idxmax()
    return df.loc[idx, ['word', 'tag']]
df2 = df.loc[idx, ['word', 'tag']].set_index('word')
df2
df2.to_dict()['tag']
Out[38]: {'a': 'T', 'an': 'T', 'the': 'S'}","[""idx = df.groupby('word')['count'].idxmax()"", ""print(df.loc[idx, ['word', 'tag']])"", ""df = pd.DataFrame({'word':'a the a an the'.split(),"", ""print(df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", ""df = pd.DataFrame({'word':'a the a an the'.split()*N,"", ""    return (df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", ""    idx = df.groupby('word')['count'].idxmax()"", ""    return df.loc[idx, ['word', 'tag']]"", ""df2 = df.loc[idx, ['word', 'tag']].set_index('word')"", ""df2.to_dict()['tag']""]","[""idx = df.groupby('word')['count'].idxmax()"", 'print(idx)', 'word', 'Name: count', ""print(df.loc[idx, ['word', 'tag']])"", 'import pandas as pd', ""                   'tag': list('SSTTT'),"", ""                   'count': [30, 20, 60, 5, 10]})"", ""print(df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", 'word', 'N = 10000', ""                   'tag': list('SSTTT')*N,"", ""                   'count': [30, 20, 60, 5, 10]*N})"", 'def using_apply(df):', ""    return (df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", 'def using_idxmax_loc(df):', ""    idx = df.groupby('word')['count'].idxmax()"", ""    return df.loc[idx, ['word', 'tag']]"", ""df2 = df.loc[idx, ['word', 'tag']].set_index('word')"", 'df2', ""df2.to_dict()['tag']"", ""Out[38]: {'a': 'T', 'an': 'T', 'the': 'S'}""]","[""idx = df.groupby('word')['count'].idxmax()"", ""print(df.loc[idx, ['word', 'tag']])"", ""df = pd.DataFrame({'word':'a the a an the'.split(),"", ""print(df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", ""df = pd.DataFrame({'word':'a the a an the'.split()*N,"", ""    return (df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))"", ""    idx = df.groupby('word')['count'].idxmax()"", ""    return df.loc[idx, ['word', 'tag']]"", ""df2 = df.loc[idx, ['word', 'tag']].set_index('word')"", ""df2.to_dict()['tag']""]",,
15322920,,[],[''],[],[],[]
15333283,df.b.str.contains('^f'),"[""df.b.str.contains('^f')""]","[""df.b.str.contains('^f')""]","[""df.b.str.contains('^f')""]",,
15361537,x[x.columns[0]],[],['x[x.columns[0]]'],[],[],[]
15362700,"import pandas as pd
df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})
df
s = df.ix[:,0]
type(s)","[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]","['import pandas as pd', 'df', 's = df.ix[:,0]', 'type(s)']",[],"[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]","[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]"
15364468,"df.iloc[:,0]","['df.iloc[:,0]']","['df.iloc[:,0]']","['df.iloc[:,0]']",,
15375176,"from pandas import *
d = {""my_label"": Series(['A','B','A','C','D','D','E'])}
df = DataFrame(d)
def as_perc(value, total):
    return value/float(total)
def get_count(values):
    return len(values)
grouped_count = df.groupby(""my_label"").my_label.agg(get_count)
data = grouped_count.apply(as_perc, total=df.my_label.count())","['grouped_count = df.groupby(""my_label"").my_label.agg(get_count)', 'data = grouped_count.apply(as_perc, total=df.my_label.count())']","['from pandas import *', 'd = {""my_label"": Series([\'A\',\'B\',\'A\',\'C\',\'D\',\'D\',\'E\'])}', 'df = DataFrame(d)', 'def as_perc(value, total):', '    return value/float(total)', 'def get_count(values):', '    return len(values)', 'grouped_count = df.groupby(""my_label"").my_label.agg(get_count)', 'data = grouped_count.apply(as_perc, total=df.my_label.count())']","['grouped_count = df.groupby(""my_label"").my_label.agg(get_count)', 'data = grouped_count.apply(as_perc, total=df.my_label.count())']",,
15411596,"table.groupby('YEARMONTH').CLIENTCODE.nunique()
table
table.groupby('YEARMONTH').CLIENTCODE.nunique()
YEARMONTH","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", 'table', ""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", 'YEARMONTH']","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]"
15433426,"import pandas as pd
from datetime import timedelta
df = pd.read_csv(""hourmelt.csv"", sep=r""\s+"")
df = pd.melt(df, id_vars=[""Date""])
df = df.rename(columns={'variable': 'hour'})
df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)
combined = df.apply(lambda x: 
                    pd.to_datetime(x['Date'], dayfirst=True) + 
                    timedelta(hours=int(x['hour'])), axis=1)
df['Date'] = combined
del df['hour']
df = df.sort(""Date"")
import pandas as pd
from datetime import datetime, timedelta
df = pd.read_csv(""hourmelt.csv"", sep=r""\s+"")
df
df = pd.melt(df, id_vars=[""Date""])
df = df.rename(columns={'variable': 'hour'})
df
df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)
df
combined = df.apply(lambda x: pd.to_datetime(x['Date'], dayfirst=True) + timedelta(hours=int(x['hour'])), axis=1)
combined
df['Date'] = combined
del df['hour']
df = df.sort(""Date"")
df","['df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", 'combined = df.apply(lambda x: ', ""                    pd.to_datetime(x['Date'], dayfirst=True) + "", 'df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", ""combined = df.apply(lambda x: pd.to_datetime(x['Date'], dayfirst=True) + timedelta(hours=int(x['hour'])), axis=1)""]","['import pandas as pd', 'from datetime import timedelta', 'df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", 'combined = df.apply(lambda x: ', ""                    pd.to_datetime(x['Date'], dayfirst=True) + "", ""                    timedelta(hours=int(x['hour'])), axis=1)"", ""df['Date'] = combined"", ""del df['hour']"", 'df = df.sort(""Date"")', 'import pandas as pd', 'from datetime import datetime, timedelta', 'df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", 'df', ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", 'df', ""combined = df.apply(lambda x: pd.to_datetime(x['Date'], dayfirst=True) + timedelta(hours=int(x['hour'])), axis=1)"", 'combined', ""df['Date'] = combined"", ""del df['hour']"", 'df = df.sort(""Date"")', 'df']","['df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", 'combined = df.apply(lambda x: ', ""                    pd.to_datetime(x['Date'], dayfirst=True) + "", 'df = pd.read_csv(""hourmelt.csv"", sep=r""\\s+"")', 'df = pd.melt(df, id_vars=[""Date""])', ""df = df.rename(columns={'variable': 'hour'})"", ""df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)"", ""combined = df.apply(lambda x: pd.to_datetime(x['Date'], dayfirst=True) + timedelta(hours=int(x['hour'])), axis=1)""]",,
15455455,"df = pd.Panel.from_dict(d).to_frame()
pd.concat(map(pd.DataFrame, d.itervalues()), keys=d.keys()).stack().unstack(0)","['df = pd.Panel.from_dict(d).to_frame()', 'pd.concat(map(pd.DataFrame, d.itervalues()), keys=d.keys()).stack().unstack(0)']",[],"['df = pd.Panel.from_dict(d).to_frame()', 'pd.concat(map(pd.DataFrame, d.itervalues()), keys=d.keys()).stack().unstack(0)']",,
15466103,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
sin = np.sin
cos = np.cos
pi = np.pi
N = 100
x = np.linspace(0, pi, N)
a = sin(x)
b = cos(x)
df = pd.DataFrame({
    'A': [True]*N + [False]*N,
    'B': np.hstack((a,b))
    })
for key, grp in df.groupby(['A']):
    plt.plot(grp['B'], label=key)
    grp['D'] = pd.rolling_mean(grp['B'], window=5)    
    plt.plot(grp['D'], label='rolling ({k})'.format(k=key))
plt.legend(loc='best')    
plt.show()","['df = pd.DataFrame({', ""for key, grp in df.groupby(['A']):"", ""    plt.plot(grp['B'], label=key)"", ""    plt.plot(grp['D'], label='rolling ({k})'.format(k=key))""]","['import pandas as pd', 'import numpy as np', 'import matplotlib.pyplot as plt', 'sin = np.sin', 'cos = np.cos', 'pi = np.pi', 'N = 100', 'x = np.linspace(0, pi, N)', 'a = sin(x)', 'b = cos(x)', ""    'A': [True]*N + [False]*N,"", ""    'B': np.hstack((a,b))"", '    })', ""for key, grp in df.groupby(['A']):"", ""    plt.plot(grp['B'], label=key)"", ""    grp['D'] = pd.rolling_mean(grp['B'], window=5)    "", ""    plt.plot(grp['D'], label='rolling ({k})'.format(k=key))"", ""plt.legend(loc='best')    "", 'plt.show()']","[""for key, grp in df.groupby(['A']):"", ""    plt.plot(grp['B'], label=key)"", ""    plt.plot(grp['D'], label='rolling ({k})'.format(k=key))""]",,
15467189,"df
df.select(lambda x: x[1] in ['SPY','GLD'])","[""df.select(lambda x: x[1] in ['SPY','GLD'])""]","['df', ""df.select(lambda x: x[1] in ['SPY','GLD'])""]","[""df.select(lambda x: x[1] in ['SPY','GLD'])""]",,
15557663,"df = pd.DataFrame(range(5))
eq2 = df[0] == 2
df_no_2 = df[~eq2]
df_no_2
df_no_2.reset_index(drop=True)","['df = pd.DataFrame(range(5))', 'df_no_2.reset_index(drop=True)']","['eq2 = df[0] == 2', 'df_no_2 = df[~eq2]', 'df_no_2', 'df_no_2.reset_index(drop=True)']",['df_no_2.reset_index(drop=True)'],,
15558350,"def transpose_table(h_in, table_path, h_out, group_name=""data"", group_path=""/""):
    tb = h_in.getNode(table_path)
    grp = h_out.createGroup(group_path, group_name, filters=tables.Filters(complevel=1))
    for col_name in tb.colnames:
        logger.debug(""Processing %s"", col_name)
        col_data = tb.col(col_name)
        arr = h_out.createCArray(grp,
                                 col_name,
                                 tables.Atom.from_dtype(col_data.dtype),
                                 col_data.shape)
        arr[:] = col_data
    h_out.flush()
def read_hdf5(hdf5_path, group_path=""/data"", columns=None):
    """"""Read a transposed data set from a HDF5 file.""""""
    if isinstance(hdf5_path, tables.file.File):
        hf = hdf5_path
    else:
        hf = tables.openFile(hdf5_path)
    grp = hf.getNode(group_path)
    if columns is None:
        data = [(child.name, child[:]) for child in grp]
    else:
        data = [(child.name, child[:]) for child in grp if child.name in columns]
    for i in range(len(data)):
        name, vec = data[i]
        if vec.dtype == np.float32:
            data[i] = (name, vec.astype(np.float64))
    if not isinstance(hdf5_path, tables.file.File):
        hf.close()
    return pd.DataFrame.from_items(data)","['                                 tables.Atom.from_dtype(col_data.dtype),', '                                 col_data.shape)', '        if vec.dtype == np.float32:', '            data[i] = (name, vec.astype(np.float64))', '    return pd.DataFrame.from_items(data)']","['def transpose_table(h_in, table_path, h_out, group_name=""data"", group_path=""/""):', '    tb = h_in.getNode(table_path)', '    grp = h_out.createGroup(group_path, group_name, filters=tables.Filters(complevel=1))', '    for col_name in tb.colnames:', '        logger.debug(""Processing %s"", col_name)', '        col_data = tb.col(col_name)', '        arr = h_out.createCArray(grp,', '                                 col_name,', '                                 tables.Atom.from_dtype(col_data.dtype),', '                                 col_data.shape)', '        arr[:] = col_data', '    h_out.flush()', 'def read_hdf5(hdf5_path, group_path=""/data"", columns=None):', '    """"""Read a transposed data set from a HDF5 file.""""""', '    if isinstance(hdf5_path, tables.file.File):', '        hf = hdf5_path', '    else:', '        hf = tables.openFile(hdf5_path)', '    grp = hf.getNode(group_path)', '    if columns is None:', '        data = [(child.name, child[:]) for child in grp]', '    else:', '        data = [(child.name, child[:]) for child in grp if child.name in columns]', '    for i in range(len(data)):', '        name, vec = data[i]', '        if vec.dtype == np.float32:', '            data[i] = (name, vec.astype(np.float64))', '    if not isinstance(hdf5_path, tables.file.File):', '        hf.close()']","['                                 tables.Atom.from_dtype(col_data.dtype),', '                                 col_data.shape)', '        if vec.dtype == np.float32:', '            data[i] = (name, vec.astype(np.float64))', '    return pd.DataFrame.from_items(data)']",,
15570546,"import pandas as pd
import StringIO
incsv = StringIO.StringIO(""""""Date,State,City,SalesToday,SalesMTD,SalesYTD
20130320,stA,ctA,20,400,1000
20130320,stA,ctB,30,500,1100
20130320,stB,ctC,10,500,900
20130320,stB,ctD,40,200,1300
20130320,stC,ctF,30,300,800"""""")
df = pd.read_csv(incsv, index_col=['Date'], parse_dates=True)
dfsum = df.groupby('State', as_index=False).sum()
dfsum['City'] = 'All'
dfsum.append(df).set_index(['State','City']).sort_index()","[""df = pd.read_csv(incsv, index_col=['Date'], parse_dates=True)"", ""dfsum = df.groupby('State', as_index=False).sum()"", ""dfsum.append(df).set_index(['State','City']).sort_index()""]","['import pandas as pd', 'import StringIO', 'incsv = StringIO.StringIO(""""""Date,State,City,SalesToday,SalesMTD,SalesYTD', '20130320,stA,ctA,20,400,1000', '20130320,stA,ctB,30,500,1100', '20130320,stB,ctC,10,500,900', '20130320,stB,ctD,40,200,1300', '20130320,stC,ctF,30,300,800"""""")', ""df = pd.read_csv(incsv, index_col=['Date'], parse_dates=True)"", ""dfsum = df.groupby('State', as_index=False).sum()"", ""dfsum['City'] = 'All'"", ""dfsum.append(df).set_index(['State','City']).sort_index()""]","[""df = pd.read_csv(incsv, index_col=['Date'], parse_dates=True)"", ""dfsum = df.groupby('State', as_index=False).sum()"", ""dfsum.append(df).set_index(['State','City']).sort_index()""]",,
15574875,"table = pivot_table(df, values=['SalesToday', 'SalesMTD','SalesYTD'],\
                     rows=['State'], cols=['City'], aggfunc=np.sum, margins=True)
table.stack('City')","[""                     rows=['State'], cols=['City'], aggfunc=np.sum, margins=True)"", ""table.stack('City')""]","[""table = pivot_table(df, values=['SalesToday', 'SalesMTD','SalesYTD'],\\"", ""                     rows=['State'], cols=['City'], aggfunc=np.sum, margins=True)"", ""table.stack('City')""]","[""                     rows=['State'], cols=['City'], aggfunc=np.sum, margins=True)"", ""table.stack('City')""]",,
15590006,"d1.groupby('ExamenYear').agg({'Participated': len, 
                              'Passed': lambda x: sum(x == 'yes')})","[""d1.groupby('ExamenYear').agg({'Participated': len, ""]","[""d1.groupby('ExamenYear').agg({'Participated': len, "", ""                              'Passed': lambda x: sum(x == 'yes')})""]","[""d1.groupby('ExamenYear').agg({'Participated': len, ""]",,
15611666,"def ZahlOccurence_0(x):
      return pd.Series({'All': len(x['StudentID']),
                       'Part': sum(x['Participated'] == 'yes'),
                       'Pass' :  sum(x['Passed'] == 'yes')})
ExamenYear                 
import numpy as np
d1['testValue'] = np.random.randn(len(d1))
def ZahlOccurence_1(x):
    return pd.Series({'All': len(x['StudentID']),
        'Part': sum(x['Participated'] == 'yes'),
        'Pass' :  sum(x['Passed'] == 'yes'),
        'test' : x['testValue'].mean()})
d1.groupby('ExamenYear').apply(ZahlOccurence_1)
ExamenYear                           ","[""      return pd.Series({'All': len(x['StudentID']),"", ""    return pd.Series({'All': len(x['StudentID']),"", ""        'test' : x['testValue'].mean()})"", ""d1.groupby('ExamenYear').apply(ZahlOccurence_1)""]","['def ZahlOccurence_0(x):', ""                       'Part': sum(x['Participated'] == 'yes'),"", ""                       'Pass' :  sum(x['Passed'] == 'yes')})"", 'ExamenYear                 ', 'import numpy as np', ""d1['testValue'] = np.random.randn(len(d1))"", 'def ZahlOccurence_1(x):', ""        'Part': sum(x['Participated'] == 'yes'),"", ""        'Pass' :  sum(x['Passed'] == 'yes'),"", ""        'test' : x['testValue'].mean()})"", ""d1.groupby('ExamenYear').apply(ZahlOccurence_1)"", 'ExamenYear                           ']","[""        'test' : x['testValue'].mean()})"", ""d1.groupby('ExamenYear').apply(ZahlOccurence_1)""]",,
15705958,"df
df.groupby(['Mt'], sort=False)['count'].max()
idx = df.groupby(['Mt'])['count'].transform(max) == df['count']
df[idx]
df['count_max'] = df.groupby(['Mt'])['count'].transform(max)
df","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","['df', ""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", 'df[idx]', ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)"", 'df']","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]"
15723905,"df['col_name'] = df['col_name'].astype(object)
df = df.astype(object)
df['col_name'] = df['col_name'].astype('category')","[""df['col_name'] = df['col_name'].astype(object)"", 'df = df.astype(object)', ""df['col_name'] = df['col_name'].astype('category')""]","[""df['col_name'] = df['col_name'].astype(object)"", 'df = df.astype(object)', ""df['col_name'] = df['col_name'].astype('category')""]","[""df['col_name'] = df['col_name'].astype(object)"", 'df = df.astype(object)', ""df['col_name'] = df['col_name'].astype('category')""]",,
15723994,"df = pd.DataFrame({'a' : [1, 2, 3, 4, 5], 'b' : ['yes', 'no', 'yes', 'no', 'absent']})
df
df['c'] = pd.Categorical.from_array(df.b).labels
df","[""df = pd.DataFrame({'a' : [1, 2, 3, 4, 5], 'b' : ['yes', 'no', 'yes', 'no', 'absent']})""]","['df', ""df['c'] = pd.Categorical.from_array(df.b).labels"", 'df']",[],,
15742147,"df.loc[df['Value'].idxmax()]
Name: 7
df = df.reset_index()","[""df.loc[df['Value'].idxmax()]"", 'df = df.reset_index()']","[""df.loc[df['Value'].idxmax()]"", 'Name: 7', 'df = df.reset_index()']","[""df.loc[df['Value'].idxmax()]"", 'df = df.reset_index()']",,
15752582,"df.set_index('month')
df = pd.DataFrame([[1, datetime(2011,1,1)], [2, datetime(2011,1,2)]], columns=['a', 'b'])
df
df.set_index('b')
b            ","[""df.set_index('month')"", ""df = pd.DataFrame([[1, datetime(2011,1,1)], [2, datetime(2011,1,2)]], columns=['a', 'b'])"", ""df.set_index('b')""]","[""df.set_index('month')"", 'df', ""df.set_index('b')"", 'b            ']","[""df.set_index('month')"", ""df.set_index('b')""]",,
15756128,"data2 = data1.reset_index()
data3 = data2.set_index([""Bool"", ""Dir"", ""index""])   
running_sum = data3.groupby(level=[0,1,2]).sum().groupby(level=[0,1]).cumsum()","['data2 = data1.reset_index()', 'data3 = data2.set_index([""Bool"", ""Dir"", ""index""])   ', 'running_sum = data3.groupby(level=[0,1,2]).sum().groupby(level=[0,1]).cumsum()']","['data2 = data1.reset_index()', 'data3 = data2.set_index([""Bool"", ""Dir"", ""index""])   ', 'running_sum = data3.groupby(level=[0,1,2]).sum().groupby(level=[0,1]).cumsum()']","['data2 = data1.reset_index()', 'data3 = data2.set_index([""Bool"", ""Dir"", ""index""])   ', 'running_sum = data3.groupby(level=[0,1,2]).sum().groupby(level=[0,1]).cumsum()']",,
15772263,"pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)
enddate
df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'enddate', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']"
15772330,"df = pd.DataFrame({'A':range(10), 'B':range(10)})
df
df.reindex(np.random.permutation(df.index))","[""df = pd.DataFrame({'A':range(10), 'B':range(10)})"", 'df.reindex(np.random.permutation(df.index))']","['df', 'df.reindex(np.random.permutation(df.index))']",['df.reindex(np.random.permutation(df.index))'],,
15772356,,[],[''],[],[],[]
15778297,"import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)",[],"['import warnings', ""warnings.simplefilter(action='ignore', category=FutureWarning)""]",[],[],[]
15786557,"def _sw(df, up_rows=10, down_rows=5, left_cols=4, right_cols=3, return_df=False):
    ncol, nrow = len(df.columns), len(df)
    if ncol <= (left_cols + right_cols) :
        up_pt = df.ix[0:up_rows, :]         
        down_pt = df.ix[-down_rows:, :]
    else:                                   
        pt_a = df.ix[0:up_rows,  0:left_cols]
        pt_b = df.ix[0:up_rows,  -right_cols:]
        pt_c = df[-down_rows:].ix[:,0:left_cols]
        pt_d = df[-down_rows:].ix[:,-right_cols:]
        up_pt   = pt_a.join(pt_b, how='inner')
        down_pt = pt_c.join(pt_d, how='inner')
        up_pt.insert(left_cols, '..', '..')
        down_pt.insert(left_cols, '..', '..')
    overlap_qty = len(up_pt) + len(down_pt) - len(df)
    down_pt = down_pt.drop(down_pt.index[range(overlap_qty)]) 
    dt_str_list = down_pt.to_string().split('\n') 
    start_row = (1 if df.index.names[0] is None else 2) ","[""        up_pt   = pt_a.join(pt_b, how='inner')"", ""        down_pt = pt_c.join(pt_d, how='inner')"", ""        up_pt.insert(left_cols, '..', '..')"", ""        down_pt.insert(left_cols, '..', '..')"", '    down_pt = down_pt.drop(down_pt.index[range(overlap_qty)]) ', ""    dt_str_list = down_pt.to_string().split('\\n') "", '    start_row = (1 if df.index.names[0] is None else 2) ']","['def _sw(df, up_rows=10, down_rows=5, left_cols=4, right_cols=3, return_df=False):', '    ncol, nrow = len(df.columns), len(df)', '    if ncol <= (left_cols + right_cols) :', '        up_pt = df.ix[0:up_rows, :]         ', '        down_pt = df.ix[-down_rows:, :]', '    else:                                   ', '        pt_a = df.ix[0:up_rows,  0:left_cols]', '        pt_b = df.ix[0:up_rows,  -right_cols:]', '        pt_c = df[-down_rows:].ix[:,0:left_cols]', '        pt_d = df[-down_rows:].ix[:,-right_cols:]', ""        up_pt   = pt_a.join(pt_b, how='inner')"", ""        down_pt = pt_c.join(pt_d, how='inner')"", ""        up_pt.insert(left_cols, '..', '..')"", ""        down_pt.insert(left_cols, '..', '..')"", '    overlap_qty = len(up_pt) + len(down_pt) - len(df)', '    down_pt = down_pt.drop(down_pt.index[range(overlap_qty)]) ', ""    dt_str_list = down_pt.to_string().split('\\n') "", '    start_row = (1 if df.index.names[0] is None else 2) ']","[""        up_pt   = pt_a.join(pt_b, how='inner')"", ""        down_pt = pt_c.join(pt_d, how='inner')"", ""        up_pt.insert(left_cols, '..', '..')"", ""        down_pt.insert(left_cols, '..', '..')"", '    down_pt = down_pt.drop(down_pt.index[range(overlap_qty)]) ', ""    dt_str_list = down_pt.to_string().split('\\n') "", '    start_row = (1 if df.index.names[0] is None else 2) ']",,
15799355,"df.groupby(pd.Grouper(freq='2D', level=-1))
level_values = df.index.get_level_values
result = (df.groupby([level_values(i) for i in [0,1]]
                      +[pd.Grouper(freq='2D', level=-1)]).sum())
import numpy as np
import pandas as pd
import datetime as DT
def using_Grouper(df):
    level_values = df.index.get_level_values
    return (df.groupby([level_values(i) for i in [0,1]]
                       +[pd.Grouper(freq='2D', level=-1)]).sum())
def using_reset_index(df):
    df = df.reset_index(level=[0, 1])
    return df.groupby(['State','City']).resample('2D').sum()
def using_stack(df):
    return (df.unstack(level=[0,1])
              .resample('2D').sum()
              .stack(level=[2,1])
              .swaplevel(2,0))
def make_orig():
    values_a = range(16)
    values_b = range(10, 26)
    states = ['Georgia']*8 + ['Alabama']*8
    cities = ['Atlanta']*4 + ['Savanna']*4 + ['Mobile']*4 + ['Montgomery']*4
    dates = pd.DatetimeIndex([DT.date(2012,1,1)+DT.timedelta(days = i) for i in range(4)]*4)
    df = pd.DataFrame(
        {'value_a': values_a, 'value_b': values_b},
        index = [states, cities, dates])
    df.index.names = ['State', 'City', 'Date']
    return df
def make_df(N):
    dates = pd.date_range('2000-1-1', periods=N)
    states = np.arange(50)
    cities = np.arange(10)
    index = pd.MultiIndex.from_product([states, cities, dates], 
                                       names=['State', 'City', 'Date'])
    df = pd.DataFrame(np.random.randint(10, size=(len(index),2)), index=index,
                      columns=['value_a', 'value_b'])
    return df
df = make_orig()
print(using_Grouper(df))
df = make_df(10)
len(df)","[""df.groupby(pd.Grouper(freq='2D', level=-1))"", 'level_values = df.index.get_level_values', 'result = (df.groupby([level_values(i) for i in [0,1]]', ""                      +[pd.Grouper(freq='2D', level=-1)]).sum())"", '    level_values = df.index.get_level_values', '    return (df.groupby([level_values(i) for i in [0,1]]', ""                       +[pd.Grouper(freq='2D', level=-1)]).sum())"", '    df = df.reset_index(level=[0, 1])', ""    return df.groupby(['State','City']).resample('2D').sum()"", '    return (df.unstack(level=[0,1])', '    dates = pd.DatetimeIndex([DT.date(2012,1,1)+DT.timedelta(days = i) for i in range(4)]*4)', '    df = pd.DataFrame(', ""    df.index.names = ['State', 'City', 'Date']"", ""    dates = pd.date_range('2000-1-1', periods=N)"", '    index = pd.MultiIndex.from_product([states, cities, dates], ', '    df = pd.DataFrame(np.random.randint(10, size=(len(index),2)), index=index,']","[""df.groupby(pd.Grouper(freq='2D', level=-1))"", 'level_values = df.index.get_level_values', 'result = (df.groupby([level_values(i) for i in [0,1]]', ""                      +[pd.Grouper(freq='2D', level=-1)]).sum())"", 'import numpy as np', 'import pandas as pd', 'import datetime as DT', 'def using_Grouper(df):', '    level_values = df.index.get_level_values', '    return (df.groupby([level_values(i) for i in [0,1]]', ""                       +[pd.Grouper(freq='2D', level=-1)]).sum())"", 'def using_reset_index(df):', '    df = df.reset_index(level=[0, 1])', ""    return df.groupby(['State','City']).resample('2D').sum()"", 'def using_stack(df):', '    return (df.unstack(level=[0,1])', ""              .resample('2D').sum()"", '              .stack(level=[2,1])', '              .swaplevel(2,0))', 'def make_orig():', '    values_a = range(16)', '    values_b = range(10, 26)', ""    states = ['Georgia']*8 + ['Alabama']*8"", ""    cities = ['Atlanta']*4 + ['Savanna']*4 + ['Mobile']*4 + ['Montgomery']*4"", '    dates = pd.DatetimeIndex([DT.date(2012,1,1)+DT.timedelta(days = i) for i in range(4)]*4)', ""        {'value_a': values_a, 'value_b': values_b},"", '        index = [states, cities, dates])', ""    df.index.names = ['State', 'City', 'Date']"", '    return df', 'def make_df(N):', ""    dates = pd.date_range('2000-1-1', periods=N)"", '    states = np.arange(50)', '    cities = np.arange(10)', '    index = pd.MultiIndex.from_product([states, cities, dates], ', ""                                       names=['State', 'City', 'Date'])"", ""                      columns=['value_a', 'value_b'])"", '    return df', 'df = make_orig()', 'print(using_Grouper(df))', 'df = make_df(10)', 'len(df)']","[""df.groupby(pd.Grouper(freq='2D', level=-1))"", 'level_values = df.index.get_level_values', 'result = (df.groupby([level_values(i) for i in [0,1]]', ""                      +[pd.Grouper(freq='2D', level=-1)]).sum())"", '    level_values = df.index.get_level_values', '    return (df.groupby([level_values(i) for i in [0,1]]', ""                       +[pd.Grouper(freq='2D', level=-1)]).sum())"", '    df = df.reset_index(level=[0, 1])', ""    return df.groupby(['State','City']).resample('2D').sum()"", '    return (df.unstack(level=[0,1])', '    dates = pd.DatetimeIndex([DT.date(2012,1,1)+DT.timedelta(days = i) for i in range(4)]*4)', ""    df.index.names = ['State', 'City', 'Date']"", ""    dates = pd.date_range('2000-1-1', periods=N)"", '    index = pd.MultiIndex.from_product([states, cities, dates], ']",,
15800314,"import numpy as np
import pandas as pd
import os
fname = 'groupby.h5'
df = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'foo',
                         'bar', 'bar', 'bar', 'bar',
                         'foo', 'foo', 'foo'],
                   'B': ['one', 'one', 'one', 'two',
                         'one', 'one', 'one', 'two',
                         'two', 'two', 'one'],
                   'C': ['dull', 'dull', 'shiny', 'dull',
                         'dull', 'shiny', 'shiny', 'dull',
                         'shiny', 'shiny', 'shiny'],
                   'D': np.random.randn(11),
                   'E': np.random.randn(11),
                   'F': np.random.randn(11)})
with pd.get_store(fname) as store:
    store.append('df',df,data_columns=['A','B','C'])
    groups = store.select_column('df','A').unique()
    l = []
    for g in groups:
        grp = store.select('df',where = [ 'A=%s' % g ])
        l.append(grp[['D','E','F']].sum())
os.remove(fname)
groups:Index([bar, foo], dtype=object)
dtype: float64","[""df = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'foo',"", ""    store.append('df',df,data_columns=['A','B','C'])"", ""    groups = store.select_column('df','A').unique()"", ""        grp = store.select('df',where = [ 'A=%s' % g ])"", ""        l.append(grp[['D','E','F']].sum())""]","['import numpy as np', 'import pandas as pd', 'import os', ""fname = 'groupby.h5'"", ""                         'bar', 'bar', 'bar', 'bar',"", ""                         'foo', 'foo', 'foo'],"", ""                   'B': ['one', 'one', 'one', 'two',"", ""                         'one', 'one', 'one', 'two',"", ""                         'two', 'two', 'one'],"", ""                   'C': ['dull', 'dull', 'shiny', 'dull',"", ""                         'dull', 'shiny', 'shiny', 'dull',"", ""                         'shiny', 'shiny', 'shiny'],"", ""                   'D': np.random.randn(11),"", ""                   'E': np.random.randn(11),"", ""                   'F': np.random.randn(11)})"", 'with pd.get_store(fname) as store:', ""    store.append('df',df,data_columns=['A','B','C'])"", ""    groups = store.select_column('df','A').unique()"", '    l = []', '    for g in groups:', ""        grp = store.select('df',where = [ 'A=%s' % g ])"", ""        l.append(grp[['D','E','F']].sum())"", 'os.remove(fname)', 'groups:Index([bar, foo], dtype=object)', 'dtype: float64']","[""    store.append('df',df,data_columns=['A','B','C'])"", ""    groups = store.select_column('df','A').unique()"", ""        grp = store.select('df',where = [ 'A=%s' % g ])"", ""        l.append(grp[['D','E','F']].sum())""]",,
15813787,"df.unstack(level=[0,1]).resample('2D', how='sum').stack(level=[2,1]).swaplevel(2,0)","[""df.unstack(level=[0,1]).resample('2D', how='sum').stack(level=[2,1]).swaplevel(2,0)""]","[""df.unstack(level=[0,1]).resample('2D', how='sum').stack(level=[2,1]).swaplevel(2,0)""]","[""df.unstack(level=[0,1]).resample('2D', how='sum').stack(level=[2,1]).swaplevel(2,0)""]",,
15822811,"df1 = pd.DataFrame(dict(A = range(10000)),index=pd.date_range('20130101',periods=10000,freq='s'))
df1
df4 = pd.DataFrame()","[""df1 = pd.DataFrame(dict(A = range(10000)),index=pd.date_range('20130101',periods=10000,freq='s'))"", 'df4 = pd.DataFrame()']",['df1'],"[""df1 = pd.DataFrame(dict(A = range(10000)),index=pd.date_range('20130101',periods=10000,freq='s'))""]",,
15855998,"cov = np.cov(a, b)
beta = cov[1, 0] / cov[0, 0]
import numpy as np
import matplotlib.pyplot as plt
np.random.seed(100)
def geometric_brownian_motion(T=1, N=100, mu=0.1, sigma=0.01, S0=20):
    """"""
    http://stackoverflow.com/a/13203189/190597 (unutbu)
    """"""
    dt = float(T) / N
    t = np.linspace(0, T, N)
    W = np.random.standard_normal(size=N)
    W = np.cumsum(W) * np.sqrt(dt)  
    X = (mu - 0.5 * sigma ** 2) * t + sigma * W
    S = S0 * np.exp(X)  
    return S
N = 10 ** 6
a = geometric_brownian_motion(T=1, mu=0.1, sigma=0.01, N=N)
b = geometric_brownian_motion(T=1, mu=0.2, sigma=0.01, N=N)
cov = np.cov(a, b)
print(cov)
beta = cov[1, 0] / cov[0, 0]
print(beta)
2.10609347015
plt.plot(a)
plt.plot(b)
plt.show()
import pandas as pd
df = pd.DataFrame({'a': a, 'b': b})
beta2 = (df.corr() * df['b'].std() * df['a'].std() / df['a'].var()).ix[0, 1]
print(beta2)
2.10609347015
assert np.allclose(beta, beta2)","['cov = np.cov(a, b)', '    W = np.cumsum(W) * np.sqrt(dt)  ', 'cov = np.cov(a, b)', 'plt.plot(a)', 'plt.plot(b)', ""df = pd.DataFrame({'a': a, 'b': b})"", ""beta2 = (df.corr() * df['b'].std() * df['a'].std() / df['a'].var()).ix[0, 1]""]","['cov = np.cov(a, b)', 'beta = cov[1, 0] / cov[0, 0]', 'import numpy as np', 'import matplotlib.pyplot as plt', 'np.random.seed(100)', 'def geometric_brownian_motion(T=1, N=100, mu=0.1, sigma=0.01, S0=20):', '    """"""', '    http://stackoverflow.com/a/13203189/190597 (unutbu)', '    """"""', '    dt = float(T) / N', '    t = np.linspace(0, T, N)', '    W = np.random.standard_normal(size=N)', '    W = np.cumsum(W) * np.sqrt(dt)  ', '    X = (mu - 0.5 * sigma ** 2) * t + sigma * W', '    S = S0 * np.exp(X)  ', '    return S', 'N = 10 ** 6', 'a = geometric_brownian_motion(T=1, mu=0.1, sigma=0.01, N=N)', 'b = geometric_brownian_motion(T=1, mu=0.2, sigma=0.01, N=N)', 'cov = np.cov(a, b)', 'print(cov)', 'beta = cov[1, 0] / cov[0, 0]', 'print(beta)', '2.10609347015', 'plt.plot(a)', 'plt.plot(b)', 'plt.show()', 'import pandas as pd', ""beta2 = (df.corr() * df['b'].std() * df['a'].std() / df['a'].var()).ix[0, 1]"", 'print(beta2)', '2.10609347015', 'assert np.allclose(beta, beta2)']","['cov = np.cov(a, b)', '    W = np.cumsum(W) * np.sqrt(dt)  ', 'cov = np.cov(a, b)', 'plt.plot(a)', 'plt.plot(b)', ""beta2 = (df.corr() * df['b'].std() * df['a'].std() / df['a'].var()).ix[0, 1]""]",,
15863028,"df = pd.DataFrame({""date"": range(10, 64, 8)})
df.index += 17
df
df[""date""].iloc[0]
10
df[""date""].iloc[-1]
58
df = pd.DataFrame({""date"": range(10, 64, 8)})
df.index += 17
df
df['date'].iget(0)
10
df['date'].iget(-1)
58
df['date'][df.index[0]]
10
df['date'][df.index[-1]]
58
df.ix[0]
[...]
KeyError: 0","['df = pd.DataFrame({""date"": range(10, 64, 8)})', 'df.index += 17', 'df[""date""].iloc[0]', 'df[""date""].iloc[-1]', 'df = pd.DataFrame({""date"": range(10, 64, 8)})', 'df.index += 17', ""df['date'][df.index[0]]"", ""df['date'][df.index[-1]]""]","['df.index += 17', 'df', 'df[""date""].iloc[0]', '10', 'df[""date""].iloc[-1]', '58', 'df.index += 17', 'df', ""df['date'].iget(0)"", '10', ""df['date'].iget(-1)"", '58', ""df['date'][df.index[0]]"", '10', ""df['date'][df.index[-1]]"", '58', 'df.ix[0]', '[...]', 'KeyError: 0']","['df.index += 17', 'df[""date""].iloc[0]', 'df[""date""].iloc[-1]', 'df.index += 17', ""df['date'][df.index[0]]"", ""df['date'][df.index[-1]]""]",,
15889056,"line = DataFrame({""onset"": 30.0, ""length"": 1.3}, index=[3])
df2 = concat([df.ix[:2], line, df.ix[3:]]).reset_index(drop=True)","['df2 = concat([df.ix[:2], line, df.ix[3:]]).reset_index(drop=True)']","['line = DataFrame({""onset"": 30.0, ""length"": 1.3}, index=[3])', 'df2 = concat([df.ix[:2], line, df.ix[3:]]).reset_index(drop=True)']","['df2 = concat([df.ix[:2], line, df.ix[3:]]).reset_index(drop=True)']",,
15911372,"df
ax = df.set_index('x')['y'].plot(style='o')
def label_point(x, y, val, ax):
    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)
    for i, point in a.iterrows():
        ax.text(point['x'], point['y'], str(point['val']))
label_point(df.x, df.y, df.val, ax)
draw()","[""ax = df.set_index('x')['y'].plot(style='o')"", ""    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)"", '    for i, point in a.iterrows():']","['df', ""ax = df.set_index('x')['y'].plot(style='o')"", 'def label_point(x, y, val, ax):', ""    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)"", '    for i, point in a.iterrows():', ""        ax.text(point['x'], point['y'], str(point['val']))"", 'label_point(df.x, df.y, df.val, ax)', 'draw()']","[""ax = df.set_index('x')['y'].plot(style='o')"", ""    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)"", '    for i, point in a.iterrows():']",,
15916686,"df = df.div(df.QT, axis='index')
df = (df.T / df.QT).T","[""df = df.div(df.QT, axis='index')"", 'df = (df.T / df.QT).T']","[""df = df.div(df.QT, axis='index')"", 'df = (df.T / df.QT).T']","[""df = df.div(df.QT, axis='index')"", 'df = (df.T / df.QT).T']",,
15923878,"import random
def some(x, n):
    return x.ix[random.sample(x.index, n)]","['    return x.ix[random.sample(x.index, n)]']","['import random', 'def some(x, n):', '    return x.ix[random.sample(x.index, n)]']","['    return x.ix[random.sample(x.index, n)]']",,
15943975,"import numpy as np
import pandas as pd
df = pd.DataFrame(np.arange(9).reshape(3,3))
df
df.shape
len(df.index)","['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']","['import numpy as np', 'import pandas as pd', 'df', 'df.shape', 'len(df.index)']","['df.shape', 'len(df.index)']","['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']","['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']"
15948271,"df.iloc[:, n]  ","['df.iloc[:, n]  ']","['df.iloc[:, n]  ']","['df.iloc[:, n]  ']",,
15990537,"df1 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))
df2 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))
df1
df2
pd.concat(dict(df1 = df1, df2 = df2),axis=1)","[""df1 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))"", ""df2 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))"", 'pd.concat(dict(df1 = df1, df2 = df2),axis=1)']","['df1', 'df2', 'pd.concat(dict(df1 = df1, df2 = df2),axis=1)']","[""df1 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))"", ""df2 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))"", 'pd.concat(dict(df1 = df1, df2 = df2),axis=1)']",,
15996274,,[],[''],[],[],[]
15998251,"s = Series([True, True, True, False])
s
-s",[],"['s = Series([True, True, True, False])', 's', '-s']",[],[],[]
15998993,"s = pd.Series([True, True, False, True])
~s
s = pd.Series([True, True, False, True]*10000)","['s = pd.Series([True, True, False, True])', 's = pd.Series([True, True, False, True]*10000)']",['~s'],[],,
16033048,"df
df['lat_long'] = df[['lat', 'long']].apply(tuple, axis=1)
df","[""df['lat_long'] = df[['lat', 'long']].apply(tuple, axis=1)""]","['df', ""df['lat_long'] = df[['lat', 'long']].apply(tuple, axis=1)"", 'df']","[""df['lat_long'] = df[['lat', 'long']].apply(tuple, axis=1)""]",,
16068497,"df['new_col'] = list(zip(df.lat, df.long))",[],"[""df['new_col'] = list(zip(df.lat, df.long))""]",[],[],[]
16074407,"ax = plt.gca()
ax.grid(True)",[],"['ax = plt.gca()', 'ax.grid(True)']",[],[],[]
16089219,"df['bar', 'three'] = [0, 1, 2]
df = df.sort_index(axis=1)
print(df)",['df = df.sort_index(axis=1)'],"[""df['bar', 'three'] = [0, 1, 2]"", 'df = df.sort_index(axis=1)', 'print(df)']",['df = df.sort_index(axis=1)'],,
16099579,,[],[''],[],[],[]
16104482,"df = DataFrame(randn(5,2),index=range(0,10,2),columns=list('AB'))
df
df.iloc[[2]]
df.loc[[2]]","['df.iloc[[2]]', 'df.loc[[2]]']","[""df = DataFrame(randn(5,2),index=range(0,10,2),columns=list('AB'))"", 'df', 'df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']"
16104567,"df = DataFrame([ Timestamp('20010101'), Timestamp('20040601') ])
df
df = DataFrame([ Timestamp('20010101'), 
                          Timestamp('20040601') ],columns=['age'])
df
df['today'] = Timestamp('20130419')
df['diff'] = df['today']-df['age']
df['years'] = df['diff'].apply(lambda x: float(x.item().days)/365)
df","[""df['years'] = df['diff'].apply(lambda x: float(x.item().days)/365)""]","[""df = DataFrame([ Timestamp('20010101'), Timestamp('20040601') ])"", 'df', ""df = DataFrame([ Timestamp('20010101'), "", ""                          Timestamp('20040601') ],columns=['age'])"", 'df', ""df['today'] = Timestamp('20130419')"", ""df['diff'] = df['today']-df['age']"", ""df['years'] = df['diff'].apply(lambda x: float(x.item().days)/365)"", 'df']","[""df['years'] = df['diff'].apply(lambda x: float(x.item().days)/365)""]",,
16134561,"a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]
df = pd.DataFrame(a, columns=['one', 'two', 'three'])
df
df.dtypes
df[['two', 'three']] = df[['two', 'three']].astype(float)
df.dtypes","[""df = pd.DataFrame(a, columns=['one', 'two', 'three'])"", 'df.dtypes', ""df[['two', 'three']] = df[['two', 'three']].astype(float)"", 'df.dtypes']","[""a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]"", 'df', 'df.dtypes', ""df[['two', 'three']] = df[['two', 'three']].astype(float)"", 'df.dtypes']","['df.dtypes', ""df[['two', 'three']] = df[['two', 'three']].astype(float)"", 'df.dtypes']",,
16168245,,[],[''],[],[],[]
16176457,"df = pd.DataFrame([1, 2, 3], index=[dt.datetime(2013, 1, 1), dt.datetime(2013, 1, 3), dt.datetime(2013, 1, 5)])
df
start = df.index.searchsorted(dt.datetime(2013, 1, 2))
end = df.index.searchsorted(dt.datetime(2013, 1, 4))
df.ix[start:end]","['df = pd.DataFrame([1, 2, 3], index=[dt.datetime(2013, 1, 1), dt.datetime(2013, 1, 3), dt.datetime(2013, 1, 5)])', 'start = df.index.searchsorted(dt.datetime(2013, 1, 2))', 'end = df.index.searchsorted(dt.datetime(2013, 1, 4))']","['df', 'start = df.index.searchsorted(dt.datetime(2013, 1, 2))', 'end = df.index.searchsorted(dt.datetime(2013, 1, 4))', 'df.ix[start:end]']","['start = df.index.searchsorted(dt.datetime(2013, 1, 2))', 'end = df.index.searchsorted(dt.datetime(2013, 1, 4))']",,
16179190,"df
df['20130419':'20130422']
df
df['20130419':'20130422']
df.sort_index()",['df.sort_index()'],"['df', ""df['20130419':'20130422']"", 'df', ""df['20130419':'20130422']"", 'df.sort_index()']",['df.sort_index()'],,
16202796,,[],[''],[],[],[]
16242202,"df = pd.DataFrame({'textcol' : np.random.rand(5)})
df
df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))
pd.concat([df, df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))], axis=1)","[""df = pd.DataFrame({'textcol' : np.random.rand(5)})"", ""df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))"", ""pd.concat([df, df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))], axis=1)""]",['df'],"[""df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))"", ""pd.concat([df, df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))], axis=1)""]",,
16245109,"df.merge(df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1})), 
    left_index=True, right_index=True)","[""df.merge(df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1})), ""]","['    left_index=True, right_index=True)']","[""df.merge(df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1})), ""]",,
16255680,"import pandas as pd
from pymongo import MongoClient
def _connect_mongo(host, port, username, password, db):
    """""" A util for making a connection to mongo """"""
    if username and password:
        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)
        conn = MongoClient(mongo_uri)
    else:
        conn = MongoClient(host, port)
    return conn[db]
def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):
    """""" Read from Mongo and Store into DataFrame """"""
    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)
    cursor = db[collection].find(query)
    df =  pd.DataFrame(list(cursor))
    if no_id:
        del df['_id']
    return df","['    cursor = db[collection].find(query)', '    df =  pd.DataFrame(list(cursor))']","['import pandas as pd', 'from pymongo import MongoClient', 'def _connect_mongo(host, port, username, password, db):', '    """""" A util for making a connection to mongo """"""', '    if username and password:', ""        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)"", '        conn = MongoClient(mongo_uri)', '    else:', '        conn = MongoClient(host, port)', '    return conn[db]', ""def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):"", '    """""" Read from Mongo and Store into DataFrame """"""', '    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)', '    cursor = db[collection].find(query)', '    if no_id:', ""        del df['_id']"", '    return df']",['    cursor = db[collection].find(query)'],,
16266318,"times = pd.to_datetime(df.timestamp_col)
df.groupby([times.hour, times.minute]).value_col.sum()","['times = pd.to_datetime(df.timestamp_col)', 'df.groupby([times.hour, times.minute]).value_col.sum()']","['times = pd.to_datetime(df.timestamp_col)', 'df.groupby([times.hour, times.minute]).value_col.sum()']","['times = pd.to_datetime(df.timestamp_col)', 'df.groupby([times.hour, times.minute]).value_col.sum()']",,
16271849,"import pandas as pd
import datetime
from myapp.models import BlogPost
df = pd.DataFrame(list(BlogPost.objects.all().values()))
df = pd.DataFrame(list(BlogPost.objects.filter(date__gte=datetime.datetime(2012, 5, 1)).values()))
df = pd.DataFrame(list(BlogPost.objects.all().values('author', 'date', 'slug')))","['df = pd.DataFrame(list(BlogPost.objects.all().values()))', 'df = pd.DataFrame(list(BlogPost.objects.filter(date__gte=datetime.datetime(2012, 5, 1)).values()))', ""df = pd.DataFrame(list(BlogPost.objects.all().values('author', 'date', 'slug')))""]","['import pandas as pd', 'import datetime', 'from myapp.models import BlogPost']","['df = pd.DataFrame(list(BlogPost.objects.all().values()))', 'df = pd.DataFrame(list(BlogPost.objects.filter(date__gte=datetime.datetime(2012, 5, 1)).values()))', ""df = pd.DataFrame(list(BlogPost.objects.all().values('author', 'date', 'slug')))""]",,
16327135,"df = pd.DataFrame({""A"": [1,2,3], ""B"": [2,3,4]})
df
df[""C""] = """"
df[""D""] = np.nan
df","['df = pd.DataFrame({""A"": [1,2,3], ""B"": [2,3,4]})']","['df', 'df[""C""] = """"', 'df[""D""] = np.nan', 'df']",[],,
16342396,,[],[''],[],[],[]
16345735,"import numpy as np
import pandas as pd
df = pd.DataFrame({'id': [1,1,2,2,1,2,1,1], 'x':[10,20,100,200,np.nan,np.nan,300,np.nan]})
df['x'] = df.groupby(['id'])['x'].ffill()
print(df)","[""df = pd.DataFrame({'id': [1,1,2,2,1,2,1,1], 'x':[10,20,100,200,np.nan,np.nan,300,np.nan]})"", ""df['x'] = df.groupby(['id'])['x'].ffill()""]","['import numpy as np', 'import pandas as pd', ""df['x'] = df.groupby(['id'])['x'].ffill()"", 'print(df)']","[""df['x'] = df.groupby(['id'])['x'].ffill()""]",,
16354103,"df['a'] % df['c']                                                                                                                                                        
0   -1.132022                                                                                                                                                                    
1   -0.939493                                                                                                                                                                    
4   -0.694647                                                                                                                                                                    
5   -0.023486                                                                                                                                                                    
Name: a",[],"[""df['a'] % df['c']                                                                                                                                                        "", '0   -1.132022                                                                                                                                                                    ', '1   -0.939493                                                                                                                                                                    ', '4   -0.694647                                                                                                                                                                    ', '5   -0.023486                                                                                                                                                                    ', 'Name: a']",[],[],[]
16354730,"df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)
df","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)"", 'df']","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]"
16359854,"df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,
                   'Days Late': [60, 60, 50, 50, 20, 20, 10, 10],
                   'quantity': [56, 20, 60, 67, 74, 87, 40, 34]})
df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)
labels = np.array('White Yellow Amber Red'.split())
df['status'] = labels[df['status']]
del df['Days Late']
print(df)
df = df.pivot(index='ID', columns='status', values='quantity')
df = df.reindex(columns=labels[::-1], index=df.index[::-1])
import numpy as np
import pandas as pd
df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,
                   'Days Late': [60, 60, 50, 50, 20, 20, 10, 10],
                   'quantity': [56, 20, 60, 67, 74, 87, 40, 34]})
df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)
labels = np.array('White Yellow Amber Red'.split())
df['status'] = labels[df['status']]
del df['Days Late']
df = df.pivot(index='ID', columns='status', values='quantity')
df = df.reindex(columns=labels[::-1], index=df.index[::-1])
print(df)
ID                               ","[""df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])', ""df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])']","[""                   'Days Late': [60, 60, 50, 50, 20, 20, 10, 10],"", ""                   'quantity': [56, 20, 60, 67, 74, 87, 40, 34]})"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df['status'] = labels[df['status']]"", ""del df['Days Late']"", 'print(df)', ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])', 'import numpy as np', 'import pandas as pd', ""                   'Days Late': [60, 60, 50, 50, 20, 20, 10, 10],"", ""                   'quantity': [56, 20, 60, 67, 74, 87, 40, 34]})"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df['status'] = labels[df['status']]"", ""del df['Days Late']"", ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])', 'print(df)', 'ID                               ']","[""df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])', ""df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,"", ""df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)"", ""labels = np.array('White Yellow Amber Red'.split())"", ""df = df.pivot(index='ID', columns='status', values='quantity')"", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])']",,
16377383,"import matplotlib.pyplot as plt
for title, group in df.groupby('ModelID'):
    group.plot(x='saleDate', y='MeanToDate', title=title)","[""for title, group in df.groupby('ModelID'):"", ""    group.plot(x='saleDate', y='MeanToDate', title=title)""]","['import matplotlib.pyplot as plt', ""for title, group in df.groupby('ModelID'):"", ""    group.plot(x='saleDate', y='MeanToDate', title=title)""]","[""for title, group in df.groupby('ModelID'):"", ""    group.plot(x='saleDate', y='MeanToDate', title=title)""]",,
16393023,"fig, axs = plt.subplots(1,2)
df['korisnika'].plot(ax=axs[0])
df['osiguranika'].plot(ax=axs[1])","[""df['korisnika'].plot(ax=axs[0])"", ""df['osiguranika'].plot(ax=axs[1])""]","['fig, axs = plt.subplots(1,2)', ""df['korisnika'].plot(ax=axs[0])"", ""df['osiguranika'].plot(ax=axs[1])""]","[""df['korisnika'].plot(ax=axs[0])"", ""df['osiguranika'].plot(ax=axs[1])""]",,
16398361,df2 = df1.iloc[3:] ,['df2 = df1.iloc[3:] '],['df2 = df1.iloc[3:] '],['df2 = df1.iloc[3:] '],,
16433953,"pd.set_option('display.height', 500)
pd.set_option('display.max_rows', 500)","[""pd.set_option('display.height', 500)"", ""pd.set_option('display.max_rows', 500)""]","[""pd.set_option('display.height', 500)"", ""pd.set_option('display.max_rows', 500)""]","[""pd.set_option('display.height', 500)"", ""pd.set_option('display.max_rows', 500)""]",,
16476974,,[],[''],[],[],[]
16477603,"df.to_sql(con=con, name='table_name_for_df', if_exists='replace', flavor='mysql')
from pandas.io import sql
import MySQLdb
con = MySQLdb.connect()  
sql.write_frame(df, con=con, name='table_name_for_df', 
                if_exists='replace', flavor='mysql')","[""df.to_sql(con=con, name='table_name_for_df', if_exists='replace', flavor='mysql')""]","[""df.to_sql(con=con, name='table_name_for_df', if_exists='replace', flavor='mysql')"", 'from pandas.io import sql', 'import MySQLdb', 'con = MySQLdb.connect()  ', ""sql.write_frame(df, con=con, name='table_name_for_df', "", ""                if_exists='replace', flavor='mysql')""]","[""df.to_sql(con=con, name='table_name_for_df', if_exists='replace', flavor='mysql')""]",,
16522626,"import matplotlib.pyplot as plt
plt.show()",[],"['import matplotlib.pyplot as plt', 'plt.show()']",[],[],[]
16545324,"df['a_bsum'] = df.groupby('A')['B'].transform(sum)
df.sort(['a_bsum','C'], ascending=[True, False]).drop('a_bsum', axis=1)","[""df['a_bsum'] = df.groupby('A')['B'].transform(sum)"", ""df.sort(['a_bsum','C'], ascending=[True, False]).drop('a_bsum', axis=1)""]","[""df['a_bsum'] = df.groupby('A')['B'].transform(sum)"", ""df.sort(['a_bsum','C'], ascending=[True, False]).drop('a_bsum', axis=1)""]","[""df['a_bsum'] = df.groupby('A')['B'].transform(sum)"", ""df.sort(['a_bsum','C'], ascending=[True, False]).drop('a_bsum', axis=1)""]",,
16576030,"df[abc_columns].applymap(categories.get)
abc_categories = map(lambda x: x + '_category', abc_columns)
abc_categories
df[abc_categories] = df[abc_columns].applymap(categories.get)
abc_columns = [col for col in df.columns if str(col).startswith('abc')]","['df[abc_columns].applymap(categories.get)', 'df[abc_categories] = df[abc_columns].applymap(categories.get)', ""abc_columns = [col for col in df.columns if str(col).startswith('abc')]""]","['df[abc_columns].applymap(categories.get)', ""abc_categories = map(lambda x: x + '_category', abc_columns)"", 'abc_categories', 'df[abc_categories] = df[abc_columns].applymap(categories.get)', ""abc_columns = [col for col in df.columns if str(col).startswith('abc')]""]","['df[abc_columns].applymap(categories.get)', 'df[abc_categories] = df[abc_columns].applymap(categories.get)', ""abc_columns = [col for col in df.columns if str(col).startswith('abc')]""]",,
16597375,"df = pd.DataFrame()
data = pd.DataFrame({""A"": range(3)})
df.append(data)
df
Columns: []
Index: []
df = df.append(data)
df","['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']","['df.append(data)', 'df', 'Columns: []', 'Index: []', 'df = df.append(data)', 'df']","['df.append(data)', 'df = df.append(data)']","['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']","['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']"
16616454,"df
col_list = [3, 5]
df = df[col_list]
df",[],"['df', 'col_list = [3, 5]', 'df = df[col_list]', 'df']",[],[],[]
16629125,"import numpy as np
import pandas as pd
x = np.random.randint(0, 200, 10**6)
df1 = pd.DataFrame({'x':x})
df2 = df1.set_index('x', drop=False)
df3 = df2.sort_index()","[""df1 = pd.DataFrame({'x':x})"", ""df2 = df1.set_index('x', drop=False)"", 'df3 = df2.sort_index()']","['import numpy as np', 'import pandas as pd', 'x = np.random.randint(0, 200, 10**6)', ""df2 = df1.set_index('x', drop=False)"", 'df3 = df2.sort_index()']","[""df2 = df1.set_index('x', drop=False)"", 'df3 = df2.sort_index()']",,
16629243,"import sqlite3
import os
from pandas.io import sql
df = DataFrame(randn(1000000,2),columns=list('AB'))
dtypes: float64(2)
def test_sql_write(df):
    if os.path.exists('test.sql'):
        os.remove('test.sql')
    sql_db = sqlite3.connect('test.sql')
    sql.write_frame(df, name='test_table', con=sql_db)
    sql_db.close()
def test_sql_read():
    sql_db = sqlite3.connect('test.sql')
    sql.read_frame(""select * from test_table"", sql_db)
    sql_db.close()
def test_hdf_fixed_write(df):
    df.to_hdf('test_fixed.hdf','test',mode='w')
def test_csv_read():
    pd.read_csv('test.csv',index_col=0)
def test_csv_write(df):
    df.to_csv('test.csv',mode='w')    
def test_hdf_fixed_read():
    pd.read_hdf('test_fixed.hdf','test')
def test_hdf_table_write(df):
    df.to_hdf('test_table.hdf','test',format='table',mode='w')
def test_hdf_table_read():
    pd.read_hdf('test_table.hdf','test')","[""    df.to_hdf('test_fixed.hdf','test',mode='w')"", ""    pd.read_csv('test.csv',index_col=0)"", ""    df.to_csv('test.csv',mode='w')    "", ""    pd.read_hdf('test_fixed.hdf','test')"", ""    df.to_hdf('test_table.hdf','test',format='table',mode='w')"", ""    pd.read_hdf('test_table.hdf','test')""]","['import sqlite3', 'import os', 'from pandas.io import sql', ""df = DataFrame(randn(1000000,2),columns=list('AB'))"", 'dtypes: float64(2)', 'def test_sql_write(df):', ""    if os.path.exists('test.sql'):"", ""        os.remove('test.sql')"", ""    sql_db = sqlite3.connect('test.sql')"", ""    sql.write_frame(df, name='test_table', con=sql_db)"", '    sql_db.close()', 'def test_sql_read():', ""    sql_db = sqlite3.connect('test.sql')"", '    sql.read_frame(""select * from test_table"", sql_db)', '    sql_db.close()', 'def test_hdf_fixed_write(df):', ""    df.to_hdf('test_fixed.hdf','test',mode='w')"", 'def test_csv_read():', ""    pd.read_csv('test.csv',index_col=0)"", 'def test_csv_write(df):', ""    df.to_csv('test.csv',mode='w')    "", 'def test_hdf_fixed_read():', ""    pd.read_hdf('test_fixed.hdf','test')"", 'def test_hdf_table_write(df):', ""    df.to_hdf('test_table.hdf','test',format='table',mode='w')"", 'def test_hdf_table_read():', ""    pd.read_hdf('test_table.hdf','test')""]","[""    df.to_hdf('test_fixed.hdf','test',mode='w')"", ""    pd.read_csv('test.csv',index_col=0)"", ""    df.to_csv('test.csv',mode='w')    "", ""    pd.read_hdf('test_fixed.hdf','test')"", ""    df.to_hdf('test_table.hdf','test',format='table',mode='w')"", ""    pd.read_hdf('test_table.hdf','test')""]",,
16637572,"for f in files:
  df = pd.read_csv(f)
  df.to_hdf('file.h5',f,df)
pd.read_hdf('my_store.h5','a_table_node',['index>100'])","['  df = pd.read_csv(f)', ""  df.to_hdf('file.h5',f,df)"", ""pd.read_hdf('my_store.h5','a_table_node',['index>100'])""]","['for f in files:', '  df = pd.read_csv(f)', ""  df.to_hdf('file.h5',f,df)"", ""pd.read_hdf('my_store.h5','a_table_node',['index>100'])""]","['  df = pd.read_csv(f)', ""  df.to_hdf('file.h5',f,df)"", ""pd.read_hdf('my_store.h5','a_table_node',['index>100'])""]",,
16637607,"s = Series([list('ABC'),list('DEF'),list('ABEF')])
s
s.apply(lambda x: Series(1,index=x)).fillna(0)","['s.apply(lambda x: Series(1,index=x)).fillna(0)']","[""s = Series([list('ABC'),list('DEF'),list('ABEF')])"", 's', 's.apply(lambda x: Series(1,index=x)).fillna(0)']","['s.apply(lambda x: Series(1,index=x)).fillna(0)']",,
16641346,"df = DataFrame(randn(1000000,10))
df",[],"['df = DataFrame(randn(1000000,10))', 'df']",[],[],[]
16648510,"df = DataFrame('10.0%',index=range(100),columns=range(10))
df.replace('%','',regex=True).astype('float')/100","[""df.replace('%','',regex=True).astype('float')/100""]","[""df = DataFrame('10.0%',index=range(100),columns=range(10))"", ""df.replace('%','',regex=True).astype('float')/100""]","[""df.replace('%','',regex=True).astype('float')/100""]",,
16667215,"df.columns
df.rename(columns=lambda x: x[1:], inplace=True)
df.columns
Out[13]: Index([u'a', u'b', u'c', u'd', u'e'], dtype=object)","['df.rename(columns=lambda x: x[1:], inplace=True)']","['df.columns', 'df.rename(columns=lambda x: x[1:], inplace=True)', 'df.columns', ""Out[13]: Index([u'a', u'b', u'c', u'd', u'e'], dtype=object)""]","['df.rename(columns=lambda x: x[1:], inplace=True)']",,
16672514,"import pandas as pd
from StringIO import StringIO
s = StringIO(""""""date,value
12/01/2012,1
12/01/2012,2
30/01/2012,3"""""")
pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)
date             
s = StringIO(""""""date
12/01/2012
12/01/2012
30/01/2012"""""")
pd.read_csv(s, parse_dates=[0], dayfirst=True)","['pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)', 'pd.read_csv(s, parse_dates=[0], dayfirst=True)']","['import pandas as pd', 'from StringIO import StringIO', 's = StringIO(""""""date,value', '12/01/2012,1', '12/01/2012,2', '30/01/2012,3"""""")', 'pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)', 'date             ', 's = StringIO(""""""date', '12/01/2012', '12/01/2012', '30/01/2012"""""")', 'pd.read_csv(s, parse_dates=[0], dayfirst=True)']","['pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)', 'pd.read_csv(s, parse_dates=[0], dayfirst=True)']",,
16673019,"s = pd.Series(['12/1/2012', '30/01/2012'])
pd.to_datetime(s, format='%d/%m/%Y')
dtype: datetime64[ns]
s.apply(pd.to_datetime, dayfirst=True)","[""s = pd.Series(['12/1/2012', '30/01/2012'])"", ""pd.to_datetime(s, format='%d/%m/%Y')"", 's.apply(pd.to_datetime, dayfirst=True)']","[""pd.to_datetime(s, format='%d/%m/%Y')"", 'dtype: datetime64[ns]', 's.apply(pd.to_datetime, dayfirst=True)']","[""pd.to_datetime(s, format='%d/%m/%Y')"", 's.apply(pd.to_datetime, dayfirst=True)']",,
16684166,"a
a.c1[a.c1 == 8].index.tolist()
Out[49]: [4]",['a.c1[a.c1 == 8].index.tolist()'],"['a', 'a.c1[a.c1 == 8].index.tolist()', 'Out[49]: [4]']",['a.c1[a.c1 == 8].index.tolist()'],,
16689573,"df
DATE                     
df.mean(axis=1)
DATE
dtype: float64",['df.mean(axis=1)'],"['df', 'DATE                     ', 'df.mean(axis=1)', 'DATE', 'dtype: float64']",['df.mean(axis=1)'],,
16729635,"df
df.a.values
df.a = df.a.astype(float).fillna(0.0)
df
df.a.values
Out[16]: array([ 0.1,  0. ,  0.4])","['df.a.values', 'df.a = df.a.astype(float).fillna(0.0)', 'df.a.values']","['df', 'df.a.values', 'df.a = df.a.astype(float).fillna(0.0)', 'df', 'df.a.values', 'Out[16]: array([ 0.1,  0. ,  0.4])']","['df.a.values', 'df.a = df.a.astype(float).fillna(0.0)', 'df.a.values']",,
16729808,"sub_df
sub_df.iloc[0]
sub_df.iloc[0]['A']
Out[5]: -0.13365288513107493","['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]","['sub_df', 'sub_df.iloc[0]', ""sub_df.iloc[0]['A']"", 'Out[5]: -0.13365288513107493']","['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]",[],"['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]"
16735476,"df = DataFrame(dict(A = Series(['1.0','1']), B = Series(['1.0','foo'])))
df
df.dtypes
df.convert_objects(convert_numeric=True)
df.convert_objects(convert_numeric=True).dtypes
dtype: object","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","[""df = DataFrame(dict(A = Series(['1.0','1']), B = Series(['1.0','foo'])))"", 'df', 'df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes', 'dtype: object']","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","['df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']"
16735536,"df = DataFrame(randn(5,3),columns=list('ABC'))
df
df.iat[0,0]
df.at[0,'A']
Out[18]: -0.074171888537611502","['df.iat[0,0]', ""df.at[0,'A']""]","[""df = DataFrame(randn(5,3),columns=list('ABC'))"", 'df', 'df.iat[0,0]', ""df.at[0,'A']"", 'Out[18]: -0.074171888537611502']","['df.iat[0,0]', ""df.at[0,'A']""]",,
16780413,"df
df.index
df['tvalue'] = df.index
df['delta'] = (df['tvalue']-df['tvalue'].shift()).fillna(0)
df
df['ans'] = df['delta'].apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64') % (24*60)
df","['df.index', ""df['tvalue'] = df.index"", ""df['delta'] = (df['tvalue']-df['tvalue'].shift()).fillna(0)"", ""df['ans'] = df['delta'].apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64') % (24*60)""]","['df', 'df.index', ""df['tvalue'] = df.index"", ""df['delta'] = (df['tvalue']-df['tvalue'].shift()).fillna(0)"", 'df', ""df['ans'] = df['delta'].apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64') % (24*60)"", 'df']","['df.index', ""df['tvalue'] = df.index"", ""df['delta'] = (df['tvalue']-df['tvalue'].shift()).fillna(0)"", ""df['ans'] = df['delta'].apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64') % (24*60)""]",,
16789254,"df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
df
df[['A']]
df[[0]]
df.loc[:, ['A']]
df.iloc[:, [0]]
df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 0])
df
df[[0]]  ","[""df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])"", ""df.loc[:, ['A']]"", 'df.iloc[:, [0]]', ""df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 0])""]","['df', ""df[['A']]"", 'df[[0]]', ""df.loc[:, ['A']]"", 'df.iloc[:, [0]]', 'df', 'df[[0]]  ']","[""df.loc[:, ['A']]"", 'df.iloc[:, [0]]']",,
16789834,"import sys
paramdata.to_csv(sys.stdout)",['paramdata.to_csv(sys.stdout)'],"['import sys', 'paramdata.to_csv(sys.stdout)']",['paramdata.to_csv(sys.stdout)'],,
16824270,"df.unstack()
dtype: float64",['df.unstack()'],"['df.unstack()', 'dtype: float64']",['df.unstack()'],,
16824696,"df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
s = df.xs(3)
s.name = 10
df.append(s)","[""df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])"", 's = df.xs(3)', 'df.append(s)']","['s = df.xs(3)', 's.name = 10', 'df.append(s)']","['s = df.xs(3)', 'df.append(s)']",,
16826250,,[],[''],[],[],[]
16827257,"import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
fig = plt.figure()
ax = fig.add_subplot(111)
bar_0_10 = ax.bar(np.arange(0,10), np.arange(1,11), color=""k"")
bar_10_100 = ax.bar(np.arange(0,10), np.arange(30,40), bottom=np.arange(1,11), color=""g"")
extra = Rectangle((0, 0), 1, 1, fc=""w"", fill=False, edgecolor='none', linewidth=0)
ax.legend([extra, bar_0_10, bar_10_100], (""My explanatory text"", ""0-10"", ""10-100""))
plt.show()","['bar_0_10 = ax.bar(np.arange(0,10), np.arange(1,11), color=""k"")', 'bar_10_100 = ax.bar(np.arange(0,10), np.arange(30,40), bottom=np.arange(1,11), color=""g"")']","['import matplotlib.pyplot as plt', 'from matplotlib.patches import Rectangle', 'fig = plt.figure()', 'ax = fig.add_subplot(111)', 'bar_0_10 = ax.bar(np.arange(0,10), np.arange(1,11), color=""k"")', 'bar_10_100 = ax.bar(np.arange(0,10), np.arange(30,40), bottom=np.arange(1,11), color=""g"")', 'extra = Rectangle((0, 0), 1, 1, fc=""w"", fill=False, edgecolor=\'none\', linewidth=0)', 'ax.legend([extra, bar_0_10, bar_10_100], (""My explanatory text"", ""0-10"", ""10-100""))', 'plt.show()']","['bar_0_10 = ax.bar(np.arange(0,10), np.arange(1,11), color=""k"")', 'bar_10_100 = ax.bar(np.arange(0,10), np.arange(30,40), bottom=np.arange(1,11), color=""g"")']",,
16834949,"df = pd.DataFrame(randn(6, 3), index=arrays, columns=['A', 'B', 'C'])
df
df = df.sortlevel(0)
df
df.loc[('bar','two'),'A'] = 9999
df
df.loc[('bar','two',1),'A'] = 999
df
df.index.lexsort_depth
df.sortlevel(0).index.lexsort_depth
df.loc[('bar','one'),'A'] = [999,888]
df","[""df = pd.DataFrame(randn(6, 3), index=arrays, columns=['A', 'B', 'C'])"", ""df.loc[('bar','two'),'A'] = 9999"", ""df.loc[('bar','two',1),'A'] = 999"", 'df.index.lexsort_depth', 'df.sortlevel(0).index.lexsort_depth', ""df.loc[('bar','one'),'A'] = [999,888]""]","['df', 'df = df.sortlevel(0)', 'df', ""df.loc[('bar','two'),'A'] = 9999"", 'df', ""df.loc[('bar','two',1),'A'] = 999"", 'df', 'df.index.lexsort_depth', 'df.sortlevel(0).index.lexsort_depth', ""df.loc[('bar','one'),'A'] = [999,888]"", 'df']","[""df.loc[('bar','two'),'A'] = 9999"", ""df.loc[('bar','two',1),'A'] = 999"", 'df.index.lexsort_depth', 'df.sortlevel(0).index.lexsort_depth', ""df.loc[('bar','one'),'A'] = [999,888]""]",,
16853161,"df
df['time'] = df['time'].astype('datetime64[ns]')
df","[""df['time'] = df['time'].astype('datetime64[ns]')""]","['df', ""df['time'] = df['time'].astype('datetime64[ns]')"", 'df']","[""df['time'] = df['time'].astype('datetime64[ns]')""]",,
16854430,"df
pd.to_datetime(df['time'])
df['time'] = pd.to_datetime(df['time'])
df","[""pd.to_datetime(df['time'])"", ""df['time'] = pd.to_datetime(df['time'])""]","['df', ""pd.to_datetime(df['time'])"", ""df['time'] = pd.to_datetime(df['time'])"", 'df']","[""pd.to_datetime(df['time'])"", ""df['time'] = pd.to_datetime(df['time'])""]",,
16884805,"data_table = df.to_html(float_format=lambda x: '%6.2f' % x,
    classes=""table display"")
data_table = data_table.replace('border=""1""','border=""0""')
data_table = data_table.replace('nan', '')","[""data_table = df.to_html(float_format=lambda x: '%6.2f' % x,"", 'data_table = data_table.replace(\'border=""1""\',\'border=""0""\')', ""data_table = data_table.replace('nan', '')""]","[""data_table = df.to_html(float_format=lambda x: '%6.2f' % x,"", '    classes=""table display"")', 'data_table = data_table.replace(\'border=""1""\',\'border=""0""\')', ""data_table = data_table.replace('nan', '')""]","[""data_table = df.to_html(float_format=lambda x: '%6.2f' % x,"", 'data_table = data_table.replace(\'border=""1""\',\'border=""0""\')', ""data_table = data_table.replace('nan', '')""]",,
16896091,"xl_file = pd.ExcelFile(file_name)
dfs = {sheet_name: xl_file.parse(sheet_name) 
          for sheet_name in xl_file.sheet_names}
dfs = pd.read_excel(file_name, sheetname=None)","['dfs = {sheet_name: xl_file.parse(sheet_name) ', 'dfs = pd.read_excel(file_name, sheetname=None)']","['xl_file = pd.ExcelFile(file_name)', 'dfs = {sheet_name: xl_file.parse(sheet_name) ', '          for sheet_name in xl_file.sheet_names}', 'dfs = pd.read_excel(file_name, sheetname=None)']","['dfs = {sheet_name: xl_file.parse(sheet_name) ', 'dfs = pd.read_excel(file_name, sheetname=None)']",,
16923367,"df.to_csv(file_name, sep='\t')
df.to_csv(file_name, sep='\t', encoding='utf-8')","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]"
16949498,"import numpy as np
import pandas
df = pandas.DataFrame({""a"": np.random.random(100),
                       ""b"": np.random.random(100),
                       ""id"": np.arange(100)})
bins = np.linspace(df.a.min(), df.a.max(), 10)
groups = df.groupby(np.digitize(df.a, bins))
groups.mean().b
import numpy as np
import pandas
df = pandas.DataFrame({""a"": np.random.random(100), 
                       ""b"": np.random.random(100) + 10})
bins = np.linspace(df.a.min(), df.a.max(), 10)
groups = df.groupby(pandas.cut(df.a, bins))
a
Name: b","['df = pandas.DataFrame({""a"": np.random.random(100),', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(np.digitize(df.a, bins))', 'groups.mean().b', 'df = pandas.DataFrame({""a"": np.random.random(100), ', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(pandas.cut(df.a, bins))']","['import numpy as np', 'import pandas', '                       ""b"": np.random.random(100),', '                       ""id"": np.arange(100)})', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(np.digitize(df.a, bins))', 'groups.mean().b', 'import numpy as np', 'import pandas', '                       ""b"": np.random.random(100) + 10})', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(pandas.cut(df.a, bins))', 'a', 'Name: b']","['bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(np.digitize(df.a, bins))', 'groups.mean().b', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(pandas.cut(df.a, bins))']",,
16949500,"df = DataFrame({""a"": np.random.random(100), ""b"": np.random.random(100), ""id"":   np.arange(100)})
bins = [0, .25, .5, .75, 1]
a_bins = df.a.groupby(cut(df.a,bins))
b_bins = df.b.groupby(cut(df.b,bins))
a_bins.agg([mean,median])
b_bins.agg([mean,median])
b","['a_bins = df.a.groupby(cut(df.a,bins))', 'b_bins = df.b.groupby(cut(df.b,bins))']","['df = DataFrame({""a"": np.random.random(100), ""b"": np.random.random(100), ""id"":   np.arange(100)})', 'bins = [0, .25, .5, .75, 1]', 'a_bins = df.a.groupby(cut(df.a,bins))', 'b_bins = df.b.groupby(cut(df.b,bins))', 'a_bins.agg([mean,median])', 'b_bins.agg([mean,median])', 'b']","['a_bins = df.a.groupby(cut(df.a,bins))', 'b_bins = df.b.groupby(cut(df.b,bins))']",,
16958464,"import pandas
dfdict={}
dfdict[""a""]=[1,2,3,4]
dfdict[""b""]=[5,6,7,8]
dfdict[""c""]=[9,10,11,12]
df=pandas.DataFrame(dfdict)
df.to_csv(""dfTest.txt"",""\t"",header=True,cols=[""b"",""a"",""c""])
pandas.version.version
df.to_csv(""dfTest.txt"",""\t"",header=True,cols=[""b"",""a"",""c""], engine='python')","['df=pandas.DataFrame(dfdict)', 'df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""])', 'df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""], engine=\'python\')']","['import pandas', 'dfdict={}', 'dfdict[""a""]=[1,2,3,4]', 'dfdict[""b""]=[5,6,7,8]', 'dfdict[""c""]=[9,10,11,12]', 'df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""])', 'pandas.version.version', 'df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""], engine=\'python\')']","['df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""])', 'df.to_csv(""dfTest.txt"",""\\t"",header=True,cols=[""b"",""a"",""c""], engine=\'python\')']",,
16958649,"df.sort('Bytes', ascending=False)",[],"[""df.sort('Bytes', ascending=False)""]",[],[],[]
16988624,"pd.read_csv('a', dtype=object, index_col=0)
pd.read_csv('a', index_col=0)","[""pd.read_csv('a', dtype=object, index_col=0)"", ""pd.read_csv('a', index_col=0)""]","[""pd.read_csv('a', dtype=object, index_col=0)"", ""pd.read_csv('a', index_col=0)""]","[""pd.read_csv('a', dtype=object, index_col=0)"", ""pd.read_csv('a', index_col=0)""]",,
16990140,dtype: float64,[],['dtype: float64'],[],[],[]
16993415,"pd.DataFrame([s1, s2]).min()
dtype: float64","['pd.DataFrame([s1, s2]).min()']",['dtype: float64'],"['pd.DataFrame([s1, s2]).min()']",,
16999397,"import pandas as pd
import numpy as np
import os
files = ['test1.csv','test2.csv']
for f in files:
    pd.DataFrame(np.random.randn(10,2),columns=list('AB')).to_csv(f)
path = 'test.h5'
if os.path.exists(path):
    os.remove(path)
with pd.get_store(path) as store:
    for f in files:
        df = pd.read_csv(f,index_col=0)
        try:
            nrows = store.get_storer('foo').nrows
        except:
            nrows = 0
        df.index = pd.Series(df.index) + nrows
        store.append('foo',df)
pd.read_hdf('test.h5','foo')
pd.read_hdf('test.h5','foo',start=12,stop=15)","[""    pd.DataFrame(np.random.randn(10,2),columns=list('AB')).to_csv(f)"", '        df = pd.read_csv(f,index_col=0)', '        df.index = pd.Series(df.index) + nrows', ""        store.append('foo',df)"", ""pd.read_hdf('test.h5','foo')"", ""pd.read_hdf('test.h5','foo',start=12,stop=15)""]","['import pandas as pd', 'import numpy as np', 'import os', ""files = ['test1.csv','test2.csv']"", 'for f in files:', ""path = 'test.h5'"", 'if os.path.exists(path):', '    os.remove(path)', 'with pd.get_store(path) as store:', '    for f in files:', '        df = pd.read_csv(f,index_col=0)', '        try:', ""            nrows = store.get_storer('foo').nrows"", '        except:', '            nrows = 0', ""        store.append('foo',df)"", ""pd.read_hdf('test.h5','foo')"", ""pd.read_hdf('test.h5','foo',start=12,stop=15)""]","[""    pd.DataFrame(np.random.randn(10,2),columns=list('AB')).to_csv(f)"", '        df = pd.read_csv(f,index_col=0)', '        df.index = pd.Series(df.index) + nrows', ""        store.append('foo',df)"", ""pd.read_hdf('test.h5','foo')"", ""pd.read_hdf('test.h5','foo',start=12,stop=15)""]",,
17001474,,[],[''],[],[],[]
17005204,"pd.Series(a, a._fields)
df = pd.DataFrame(l, columns=l[0]._fields)
df
df.set_index(['ticker', 'date'], inplace=True)
df","['pd.Series(a, a._fields)', 'df = pd.DataFrame(l, columns=l[0]._fields)', ""df.set_index(['ticker', 'date'], inplace=True)""]","['df', ""df.set_index(['ticker', 'date'], inplace=True)"", 'df']","[""df.set_index(['ticker', 'date'], inplace=True)""]",,
17027507,"pd.DatetimeIndex([i.replace(tzinfo=None) for i in t])
def replace(self, **kwds):
    return Timestamp(datetime.replace(self, **kwds),
                     offset=self.offset)","['pd.DatetimeIndex([i.replace(tzinfo=None) for i in t])', '    return Timestamp(datetime.replace(self, **kwds),']","['pd.DatetimeIndex([i.replace(tzinfo=None) for i in t])', 'def replace(self, **kwds):', '    return Timestamp(datetime.replace(self, **kwds),', '                     offset=self.offset)']","['pd.DatetimeIndex([i.replace(tzinfo=None) for i in t])', '    return Timestamp(datetime.replace(self, **kwds),']",,
17056022,,[],[''],[],[],[]
17063653,"xl = pd.ExcelFile(""dummydata.xlsx"")
xl.sheet_names
[u'Sheet1', u'Sheet2', u'Sheet3']
df = xl.parse(""Sheet1"")
df.head()
parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")
parsed.columns
Index([u'Tid', u'dummy1', u'dummy2', u'dummy3', u'dummy4', u'dummy5', u'dummy6', u'dummy7', u'dummy8', u'dummy9'], dtype=object)","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['xl = pd.ExcelFile(""dummydata.xlsx"")', 'xl.sheet_names', ""[u'Sheet1', u'Sheet2', u'Sheet3']"", 'df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")', 'parsed.columns', ""Index([u'Tid', u'dummy1', u'dummy2', u'dummy3', u'dummy4', u'dummy5', u'dummy6', u'dummy7', u'dummy8', u'dummy9'], dtype=object)""]","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']"
17068439,"df = DataFrame(randn(5,1),columns=['value'])
df
df.loc[df['value']<0,'value'] = 0
df","[""df.loc[df['value']<0,'value'] = 0""]","[""df = DataFrame(randn(5,1),columns=['value'])"", 'df', ""df.loc[df['value']<0,'value'] = 0"", 'df']","[""df.loc[df['value']<0,'value'] = 0""]",,
17068462,"import pandas as pd
import numpy as np
df = pd.DataFrame({'value': np.arange(-5,5)})
df['value'] = df['value'].clip(0, None)
print(df)","[""df = pd.DataFrame({'value': np.arange(-5,5)})"", ""df['value'] = df['value'].clip(0, None)""]","['import pandas as pd', 'import numpy as np', ""df['value'] = df['value'].clip(0, None)"", 'print(df)']","[""df['value'] = df['value'].clip(0, None)""]",,
17071908,"df.loc[df['column_name'] == some_value]
df.loc[df['column_name'].isin(some_values)]
df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]
df.loc[df['column_name'] != some_value]
df.loc[~df['column_name'].isin(some_values)]
import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
print(df.loc[df['A'] == 'foo'])
print(df.loc[df['B'].isin(['one','three'])])
df = df.set_index(['B'])
print(df.loc['one'])
B              
df.loc[df.index.isin(['one','two'])]
B              ","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", 'import pandas as pd', 'import numpy as np', ""                   'B': 'one one two three two two one three'.split(),"", ""                   'C': np.arange(8), 'D': np.arange(8) * 2})"", 'print(df)', ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", 'B              ', ""df.loc[df.index.isin(['one','two'])]"", 'B              ']","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]"
17073442,"df[df['from_date'] == 19951227]
df[(19951227 <= df['from_date']) & (df['to_date'] <= 19960102)]
pd.to_datetime(df['from_date'].astype(str))
df['from_date'] = pd.to_datetime(df['from_date'].astype(str))
pd.to_datetime(df['from_date'].astype(str))  
df['1995-12-27' == df['from_date']]","[""pd.to_datetime(df['from_date'].astype(str))"", ""df['from_date'] = pd.to_datetime(df['from_date'].astype(str))"", ""pd.to_datetime(df['from_date'].astype(str))  ""]","[""df[df['from_date'] == 19951227]"", ""df[(19951227 <= df['from_date']) & (df['to_date'] <= 19960102)]"", ""pd.to_datetime(df['from_date'].astype(str))"", ""df['from_date'] = pd.to_datetime(df['from_date'].astype(str))"", ""pd.to_datetime(df['from_date'].astype(str))  "", ""df['1995-12-27' == df['from_date']]""]","[""pd.to_datetime(df['from_date'].astype(str))"", ""df['from_date'] = pd.to_datetime(df['from_date'].astype(str))"", ""pd.to_datetime(df['from_date'].astype(str))  ""]",,
17085016,"df.index = df.index.droplevel(2)
df",['df.index = df.index.droplevel(2)'],"['df.index = df.index.droplevel(2)', 'df']",['df.index = df.index.droplevel(2)'],,
17085044,"df.reset_index(level=2, drop=True)","['df.reset_index(level=2, drop=True)']","['df.reset_index(level=2, drop=True)']","['df.reset_index(level=2, drop=True)']",,
17086321,"from pandas import DataFrame
d = {'Revenue':[100,111,222], 
     'Cost':[333,444,555]}
df = DataFrame(d)
mask = df['Revenue'] == 111
df[mask]",[],"['from pandas import DataFrame', ""d = {'Revenue':[100,111,222], "", ""     'Cost':[333,444,555]}"", 'df = DataFrame(d)', ""mask = df['Revenue'] == 111"", 'df[mask]']",[],[],[]
17092113,"df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z'])
df.loc['y'] = pandas.Series({'a':1, 'b':5, 'c':2, 'd':3})
df","[""df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z'])"", ""df.loc['y'] = pandas.Series({'a':1, 'b':5, 'c':2, 'd':3})""]",['df'],"[""df.loc['y'] = pandas.Series({'a':1, 'b':5, 'c':2, 'd':3})""]",,
17092718,,[],[''],[],[],[]
17092986,,[],[''],[],[],[]
17095620,"ne = (df1 != df2).any(1)
ne
ne_stacked = (df1 != df2).stack()
changed = ne_stacked[ne_stacked]
changed.index.names = ['id', 'col']
changed
difference_locations = np.where(df1 != df2)
changed_from = df1.values[difference_locations]
changed_to = df2.values[difference_locations]
pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne', 'ne_stacked = (df1 != df2).stack()', 'changed = ne_stacked[ne_stacked]', ""changed.index.names = ['id', 'col']"", 'changed', 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]']","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]"
17096675,"import pandas as pd
import io
df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20])
df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20])
df = pd.concat([df1,df2]) 
print(df)
df.set_index(['id', 'Name'], inplace=True)
print(df)
def report_diff(x):
    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)
changes = df.groupby(level=['id', 'Name']).agg(report_diff)
print(changes)","['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20])', 'df = pd.concat([df1,df2]) ', ""df.set_index(['id', 'Name'], inplace=True)"", ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", ""changes = df.groupby(level=['id', 'Name']).agg(report_diff)""]","['import pandas as pd', 'import io', 'df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20])', 'df = pd.concat([df1,df2]) ', 'print(df)', ""df.set_index(['id', 'Name'], inplace=True)"", 'print(df)', 'def report_diff(x):', ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", ""changes = df.groupby(level=['id', 'Name']).agg(report_diff)"", 'print(changes)']","['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20])', 'df = pd.concat([df1,df2]) ', ""df.set_index(['id', 'Name'], inplace=True)"", ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", ""changes = df.groupby(level=['id', 'Name']).agg(report_diff)""]",,
17097397,"df.replace('-', None)","[""df.replace('-', None)""]","[""df.replace('-', None)""]","[""df.replace('-', None)""]",,
17097777,"~df[""col""].str.contains(word)","['~df[""col""].str.contains(word)']","['~df[""col""].str.contains(word)']","['~df[""col""].str.contains(word)']",,
17098736,"df.to_pickle(file_name)  
df = pd.read_pickle(file_name)
store = HDFStore('store.h5')
store['df'] = df  
store['df']  ","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)', ""store = HDFStore('store.h5')"", ""store['df'] = df  "", ""store['df']  ""]","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']"
17098885,,[],[''],[],[],[]
17106156,"fig, axes = plt.subplots(nrows=2, ncols=2)
fig.set_figheight(6)
fig.set_figwidth(8)
df[0].plot(ax=axes[0,0], style='r', label='Series'); axes[0,0].set_title(0)
df[1].plot(ax=axes[0,1]); axes[0,1].set_title(1)
df[2].plot(ax=axes[1,0]); axes[1,0].set_title(2)
df[3].plot(ax=axes[1,1]); axes[1,1].set_title(3)
fig.tight_layout()","[""df[0].plot(ax=axes[0,0], style='r', label='Series'); axes[0,0].set_title(0)"", 'df[1].plot(ax=axes[0,1]); axes[0,1].set_title(1)', 'df[2].plot(ax=axes[1,0]); axes[1,0].set_title(2)', 'df[3].plot(ax=axes[1,1]); axes[1,1].set_title(3)']","['fig, axes = plt.subplots(nrows=2, ncols=2)', 'fig.set_figheight(6)', 'fig.set_figwidth(8)', ""df[0].plot(ax=axes[0,0], style='r', label='Series'); axes[0,0].set_title(0)"", 'df[1].plot(ax=axes[0,1]); axes[0,1].set_title(1)', 'df[2].plot(ax=axes[1,0]); axes[1,0].set_title(2)', 'df[3].plot(ax=axes[1,1]); axes[1,1].set_title(3)', 'fig.tight_layout()']","[""df[0].plot(ax=axes[0,0], style='r', label='Series'); axes[0,0].set_title(0)"", 'df[1].plot(ax=axes[0,1]); axes[0,1].set_title(1)', 'df[2].plot(ax=axes[1,0]); axes[1,0].set_title(2)', 'df[3].plot(ax=axes[1,1]); axes[1,1].set_title(3)']",,
17115229,"mapping = {'set': 1, 'test': 2}
df.replace({'set': mapping, 'tesst': mapping})","[""df.replace({'set': mapping, 'tesst': mapping})""]","[""mapping = {'set': 1, 'test': 2}"", ""df.replace({'set': mapping, 'tesst': mapping})""]","[""df.replace({'set': mapping, 'tesst': mapping})""]",,
17116976,"df
s = df['Seatblocks'].str.split(' ').apply(Series, 1).stack()
s.index = s.index.droplevel(-1) 
s.name = 'Seatblocks' 
s
del df['Seatblocks']
df.join(s)
df.join(s.apply(lambda x: Series(x.split(':'))))","[""s = df['Seatblocks'].str.split(' ').apply(Series, 1).stack()"", 's.index = s.index.droplevel(-1) ', 'df.join(s)', ""df.join(s.apply(lambda x: Series(x.split(':'))))""]","['df', ""s = df['Seatblocks'].str.split(' ').apply(Series, 1).stack()"", 's.index = s.index.droplevel(-1) ', ""s.name = 'Seatblocks' "", 's', ""del df['Seatblocks']"", 'df.join(s)', ""df.join(s.apply(lambda x: Series(x.split(':'))))""]","[""s = df['Seatblocks'].str.split(' ').apply(Series, 1).stack()"", 's.index = s.index.droplevel(-1) ', 'df.join(s)', ""df.join(s.apply(lambda x: Series(x.split(':'))))""]",,
17128356,"df.ix[df.type==7, ['var1001', 'var1002']] = 0
columnsToReplace = ['var1001', 'var1002', ...]
df.ix[df.type==8, columnsToReplace] = 0",[],"[""df.ix[df.type==7, ['var1001', 'var1002']] = 0"", ""columnsToReplace = ['var1001', 'var1002', ...]"", 'df.ix[df.type==8, columnsToReplace] = 0']",[],[],[]
17134750,"df['col'] = pd.to_datetime(df['col'])
pd.to_datetime(pd.Series(['05/23/2005']))
pd.to_datetime(pd.Series(['05/23/2005']), format=""%m/%d/%Y"")
dtype: datetime64[ns]","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", 'dtype: datetime64[ns]']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']"
17135044,"with open(file_name, 'a') as f:
    df.to_csv(f, header=False)
df.to_csv(f, mode='a', header=False)","['    df.to_csv(f, header=False)', ""df.to_csv(f, mode='a', header=False)""]","[""with open(file_name, 'a') as f:"", '    df.to_csv(f, header=False)', ""df.to_csv(f, mode='a', header=False)""]","['    df.to_csv(f, header=False)', ""df.to_csv(f, mode='a', header=False)""]",,
17141755,"df.sort_values(['a', 'b'], ascending=[True, False])
df.sort(['a', 'b'], ascending=[True, False])
df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])
df1.sort(['a', 'b'], ascending=[True, False])
df1 = df1.sort(['a', 'b'], ascending=[True, False])
df1.sort(['a', 'b'], ascending=[True, False], inplace=True)","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df.sort(['a', 'b'], ascending=[True, False])"", ""df1.sort(['a', 'b'], ascending=[True, False])"", ""df1 = df1.sort(['a', 'b'], ascending=[True, False])"", ""df1.sort(['a', 'b'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['a', 'b'], ascending=[True, False])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]"
17142595,"df.replace(['very bad', 'bad', 'poor', 'good', 'very good'], 
                     [1, 2, 3, 4, 5]) ","[""df.replace(['very bad', 'bad', 'poor', 'good', 'very good'], ""]","[""df.replace(['very bad', 'bad', 'poor', 'good', 'very good'], "", '                     [1, 2, 3, 4, 5]) ']","[""df.replace(['very bad', 'bad', 'poor', 'good', 'very good'], ""]",,
17148934,"s = pd.Series([1, 1, 2, 1, 2, 2, 3])
s.value_counts()
dtype: int64
s.groupby(lambda i: np.floor(2*s[i]) / 2).count()","['s = pd.Series([1, 1, 2, 1, 2, 2, 3])', 's.value_counts()', 's.groupby(lambda i: np.floor(2*s[i]) / 2).count()']","['s.value_counts()', 'dtype: int64', 's.groupby(lambda i: np.floor(2*s[i]) / 2).count()']","['s.value_counts()', 's.groupby(lambda i: np.floor(2*s[i]) / 2).count()']",,
17150734,"s = Series(randn(100))
counts, bins = np.histogram(s)
Series(counts, index=bins[:-1])
dtype: int32",[],"['s = Series(randn(100))', 'counts, bins = np.histogram(s)', 'Series(counts, index=bins[:-1])', 'dtype: int32']",[],[],[]
17156183,"import psycopg2
conn = psycopg2.connect(""dbname='db' user='user' host='host' password='pass'"")
cur = conn.cursor()
cur.execute(""select instrument, price, date from my_prices"")
df = DataFrame(cur.fetchall(), columns=['instrument', 'price', 'date'])
df.set_index('date', drop=False)
df.index =  df['date']","[""df.set_index('date', drop=False)"", ""df.index =  df['date']""]","['import psycopg2', 'conn = psycopg2.connect(""dbname=\'db\' user=\'user\' host=\'host\' password=\'pass\'"")', 'cur = conn.cursor()', 'cur.execute(""select instrument, price, date from my_prices"")', ""df = DataFrame(cur.fetchall(), columns=['instrument', 'price', 'date'])"", ""df.set_index('date', drop=False)"", ""df.index =  df['date']""]","[""df.set_index('date', drop=False)"", ""df.index =  df['date']""]",,
17156233,"from sqlalchemy import create_engine
engine = create_engine('mysql://scott:tiger@localhost/foo')
table_name = 'my_prices'
df = pd.read_sql_table(table_name, engine)
df = pd.read_sql_query(""SELECT instrument, price, date FROM my_prices;"", engine)
df.reset_index().pivot('date', 'instrument', 'price')","['df = pd.read_sql_table(table_name, engine)', 'df = pd.read_sql_query(""SELECT instrument, price, date FROM my_prices;"", engine)', ""df.reset_index().pivot('date', 'instrument', 'price')""]","['from sqlalchemy import create_engine', ""engine = create_engine('mysql://scott:tiger@localhost/foo')"", ""table_name = 'my_prices'"", 'df = pd.read_sql_table(table_name, engine)', 'df = pd.read_sql_query(""SELECT instrument, price, date FROM my_prices;"", engine)', ""df.reset_index().pivot('date', 'instrument', 'price')""]","['df = pd.read_sql_table(table_name, engine)', 'df = pd.read_sql_query(""SELECT instrument, price, date FROM my_prices;"", engine)', ""df.reset_index().pivot('date', 'instrument', 'price')""]",,
17158735,"import matplotlib.ticker as ticker
a.xaxis.set_major_formatter(ticker.NullFormatter())
a.xaxis.set_minor_locator(ticker.FixedLocator([1.5,2.5,3.5,4.5,5.5]))
a.xaxis.set_minor_formatter(ticker.FixedFormatter(['1','2','3','4','5']))
a.set_xticklabels('')
a.set_xticks([1.5,2.5,3.5,4.5,5.5],      minor=True)
a.set_xticklabels(['1','2','3','4','5'], minor=True)",[],"['import matplotlib.ticker as ticker', 'a.xaxis.set_major_formatter(ticker.NullFormatter())', 'a.xaxis.set_minor_locator(ticker.FixedLocator([1.5,2.5,3.5,4.5,5.5]))', ""a.xaxis.set_minor_formatter(ticker.FixedFormatter(['1','2','3','4','5']))"", ""a.set_xticklabels('')"", 'a.set_xticks([1.5,2.5,3.5,4.5,5.5],      minor=True)', ""a.set_xticklabels(['1','2','3','4','5'], minor=True)""]",[],[],[]
17159276,"dat.index = pd.to_datetime(dat.pop('datetime'), utc=True)
dat
dat.index = dat.index.tz_localize('UTC').tz_convert('US/Pacific')
dat
dat.set_index('label', append=True).swaplevel(0, 1)
dat.index.levels[1] = dat.index.get_level_values(1).tz_localize('UTC').tz_convert('US/Pacific')
dat1","[""dat.index = pd.to_datetime(dat.pop('datetime'), utc=True)"", ""dat.index = dat.index.tz_localize('UTC').tz_convert('US/Pacific')"", ""dat.set_index('label', append=True).swaplevel(0, 1)"", ""dat.index.levels[1] = dat.index.get_level_values(1).tz_localize('UTC').tz_convert('US/Pacific')""]","[""dat.index = pd.to_datetime(dat.pop('datetime'), utc=True)"", 'dat', ""dat.index = dat.index.tz_localize('UTC').tz_convert('US/Pacific')"", 'dat', ""dat.set_index('label', append=True).swaplevel(0, 1)"", ""dat.index.levels[1] = dat.index.get_level_values(1).tz_localize('UTC').tz_convert('US/Pacific')"", 'dat1']","[""dat.index = pd.to_datetime(dat.pop('datetime'), utc=True)"", ""dat.index = dat.index.tz_localize('UTC').tz_convert('US/Pacific')"", ""dat.set_index('label', append=True).swaplevel(0, 1)"", ""dat.index.levels[1] = dat.index.get_level_values(1).tz_localize('UTC').tz_convert('US/Pacific')""]",,
17169776,"df = pd.DataFrame(prcpSeries, columns=['prcp'])
df['tmax'] = tmaxSeries
...
df = prcpSeries.to_frame(name='prcp')
df1 = pd.DataFrame(prcpSeries, columns=['prcp'])
df2 = pd.DataFrame(tmaxSeries, columns=['tmax'])
...
df = pd.concat([df1, df2, ...], join='outer', axis=1)
dfA = pd.DataFrame([1,2], columns=['A'])
dfB = pd.DataFrame([1], columns=['B'])
pd.concat([dfA, dfB], join='outer', axis=1)","[""df = pd.DataFrame(prcpSeries, columns=['prcp'])"", ""df = prcpSeries.to_frame(name='prcp')"", ""df1 = pd.DataFrame(prcpSeries, columns=['prcp'])"", ""df2 = pd.DataFrame(tmaxSeries, columns=['tmax'])"", ""df = pd.concat([df1, df2, ...], join='outer', axis=1)"", ""dfA = pd.DataFrame([1,2], columns=['A'])"", ""dfB = pd.DataFrame([1], columns=['B'])"", ""pd.concat([dfA, dfB], join='outer', axis=1)""]","[""df['tmax'] = tmaxSeries"", '...', ""df = prcpSeries.to_frame(name='prcp')"", '...', ""df = pd.concat([df1, df2, ...], join='outer', axis=1)"", ""pd.concat([dfA, dfB], join='outer', axis=1)""]","[""df = prcpSeries.to_frame(name='prcp')"", ""df = pd.concat([df1, df2, ...], join='outer', axis=1)"", ""pd.concat([dfA, dfB], join='outer', axis=1)""]",,
17171819,"rows = np.random.choice(df.index.values, 10)
sampled_df = df.ix[rows]","['rows = np.random.choice(df.index.values, 10)']","['rows = np.random.choice(df.index.values, 10)', 'sampled_df = df.ix[rows]']","['rows = np.random.choice(df.index.values, 10)']",,
17194149,"df = pd.DataFrame([[1,2], [3,4]], columns=['a', 'b'])
df
df['b']
df[[1]]
df.iloc[:, [1]]
df.loc[:, ['b']]
df.loc[:, 'b']","[""df = pd.DataFrame([[1,2], [3,4]], columns=['a', 'b'])"", 'df.iloc[:, [1]]', ""df.loc[:, ['b']]"", ""df.loc[:, 'b']""]","['df', ""df['b']"", 'df[[1]]', 'df.iloc[:, [1]]', ""df.loc[:, ['b']]"", ""df.loc[:, 'b']""]","['df.iloc[:, [1]]', ""df.loc[:, ['b']]"", ""df.loc[:, 'b']""]",,
17211698,"import warnings
warnings.filterwarnings('error')
warnings.filterwarnings('error', category=UnicodeWarning)
warnings.filterwarnings('error', message='*equal comparison failed*')",[],"['import warnings', ""warnings.filterwarnings('error')"", ""warnings.filterwarnings('error', category=UnicodeWarning)"", ""warnings.filterwarnings('error', message='*equal comparison failed*')""]",[],[],[]
17216674,d[(d['x']>2) & (d['y']>7)],[],"[""d[(d['x']>2) & (d['y']>7)]""]",[],[],[]
17241104,,[],[''],[],[],[]
17242374,"df = pd.DataFrame(index=['a', 'b'])
df.index.values
Out[2]: array(['a', 'b'], dtype=object)","[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']","['df.index.values', ""Out[2]: array(['a', 'b'], dtype=object)""]",['df.index.values'],"[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']","[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']"
17243346,"g
g.index = g.index.swaplevel(1, 2)
g = g.sortlevel()
g.index = g.index.swaplevel(1, 2)
g
g = df.groupby(['Manufacturer', 'Product Launch Date', 'Product Name']).sum()","['g.index = g.index.swaplevel(1, 2)', 'g.index = g.index.swaplevel(1, 2)', ""g = df.groupby(['Manufacturer', 'Product Launch Date', 'Product Name']).sum()""]","['g', 'g.index = g.index.swaplevel(1, 2)', 'g = g.sortlevel()', 'g.index = g.index.swaplevel(1, 2)', 'g', ""g = df.groupby(['Manufacturer', 'Product Launch Date', 'Product Name']).sum()""]","['g.index = g.index.swaplevel(1, 2)', 'g.index = g.index.swaplevel(1, 2)', ""g = df.groupby(['Manufacturer', 'Product Launch Date', 'Product Name']).sum()""]",,
17244095,"df.index.get_loc(ds)
Out[11]: 1",['df.index.get_loc(ds)'],"['df.index.get_loc(ds)', 'Out[11]: 1']",['df.index.get_loc(ds)'],,
17287046,"df[df > df.quantile(0.8)].dropna()
list(df[df > df.quantile(0.8)].dropna().index)
Out[14]: ['c', 'j']","['df[df > df.quantile(0.8)].dropna()', 'list(df[df > df.quantile(0.8)].dropna().index)']","['df[df > df.quantile(0.8)].dropna()', 'list(df[df > df.quantile(0.8)].dropna().index)', ""Out[14]: ['c', 'j']""]","['df[df > df.quantile(0.8)].dropna()', 'list(df[df > df.quantile(0.8)].dropna().index)']",,
17298454,"medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')
medals
medals.reindex_axis(['Gold', 'Silver', 'Bronze'], axis=1)","[""medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')"", ""medals.reindex_axis(['Gold', 'Silver', 'Bronze'], axis=1)""]","[""medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')"", 'medals', ""medals.reindex_axis(['Gold', 'Silver', 'Bronze'], axis=1)""]","[""medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')"", ""medals.reindex_axis(['Gold', 'Silver', 'Bronze'], axis=1)""]",,
17302673,"groups = dict(list(gb))
groups['foo']",[],"['groups = dict(list(gb))', ""groups['foo']""]",[],[],[]
17315875,import pandas as pd,[],['import pandas as pd'],[],[],[]
17322585,"df = DataFrame(randn(20,4),columns=list('ABCD'))
df[(df['A']>0) & (df['B']>0) & (df['C']>0)]
df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()
len(df[(df['A']>0) & (df['B']>0) & (df['C']>0)])
Out[20]: 3","[""df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()""]","[""df = DataFrame(randn(20,4),columns=list('ABCD'))"", ""df[(df['A']>0) & (df['B']>0) & (df['C']>0)]"", ""df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()"", ""len(df[(df['A']>0) & (df['B']>0) & (df['C']>0)])"", 'Out[20]: 3']","[""df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()""]",,
17347945,,[],[''],[],[],[]
17383140,"True == 1
True
False == 0
True
issubclass(bool, int)
True
True * 5
5",[],"['True == 1', 'True', 'False == 0', 'True', 'issubclass(bool, int)', 'True', 'True * 5', '5']",[],[],[]
17383325,"df = DataFrame(dict(A = True, B = False),index=range(3))
df
df.dtypes
df.astype(int)
df.astype(int).dtypes
dtype: object","['df.dtypes', 'df.astype(int)', 'df.astype(int).dtypes']","['df = DataFrame(dict(A = True, B = False),index=range(3))', 'df', 'df.dtypes', 'df.astype(int)', 'df.astype(int).dtypes', 'dtype: object']","['df.dtypes', 'df.astype(int)', 'df.astype(int).dtypes']",,
17426500,"Series(df.Letter.values,index=df.Position).to_dict()
df = DataFrame(randint(0,10,10000).reshape(5000,2),columns=list('AB'))","['Series(df.Letter.values,index=df.Position).to_dict()']","['Series(df.Letter.values,index=df.Position).to_dict()', ""df = DataFrame(randint(0,10,10000).reshape(5000,2),columns=list('AB'))""]","['Series(df.Letter.values,index=df.Position).to_dict()']",,
17439693,"df
city_id                       
df.groupby(df.index).sum()
city_id                       
df.reset_index().groupby(""city_id"").sum()
city_id                       
df.groupby(df.index)
df.groupby(df.index).max()
city_id                       
df.groupby(df.index).mean()
city_id                           ","['df.groupby(df.index).sum()', 'df.reset_index().groupby(""city_id"").sum()', 'df.groupby(df.index)', 'df.groupby(df.index).max()', 'df.groupby(df.index).mean()']","['df', 'city_id                       ', 'df.groupby(df.index).sum()', 'city_id                       ', 'df.reset_index().groupby(""city_id"").sum()', 'city_id                       ', 'df.groupby(df.index)', 'df.groupby(df.index).max()', 'city_id                       ', 'df.groupby(df.index).mean()', 'city_id                           ']","['df.groupby(df.index).sum()', 'df.reset_index().groupby(""city_id"").sum()', 'df.groupby(df.index)', 'df.groupby(df.index).max()', 'df.groupby(df.index).mean()']",,
17468012,"dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')
df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)
dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')
df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)","[""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)""]","[""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)""]","[""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"", ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)""]",,
17468154,date_parser : function,[],['date_parser : function'],[],[],[]
17478495,"df.replace([np.inf, -np.inf], np.nan)
df.replace([np.inf, -np.inf], np.nan).dropna(subset=[""col1"", ""col2""], how=""all"")
df = pd.DataFrame([1, 2, np.inf, -np.inf])
df.replace([np.inf, -np.inf], np.nan)","['df.replace([np.inf, -np.inf], np.nan)', 'df.replace([np.inf, -np.inf], np.nan).dropna(subset=[""col1"", ""col2""], how=""all"")', 'df = pd.DataFrame([1, 2, np.inf, -np.inf])', 'df.replace([np.inf, -np.inf], np.nan)']","['df.replace([np.inf, -np.inf], np.nan)', 'df.replace([np.inf, -np.inf], np.nan).dropna(subset=[""col1"", ""col2""], how=""all"")', 'df.replace([np.inf, -np.inf], np.nan)']","['df.replace([np.inf, -np.inf], np.nan)', 'df.replace([np.inf, -np.inf], np.nan).dropna(subset=[""col1"", ""col2""], how=""all"")', 'df.replace([np.inf, -np.inf], np.nan)']",,
17491690,"import pyodbc
import pandas as pd
cnxn = pyodbc.connect(databasez)
DF = pd.read_sql_query(""SELECT ID, NAME AS Nickname, ADDRESS AS Residence FROM tablez"", cnxn)","['DF = pd.read_sql_query(""SELECT ID, NAME AS Nickname, ADDRESS AS Residence FROM tablez"", cnxn)']","['import pyodbc', 'import pandas as pd', 'cnxn = pyodbc.connect(databasez)', 'DF = pd.read_sql_query(""SELECT ID, NAME AS Nickname, ADDRESS AS Residence FROM tablez"", cnxn)']","['DF = pd.read_sql_query(""SELECT ID, NAME AS Nickname, ADDRESS AS Residence FROM tablez"", cnxn)']",,
17496530,"rows_list = []
for row in input_rows:
        dict1 = {}
        rows_list.append(dict1)
df = pd.DataFrame(rows_list)               ","['        rows_list.append(dict1)', 'df = pd.DataFrame(rows_list)               ']","['rows_list = []', 'for row in input_rows:', '        dict1 = {}', '        rows_list.append(dict1)']",['        rows_list.append(dict1)'],,
17531025,"with open('my_csv.csv', 'a') as f:
    df.to_csv(f, header=False)
0,1,2,3
1,4,5,6
df = pd.read_csv('foo.csv', index_col=0)
df
df + 6
with open('foo.csv', 'a') as f:
             (df + 6).to_csv(f, header=False)
0,1,2,3
1,4,5,6
0,7,8,9
1,10,11,12","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","[""with open('my_csv.csv', 'a') as f:"", '    df.to_csv(f, header=False)', '0,1,2,3', '1,4,5,6', ""df = pd.read_csv('foo.csv', index_col=0)"", 'df', 'df + 6', ""with open('foo.csv', 'a') as f:"", '             (df + 6).to_csv(f, header=False)', '0,1,2,3', '1,4,5,6', '0,7,8,9', '1,10,11,12']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']"
17534256,,[],[''],[],[],[]
17534682,"s_bad = pd.Series([1, None], dtype=object)
s_good = pd.Series([1, np.nan])
s_bad.dtype
s_good.dtype
s_bad.sum()
s_good.sum()
Out[16]: 1.0","['s_bad = pd.Series([1, None], dtype=object)', 's_good = pd.Series([1, np.nan])', 's_bad.dtype', 's_good.dtype', 's_bad.sum()', 's_good.sum()']","['s_bad.dtype', 's_good.dtype', 's_bad.sum()', 's_good.sum()', 'Out[16]: 1.0']","['s_bad.dtype', 's_good.dtype', 's_bad.sum()', 's_good.sum()']",,
17591423,"def very_deep_copy(self):
    return pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())
pd.DataFrame.very_deep_copy = very_deep_copy
df2 = df.very_deep_copy()
id(df.columns)
id(df2.columns)
Out[15]: 4372118776","['    return pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())', 'pd.DataFrame.very_deep_copy = very_deep_copy']","['def very_deep_copy(self):', 'df2 = df.very_deep_copy()', 'id(df.columns)', 'id(df2.columns)', 'Out[15]: 4372118776']","['    return pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())']",,
17619032,"import pandas
df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])
df.sort(['c1','c2'], ascending=[False,True])
df.sort(['c1','c2'], ascending=[True,True])
df.sort(['c1','c2'], ascending=[False,True])
df.sort_values(['c1','c2'], ascending=[False,True])","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","['import pandas', ""df.sort(['c1','c2'], ascending=[False,True])"", ""df.sort(['c1','c2'], ascending=[True,True])"", ""df.sort(['c1','c2'], ascending=[False,True])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]"
17645475,"pandas.date_range(""11:00"", ""21:30"", freq=""30min"")
pandas.date_range(""11:00"", ""21:30"", freq=""30min"").time
array([datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0),
       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30),
       datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0),
       datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30),
       datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0),
       datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30),
       datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0),
       datetime.time(21, 30)], dtype=object)","['pandas.date_range(""11:00"", ""21:30"", freq=""30min"")', 'pandas.date_range(""11:00"", ""21:30"", freq=""30min"").time', 'array([datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0),', '       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30),', '       datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0),', '       datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30),', '       datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0),', '       datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30),', '       datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0),', '       datetime.time(21, 30)], dtype=object)']","['pandas.date_range(""11:00"", ""21:30"", freq=""30min"")', 'pandas.date_range(""11:00"", ""21:30"", freq=""30min"").time', 'array([datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0),', '       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30),', '       datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0),', '       datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30),', '       datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0),', '       datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30),', '       datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0),', '       datetime.time(21, 30)], dtype=object)']","['pandas.date_range(""11:00"", ""21:30"", freq=""30min"")', 'pandas.date_range(""11:00"", ""21:30"", freq=""30min"").time', 'array([datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0),', '       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30),', '       datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0),', '       datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30),', '       datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0),', '       datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30),', '       datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0),', '       datetime.time(21, 30)], dtype=object)']",,
17666287,"g = df.groupby(['A', 'B'])
df1 = df.set_index(['A', 'B'])
df1['D'] = g.size()  
df1.reset_index()","[""g = df.groupby(['A', 'B'])"", ""df1 = df.set_index(['A', 'B'])"", ""df1['D'] = g.size()  "", 'df1.reset_index()']","[""g = df.groupby(['A', 'B'])"", ""df1 = df.set_index(['A', 'B'])"", ""df1['D'] = g.size()  "", 'df1.reset_index()']","[""g = df.groupby(['A', 'B'])"", ""df1 = df.set_index(['A', 'B'])"", ""df1['D'] = g.size()  "", 'df1.reset_index()']",,
17679517,"df.groupby(['col5', 'col2']).size()
df.groupby(['col5', 'col2']).size().groupby(level=1).max()
col2
dtype: int64","[""df.groupby(['col5', 'col2']).size()"", ""df.groupby(['col5', 'col2']).size().groupby(level=1).max()""]","[""df.groupby(['col5', 'col2']).size()"", ""df.groupby(['col5', 'col2']).size().groupby(level=1).max()"", 'col2', 'dtype: int64']","[""df.groupby(['col5', 'col2']).size()"", ""df.groupby(['col5', 'col2']).size().groupby(level=1).max()""]",,
17679980,"df.groupby(['col5','col2']).size().reset_index().groupby('col2')[[0]].max()
col2   ","[""df.groupby(['col5','col2']).size().reset_index().groupby('col2')[[0]].max()""]","[""df.groupby(['col5','col2']).size().reset_index().groupby('col2')[[0]].max()"", 'col2   ']","[""df.groupby(['col5','col2']).size().reset_index().groupby('col2')[[0]].max()""]",,
17682662,"df[df.c > 0.5][['b', 'e']].values
array([[ 0.98836259,  0.82403141],
       [ 0.337358  ,  0.02054435],
       [ 0.29271728,  0.37813099],
       [ 0.70033513,  0.69919695]])","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values"", 'array([[ 0.98836259,  0.82403141],', '       [ 0.337358  ,  0.02054435],', '       [ 0.29271728,  0.37813099],', '       [ 0.70033513,  0.69919695]])']","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values""]"
17682665,"df = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))
df[df['c']>.5][['b','e']]
df[df['c']>.5][['b','e']].values
array([[ 0.07114556,  0.13214495],
       [ 0.49515157,  0.42021946]])","[""df = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))"", ""df[df['c']>.5][['b','e']].values""]","[""df[df['c']>.5][['b','e']]"", ""df[df['c']>.5][['b','e']].values"", 'array([[ 0.07114556,  0.13214495],', '       [ 0.49515157,  0.42021946]])']","[""df[df['c']>.5][['b','e']].values""]",,
17682726,"df = DataFrame(np.random.rand(4,5), columns = list('abcde'))
df
df.loc[df['c']>0.5,['a','d']]
df.loc[df['c']>0.5,['a','d']].values
array([[ 0.66970138,  0.45157274],
       [ 0.95276167,  0.64325143],
       [ 0.90071271,  0.50577509]])","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df = DataFrame(np.random.rand(4,5), columns = list('abcde'))"", 'df', ""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values"", 'array([[ 0.66970138,  0.45157274],', '       [ 0.95276167,  0.64325143],', '       [ 0.90071271,  0.50577509]])']","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]"
17690795,"import pandas as pd
date_stngs = ('2008-12-20','2008-12-21','2008-12-22','2008-12-23')
a = pd.Series([pd.to_datetime(date) for date in date_stngs])
a
pd.to_datetime(pd.Series(date_stngs))","['a = pd.Series([pd.to_datetime(date) for date in date_stngs])', 'pd.to_datetime(pd.Series(date_stngs))']","['import pandas as pd', ""date_stngs = ('2008-12-20','2008-12-21','2008-12-22','2008-12-23')"", 'a']","['a = pd.Series([pd.to_datetime(date) for date in date_stngs])', 'pd.to_datetime(pd.Series(date_stngs))']",,
17690868,"pd.to_datetime(pd.Series(date_stngs))
dates = [(dt.datetime(1960, 1, 1)+dt.timedelta(days=i)).date().isoformat() for i in range(20000)]","['pd.to_datetime(pd.Series(date_stngs))', 'dates = [(dt.datetime(1960, 1, 1)+dt.timedelta(days=i)).date().isoformat() for i in range(20000)]']","['dates = [(dt.datetime(1960, 1, 1)+dt.timedelta(days=i)).date().isoformat() for i in range(20000)]']","['pd.to_datetime(pd.Series(date_stngs))', 'dates = [(dt.datetime(1960, 1, 1)+dt.timedelta(days=i)).date().isoformat() for i in range(20000)]']",,
17692156,"df.stack().value_counts()
dtype: int64",['df.stack().value_counts()'],"['df.stack().value_counts()', 'dtype: int64']",['df.stack().value_counts()'],,
17702833,"df = pd.DataFrame({'Status':['Delivered', 'Delivered', 'Undelivered',
                                     'SomethingElse']})
df
d = {'Delivered': True, 'Undelivered': False}
df['Status'].map(d)","[""df = pd.DataFrame({'Status':['Delivered', 'Delivered', 'Undelivered',"", ""df['Status'].map(d)""]","[""                                     'SomethingElse']})"", 'df', ""d = {'Delivered': True, 'Undelivered': False}"", ""df['Status'].map(d)""]","[""df['Status'].map(d)""]",,
17709453,"df['Counts'] = df.groupby(['Color'])['Value'].transform('count')
df = pd.DataFrame({'Color': 'Red Red Blue'.split(), 'Value': [100, 150, 50]})
df
df['Counts'] = df.groupby(['Color'])['Value'].transform('count')
df","[""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')"", ""df = pd.DataFrame({'Color': 'Red Red Blue'.split(), 'Value': [100, 150, 50]})"", ""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')""]","[""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')"", 'df', ""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')"", 'df']","[""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')"", ""df = pd.DataFrame({'Color': 'Red Red Blue'.split(), 'Value': [100, 150, 50]})"", ""df['Counts'] = df.groupby(['Color'])['Value'].transform('count')""]",,
17712440,"df = pd.DataFrame(np.random.randn(4,4), columns=list('ABCD'))
df
df.mean()
df.mean().sort_values()
df.reindex_axis(df.mean().sort_values().index, axis=1)","[""df = pd.DataFrame(np.random.randn(4,4), columns=list('ABCD'))"", 'df.mean()', 'df.mean().sort_values()', 'df.reindex_axis(df.mean().sort_values().index, axis=1)']","['df', 'df.mean()', 'df.mean().sort_values()', 'df.reindex_axis(df.mean().sort_values().index, axis=1)']","['df.mean()', 'df.mean().sort_values()', 'df.reindex_axis(df.mean().sort_values().index, axis=1)']",,
17729985,"d.sales[d.sales==24] = 100
d
d.loc[d.sales == 12, 'sales'] = 99
d
d.sales = d.sales.replace(23, 24)
d","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","['d.sales[d.sales==24] = 100', 'd', ""d.loc[d.sales == 12, 'sales'] = 99"", 'd', 'd.sales = d.sales.replace(23, 24)', 'd']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']"
17758115,"df = pd.DataFrame({""A"": 1e4*np.arange(100), ""num"": np.random.random(100)})
x = 0.75
df.ix[(df.num-x).abs().argsort()[:5]]
x = 0.33
df.ix[(df.num-x).abs().argsort()[:5]]","['df = pd.DataFrame({""A"": 1e4*np.arange(100), ""num"": np.random.random(100)})', 'df.ix[(df.num-x).abs().argsort()[:5]]', 'df.ix[(df.num-x).abs().argsort()[:5]]']","['x = 0.75', 'df.ix[(df.num-x).abs().argsort()[:5]]', 'x = 0.33', 'df.ix[(df.num-x).abs().argsort()[:5]]']","['df.ix[(df.num-x).abs().argsort()[:5]]', 'df.ix[(df.num-x).abs().argsort()[:5]]']",,
17778786,"import pandas as pd
import numpy as np
shape = (50, 4460)
data = np.random.normal(size=shape)
data[:, 1000] += data[:, 2000]
df = pd.DataFrame(data)
c = df.corr().abs()
s = c.unstack()
so = s.order(kind=""quicksort"")
dtype: float64","['df = pd.DataFrame(data)', 'c = df.corr().abs()', 's = c.unstack()']","['import pandas as pd', 'import numpy as np', 'shape = (50, 4460)', 'data = np.random.normal(size=shape)', 'data[:, 1000] += data[:, 2000]', 'c = df.corr().abs()', 's = c.unstack()', 'so = s.order(kind=""quicksort"")', 'dtype: float64']","['c = df.corr().abs()', 's = c.unstack()']",,
17779230,,[],[''],[],[],[]
17811984,writer.sheets['Summary'].column_dimensions['A'].width = 15,[],"[""writer.sheets['Summary'].column_dimensions['A'].width = 15""]",[],[],[]
17813222,"df.plot(x='col_name_1', y='col_name_2', style='o')
import numpy as np
import pandas as pd
d = {'one' : np.random.rand(10),
     'two' : np.random.rand(10)}
df = pd.DataFrame(d)
df.plot(style=['o','rx'])","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'import numpy as np', 'import pandas as pd', ""d = {'one' : np.random.rand(10),"", ""     'two' : np.random.rand(10)}"", ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]"
17813277,"import matplotlib.pyplot as plt
plt.scatter(df['col_name_1'], df['col_name_2'])
plt.show() ",[],"['import matplotlib.pyplot as plt', ""plt.scatter(df['col_name_1'], df['col_name_2'])"", 'plt.show() ']",[],[],[]
17819427,"col = np.array([0,0,1,2,2,2])
data = np.array([1,2,3,4,5,6],dtype='float64')
m = csc_matrix( (data,(row,col)), shape=(3,3) )
m
pd.SparseDataFrame([ pd.SparseSeries(m[i].toarray().ravel()) 
                              for i in np.arange(m.shape[0]) ])
df = pd.SparseDataFrame([ pd.SparseSeries(m[i].toarray().ravel()) 
                                   for i in np.arange(m.shape[0]) ])
type(df)
Out[48]: pandas.sparse.frame.SparseDataFrame","['                              for i in np.arange(m.shape[0]) ])', '                                   for i in np.arange(m.shape[0]) ])']","['col = np.array([0,0,1,2,2,2])', ""data = np.array([1,2,3,4,5,6],dtype='float64')"", 'm = csc_matrix( (data,(row,col)), shape=(3,3) )', 'm', 'pd.SparseDataFrame([ pd.SparseSeries(m[i].toarray().ravel()) ', '                              for i in np.arange(m.shape[0]) ])', 'df = pd.SparseDataFrame([ pd.SparseSeries(m[i].toarray().ravel()) ', '                                   for i in np.arange(m.shape[0]) ])', 'type(df)', 'Out[48]: pandas.sparse.frame.SparseDataFrame']","['                              for i in np.arange(m.shape[0]) ])', '                                   for i in np.arange(m.shape[0]) ])']",,
17840195,"df = pd.DataFrame({'A': [a], 'B': [b]})
df
df = pd.DataFrame({'A': a, 'B': b}, index=[0])
df","[""df = pd.DataFrame({'A': [a], 'B': [b]})"", ""df = pd.DataFrame({'A': a, 'B': b}, index=[0])""]","['df', 'df']",[],,
17840197,"df2 = pd.DataFrame({'A':[a],'B':[b]})","[""df2 = pd.DataFrame({'A':[a],'B':[b]})""]",[],[],,
17841294,"df = read_csv(StringIO(data),sep='\s+')
df
df.dtypes
df.groupby('A').apply(lambda x: x.sum())
df.groupby('A')['C'].apply(lambda x: x.sum())
df.groupby('A')['C'].apply(lambda x: ""{%s}"" % ', '.join(x))
df.groupby('A').apply(f)
A                             ","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","[""df = read_csv(StringIO(data),sep='\\s+')"", 'df', 'df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)"", 'A                             ']","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]"
17841308,"d
d.groupby('A')['B'].apply(list)
A
1    [This, string]
3               [a]
4          [random]
dtype: object","[""d.groupby('A')['B'].apply(list)""]","['d', ""d.groupby('A')['B'].apply(list)"", 'A', '1    [This, string]', '3               [a]', '4          [random]', 'dtype: object']","[""d.groupby('A')['B'].apply(list)""]",,
17877159,"x = np.random.randn(30)
fig, ax = plt.subplots(1,2, figsize=(10,4))
ax[0].hist(x, normed=True, color='grey')
hist, bins = np.histogram(x)
ax[1].bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1]-bins[0]), color='grey')
ax[0].set_title('normed=True')
ax[1].set_title('hist = hist / hist.sum()')","[""ax[1].bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1]-bins[0]), color='grey')""]","['x = np.random.randn(30)', 'fig, ax = plt.subplots(1,2, figsize=(10,4))', ""ax[0].hist(x, normed=True, color='grey')"", 'hist, bins = np.histogram(x)', ""ax[1].bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1]-bins[0]), color='grey')"", ""ax[0].set_title('normed=True')"", ""ax[1].set_title('hist = hist / hist.sum()')""]","[""ax[1].bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1]-bins[0]), color='grey')""]",,
17910713,"df.to_csv(file_name, header=False, mode = 'a')","[""df.to_csv(file_name, header=False, mode = 'a')""]","[""df.to_csv(file_name, header=False, mode = 'a')""]","[""df.to_csv(file_name, header=False, mode = 'a')""]",,
17923621,"df
x = df.reset_index()
x.loc[(x.A>=3.3)&(x.A<=6.6)]
x.loc[(x.A>=2.0)&(x.A<=4.0)]
x.loc[(x.B>=111.0)&(x.B<=500.0)]
x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B'])
x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B']).index
MultiIndex
[(1.1, 111), (1.1, 222), (3.3, 222), (3.3, 333), (5.5, 333)]","['x = df.reset_index()', 'x.loc[(x.A>=3.3)&(x.A<=6.6)]', 'x.loc[(x.A>=2.0)&(x.A<=4.0)]', 'x.loc[(x.B>=111.0)&(x.B<=500.0)]', ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B'])"", ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B']).index""]","['df', 'x = df.reset_index()', 'x.loc[(x.A>=3.3)&(x.A<=6.6)]', 'x.loc[(x.A>=2.0)&(x.A<=4.0)]', 'x.loc[(x.B>=111.0)&(x.B<=500.0)]', ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B'])"", ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B']).index"", 'MultiIndex', '[(1.1, 111), (1.1, 222), (3.3, 222), (3.3, 333), (5.5, 333)]']","['x = df.reset_index()', 'x.loc[(x.A>=3.3)&(x.A<=6.6)]', 'x.loc[(x.A>=2.0)&(x.A<=4.0)]', 'x.loc[(x.B>=111.0)&(x.B<=500.0)]', ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B'])"", ""x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B']).index""]",,
17926411,"df.groupby(['col1','col2'])['col3'].nunique().reset_index()","[""df.groupby(['col1','col2'])['col3'].nunique().reset_index()""]","[""df.groupby(['col1','col2'])['col3'].nunique().reset_index()""]","[""df.groupby(['col1','col2'])['col3'].nunique().reset_index()""]",,
17926436,"df
df.groupby([0,1])[2].apply(lambda x: len(x.unique()))
dtype: int64","['df.groupby([0,1])[2].apply(lambda x: len(x.unique()))']","['df', 'df.groupby([0,1])[2].apply(lambda x: len(x.unique()))', 'dtype: int64']","['df.groupby([0,1])[2].apply(lambda x: len(x.unique()))']",,
17933417,"import csv
import numpy as np
np.genfromtxt((""\t"".join(i) for i in csv.reader(open('myfile.csv'))), delimiter=""\t"")","['np.genfromtxt((""\\t"".join(i) for i in csv.reader(open(\'myfile.csv\'))), delimiter=""\\t"")']","['import csv', 'import numpy as np', 'np.genfromtxt((""\\t"".join(i) for i in csv.reader(open(\'myfile.csv\'))), delimiter=""\\t"")']","['np.genfromtxt((""\\t"".join(i) for i in csv.reader(open(\'myfile.csv\'))), delimiter=""\\t"")']",,
17942117,"import pandas as pd
from StringIO import StringIO
s=""""""year, city, value
   ...: 2012, ""Louisville KY"", 3.5
   ...: 2011, ""Lexington, KY"", 4.0""""""
pd.read_csv(StringIO(s), quotechar='""', skipinitialspace=True)","['pd.read_csv(StringIO(s), quotechar=\'""\', skipinitialspace=True)']","['import pandas as pd', 'from StringIO import StringIO', 's=""""""year, city, value', '   ...: 2012, ""Louisville KY"", 3.5', '   ...: 2011, ""Lexington, KY"", 4.0""""""', 'pd.read_csv(StringIO(s), quotechar=\'""\', skipinitialspace=True)']","['pd.read_csv(StringIO(s), quotechar=\'""\', skipinitialspace=True)']",,
17950081,"df.drop(label)
df.drop(label, inplace=True)
df.drop(df.index[:3], inplace=True)
df.drop(df.head(3).index, inplace=True)","['df.drop(label)', 'df.drop(label, inplace=True)', 'df.drop(df.index[:3], inplace=True)', 'df.drop(df.head(3).index, inplace=True)']","['df.drop(label)', 'df.drop(label, inplace=True)', 'df.drop(df.index[:3], inplace=True)', 'df.drop(df.head(3).index, inplace=True)']","['df.drop(label)', 'df.drop(label, inplace=True)', 'df.drop(df.index[:3], inplace=True)', 'df.drop(df.head(3).index, inplace=True)']",,
17950531,"df = DataFrame(np.arange(10).reshape(5,2),columns=list('AB'))
df
df.dtypes
df['A'].apply(str)
df['A'].apply(str)[0]
df.applymap(str)
df.applymap(str).iloc[0,0]
Out[22]: '0'","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","[""df = DataFrame(np.arange(10).reshape(5,2),columns=list('AB'))"", 'df', 'df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]', ""Out[22]: '0'""]","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']"
17958424,"s = pd.Series(['a', 'ab', 'c', 11, np.nan])
s
s.str.startswith('a', na=False)
s.loc[s.str.startswith('a', na=False)]
dtype: object","[""s = pd.Series(['a', 'ab', 'c', 11, np.nan])"", ""s.str.startswith('a', na=False)"", ""s.loc[s.str.startswith('a', na=False)]""]","['s', ""s.str.startswith('a', na=False)"", ""s.loc[s.str.startswith('a', na=False)]"", 'dtype: object']","[""s.str.startswith('a', na=False)"", ""s.loc[s.str.startswith('a', na=False)]""]",,
17961468,"import pandas as pd
pd.__version__
np.__version__
bar = foo.iloc[3:5,1:4]
bar == foo.iloc[3:5,1:4] == foo_copy.iloc[3:5,1:4]","['bar = foo.iloc[3:5,1:4]', 'bar == foo.iloc[3:5,1:4] == foo_copy.iloc[3:5,1:4]']","['import pandas as pd', 'pd.__version__', 'np.__version__', 'bar = foo.iloc[3:5,1:4]', 'bar == foo.iloc[3:5,1:4] == foo_copy.iloc[3:5,1:4]']","['bar = foo.iloc[3:5,1:4]', 'bar == foo.iloc[3:5,1:4] == foo_copy.iloc[3:5,1:4]']",,
17973255,"pattern = '|'.join(mylist)
pattern
frame.a.str.contains(pattern)","[""pattern = '|'.join(mylist)"", 'frame.a.str.contains(pattern)']","[""pattern = '|'.join(mylist)"", 'pattern', 'frame.a.str.contains(pattern)']","[""pattern = '|'.join(mylist)"", 'frame.a.str.contains(pattern)']",,
17975690,,[],[''],[],[],[]
17977609,"xl = pd.ExcelFile('foo.xls')
xl.sheet_names  
xl.parse(sheet_name)  ",['xl.parse(sheet_name)  '],"[""xl = pd.ExcelFile('foo.xls')"", 'xl.sheet_names  ', 'xl.parse(sheet_name)  ']",['xl.parse(sheet_name)  '],,
17978188,"df['Date'] + ' ' + df['Time']
pd.to_datetime(df['Date'] + ' ' + df['Time'])
dtype: datetime64[ns]","[""pd.to_datetime(df['Date'] + ' ' + df['Time'])""]","[""df['Date'] + ' ' + df['Time']"", ""pd.to_datetime(df['Date'] + ' ' + df['Time'])"", 'dtype: datetime64[ns]']","[""pd.to_datetime(df['Date'] + ' ' + df['Time'])""]",,
17978414,"df2[list('xab')]  
df1.merge(df2[list('xab')])","[""df1.merge(df2[list('xab')])""]","[""df2[list('xab')]  "", ""df1.merge(df2[list('xab')])""]","[""df1.merge(df2[list('xab')])""]",,
17995122,"df['size'] = df.groupby(['A','B']).transform(np.size)","[""df['size'] = df.groupby(['A','B']).transform(np.size)""]","[""df['size'] = df.groupby(['A','B']).transform(np.size)""]","[""df['size'] = df.groupby(['A','B']).transform(np.size)""]",,
18013682,"area_dict = dict(zip(lakes.area, lakes.count))","['area_dict = dict(zip(lakes.area, lakes.count))']","['area_dict = dict(zip(lakes.area, lakes.count))']","['area_dict = dict(zip(lakes.area, lakes.count))']",,
18023468,"df.index.name
df.index.name = 'foo'
df.index.name
df
foo              ","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name', 'df', 'foo              ']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']"
18023485,,[],[''],[],[],[]
18039175,,[],[''],[],[],[]
18046682,,[],[''],[],[],[]
18061253,"dr = date_range('1/1/2010', periods=3, freq=3 * datetools.bday)
raw = randn(3)
ts = Series(raw, index=dr)
ts
ts.asfreq(datetools.BDay())
ts.resample(datetools.BDay())","['ts.asfreq(datetools.BDay())', 'ts.resample(datetools.BDay())']","[""dr = date_range('1/1/2010', periods=3, freq=3 * datetools.bday)"", 'raw = randn(3)', 'ts = Series(raw, index=dr)', 'ts', 'ts.asfreq(datetools.BDay())', 'ts.resample(datetools.BDay())']","['ts.asfreq(datetools.BDay())', 'ts.resample(datetools.BDay())']",,
18062430,"s1 = Series(randn(5),index=[1,2,4,5,6])
s2 = Series(randn(5),index=[1,2,4,5,6])
DataFrame(dict(s1 = s1, s2 = s2)).reset_index()","['DataFrame(dict(s1 = s1, s2 = s2)).reset_index()']","['s1 = Series(randn(5),index=[1,2,4,5,6])', 's2 = Series(randn(5),index=[1,2,4,5,6])', 'DataFrame(dict(s1 = s1, s2 = s2)).reset_index()']","['DataFrame(dict(s1 = s1, s2 = s2)).reset_index()']",,
18062521,"s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')
s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')
pd.concat([s1, s2], axis=1)
pd.concat([s1, s2], axis=1).reset_index()","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","['pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","['pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']"
18067431,,[],[''],[],[],[]
18079695,"pd.Series(list(set(s1).intersection(set(s2))))
Series(list(set(s1) & set(s2)))",['pd.Series(list(set(s1).intersection(set(s2))))'],['Series(list(set(s1) & set(s2)))'],['pd.Series(list(set(s1).intersection(set(s2))))'],,
18080142,"pd.Series(np.intersect1d(pd.Series([1,2,3,5,42]), pd.Series([4,5,6,20,42])))","['pd.Series(np.intersect1d(pd.Series([1,2,3,5,42]), pd.Series([4,5,6,20,42])))']",[],[],,
18090009,nbytes = sum(block.values.nbytes for block in df.blocks.values()),['nbytes = sum(block.values.nbytes for block in df.blocks.values())'],['nbytes = sum(block.values.nbytes for block in df.blocks.values())'],['nbytes = sum(block.values.nbytes for block in df.blocks.values())'],,
18090393,"DataFrame(randn(1000000,20)).to_csv('test.csv')
df.values.nbytes + df.index.nbytes + df.columns.nbytes
DataFrame(randn(1000000,20)).to_hdf('test.h5','df',complevel=9,complib='blosc')","[""DataFrame(randn(1000000,20)).to_csv('test.csv')"", 'df.values.nbytes + df.index.nbytes + df.columns.nbytes', ""DataFrame(randn(1000000,20)).to_hdf('test.h5','df',complevel=9,complib='blosc')""]","[""DataFrame(randn(1000000,20)).to_csv('test.csv')"", 'df.values.nbytes + df.index.nbytes + df.columns.nbytes', ""DataFrame(randn(1000000,20)).to_hdf('test.h5','df',complevel=9,complib='blosc')""]","[""DataFrame(randn(1000000,20)).to_csv('test.csv')"", 'df.values.nbytes + df.index.nbytes + df.columns.nbytes', ""DataFrame(randn(1000000,20)).to_hdf('test.h5','df',complevel=9,complib='blosc')""]",,
18101965,"df.to_html(classes='my_class')
df.to_html(classes=['my_class', 'my_other_class'])
import numpy as np
df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})
HTML(df.to_html(classes='my_class'))
Javascript()
HTML( + df.to_html(classes='df'))
import numpy as np
import pandas as pd
df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})
with open('test.html', 'w') as f:
    f.write(HEADER)
    f.write(df.to_html(classes='df'))
    f.write(FOOTER)","[""df.to_html(classes='my_class')"", ""df.to_html(classes=['my_class', 'my_other_class'])"", ""df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})"", ""HTML(df.to_html(classes='my_class'))"", ""HTML( + df.to_html(classes='df'))"", ""df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})"", ""    f.write(df.to_html(classes='df'))""]","[""df.to_html(classes='my_class')"", ""df.to_html(classes=['my_class', 'my_other_class'])"", 'import numpy as np', ""HTML(df.to_html(classes='my_class'))"", 'Javascript()', ""HTML( + df.to_html(classes='df'))"", 'import numpy as np', 'import pandas as pd', ""with open('test.html', 'w') as f:"", '    f.write(HEADER)', ""    f.write(df.to_html(classes='df'))"", '    f.write(FOOTER)']","[""df.to_html(classes='my_class')"", ""df.to_html(classes=['my_class', 'my_other_class'])"", ""HTML(df.to_html(classes='my_class'))"", ""HTML( + df.to_html(classes='df'))"", ""    f.write(df.to_html(classes='df'))""]",,
18103894,"result_df = df.loc[(df.index.get_level_values('A') > 1.7) & (df.index.get_level_values('B') < 666)]
result_df
result_df.index.get_level_values('A')
df = store.select(STORE_EXTENT_BURSTS_DF_KEY)
len(df)
df.sort(inplace=True)
df_without_index = df.reset_index()","[""result_df = df.loc[(df.index.get_level_values('A') > 1.7) & (df.index.get_level_values('B') < 666)]"", ""result_df.index.get_level_values('A')"", 'df = store.select(STORE_EXTENT_BURSTS_DF_KEY)', 'df_without_index = df.reset_index()']","[""result_df = df.loc[(df.index.get_level_values('A') > 1.7) & (df.index.get_level_values('B') < 666)]"", 'result_df', ""result_df.index.get_level_values('A')"", 'df = store.select(STORE_EXTENT_BURSTS_DF_KEY)', 'len(df)', 'df.sort(inplace=True)', 'df_without_index = df.reset_index()']","[""result_df = df.loc[(df.index.get_level_values('A') > 1.7) & (df.index.get_level_values('B') < 666)]"", ""result_df.index.get_level_values('A')"", 'df = store.select(STORE_EXTENT_BURSTS_DF_KEY)', 'df_without_index = df.reset_index()']",,
18108357,"import pandas as pd
import pandas.io.sql as psql
chunk_size = 10000
offset = 0
dfs = []
while True:
  sql = ""SELECT * FROM MyTable limit %d offset %d order by ID"" % (chunk_size,offset) 
  dfs.append(psql.read_frame(sql, cnxn))
  offset += chunk_size
  if len(dfs[-1]) < chunk_size:
    break
full_df = pd.concat(dfs)","['  dfs.append(psql.read_frame(sql, cnxn))', 'full_df = pd.concat(dfs)']","['import pandas as pd', 'import pandas.io.sql as psql', 'chunk_size = 10000', 'offset = 0', 'dfs = []', 'while True:', '  sql = ""SELECT * FROM MyTable limit %d offset %d order by ID"" % (chunk_size,offset) ', '  dfs.append(psql.read_frame(sql, cnxn))', '  offset += chunk_size', '  if len(dfs[-1]) < chunk_size:', '    break', 'full_df = pd.concat(dfs)']","['  dfs.append(psql.read_frame(sql, cnxn))', 'full_df = pd.concat(dfs)']",,
18129082,"data = pd.read_csv('file1.csv', error_bad_lines=False)","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]"
18145399,"df = df.drop('column_name', 1)
df.drop('column_name', axis=1, inplace=True)
df.drop(df.columns[[0, 1, 3]], axis=1)  ","[""df = df.drop('column_name', 1)"", ""df.drop('column_name', axis=1, inplace=True)"", 'df.drop(df.columns[[0, 1, 3]], axis=1)  ']","[""df = df.drop('column_name', 1)"", ""df.drop('column_name', axis=1, inplace=True)"", 'df.drop(df.columns[[0, 1, 3]], axis=1)  ']","[""df = df.drop('column_name', 1)"", ""df.drop('column_name', axis=1, inplace=True)"", 'df.drop(df.columns[[0, 1, 3]], axis=1)  ']",,
18162021,"import pandas
sample={'user1': {'item1': 2.5, 'item2': 3.5, 'item3': 3.0, 'item4': 3.5, 'item5': 2.5, 'item6': 3.0},
        'user2': {'item1': 2.5, 'item2': 3.0, 'item3': 3.5, 'item4': 4.0},
        'user3': {'item2':4.5,'item5':1.0,'item6':4.0}}
df = pandas.DataFrame([
    [col1,col2,col3] for col1, d in sample.items() for col2, col3 in d.items()
])",['df = pandas.DataFrame(['],"['import pandas', ""sample={'user1': {'item1': 2.5, 'item2': 3.5, 'item3': 3.0, 'item4': 3.5, 'item5': 2.5, 'item6': 3.0},"", ""        'user2': {'item1': 2.5, 'item2': 3.0, 'item3': 3.5, 'item4': 4.0},"", ""        'user3': {'item2':4.5,'item5':1.0,'item6':4.0}}"", '    [col1,col2,col3] for col1, d in sample.items() for col2, col3 in d.items()', '])']",[],,
18162196,"df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})
df = pd.melt(df, ""item"", var_name=""user"").dropna()
df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)
df = pd.DataFrame(sample)
df
df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})
df
df = pd.melt(df, ""item"", var_name=""user"").dropna()
df
df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)
df","['df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})', 'df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)', 'df = pd.DataFrame(sample)', 'df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})', 'df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)']","['df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)', 'df', 'df', 'df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)', 'df']","['df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})', 'df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)', 'df = pd.DataFrame(sample).reset_index().rename(columns={""index"": ""item""})', 'df = pd.melt(df, ""item"", var_name=""user"").dropna()', 'df = df[[""user"", ""item"", ""value""]].reset_index(drop=True)']",,
18172249,,[],[''],[],[],[]
18173074,df = df[df.line_race != 0],[],['df = df[df.line_race != 0]'],[],[],[]
18173088,"df
df[df.line_race != 0]",[],"['df', 'df[df.line_race != 0]']",[],[],[]
18176957,df2 = pd.DataFrame(index=df1.index),['df2 = pd.DataFrame(index=df1.index)'],[],['df2 = pd.DataFrame(index=df1.index)'],,
18184990,"ds1 = set([ tuple(line) for line in df1.values.tolist()])
ds2 = set([ tuple(line) for line in df2.values.tolist()])
set([(1, 2), (3, 4), (2, 3)])   
ds1.difference(ds2)
pd.DataFrame(list(ds1.difference(ds2)))","['ds1 = set([ tuple(line) for line in df1.values.tolist()])', 'ds2 = set([ tuple(line) for line in df2.values.tolist()])', 'ds1.difference(ds2)', 'pd.DataFrame(list(ds1.difference(ds2)))']","['ds1 = set([ tuple(line) for line in df1.values.tolist()])', 'ds2 = set([ tuple(line) for line in df2.values.tolist()])', 'set([(1, 2), (3, 4), (2, 3)])   ', 'ds1.difference(ds2)']","['ds1 = set([ tuple(line) for line in df1.values.tolist()])', 'ds2 = set([ tuple(line) for line in df2.values.tolist()])', 'ds1.difference(ds2)', 'pd.DataFrame(list(ds1.difference(ds2)))']",,
18196299,"df.loc[df['line_race'] == 0, 'rating'] = 0","[""df.loc[df['line_race'] == 0, 'rating'] = 0""]","[""df.loc[df['line_race'] == 0, 'rating'] = 0""]","[""df.loc[df['line_race'] == 0, 'rating'] = 0""]",,
18199337,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(1,7).reshape(2,3),
                  columns = list('abc'), 
                  index=pd.Series([2,5], name='b'))
print(df)
b         
print(np.where(df.index==5)[0])
print(np.where(df['c']==6)[0])","['df = pd.DataFrame(np.arange(1,7).reshape(2,3),', ""                  index=pd.Series([2,5], name='b'))"", 'print(np.where(df.index==5)[0])', ""print(np.where(df['c']==6)[0])""]","['import pandas as pd', 'import numpy as np', ""                  columns = list('abc'), "", 'print(df)', 'b         ', 'print(np.where(df.index==5)[0])', ""print(np.where(df['c']==6)[0])""]","['print(np.where(df.index==5)[0])', ""print(np.where(df['c']==6)[0])""]",,
18215499,"x = np.timedelta64(2069211000000000, 'ns')
days = x.astype('timedelta64[D]')
days / np.timedelta64(1, 'D')
23","[""days = x.astype('timedelta64[D]')""]","[""x = np.timedelta64(2069211000000000, 'ns')"", ""days = x.astype('timedelta64[D]')"", ""days / np.timedelta64(1, 'D')"", '23']","[""days = x.astype('timedelta64[D]')""]",,
18233876,"df = DataFrame(dict(date = [Timestamp('20130101'),Timestamp('20130131'),Timestamp('20130331'),Timestamp('20130330')],value=randn(4))).set_index('date')
df
df.index = df.index.to_period('M').to_timestamp('M')
df
df.index + pd.offsets.MonthEnd(0) 
Out[85]: DatetimeIndex(['2013-01-31', '2013-01-31', '2013-03-31', '2013-03-31'], dtype='datetime64[ns]', name=u'date', freq=None, tz=None)","[""df = DataFrame(dict(date = [Timestamp('20130101'),Timestamp('20130131'),Timestamp('20130331'),Timestamp('20130330')],value=randn(4))).set_index('date')"", ""df.index = df.index.to_period('M').to_timestamp('M')"", 'df.index + pd.offsets.MonthEnd(0) ']","[""df = DataFrame(dict(date = [Timestamp('20130101'),Timestamp('20130131'),Timestamp('20130331'),Timestamp('20130330')],value=randn(4))).set_index('date')"", 'df', ""df.index = df.index.to_period('M').to_timestamp('M')"", 'df', 'df.index + pd.offsets.MonthEnd(0) ', ""Out[85]: DatetimeIndex(['2013-01-31', '2013-01-31', '2013-03-31', '2013-03-31'], dtype='datetime64[ns]', name=u'date', freq=None, tz=None)""]","[""df = DataFrame(dict(date = [Timestamp('20130101'),Timestamp('20130131'),Timestamp('20130331'),Timestamp('20130330')],value=randn(4))).set_index('date')"", ""df.index = df.index.to_period('M').to_timestamp('M')"", 'df.index + pd.offsets.MonthEnd(0) ']",,
18259236,"df
df.unstack()
df = df.unstack().reset_index(name='value')
df
df.rename(columns={'level_0': 'month', 'level_1': 'year'}, inplace=True)
df","['df.unstack()', ""df = df.unstack().reset_index(name='value')"", ""df.rename(columns={'level_0': 'month', 'level_1': 'year'}, inplace=True)""]","['df', 'df.unstack()', ""df = df.unstack().reset_index(name='value')"", 'df', ""df.rename(columns={'level_0': 'month', 'level_1': 'year'}, inplace=True)"", 'df']","['df.unstack()', ""df = df.unstack().reset_index(name='value')"", ""df.rename(columns={'level_0': 'month', 'level_1': 'year'}, inplace=True)""]",,
18261958,grouped.filter(lambda x: len(x) > 1),['grouped.filter(lambda x: len(x) > 1)'],['grouped.filter(lambda x: len(x) > 1)'],['grouped.filter(lambda x: len(x) > 1)'],,
18283014,"df.apply(you_function, axis=1)
df = pd.DataFrame({'a': np.arange(3),
                       'b': np.random.rand(3)})
df
def func(row):
        return row['a'] + row['b']
df.apply(func, axis=1)
dtype: float64","['df.apply(you_function, axis=1)', ""df = pd.DataFrame({'a': np.arange(3),"", 'df.apply(func, axis=1)']","['df.apply(you_function, axis=1)', ""                       'b': np.random.rand(3)})"", 'df', 'def func(row):', ""        return row['a'] + row['b']"", 'df.apply(func, axis=1)', 'dtype: float64']","['df.apply(you_function, axis=1)', 'df.apply(func, axis=1)']",,
18290143,"df
df.values
array([[4, 'GE'],
       [1, 'RE'],
       [1, 'AE'],
       [4, 'CD']], dtype=object)
df.values is df.values
False
df1 = pd.DataFrame([[1, 2], [3, 4]])
df2 = pd.DataFrame(df1)
df2.iloc[0,0] = 42
df1
df1 = pd.DataFrame([[1, 2], [3, 4]])
df2 = pd.DataFrame(df1, copy=True)
df2.iloc[0,0] = 42
df1","['df.values', 'df.values is df.values', 'df1 = pd.DataFrame([[1, 2], [3, 4]])', 'df2 = pd.DataFrame(df1)', 'df2.iloc[0,0] = 42', 'df1 = pd.DataFrame([[1, 2], [3, 4]])', 'df2 = pd.DataFrame(df1, copy=True)', 'df2.iloc[0,0] = 42']","['df', 'df.values', ""array([[4, 'GE'],"", ""       [1, 'RE'],"", ""       [1, 'AE'],"", ""       [4, 'CD']], dtype=object)"", 'df.values is df.values', 'False', 'df2.iloc[0,0] = 42', 'df1', 'df2.iloc[0,0] = 42', 'df1']","['df.values', 'df.values is df.values', 'df2.iloc[0,0] = 42', 'df2.iloc[0,0] = 42']",,
18316830,"s.apply(lambda x: type(x))
Series(s.reset_index().apply(f, axis=1).values, index=s.index)","['s.apply(lambda x: type(x))', 'Series(s.reset_index().apply(f, axis=1).values, index=s.index)']","['s.apply(lambda x: type(x))', 'Series(s.reset_index().apply(f, axis=1).values, index=s.index)']","['s.apply(lambda x: type(x))', 'Series(s.reset_index().apply(f, axis=1).values, index=s.index)']",,
18317067,,[],[''],[],[],[]
18327852,"myseries[myseries == 7]
dtype: int64
myseries[myseries == 7].index[0]
3",['myseries[myseries == 7].index[0]'],"['myseries[myseries == 7]', 'dtype: int64', 'myseries[myseries == 7].index[0]', '3']",['myseries[myseries == 7].index[0]'],['myseries[myseries == 7].index[0]'],['myseries[myseries == 7].index[0]']
18334025,"myseries = pd.Series([1,4,0,7,5], index=[0,1,2,3,4])
Index(myseries).get_loc(7)
Index(myseries).get_loc(10)
KeyError: 10
Index([1,1,2,2,3,4]).get_loc(2)
Index([1,1,2,1,3,2,4]).get_loc(2)
s = Series(randint(0,10,10000))
i = Index(s)
s = Series(randint(0,10,10000))","['myseries = pd.Series([1,4,0,7,5], index=[0,1,2,3,4])', 'Index(myseries).get_loc(7)', 'Index(myseries).get_loc(10)', 'Index([1,1,2,2,3,4]).get_loc(2)', 'Index([1,1,2,1,3,2,4]).get_loc(2)']","['Index(myseries).get_loc(7)', 'Index(myseries).get_loc(10)', 'KeyError: 10', 'Index([1,1,2,2,3,4]).get_loc(2)', 'Index([1,1,2,1,3,2,4]).get_loc(2)', 's = Series(randint(0,10,10000))', 'i = Index(s)', 's = Series(randint(0,10,10000))']","['Index(myseries).get_loc(7)', 'Index(myseries).get_loc(10)', 'Index([1,1,2,2,3,4]).get_loc(2)', 'Index([1,1,2,1,3,2,4]).get_loc(2)']",,
18357933,"g = data.groupby('tag')
g.filter(lambda x: len(x) > 1)  
g.filter(lambda x: len(x) > 1)  ","[""g = data.groupby('tag')"", 'g.filter(lambda x: len(x) > 1)  ', 'g.filter(lambda x: len(x) > 1)  ']","[""g = data.groupby('tag')"", 'g.filter(lambda x: len(x) > 1)  ', 'g.filter(lambda x: len(x) > 1)  ']","[""g = data.groupby('tag')"", 'g.filter(lambda x: len(x) > 1)  ', 'g.filter(lambda x: len(x) > 1)  ']",,
18360223,"df.index.values.tolist()  
list(df.index.values)  ","['df.index.values.tolist()  ', 'list(df.index.values)  ']","['df.index.values.tolist()  ', 'list(df.index.values)  ']","['df.index.values.tolist()  ', 'list(df.index.values)  ']",,
18366911,,[],[''],[],[],[]
18369312,,[],[''],[],[],[]
18405221,"import pandas as pd
import numpy as np
data = np.random.random((8,3))*10000
df = pd.DataFrame (data)
pd.options.display.float_format = '{:20,.2f}'.format
print(df)","['df = pd.DataFrame (data)', ""pd.options.display.float_format = '{:20,.2f}'.format""]","['import pandas as pd', 'import numpy as np', 'data = np.random.random((8,3))*10000', ""pd.options.display.float_format = '{:20,.2f}'.format"", 'print(df)']","[""pd.options.display.float_format = '{:20,.2f}'.format""]",,
18431417,"df.fillna(-1)
df.fillna(-1).groupby('b').sum()
b    ","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()"", 'b    ']","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]"
18434234,"df['foo'][df['foo'] == '-'] = None
df['foo'] = df['foo'].astype(float)","[""df['foo'] = df['foo'].astype(float)""]","[""df['foo'][df['foo'] == '-'] = None"", ""df['foo'] = df['foo'].astype(float)""]","[""df['foo'] = df['foo'].astype(float)""]",,
18434403,"s
s.convert_objects(convert_numeric=True)
dtype: float64",['s.convert_objects(convert_numeric=True)'],"['s', 's.convert_objects(convert_numeric=True)', 'dtype: float64']",['s.convert_objects(convert_numeric=True)'],,
18467097,"from pandas import Series, DataFrame
import pandas as pd
from datetime import datetime, timedelta
import numpy as np
def rolling_mean(data, window, min_periods=1, center=False):
    def f(x):
        if center == False:
            dslice = col[x-pd.datetools.to_offset(window).delta+timedelta(0,0,1):x]
        else:
            dslice = col[x-pd.datetools.to_offset(window).delta/2+timedelta(0,0,1):
                         x+pd.datetools.to_offset(window).delta/2]
        if dslice.size < min_periods:
            return np.nan
        else:
            return dslice.mean()
    data = DataFrame(data.copy())
    dfout = DataFrame()
    if isinstance(window, int):
        dfout = pd.rolling_mean(data, window, min_periods=min_periods, center=center)
    elif isinstance(window, basestring):
        idx = Series(data.index.to_pydatetime(), index=data.index)
        for colname, col in data.iterkv():
            result = idx.apply(f)
            result.name = colname
            dfout = dfout.join(result, how='outer')
    if dfout.columns.size == 1:
        dfout = dfout.ix[:,0]
    return dfout
Example
idx = [datetime(2011, 2, 7, 0, 0),
       datetime(2011, 2, 7, 0, 1),
       datetime(2011, 2, 7, 0, 1, 30),
       datetime(2011, 2, 7, 0, 2),
       datetime(2011, 2, 7, 0, 4),
       datetime(2011, 2, 7, 0, 5),
       datetime(2011, 2, 7, 0, 5, 10),
       datetime(2011, 2, 7, 0, 6),
       datetime(2011, 2, 7, 0, 8),
       datetime(2011, 2, 7, 0, 9)]
idx = pd.Index(idx)
vals = np.arange(len(idx)).astype(float)
s = Series(vals, index=idx)
rm = rolling_mean(s, window='2min')","['        if dslice.size < min_periods:', '            return dslice.mean()', '    data = DataFrame(data.copy())', '        idx = Series(data.index.to_pydatetime(), index=data.index)', '            result = idx.apply(f)', ""            dfout = dfout.join(result, how='outer')"", '    if dfout.columns.size == 1:', 'vals = np.arange(len(idx)).astype(float)']","['from pandas import Series, DataFrame', 'import pandas as pd', 'from datetime import datetime, timedelta', 'import numpy as np', 'def rolling_mean(data, window, min_periods=1, center=False):', '    def f(x):', '        if center == False:', '            dslice = col[x-pd.datetools.to_offset(window).delta+timedelta(0,0,1):x]', '        else:', '            dslice = col[x-pd.datetools.to_offset(window).delta/2+timedelta(0,0,1):', '                         x+pd.datetools.to_offset(window).delta/2]', '        if dslice.size < min_periods:', '            return np.nan', '        else:', '            return dslice.mean()', '    data = DataFrame(data.copy())', '    dfout = DataFrame()', '    if isinstance(window, int):', '        dfout = pd.rolling_mean(data, window, min_periods=min_periods, center=center)', '    elif isinstance(window, basestring):', '        idx = Series(data.index.to_pydatetime(), index=data.index)', '        for colname, col in data.iterkv():', '            result = idx.apply(f)', '            result.name = colname', ""            dfout = dfout.join(result, how='outer')"", '    if dfout.columns.size == 1:', '        dfout = dfout.ix[:,0]', '    return dfout', 'Example', 'idx = [datetime(2011, 2, 7, 0, 0),', '       datetime(2011, 2, 7, 0, 1),', '       datetime(2011, 2, 7, 0, 1, 30),', '       datetime(2011, 2, 7, 0, 2),', '       datetime(2011, 2, 7, 0, 4),', '       datetime(2011, 2, 7, 0, 5),', '       datetime(2011, 2, 7, 0, 5, 10),', '       datetime(2011, 2, 7, 0, 6),', '       datetime(2011, 2, 7, 0, 8),', '       datetime(2011, 2, 7, 0, 9)]', 'idx = pd.Index(idx)', 'vals = np.arange(len(idx)).astype(float)', 's = Series(vals, index=idx)', ""rm = rolling_mean(s, window='2min')""]","['        if dslice.size < min_periods:', '            return dslice.mean()', '    data = DataFrame(data.copy())', '        idx = Series(data.index.to_pydatetime(), index=data.index)', '            result = idx.apply(f)', ""            dfout = dfout.join(result, how='outer')"", '    if dfout.columns.size == 1:', 'vals = np.arange(len(idx)).astype(float)']",,
18500854,"d = pandas.read_csv('foo.csv', dtype={'BAR': 'S10'})","[""d = pandas.read_csv('foo.csv', dtype={'BAR': 'S10'})""]","[""d = pandas.read_csv('foo.csv', dtype={'BAR': 'S10'})""]","[""d = pandas.read_csv('foo.csv', dtype={'BAR': 'S10'})""]",,
18505101,"df['A_perc'] = df['A']/df['sum']
ds.div(ds['sum'], axis=0)
ds.join(ds.div(ds['sum'], axis=0), rsuffix='_perc')","[""ds.div(ds['sum'], axis=0)"", ""ds.join(ds.div(ds['sum'], axis=0), rsuffix='_perc')""]","[""df['A_perc'] = df['A']/df['sum']"", ""ds.div(ds['sum'], axis=0)"", ""ds.join(ds.div(ds['sum'], axis=0), rsuffix='_perc')""]","[""ds.div(ds['sum'], axis=0)"", ""ds.join(ds.div(ds['sum'], axis=0), rsuffix='_perc')""]",,
18518561,"bin_avg[index] = np.average(items_in_bin, weights=my_weights)",[],"['bin_avg[index] = np.average(items_in_bin, weights=my_weights)']",[],[],[]
18527067,"format = ""%Y%m%d %H""
times = pd.to_datetime(df.YYYYMMDD + ' ' + df.HH, format=format)
df.set_index(times, inplace=True)
df = df.drop(['YYYYMMDD','HH'], axis=1)","[""times = pd.to_datetime(df.YYYYMMDD + ' ' + df.HH, format=format)"", 'df.set_index(times, inplace=True)', ""df = df.drop(['YYYYMMDD','HH'], axis=1)""]","['format = ""%Y%m%d %H""', ""times = pd.to_datetime(df.YYYYMMDD + ' ' + df.HH, format=format)"", 'df.set_index(times, inplace=True)', ""df = df.drop(['YYYYMMDD','HH'], axis=1)""]","[""times = pd.to_datetime(df.YYYYMMDD + ' ' + df.HH, format=format)"", 'df.set_index(times, inplace=True)', ""df = df.drop(['YYYYMMDD','HH'], axis=1)""]",,
18528589,"from StringIO import StringIO
import prettytable    
output = StringIO()
data_frame.to_csv(output)
output.seek(0)
pt = prettytable.from_csv(output)","['data_frame.to_csv(output)', 'pt = prettytable.from_csv(output)']","['from StringIO import StringIO', 'import prettytable    ', 'output = StringIO()', 'data_frame.to_csv(output)', 'output.seek(0)', 'pt = prettytable.from_csv(output)']","['data_frame.to_csv(output)', 'pt = prettytable.from_csv(output)']",,
18554949,"df
df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": pd.Series.nunique})
date                         
df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": lambda x: x.nunique()})
date                         ","['df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": pd.Series.nunique})', 'df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": lambda x: x.nunique()})']","['df', 'date                         ', 'df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": lambda x: x.nunique()})', 'date                         ']","['df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": pd.Series.nunique})', 'df.groupby(""date"").agg({""duration"": np.sum, ""user_id"": lambda x: x.nunique()})']",,
18580496,"cols = list('abc')
df = DataFrame(randn(10, len(cols)), columns=cols)
df.a.quantile(0.95)
df[df.a < df.a.quantile(.95)]
0 -1.044 -0.247 -1.149
4 -0.707 -0.736 -1.345","['df.a.quantile(0.95)', 'df[df.a < df.a.quantile(.95)]']","[""cols = list('abc')"", 'df = DataFrame(randn(10, len(cols)), columns=cols)', 'df.a.quantile(0.95)', 'df[df.a < df.a.quantile(.95)]', '0 -1.044 -0.247 -1.149', '4 -0.707 -0.736 -1.345']","['df.a.quantile(0.95)', 'df[df.a < df.a.quantile(.95)]']",,
18588980,,[],[''],[],[],[]
18594595,"df.div(df.sum(axis=1), axis=0)","['df.div(df.sum(axis=1), axis=0)']","['df.div(df.sum(axis=1), axis=0)']","['df.div(df.sum(axis=1), axis=0)']",,
18611535,"def logged_apply(g, func, *args, **kwargs):
    step_percentage = 100. / len(g)
    import sys
    sys.stdout.write('apply progress:   0%')
    sys.stdout.flush()
    def logging_decorator(func):
        def wrapper(*args, **kwargs):
            progress = wrapper.count * step_percentage
            sys.stdout.write('\033[D \033[D' * 4 + format(progress, '3.0f') + '%')
            sys.stdout.flush()
            wrapper.count += 1
            return func(*args, **kwargs)
        wrapper.count = 0
        return wrapper
    logged_func = logging_decorator(func)
    res = g.apply(logged_func, *args, **kwargs)
    sys.stdout.write('\033[D \033[D' * 4 + format(100., '3.0f') + '%' + '\n')
    sys.stdout.flush()
    return res
g = df_users.groupby(['userID', 'requestDate'])
f = feature_rollup
logged_apply(g, f)
g.logged_apply(f)
...","['            progress = wrapper.count * step_percentage', '            wrapper.count += 1', '        wrapper.count = 0', '    res = g.apply(logged_func, *args, **kwargs)', ""g = df_users.groupby(['userID', 'requestDate'])""]","['def logged_apply(g, func, *args, **kwargs):', '    step_percentage = 100. / len(g)', '    import sys', ""    sys.stdout.write('apply progress:   0%')"", '    sys.stdout.flush()', '    def logging_decorator(func):', '        def wrapper(*args, **kwargs):', '            progress = wrapper.count * step_percentage', ""            sys.stdout.write('\\033[D \\033[D' * 4 + format(progress, '3.0f') + '%')"", '            sys.stdout.flush()', '            wrapper.count += 1', '            return func(*args, **kwargs)', '        wrapper.count = 0', '        return wrapper', '    logged_func = logging_decorator(func)', '    res = g.apply(logged_func, *args, **kwargs)', ""    sys.stdout.write('\\033[D \\033[D' * 4 + format(100., '3.0f') + '%' + '\\n')"", '    sys.stdout.flush()', '    return res', ""g = df_users.groupby(['userID', 'requestDate'])"", 'f = feature_rollup', 'logged_apply(g, f)', 'g.logged_apply(f)', '...']","['            progress = wrapper.count * step_percentage', '            wrapper.count += 1', '        wrapper.count = 0', '    res = g.apply(logged_func, *args, **kwargs)', ""g = df_users.groupby(['userID', 'requestDate'])""]",,
18624069,"s
s.reset_index()
s.reset_index(0).reset_index(drop=True)
df = s.reset_index()
df
del df[1]
df
s.reset_index().drop(1, axis=1)
df.columns = ['Date', 'Sales']
df","['s.reset_index()', 's.reset_index(0).reset_index(drop=True)', 'df = s.reset_index()', 's.reset_index().drop(1, axis=1)']","['s', 's.reset_index()', 's.reset_index(0).reset_index(drop=True)', 'df = s.reset_index()', 'df', 'del df[1]', 'df', 's.reset_index().drop(1, axis=1)', ""df.columns = ['Date', 'Sales']"", 'df']","['s.reset_index()', 's.reset_index(0).reset_index(drop=True)', 'df = s.reset_index()', 's.reset_index().drop(1, axis=1)']",,
18624323,"H3 = H2[['SOLD_PRICE']]
H3 = H2['SOLD_PRICE']
import pandas as pd
import numpy as np
rng = pd.date_range('1/1/2011', periods=72, freq='M')
H2 = pd.DataFrame(np.arange(len(rng)), index=rng, columns=['SOLD_PRICE'])
H3 = H2['SOLD_PRICE']
H5 = H3.resample('Q', how='count')
H6 = pd.rolling_mean(H5,4)
print(H6.head())
dtype: float64","[""rng = pd.date_range('1/1/2011', periods=72, freq='M')"", ""H2 = pd.DataFrame(np.arange(len(rng)), index=rng, columns=['SOLD_PRICE'])"", ""H5 = H3.resample('Q', how='count')"", 'print(H6.head())']","[""H3 = H2[['SOLD_PRICE']]"", ""H3 = H2['SOLD_PRICE']"", 'import pandas as pd', 'import numpy as np', ""rng = pd.date_range('1/1/2011', periods=72, freq='M')"", ""H3 = H2['SOLD_PRICE']"", ""H5 = H3.resample('Q', how='count')"", 'H6 = pd.rolling_mean(H5,4)', 'print(H6.head())', 'dtype: float64']","[""rng = pd.date_range('1/1/2011', periods=72, freq='M')"", ""H5 = H3.resample('Q', how='count')"", 'print(H6.head())']",,
18646275,"import numpy as np
import pandas as pd
import scipy.sparse as sparse
df = pd.DataFrame(np.arange(1,10).reshape(3,3))
arr = sparse.coo_matrix(([1,1,1], ([0,1,2], [1,2,0])), shape=(3,3))
df['newcol'] = arr.toarray().tolist()
print(df)","['df = pd.DataFrame(np.arange(1,10).reshape(3,3))', ""df['newcol'] = arr.toarray().tolist()""]","['import numpy as np', 'import pandas as pd', 'import scipy.sparse as sparse', 'arr = sparse.coo_matrix(([1,1,1], ([0,1,2], [1,2,0])), shape=(3,3))', ""df['newcol'] = arr.toarray().tolist()"", 'print(df)']","[""df['newcol'] = arr.toarray().tolist()""]",,
18646802,"p = pd.Panel({'df': df, 'csc': csc})
p.df
p.csc
p.xs(0)","[""p = pd.Panel({'df': df, 'csc': csc})"", 'p.xs(0)']","['p.df', 'p.csc', 'p.xs(0)']",['p.xs(0)'],,
18661440,"def changeencode(data, cols):
    for col in cols:
        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')
    return data   ","[""        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')""]","['def changeencode(data, cols):', '    for col in cols:', ""        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')"", '    return data   ']","[""        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')""]",,
18666142,"df = pd.DataFrame([[1, {'a': 2}], [2, {'a': 1, 'b': 3}]])
df
df[1].apply(pd.Series)
dict_col = df.pop(1)  
pd.concat([df, dict_col.apply(pd.Series)], axis=1)","[""df = pd.DataFrame([[1, {'a': 2}], [2, {'a': 1, 'b': 3}]])"", 'df[1].apply(pd.Series)', 'dict_col = df.pop(1)  ', 'pd.concat([df, dict_col.apply(pd.Series)], axis=1)']","['df', 'dict_col = df.pop(1)  ']","['df[1].apply(pd.Series)', 'dict_col = df.pop(1)  ', 'pd.concat([df, dict_col.apply(pd.Series)], axis=1)']",,
18674915,"df.insert(idx, col_name, value)","['df.insert(idx, col_name, value)']","['df.insert(idx, col_name, value)']","['df.insert(idx, col_name, value)']",,
18677517,"string = Series(np.random.choice(df.string.values, size=100), name='string')
visits = Series(poisson(1000, size=100), name='date')
date = Series(np.random.choice([df.date[0], now(), Timestamp('1/1/2001'), Timestamp('11/15/2001'), Timestamp('12/1/01'), Timestamp('5/1/01')], size=100), dtype='datetime64[ns]', name='date')
df = DataFrame({'string': string, 'visits': visits, 'date': date})
df.head()
resamp = df.set_index('date').groupby('string').resample('M', how='sum')
resamp.head()
g = resamp.groupby(level='date').apply(lambda x: x / x.sum())
g.head()
h = g.sortlevel('date').head()
h
h.sum()
resamp.dropna()
resamp.dropna().reset_index()
g.dropna()
g.dropna().reset_index()
g.dropna().reset_index().reindex(columns=['visits', 'string', 'date'])","[""string = Series(np.random.choice(df.string.values, size=100), name='string')"", ""date = Series(np.random.choice([df.date[0], now(), Timestamp('1/1/2001'), Timestamp('11/15/2001'), Timestamp('12/1/01'), Timestamp('5/1/01')], size=100), dtype='datetime64[ns]', name='date')"", 'df.head()', ""resamp = df.set_index('date').groupby('string').resample('M', how='sum')"", 'resamp.head()', ""g = resamp.groupby(level='date').apply(lambda x: x / x.sum())"", 'g.head()', ""h = g.sortlevel('date').head()"", 'h.sum()', 'resamp.dropna()', 'resamp.dropna().reset_index()', 'g.dropna()', 'g.dropna().reset_index()', ""g.dropna().reset_index().reindex(columns=['visits', 'string', 'date'])""]","[""string = Series(np.random.choice(df.string.values, size=100), name='string')"", ""visits = Series(poisson(1000, size=100), name='date')"", ""date = Series(np.random.choice([df.date[0], now(), Timestamp('1/1/2001'), Timestamp('11/15/2001'), Timestamp('12/1/01'), Timestamp('5/1/01')], size=100), dtype='datetime64[ns]', name='date')"", ""df = DataFrame({'string': string, 'visits': visits, 'date': date})"", 'df.head()', ""resamp = df.set_index('date').groupby('string').resample('M', how='sum')"", 'resamp.head()', ""g = resamp.groupby(level='date').apply(lambda x: x / x.sum())"", 'g.head()', ""h = g.sortlevel('date').head()"", 'h', 'h.sum()', 'resamp.dropna()', 'resamp.dropna().reset_index()', 'g.dropna()', 'g.dropna().reset_index()', ""g.dropna().reset_index().reindex(columns=['visits', 'string', 'date'])""]","[""string = Series(np.random.choice(df.string.values, size=100), name='string')"", ""date = Series(np.random.choice([df.date[0], now(), Timestamp('1/1/2001'), Timestamp('11/15/2001'), Timestamp('12/1/01'), Timestamp('5/1/01')], size=100), dtype='datetime64[ns]', name='date')"", 'df.head()', ""resamp = df.set_index('date').groupby('string').resample('M', how='sum')"", 'resamp.head()', ""g = resamp.groupby(level='date').apply(lambda x: x / x.sum())"", 'g.head()', ""h = g.sortlevel('date').head()"", 'h.sum()', 'resamp.dropna()', 'resamp.dropna().reset_index()', 'g.dropna()', 'g.dropna().reset_index()', ""g.dropna().reset_index().reindex(columns=['visits', 'string', 'date'])""]",,
18689514,"s
dtype: float64
s.groupby(level=['first','second']).sum()
dtype: float64","[""s.groupby(level=['first','second']).sum()""]","['s', 'dtype: float64', ""s.groupby(level=['first','second']).sum()"", 'dtype: float64']","[""s.groupby(level=['first','second']).sum()""]",,
18689589,,[],[''],[],[],[]
18689712,"import pandas as pd
import numpy as np
s = pd.Series(['apple', np.nan, 'banana'])
pd.isnull(s)
s = Series([Timestamp('20130101'),np.nan,Timestamp('20130102 9:30')],dtype='M8[ns]')
s
pd.isnull(s)
dtype: bool","[""s = pd.Series(['apple', np.nan, 'banana'])"", 'pd.isnull(s)', 'pd.isnull(s)']","['import pandas as pd', 'import numpy as np', 'pd.isnull(s)', ""s = Series([Timestamp('20130101'),np.nan,Timestamp('20130102 9:30')],dtype='M8[ns]')"", 's', 'pd.isnull(s)', 'dtype: bool']","['pd.isnull(s)', 'pd.isnull(s)']",,
18691949,"df 
df.mean()
df.fillna(df.mean())
1 -0.297953 -0.912674 -1.365463
2 -0.120211 -0.540679 -0.680481
5 -0.788073 -0.231291 -0.530307
6 -0.916080 -0.612343 -0.530307","['df.mean()', 'df.fillna(df.mean())']","['df ', 'df.mean()', 'df.fillna(df.mean())', '1 -0.297953 -0.912674 -1.365463', '2 -0.120211 -0.540679 -0.680481', '5 -0.788073 -0.231291 -0.530307', '6 -0.916080 -0.612343 -0.530307']","['df.mean()', 'df.fillna(df.mean())']",,
18695700,"df.set_index('id').to_dict()
df.set_index('id')['value'].to_dict()","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]"
18714509,"df = pd.DataFrame(np.random.rand(10))
df.loc[np.random.choice(df.index, 5, replace=False)]
df.loc[np.random.permutation(df.index)[:5]]","['df = pd.DataFrame(np.random.rand(10))', 'df.loc[np.random.choice(df.index, 5, replace=False)]', 'df.loc[np.random.permutation(df.index)[:5]]']","['df.loc[np.random.choice(df.index, 5, replace=False)]', 'df.loc[np.random.permutation(df.index)[:5]]']","['df.loc[np.random.choice(df.index, 5, replace=False)]', 'df.loc[np.random.permutation(df.index)[:5]]']",,
18714869,"from random import sample
df.loc[sample(df.index, 1000)]","['df.loc[sample(df.index, 1000)]']","['from random import sample', 'df.loc[sample(df.index, 1000)]']","['df.loc[sample(df.index, 1000)]']",,
18793067,"restaurant_review_frame.join(restaurant_ids_dataframe, on='business_id', how='left', lsuffix=""_review"")","['restaurant_review_frame.join(restaurant_ids_dataframe, on=\'business_id\', how=\'left\', lsuffix=""_review"")']","['restaurant_review_frame.join(restaurant_ids_dataframe, on=\'business_id\', how=\'left\', lsuffix=""_review"")']","['restaurant_review_frame.join(restaurant_ids_dataframe, on=\'business_id\', how=\'left\', lsuffix=""_review"")']",,
18799713,"import pandas as pd
pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')","[""pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')""]","['import pandas as pd', ""pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')""]","[""pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')""]",,
18835121,"df
df.iloc[df.index.get_level_values('A') == 1]
df1 = df.T
df1.iloc[:, df1.columns.get_level_values('A') == 1]","[""df.iloc[df.index.get_level_values('A') == 1]"", 'df1 = df.T', ""df1.iloc[:, df1.columns.get_level_values('A') == 1]""]","['df', ""df.iloc[df.index.get_level_values('A') == 1]"", 'df1 = df.T', ""df1.iloc[:, df1.columns.get_level_values('A') == 1]""]","[""df.iloc[df.index.get_level_values('A') == 1]"", 'df1 = df.T', ""df1.iloc[:, df1.columns.get_level_values('A') == 1]""]",,
18835174,"df = DataFrame(np.random.randn(10, 4))
df.columns = [np.random.choice(['a', 'b'], size=4).tolist(), np.random.choice(['c', 'd'], size=4)]
df.columns.names = ['A', 'B']
df
df.xs('a', level='A', axis=1)
df.xs('a', level='A', axis=1, drop_level=False)
2 -0.477 -1.230
9 -1.885 -1.543","[""df.columns = [np.random.choice(['a', 'b'], size=4).tolist(), np.random.choice(['c', 'd'], size=4)]"", ""df.xs('a', level='A', axis=1)"", ""df.xs('a', level='A', axis=1, drop_level=False)""]","['df = DataFrame(np.random.randn(10, 4))', ""df.columns = [np.random.choice(['a', 'b'], size=4).tolist(), np.random.choice(['c', 'd'], size=4)]"", ""df.columns.names = ['A', 'B']"", 'df', ""df.xs('a', level='A', axis=1)"", ""df.xs('a', level='A', axis=1, drop_level=False)"", '2 -0.477 -1.230', '9 -1.885 -1.543']","[""df.columns = [np.random.choice(['a', 'b'], size=4).tolist(), np.random.choice(['c', 'd'], size=4)]"", ""df.xs('a', level='A', axis=1)"", ""df.xs('a', level='A', axis=1, drop_level=False)""]",,
18837378,"df = pd.DataFrame(data.items(), columns=['Date', 'DateValue'])
df['Date'] = pd.to_datetime(df['Date'])","[""df = pd.DataFrame(data.items(), columns=['Date', 'DateValue'])"", ""df['Date'] = pd.to_datetime(df['Date'])""]","[""df['Date'] = pd.to_datetime(df['Date'])""]","[""df['Date'] = pd.to_datetime(df['Date'])""]",,
18837389,"pd.DataFrame(d)
pd.DataFrame(d.items())  
pd.DataFrame(d.items(), columns=['Date', 'DateValue'])
s = pd.Series(d, name='DateValue')
s.index.name = 'Date'
s.reset_index()","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", ""s = pd.Series(d, name='DateValue')"", ""s.index.name = 'Date'"", 's.reset_index()']","[""s.index.name = 'Date'"", 's.reset_index()']","[""s.index.name = 'Date'"", 's.reset_index()']","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", 's.reset_index()']","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", ""s = pd.Series(d, name='DateValue')"", ""s.index.name = 'Date'""]"
18837709,"grouped.agg({'numberA':'sum', 'numberB':'min'})
import numpy as np
import pandas as pd
df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',
                         'foo', 'bar', 'foo', 'foo'],
                   'B': ['one', 'one', 'two', 'three',
                         'two', 'two', 'one', 'three'],
                   'number A': np.arange(8),
                   'number B': np.arange(8) * 2})
grouped = df.groupby('A')
print(grouped.agg({
    'number A': 'sum',
    'number B': 'min'}))
A                      
print(df.columns)","[""df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',"", ""grouped = df.groupby('A')""]","[""grouped.agg({'numberA':'sum', 'numberB':'min'})"", 'import numpy as np', 'import pandas as pd', ""                         'foo', 'bar', 'foo', 'foo'],"", ""                   'B': ['one', 'one', 'two', 'three',"", ""                         'two', 'two', 'one', 'three'],"", ""                   'number A': np.arange(8),"", ""                   'number B': np.arange(8) * 2})"", ""grouped = df.groupby('A')"", 'print(grouped.agg({', ""    'number A': 'sum',"", ""    'number B': 'min'}))"", 'A                      ', 'print(df.columns)']","[""grouped = df.groupby('A')""]",,
18852224,"df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])
df
count_appkey = df.groupby('AppKey')['AppKey'].transform('count')
count_appkey
count_appkey == 1
df[count_appkey == 1]","[""df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])"", ""count_appkey = df.groupby('AppKey')['AppKey'].transform('count')""]","['df', ""count_appkey = df.groupby('AppKey')['AppKey'].transform('count')"", 'count_appkey', 'count_appkey == 1', 'df[count_appkey == 1]']","[""count_appkey = df.groupby('AppKey')['AppKey'].transform('count')""]",,
18852410,"df.groupby('AppKey').filter(lambda x: x.count() == 1)
df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])
df.groupby('AppKey').filter(lambda x: x.count() == 1)","[""df.groupby('AppKey').filter(lambda x: x.count() == 1)"", ""df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])"", ""df.groupby('AppKey').filter(lambda x: x.count() == 1)""]","[""df.groupby('AppKey').filter(lambda x: x.count() == 1)"", ""df.groupby('AppKey').filter(lambda x: x.count() == 1)""]","[""df.groupby('AppKey').filter(lambda x: x.count() == 1)"", ""df.groupby('AppKey').filter(lambda x: x.count() == 1)""]",,
18878267,"style = '<style>.dataframe td { text-align: right; }</style>'
HTML( style + df.to_html( formatters=frmt ) )
style = '<style>.right_aligned_df td { text-align: right; }</style>'
HTML(style + df.to_html(formatters=frmt, classes='right_aligned_df'))
HTML()
...
HTML(df.to_html(classes='pink_df'))","['HTML( style + df.to_html( formatters=frmt ) )', ""HTML(style + df.to_html(formatters=frmt, classes='right_aligned_df'))"", ""HTML(df.to_html(classes='pink_df'))""]","[""style = '<style>.dataframe td { text-align: right; }</style>'"", 'HTML( style + df.to_html( formatters=frmt ) )', ""style = '<style>.right_aligned_df td { text-align: right; }</style>'"", ""HTML(style + df.to_html(formatters=frmt, classes='right_aligned_df'))"", 'HTML()', '...', ""HTML(df.to_html(classes='pink_df'))""]","['HTML( style + df.to_html( formatters=frmt ) )', ""HTML(style + df.to_html(formatters=frmt, classes='right_aligned_df'))"", ""HTML(df.to_html(classes='pink_df'))""]",,
18878413,"dfm.index = range(1,len(dfm) + 1)","['dfm.index = range(1,len(dfm) + 1)']","['dfm.index = range(1,len(dfm) + 1)']","['dfm.index = range(1,len(dfm) + 1)']",,
18878425,"df = DataFrame(randn(10, 2), columns=['a', 'delt'])
df
df.reindex(index=arange(1, len(df) + 1))
df.index = arange(1, len(df) + 1)
df
5  -0.455 -0.594
7  -0.080 -0.235","['df.reindex(index=arange(1, len(df) + 1))', 'df.index = arange(1, len(df) + 1)']","[""df = DataFrame(randn(10, 2), columns=['a', 'delt'])"", 'df', 'df.reindex(index=arange(1, len(df) + 1))', 'df.index = arange(1, len(df) + 1)', 'df', '5  -0.455 -0.594', '7  -0.080 -0.235']","['df.reindex(index=arange(1, len(df) + 1))', 'df.index = arange(1, len(df) + 1)']",,
18885319,"crime2013 = pd.read_csv(z.open('crime_incidents_2013_CSV.csv'))
crime2013","[""crime2013 = pd.read_csv(z.open('crime_incidents_2013_CSV.csv'))""]","[""crime2013 = pd.read_csv(z.open('crime_incidents_2013_CSV.csv'))"", 'crime2013']","[""crime2013 = pd.read_csv(z.open('crime_incidents_2013_CSV.csv'))""]",,
18916457,"def gen():
    lines = [
        'col1,col2\n',
        'foo,bar\n',
        'foo,baz\n',
        'bar,baz\n'
    ]
    for line in lines:
        yield line
class Reader(object):
    def __init__(self, g):
        self.g = g
    def read(self, n=0):
        try:
            return next(self.g)
        except StopIteration:
            return ''
pd.read_csv(Reader(gen()))",['pd.read_csv(Reader(gen()))'],"['def gen():', '    lines = [', ""        'col1,col2\\n',"", ""        'foo,bar\\n',"", ""        'foo,baz\\n',"", ""        'bar,baz\\n'"", '    ]', '    for line in lines:', '        yield line', 'class Reader(object):', '    def __init__(self, g):', '        self.g = g', '    def read(self, n=0):', '        try:', '            return next(self.g)', '        except StopIteration:', ""            return ''"", 'pd.read_csv(Reader(gen()))']",['pd.read_csv(Reader(gen()))'],,
18937023,"from collections import Counter
r1=['My nickname is ft.jgt','Someone is going to my place']
Counter("" "".join(r1).split("" "")).items()
[('Someone', 1), ('ft.jgt', 1), ('My', 1), ('is', 2), ('to', 1), ('going', 1), ('place', 1), ('my', 1), ('nickname', 1)]","['Counter("" "".join(r1).split("" "")).items()']","['from collections import Counter', ""r1=['My nickname is ft.jgt','Someone is going to my place']"", 'Counter("" "".join(r1).split("" "")).items()', ""[('Someone', 1), ('ft.jgt', 1), ('My', 1), ('is', 2), ('to', 1), ('going', 1), ('place', 1), ('my', 1), ('nickname', 1)]""]","['Counter("" "".join(r1).split("" "")).items()']",,
18937309,"df['text'].str.lower().str.split()
results = set()
df['text'].str.lower().str.split().apply(results.update)
set(['someone', 'ft.jgt', 'my', 'is', 'to', 'going', 'place', 'nickname'])","[""df['text'].str.lower().str.split()"", ""df['text'].str.lower().str.split().apply(results.update)""]","[""df['text'].str.lower().str.split()"", 'results = set()', ""df['text'].str.lower().str.split().apply(results.update)"", ""set(['someone', 'ft.jgt', 'my', 'is', 'to', 'going', 'place', 'nickname'])""]","[""df['text'].str.lower().str.split()"", ""df['text'].str.lower().str.split().apply(results.update)""]",,
18937417,"import pandas as pd
r1=['My nickname is ft.jgt','Someone is going to my place']
df=pd.DataFrame(r1,columns=['text'])
df.text.apply(lambda x: pd.value_counts(x.split("" ""))).sum(axis = 0)
dtype: float64","[""df=pd.DataFrame(r1,columns=['text'])"", 'df.text.apply(lambda x: pd.value_counts(x.split("" ""))).sum(axis = 0)']","['import pandas as pd', ""r1=['My nickname is ft.jgt','Someone is going to my place']"", 'df.text.apply(lambda x: pd.value_counts(x.split("" ""))).sum(axis = 0)', 'dtype: float64']","['df.text.apply(lambda x: pd.value_counts(x.split("" ""))).sum(axis = 0)']",,
18942558,"df['Col3'] = (df['Col2'] <= 1).astype(int)
df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)
df['Col3'] = 0
condition = df['Col2'] > 1
df.loc[condition, 'Col3'] = 42
df.loc[~condition, 'Col3'] = 55","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df['Col3'] = 0"", ""condition = df['Col2'] > 1"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]"
18973430,"barlist=plt.bar([1,2,3,4], [1,2,3,4])
barlist[0].set_color('r')
plt.show()
f=plt.figure()
ax=f.add_subplot(1,1,1)
ax.bar([1,2,3,4], [1,2,3,4])
ax.get_children()
ax.get_children()[2].set_color('r') 
import matplotlib
childrenLS=ax.get_children()
barlist=filter(lambda x: isinstance(x, matplotlib.patches.Rectangle), childrenLS)","['barlist=plt.bar([1,2,3,4], [1,2,3,4])', 'ax.bar([1,2,3,4], [1,2,3,4])']","['barlist=plt.bar([1,2,3,4], [1,2,3,4])', ""barlist[0].set_color('r')"", 'plt.show()', 'f=plt.figure()', 'ax=f.add_subplot(1,1,1)', 'ax.bar([1,2,3,4], [1,2,3,4])', 'ax.get_children()', ""ax.get_children()[2].set_color('r') "", 'import matplotlib', 'childrenLS=ax.get_children()', 'barlist=filter(lambda x: isinstance(x, matplotlib.patches.Rectangle), childrenLS)']","['barlist=plt.bar([1,2,3,4], [1,2,3,4])', 'ax.bar([1,2,3,4], [1,2,3,4])']",,
18975065,"kwds : keywords
import pandas as pd
import matplotlib.pyplot as plt
s = pd.Series(
    [5, 4, 4, 1, 12],
    index = [""AK"", ""AX"", ""GA"", ""SQ"", ""WN""]
)
plt.title(""Total Delay Incident Caused by Carrier"")
plt.ylabel('Delay Incident')
plt.xlabel('Carrier')
ax = plt.gca()
ax.tick_params(axis='x', colors='blue')
ax.tick_params(axis='y', colors='red')
my_colors = 'rgbkymc'  
pd.Series.plot(
    s, 
    kind='bar', 
    color=my_colors,
)
plt.show()","['s = pd.Series(', 'plt.title(""Total Delay Incident Caused by Carrier"")', 'pd.Series.plot(']","['kwds : keywords', 'import pandas as pd', 'import matplotlib.pyplot as plt', '    [5, 4, 4, 1, 12],', '    index = [""AK"", ""AX"", ""GA"", ""SQ"", ""WN""]', ')', 'plt.title(""Total Delay Incident Caused by Carrier"")', ""plt.ylabel('Delay Incident')"", ""plt.xlabel('Carrier')"", 'ax = plt.gca()', ""ax.tick_params(axis='x', colors='blue')"", ""ax.tick_params(axis='y', colors='red')"", ""my_colors = 'rgbkymc'  "", '    s, ', ""    kind='bar', "", '    color=my_colors,', ')', 'plt.show()']","['plt.title(""Total Delay Incident Caused by Carrier"")', 'pd.Series.plot(']",,
18992172,"ax = s.hist()  
fig = ax.get_figure()
fig.savefig('/path/to/figure.pdf')
s.hist()
savefig('path/to/figure.pdf')  ",[],"['ax = s.hist()  ', 'fig = ax.get_figure()', ""fig.savefig('/path/to/figure.pdf')"", 's.hist()', ""savefig('path/to/figure.pdf')  ""]",[],[],[]
19031661,"data_records = [rec.__dict__ for rec in query.all()]
df = pandas.DataFrame.from_records(data_records)","['data_records = [rec.__dict__ for rec in query.all()]', 'df = pandas.DataFrame.from_records(data_records)']",['data_records = [rec.__dict__ for rec in query.all()]'],"['data_records = [rec.__dict__ for rec in query.all()]', 'df = pandas.DataFrame.from_records(data_records)']",,
19062640,df = df[['bob']],[],"[""df = df[['bob']]""]",[],[],[]
19071572,"import pandas as pd
import numpy as np
array=np.random.random((2,4))
df=pd.DataFrame(array, columns=('Test1', 'toto', 'test2', 'riri'))
cols = [c for c in df.columns if c.lower()[:4] != 'test']
df=df[cols]","[""df=pd.DataFrame(array, columns=('Test1', 'toto', 'test2', 'riri'))"", ""cols = [c for c in df.columns if c.lower()[:4] != 'test']""]","['import pandas as pd', 'import numpy as np', 'array=np.random.random((2,4))', ""cols = [c for c in df.columns if c.lower()[:4] != 'test']"", 'df=df[cols]']","[""cols = [c for c in df.columns if c.lower()[:4] != 'test']""]",,
19071679,"df = DataFrame({'Test1': randn(10), 'Test2': randn(10), 'awesome': randn(10)})
df.select(lambda x: not re.search('Test\d+', x), axis=1)
5   -0.971
9   -0.214","[""df.select(lambda x: not re.search('Test\\d+', x), axis=1)""]","[""df = DataFrame({'Test1': randn(10), 'Test2': randn(10), 'awesome': randn(10)})"", ""df.select(lambda x: not re.search('Test\\d+', x), axis=1)"", '5   -0.971', '9   -0.214']","[""df.select(lambda x: not re.search('Test\\d+', x), axis=1)""]",,
19078773,"df = data.groupby(...).agg(...)
df.columns = df.columns.droplevel(0)
df.columns = [""_"".join(x) for x in df.columns.ravel()]
import pandas as pd
import pandas.rpy.common as com
import numpy as np
data = com.load_data('Loblolly')
print(data.head())
df = data.groupby('Seed').agg(
    {'age':['sum'],
     'height':['mean', 'std']})
print(df.head())
Seed                           
df.columns = df.columns.droplevel(0)
print(df.head())
Seed                           
df = data.groupby('Seed').agg(
    {'age':['sum'],
     'height':['mean', 'std']})
df.columns = [""_"".join(x) for x in df.columns.ravel()]
Seed                           ","['df = data.groupby(...).agg(...)', 'df.columns = df.columns.droplevel(0)', 'df.columns = [""_"".join(x) for x in df.columns.ravel()]', 'print(data.head())', ""df = data.groupby('Seed').agg("", 'print(df.head())', 'df.columns = df.columns.droplevel(0)', 'print(df.head())', ""df = data.groupby('Seed').agg("", 'df.columns = [""_"".join(x) for x in df.columns.ravel()]']","['df = data.groupby(...).agg(...)', 'df.columns = df.columns.droplevel(0)', 'df.columns = [""_"".join(x) for x in df.columns.ravel()]', 'import pandas as pd', 'import pandas.rpy.common as com', 'import numpy as np', ""data = com.load_data('Loblolly')"", 'print(data.head())', ""df = data.groupby('Seed').agg("", ""    {'age':['sum'],"", ""     'height':['mean', 'std']})"", 'print(df.head())', 'Seed                           ', 'df.columns = df.columns.droplevel(0)', 'print(df.head())', 'Seed                           ', ""df = data.groupby('Seed').agg("", ""    {'age':['sum'],"", ""     'height':['mean', 'std']})"", 'df.columns = [""_"".join(x) for x in df.columns.ravel()]', 'Seed                           ']","['df = data.groupby(...).agg(...)', 'df.columns = df.columns.droplevel(0)', 'df.columns = [""_"".join(x) for x in df.columns.ravel()]', 'print(data.head())', ""df = data.groupby('Seed').agg("", 'print(df.head())', 'df.columns = df.columns.droplevel(0)', 'print(df.head())', ""df = data.groupby('Seed').agg("", 'df.columns = [""_"".join(x) for x in df.columns.ravel()]']",,
19089210,"import sys
reload(sys)
sys.setdefaultencoding(""utf-8"")",[],"['import sys', 'reload(sys)', 'sys.setdefaultencoding(""utf-8"")']",[],[],[]
19103754,"df = pd.read_csv(""test_data2.csv"", index_col=[0,1], skipinitialspace=True)
df","['df = pd.read_csv(""test_data2.csv"", index_col=[0,1], skipinitialspace=True)']","['df = pd.read_csv(""test_data2.csv"", index_col=[0,1], skipinitialspace=True)', 'df']","['df = pd.read_csv(""test_data2.csv"", index_col=[0,1], skipinitialspace=True)']",,
19106012,"from operator import methodcaller
s = Series(date_range(Timestamp('now'), periods=2))
s
s.map(lambda x: x.strftime('%d-%m-%Y'))
s.map(methodcaller('strftime', '%d-%m-%Y'))
s.map(methodcaller('date'))
s.map(methodcaller('date')).values
s.map(Timestamp.date)
index = DatetimeIndex(s)
index
index.date
f = methodcaller('date')
flam = lambda x: x.date()
fmeth = Timestamp.date
s2 = Series(date_range('20010101', periods=1000000, freq='T'))
s2","[""s.map(lambda x: x.strftime('%d-%m-%Y'))"", ""s.map(methodcaller('strftime', '%d-%m-%Y'))"", ""s.map(methodcaller('date'))"", ""s.map(methodcaller('date')).values"", 's.map(Timestamp.date)', 'index.date', 'flam = lambda x: x.date()', 'fmeth = Timestamp.date']","['from operator import methodcaller', ""s = Series(date_range(Timestamp('now'), periods=2))"", 's', ""s.map(lambda x: x.strftime('%d-%m-%Y'))"", ""s.map(methodcaller('strftime', '%d-%m-%Y'))"", ""s.map(methodcaller('date'))"", ""s.map(methodcaller('date')).values"", 's.map(Timestamp.date)', 'index = DatetimeIndex(s)', 'index', 'index.date', ""f = methodcaller('date')"", 'flam = lambda x: x.date()', 'fmeth = Timestamp.date', ""s2 = Series(date_range('20010101', periods=1000000, freq='T'))"", 's2']","[""s.map(lambda x: x.strftime('%d-%m-%Y'))"", ""s.map(methodcaller('strftime', '%d-%m-%Y'))"", ""s.map(methodcaller('date'))"", ""s.map(methodcaller('date')).values"", 's.map(Timestamp.date)', 'index.date', 'flam = lambda x: x.date()', 'fmeth = Timestamp.date']",,
19112890,"df = DataFrame(table, columns=headers)
df",[],"['df = DataFrame(table, columns=headers)', 'df']",[],[],[]
19125531,"cols_to_use = df2.columns - df.columns
dfNew = merge(df, df2[cols_to_use], left_index=True, right_index=True, how='outer')
cols_to_use = df2.columns.difference(df.columns)",['cols_to_use = df2.columns.difference(df.columns)'],"['cols_to_use = df2.columns - df.columns', ""dfNew = merge(df, df2[cols_to_use], left_index=True, right_index=True, how='outer')"", 'cols_to_use = df2.columns.difference(df.columns)']",['cols_to_use = df2.columns.difference(df.columns)'],,
19126566,"def print_full(x):
    pd.set_option('display.max_rows', len(x))
    print(x)
    pd.reset_option('display.max_rows')","[""    pd.set_option('display.max_rows', len(x))"", ""    pd.reset_option('display.max_rows')""]","['def print_full(x):', ""    pd.set_option('display.max_rows', len(x))"", '    print(x)', ""    pd.reset_option('display.max_rows')""]","[""    pd.set_option('display.max_rows', len(x))"", ""    pd.reset_option('display.max_rows')""]",,
19155860,,[],[''],[],[],[]
19170098,"""nt|nv""  
f_recs[f_recs['Behavior'].str.contains(""nt|nv"", na=False)]
""nt"" | ""nv""","['f_recs[f_recs[\'Behavior\'].str.contains(""nt|nv"", na=False)]']","['""nt|nv""  ', 'f_recs[f_recs[\'Behavior\'].str.contains(""nt|nv"", na=False)]', '""nt"" | ""nv""']","['f_recs[f_recs[\'Behavior\'].str.contains(""nt|nv"", na=False)]']",,
19213836,"plt.axvline(x_position)
ax.axvline(x, color='k', linestyle='--')",[],"['plt.axvline(x_position)', ""ax.axvline(x, color='k', linestyle='--')""]",[],[],[]
19214708,"aggregated_df.reset_index().to_json(orient='index')
Out[11]: '{""0"":{""created"":""05-16-13"",""counter"":3},""1"":{""created"":""05-17-13"",""counter"":1},""2"":{""created"":""05-18-13"",""counter"":1}}'","[""aggregated_df.reset_index().to_json(orient='index')""]","[""aggregated_df.reset_index().to_json(orient='index')"", 'Out[11]: \'{""0"":{""created"":""05-16-13"",""counter"":3},""1"":{""created"":""05-17-13"",""counter"":1},""2"":{""created"":""05-18-13"",""counter"":1}}\'']","[""aggregated_df.reset_index().to_json(orient='index')""]",,
19226617,"import pandas
df = pandas.read_csv(""test.csv"")
df.loc[df.ID == 103, 'FirstName'] = ""Matt""
df.loc[df.ID == 103, 'LastName'] = ""Jones""
df.loc[df.ID == 103, ['FirstName', 'LastName']] = 'Matt', 'Jones'
import pandas
df = pandas.read_csv(""test.csv"")
df['FirstName'][df.ID == 103] = ""Matt""
df['LastName'][df.ID == 103] = ""Jones""","['df = pandas.read_csv(""test.csv"")', 'df.loc[df.ID == 103, \'FirstName\'] = ""Matt""', 'df.loc[df.ID == 103, \'LastName\'] = ""Jones""', ""df.loc[df.ID == 103, ['FirstName', 'LastName']] = 'Matt', 'Jones'"", 'df = pandas.read_csv(""test.csv"")']","['import pandas', 'df = pandas.read_csv(""test.csv"")', 'df.loc[df.ID == 103, \'FirstName\'] = ""Matt""', 'df.loc[df.ID == 103, \'LastName\'] = ""Jones""', ""df.loc[df.ID == 103, ['FirstName', 'LastName']] = 'Matt', 'Jones'"", 'import pandas', 'df = pandas.read_csv(""test.csv"")', 'df[\'FirstName\'][df.ID == 103] = ""Matt""', 'df[\'LastName\'][df.ID == 103] = ""Jones""']","['df = pandas.read_csv(""test.csv"")', 'df.loc[df.ID == 103, \'FirstName\'] = ""Matt""', 'df.loc[df.ID == 103, \'LastName\'] = ""Jones""', ""df.loc[df.ID == 103, ['FirstName', 'LastName']] = 'Matt', 'Jones'"", 'df = pandas.read_csv(""test.csv"")']",,
19226745,"fnames = {103: ""Matt"", 104: ""Mr""}
lnames = {103: ""Jones"", 104: ""X""}
df['First_Name'] = df['ID'].map(fnames)
df['Last_Name'] = df['ID'].map(lnames)
names = {103: (""Matt"", ""Jones""), 104: (""Mr"", ""X"")}
df['First_Name'] = df['ID'].map(lambda x: names[x][0])","[""df['First_Name'] = df['ID'].map(fnames)"", ""df['Last_Name'] = df['ID'].map(lnames)"", ""df['First_Name'] = df['ID'].map(lambda x: names[x][0])""]","['fnames = {103: ""Matt"", 104: ""Mr""}', 'lnames = {103: ""Jones"", 104: ""X""}', ""df['First_Name'] = df['ID'].map(fnames)"", ""df['Last_Name'] = df['ID'].map(lnames)"", 'names = {103: (""Matt"", ""Jones""), 104: (""Mr"", ""X"")}', ""df['First_Name'] = df['ID'].map(lambda x: names[x][0])""]","[""df['First_Name'] = df['ID'].map(fnames)"", ""df['Last_Name'] = df['ID'].map(lnames)"", ""df['First_Name'] = df['ID'].map(lambda x: names[x][0])""]",,
19231939,"df = DataFrame(data['values'])
df.columns = [""date"",""price""]
df
df.head()
df['date'] = pd.to_datetime(df['date'],unit='s')
df.head()
df.dtypes
dtype: object","['df.head()', ""df['date'] = pd.to_datetime(df['date'],unit='s')"", 'df.head()', 'df.dtypes']","[""df = DataFrame(data['values'])"", 'df.columns = [""date"",""price""]', 'df', 'df.head()', ""df['date'] = pd.to_datetime(df['date'],unit='s')"", 'df.head()', 'df.dtypes', 'dtype: object']","['df.head()', ""df['date'] = pd.to_datetime(df['date'],unit='s')"", 'df.head()', 'df.dtypes']",,
19237920,"k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]
df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')
df = DataFrame({'gender': np.random.choice(['m', 'f'], size=10), 'price': poisson(100, size=10)})
df
df.query('gender == ""m"" and price < 100')
k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", ""df = DataFrame({'gender': np.random.choice(['m', 'f'], size=10), 'price': poisson(100, size=10)})"", 'df', 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]"
19238029,"data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)
vals = randint(low=16, high=80, size=25).reshape(5,5)
cols = ['Q1.3', 'Q6.1', 'Q1.2', 'Q9.1', 'Q10.2']
data = DataFrame(vals, columns = cols)
data
data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)
data","['data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)', 'data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)']","['data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)', 'vals = randint(low=16, high=80, size=25).reshape(5,5)', ""cols = ['Q1.3', 'Q6.1', 'Q1.2', 'Q9.1', 'Q10.2']"", 'data = DataFrame(vals, columns = cols)', 'data', 'data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)', 'data']","['data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)', 'data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)']",,
19271841,"df.groupby('a')['a'].transform('count')
df.groupby('a').transform('count')
df2.groupby('a').transform('count')
type(df2.groupby('a').transform('count'))
df2.groupby('a')['a'].transform('count')
type(df.groupby('a')['a'].transform('count'))
Out[46]: pandas.core.series.Series","[""df.groupby('a')['a'].transform('count')"", ""df.groupby('a').transform('count')"", ""df2.groupby('a').transform('count')"", ""type(df2.groupby('a').transform('count'))"", ""df2.groupby('a')['a'].transform('count')"", ""type(df.groupby('a')['a'].transform('count'))"", 'Out[46]: pandas.core.series.Series']","[""df.groupby('a')['a'].transform('count')"", ""df.groupby('a').transform('count')"", ""df2.groupby('a').transform('count')"", ""type(df2.groupby('a').transform('count'))"", ""df2.groupby('a')['a'].transform('count')"", ""type(df.groupby('a')['a'].transform('count'))""]","[""df.groupby('a')['a'].transform('count')"", ""df.groupby('a').transform('count')"", ""df2.groupby('a').transform('count')"", ""type(df2.groupby('a').transform('count'))"", ""df2.groupby('a')['a'].transform('count')"", ""type(df.groupby('a')['a'].transform('count'))""]",,
19295539,"df.iloc[[1,3],:]","['df.iloc[[1,3],:]']","['df.iloc[[1,3],:]']","['df.iloc[[1,3],:]']",,
19295726,b = df[(df['a'] > 1) & (df['a'] < 5)],[],"[""b = df[(df['a'] > 1) & (df['a'] < 5)]""]",[],[],[]
19324591,"import pandas as pd
idx = pd.date_range('09-01-2013', '09-30-2013')
s = pd.Series({'09-02-2013': 2,
               '09-03-2013': 10,
               '09-06-2013': 5,
               '09-07-2013': 1})
s.index = pd.DatetimeIndex(s.index)
s = s.reindex(idx, fill_value=0)
print(s)
...","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","['import pandas as pd', ""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""               '09-03-2013': 10,"", ""               '09-06-2013': 5,"", ""               '09-07-2013': 1})"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)', 'print(s)', '...']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']"
19349005,df['index_col'] = df.index,"[""df['index_col'] = df.index""]","[""df['index_col'] = df.index""]","[""df['index_col'] = df.index""]",,
19351003,"df
df.dtypes
pd.to_datetime((df.Y*10000+df.M*100+df.D).apply(str),format='%Y%m%d')
pd.to_datetime(df.Y*10000+df.M*100+df.D,format='%Y%m%d')
dtype: datetime64[ns]","['df.dtypes', ""pd.to_datetime((df.Y*10000+df.M*100+df.D).apply(str),format='%Y%m%d')"", ""pd.to_datetime(df.Y*10000+df.M*100+df.D,format='%Y%m%d')""]","['df', 'df.dtypes', ""pd.to_datetime((df.Y*10000+df.M*100+df.D).apply(str),format='%Y%m%d')"", ""pd.to_datetime(df.Y*10000+df.M*100+df.D,format='%Y%m%d')"", 'dtype: datetime64[ns]']","['df.dtypes', ""pd.to_datetime((df.Y*10000+df.M*100+df.D).apply(str),format='%Y%m%d')"", ""pd.to_datetime(df.Y*10000+df.M*100+df.D,format='%Y%m%d')""]",,
19368360,,[],[''],[],[],[]
19378497,"dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']"
19385591,"df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]"
19403897,"import pandas as pd
df = pd.DataFrame({'A':'foo foo foo bar bar bar'.split(),
                   'B':[0.1, 0.5, 1.0]*2})
df['C'] = df.groupby(['A'])['B'].transform(
                     lambda x: pd.qcut(x, 3, labels=range(1,4)))
print(df)","[""df = pd.DataFrame({'A':'foo foo foo bar bar bar'.split(),"", ""df['C'] = df.groupby(['A'])['B'].transform("", '                     lambda x: pd.qcut(x, 3, labels=range(1,4)))']","['import pandas as pd', ""                   'B':[0.1, 0.5, 1.0]*2})"", ""df['C'] = df.groupby(['A'])['B'].transform("", '                     lambda x: pd.qcut(x, 3, labels=range(1,4)))', 'print(df)']","[""df = pd.DataFrame({'A':'foo foo foo bar bar bar'.split(),"", ""df['C'] = df.groupby(['A'])['B'].transform("", '                     lambda x: pd.qcut(x, 3, labels=range(1,4)))']",,
19415186,,[],[''],[],[],[]
19464054,"a.loc[a.shift(-1) != a]
dtype: int64
a.loc[a.diff() != 0]
dtype: int64
a.loc[a.shift() != a]
dtype: int64","['a.loc[a.shift(-1) != a]', 'a.loc[a.diff() != 0]', 'a.loc[a.shift() != a]']","['a.loc[a.shift(-1) != a]', 'dtype: int64', 'a.loc[a.diff() != 0]', 'dtype: int64', 'a.loc[a.shift() != a]', 'dtype: int64']","['a.loc[a.shift(-1) != a]', 'a.loc[a.diff() != 0]', 'a.loc[a.shift() != a]']",,
19473752,"df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)",[],"[""df.sort(['Peak', 'Weeks'], ascending=[True, False], inplace=True)""]",[],[],[]
19482988,,[],[''],[],[],[]
19483025,"list(my_dataframe.columns.values)
list(my_dataframe)",['list(my_dataframe.columns.values)'],"['list(my_dataframe.columns.values)', 'list(my_dataframe)']",['list(my_dataframe.columns.values)'],['list(my_dataframe.columns.values)'],['list(my_dataframe.columns.values)']
19483602,"my_dataframe.columns.values.tolist()
list(df)",['my_dataframe.columns.values.tolist()'],"['my_dataframe.columns.values.tolist()', 'list(df)']",['my_dataframe.columns.values.tolist()'],,
19486140,"from io import StringIO
import pandas as pd
data = StringIO(u""""""
121301234
121300123
121300012
"""""")
pd.read_fwf(data, colspecs=[(0,3),(4,8)], converters = {1: str})","['pd.read_fwf(data, colspecs=[(0,3),(4,8)], converters = {1: str})']","['from io import StringIO', 'import pandas as pd', 'data = StringIO(u""""""', '121301234', '121300123', '121300012', '"""""")', 'pd.read_fwf(data, colspecs=[(0,3),(4,8)], converters = {1: str})']","['pd.read_fwf(data, colspecs=[(0,3),(4,8)], converters = {1: str})']",,
19523512,,[],[''],[],[],[]
19555675,"dtf = pd.DataFrame.from_records(d,columns=h)
dtf2.plot()
fig = plt.gcf()
fig.savefig('output.png')","['dtf = pd.DataFrame.from_records(d,columns=h)', 'dtf2.plot()']","['dtf2.plot()', 'fig = plt.gcf()', ""fig.savefig('output.png')""]","['dtf = pd.DataFrame.from_records(d,columns=h)', 'dtf2.plot()']",,
19585378,"temp=[]
for row in df.iterrows():
    index, data = row
    temp.append(data.tolist())
df.apply(lambda x: x.tolist(), axis=1)
df.values.tolist()
[[0.0, 3.61, 380.0, 3.0],
 [1.0, 3.67, 660.0, 3.0],
 [1.0, 3.19, 640.0, 4.0],
 [0.0, 2.93, 520.0, 4.0]]","['for row in df.iterrows():', '    temp.append(data.tolist())', 'df.apply(lambda x: x.tolist(), axis=1)', 'df.values.tolist()']","['temp=[]', 'for row in df.iterrows():', '    index, data = row', '    temp.append(data.tolist())', 'df.apply(lambda x: x.tolist(), axis=1)', 'df.values.tolist()', '[[0.0, 3.61, 380.0, 3.0],', ' [1.0, 3.67, 660.0, 3.0],', ' [1.0, 3.19, 640.0, 4.0],', ' [0.0, 2.93, 520.0, 4.0]]']","['for row in df.iterrows():', '    temp.append(data.tolist())', 'df.apply(lambda x: x.tolist(), axis=1)', 'df.values.tolist()']",,
19585413,"map(list, df.values)","['map(list, df.values)']","['map(list, df.values)']","['map(list, df.values)']",,
19592693,"df.reset_index().pivot('index','Letter','N').hist()","[""df.reset_index().pivot('index','Letter','N').hist()""]","[""df.reset_index().pivot('index','Letter','N').hist()""]","[""df.reset_index().pivot('index','Letter','N').hist()""]",,
19599661,"df[df[""location""] == ""c""].squeeze()",[],"['df[df[""location""] == ""c""].squeeze()']",[],[],[]
19599776,"df[df[""location""] == ""c""].iloc[0]","['df[df[""location""] == ""c""].iloc[0]']","['df[df[""location""] == ""c""].iloc[0]']","['df[df[""location""] == ""c""].iloc[0]']",,
19600533,"pandas.pivot_table(df,values='count',index='site_id',columns='week')","[""pandas.pivot_table(df,values='count',index='site_id',columns='week')""]","[""pandas.pivot_table(df,values='count',index='site_id',columns='week')""]","[""pandas.pivot_table(df,values='count',index='site_id',columns='week')""]",,
19603918,df['N'].hist(by=df['Letter']),[],"[""df['N'].hist(by=df['Letter'])""]",[],[],[]
19609945,followers_df.index = range(20),['followers_df.index = range(20)'],['followers_df.index = range(20)'],['followers_df.index = range(20)'],,
19609954,"followers_df.reset_index()
followers_df.reindex(index=range(0,20))","['followers_df.reset_index()', 'followers_df.reindex(index=range(0,20))']","['followers_df.reset_index()', 'followers_df.reindex(index=range(0,20))']","['followers_df.reset_index()', 'followers_df.reindex(index=range(0,20))']",,
19611857,"from StringIO import StringIO  
import requests
r = requests.get('https://docs.google.com/spreadsheet/ccc?key=0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc&output=csv')
data = r.content
df = pd.read_csv(StringIO(data), index_col=0,parse_dates=['Quradate'])
df.head()","[""r = requests.get('https://docs.google.com/spreadsheet/ccc?key=0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc&output=csv')"", ""df = pd.read_csv(StringIO(data), index_col=0,parse_dates=['Quradate'])"", 'df.head()']","['from StringIO import StringIO  ', 'import requests', ""r = requests.get('https://docs.google.com/spreadsheet/ccc?key=0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc&output=csv')"", 'data = r.content', ""df = pd.read_csv(StringIO(data), index_col=0,parse_dates=['Quradate'])"", 'df.head()']","[""r = requests.get('https://docs.google.com/spreadsheet/ccc?key=0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc&output=csv')"", ""df = pd.read_csv(StringIO(data), index_col=0,parse_dates=['Quradate'])"", 'df.head()']",,
19619020,"df1
df2
ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)
ind
df1[ind].append(df2[ind])
df1.index & df2.index
Out[93]: Int64Index([], dtype='int64')","['ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)', 'df1[ind].append(df2[ind])', 'df1.index & df2.index']","['df1', 'df2', 'ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)', 'ind', 'df1[ind].append(df2[ind])', 'df1.index & df2.index', ""Out[93]: Int64Index([], dtype='int64')""]","['ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)', 'df1[ind].append(df2[ind])', 'df1.index & df2.index']",,
19632099,"pd.read_csv(""whitespace.csv"", header=None, delimiter=r""\s+"")","['pd.read_csv(""whitespace.csv"", header=None, delimiter=r""\\s+"")']","['pd.read_csv(""whitespace.csv"", header=None, delimiter=r""\\s+"")']","['pd.read_csv(""whitespace.csv"", header=None, delimiter=r""\\s+"")']",,
19633103,,[],[''],[],[],[]
19726078,"data.columns = map(str.lower, data.columns)
data.columns = [x.lower() for x in data.columns]
data = pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})
data
data.columns = map(str.lower, data.columns)
data","['data.columns = map(str.lower, data.columns)', 'data.columns = [x.lower() for x in data.columns]', ""data = pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})"", 'data.columns = map(str.lower, data.columns)']","['data.columns = map(str.lower, data.columns)', 'data.columns = [x.lower() for x in data.columns]', 'data', 'data.columns = map(str.lower, data.columns)', 'data']","['data.columns = map(str.lower, data.columns)', 'data.columns = [x.lower() for x in data.columns]', 'data.columns = map(str.lower, data.columns)']",,
19736406,"d = dict( A = np.array([1,2]), B = np.array([1,2,3,4]) )
DataFrame(dict([ (k,Series(v)) for k,v in d.items() ]))",[],"['d = dict( A = np.array([1,2]), B = np.array([1,2,3,4]) )', 'DataFrame(dict([ (k,Series(v)) for k,v in d.items() ]))']",[],[],[]
19739768,,[],[''],[],[],[]
19758398,"data.rename(columns={'gdp':'log(gdp)'}, inplace=True)","[""data.rename(columns={'gdp':'log(gdp)'}, inplace=True)""]","[""data.rename(columns={'gdp':'log(gdp)'}, inplace=True)""]","[""data.rename(columns={'gdp':'log(gdp)'}, inplace=True)""]",,
19782137,"df.to_csv('filename.csv', header=False)
df.to_csv('filename.tsv', sep='\t', index=False)","[""df.to_csv('filename.csv', header=False)"", ""df.to_csv('filename.tsv', sep='\\t', index=False)""]","[""df.to_csv('filename.csv', header=False)"", ""df.to_csv('filename.tsv', sep='\\t', index=False)""]","[""df.to_csv('filename.csv', header=False)"", ""df.to_csv('filename.tsv', sep='\\t', index=False)""]",,
19791302,"data = pd.DataFrame({'Names': ['Joe', 'John', 'Jasper', 'Jez'] *4, 'Ob1' : np.random.rand(16), 'Ob2' : np.random.rand(16)})
UniqueNames = data.Names.unique()
DataFrameDict = {elem : pd.DataFrame for elem in UniqueNames}
for key in DataFrameDict.keys():
    DataFrameDict[key] = data[:][data.Names == key]
DataFrameDict['Joe']","[""data = pd.DataFrame({'Names': ['Joe', 'John', 'Jasper', 'Jez'] *4, 'Ob1' : np.random.rand(16), 'Ob2' : np.random.rand(16)})"", 'UniqueNames = data.Names.unique()', 'DataFrameDict = {elem : pd.DataFrame for elem in UniqueNames}']","['UniqueNames = data.Names.unique()', 'for key in DataFrameDict.keys():', '    DataFrameDict[key] = data[:][data.Names == key]', ""DataFrameDict['Joe']""]",['UniqueNames = data.Names.unique()'],,
19798528,"frame = DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])
frame
f = lambda x: x.max() - x.min()
frame.apply(f)
format = lambda x: '%.2f' % x
frame.applymap(format)
frame['e'].map(format)
Ohio      -1.55
Oregon    -0.31","['f = lambda x: x.max() - x.min()', 'frame.apply(f)', 'frame.applymap(format)', ""frame['e'].map(format)""]","[""frame = DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])"", 'frame', 'f = lambda x: x.max() - x.min()', 'frame.apply(f)', ""format = lambda x: '%.2f' % x"", 'frame.applymap(format)', ""frame['e'].map(format)"", 'Ohio      -1.55', 'Oregon    -0.31']","['f = lambda x: x.max() - x.min()', 'frame.apply(f)', 'frame.applymap(format)', ""frame['e'].map(format)""]",,
19809616,"df.sort(columns=['name'], inplace=True)
df.set_index(keys=['name'], drop=False,inplace=True)
names=df['name'].unique().tolist()
joe = df.loc[df.name=='joe']","[""df.set_index(keys=['name'], drop=False,inplace=True)"", ""names=df['name'].unique().tolist()"", ""joe = df.loc[df.name=='joe']""]","[""df.sort(columns=['name'], inplace=True)"", ""df.set_index(keys=['name'], drop=False,inplace=True)"", ""names=df['name'].unique().tolist()"", ""joe = df.loc[df.name=='joe']""]","[""df.set_index(keys=['name'], drop=False,inplace=True)"", ""names=df['name'].unique().tolist()"", ""joe = df.loc[df.name=='joe']""]",,
19818942,"df.groupby('Mt').first()
df.groupby('Mt', as_index=False).first()
df.sort('count', ascending=False).groupby('Mt', as_index=False).first()","[""df.groupby('Mt').first()"", ""df.groupby('Mt', as_index=False).first()"", ""df.sort('count', ascending=False).groupby('Mt', as_index=False).first()""]","[""df.groupby('Mt').first()"", ""df.groupby('Mt', as_index=False).first()"", ""df.sort('count', ascending=False).groupby('Mt', as_index=False).first()""]","[""df.groupby('Mt').first()"", ""df.groupby('Mt', as_index=False).first()"", ""df.sort('count', ascending=False).groupby('Mt', as_index=False).first()""]",,
19819118,df.iloc[df.groupby(['Mt']).apply(lambda x: x['count'].idxmax())],"[""df.iloc[df.groupby(['Mt']).apply(lambda x: x['count'].idxmax())]""]","[""df.iloc[df.groupby(['Mt']).apply(lambda x: x['count'].idxmax())]""]","[""df.iloc[df.groupby(['Mt']).apply(lambda x: x['count'].idxmax())]""]",,
19821311,,[],[''],[],[],[]
19828967,"if df.empty:
    print('DataFrame is empty!')",['if df.empty:'],"['if df.empty:', ""    print('DataFrame is empty!')""]",['if df.empty:'],,
19851521,"df.index.names = ['Date']
df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))
df
df1 = df.set_index('A')
df1
df1.rename(index={1: 'a'})
df1.rename(columns={'B': 'BB'})
df1.index.names = ['index']
df1
index       ","[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", 'df', ""df1 = df.set_index('A')"", 'df1', ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']"", 'df1', 'index       ']","[""df.index.names = ['Date']"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]"
19861545,"select  = df.apply(lambda r : any([isinstance(e, basestring) for e in r  ]),axis=1) 
df[~select]                                                                                                                                ","['select  = df.apply(lambda r : any([isinstance(e, basestring) for e in r  ]),axis=1) ']","['select  = df.apply(lambda r : any([isinstance(e, basestring) for e in r  ]),axis=1) ', 'df[~select]                                                                                                                                ']","['select  = df.apply(lambda r : any([isinstance(e, basestring) for e in r  ]),axis=1) ']",,
19867768,"df.loc[df.cherry == 'bad', ['apple', 'banana']] = np.nan
df","[""df.loc[df.cherry == 'bad', ['apple', 'banana']] = np.nan""]","[""df.loc[df.cherry == 'bad', ['apple', 'banana']] = np.nan"", 'df']","[""df.loc[df.cherry == 'bad', ['apple', 'banana']] = np.nan""]",,
19895152,"df
df.groupby('C').quantile(.95)
C                      ","[""df.groupby('C').quantile(.95)""]","['df', ""df.groupby('C').quantile(.95)"", 'C                      ']","[""df.groupby('C').quantile(.95)""]",,
19900276,"def recur_dictify(frame):
    if len(frame.columns) == 1:
        if frame.values.size == 1: return frame.values[0][0]
        return frame.values.squeeze()
    grouped = frame.groupby(frame.columns[0])
    d = {k: recur_dictify(g.ix[:,1:]) for k,g in grouped}
    return d
df
pprint.pprint(recur_dictify(df))
{'A': {'A1': {'A11': 1}, 'A2': {'A12': 2, 'A21': 6}},
 'B': {'B1': {'B12': 3}, 'B2': {'B21': 5}},
 'C': {'C1': {'C11': 4}}}
def retro_dictify(frame):
    d = {}
    for row in frame.values:
        here = d
        for elem in row[:-2]:
            if elem not in here:
                here[elem] = {}
            here = here[elem]
        here[row[-2]] = row[-1]
    return d","['        if frame.values.size == 1: return frame.values[0][0]', '        return frame.values.squeeze()', '    grouped = frame.groupby(frame.columns[0])', '    for row in frame.values:']","['def recur_dictify(frame):', '    if len(frame.columns) == 1:', '        if frame.values.size == 1: return frame.values[0][0]', '        return frame.values.squeeze()', '    grouped = frame.groupby(frame.columns[0])', '    d = {k: recur_dictify(g.ix[:,1:]) for k,g in grouped}', '    return d', 'df', 'pprint.pprint(recur_dictify(df))', ""{'A': {'A1': {'A11': 1}, 'A2': {'A12': 2, 'A21': 6}},"", "" 'B': {'B1': {'B12': 3}, 'B2': {'B21': 5}},"", "" 'C': {'C1': {'C11': 4}}}"", 'def retro_dictify(frame):', '    d = {}', '    for row in frame.values:', '        here = d', '        for elem in row[:-2]:', '            if elem not in here:', '                here[elem] = {}', '            here = here[elem]', '        here[row[-2]] = row[-1]', '    return d']","['        if frame.values.size == 1: return frame.values[0][0]', '        return frame.values.squeeze()', '    grouped = frame.groupby(frame.columns[0])', '    for row in frame.values:']",,
19913845,"df['color'] = np.where(df['Set']=='Z', 'green', 'red')
import pandas as pd
import numpy as np
df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})
df['color'] = np.where(df['Set']=='Z', 'green', 'red')
print(df)
df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})
conditions = [
    (df['Set'] == 'Z') & (df['Type'] == 'A'),
    (df['Set'] == 'Z') & (df['Type'] == 'B'),
    (df['Type'] == 'B')]
choices = ['yellow', 'blue', 'purple']
df['color'] = np.select(conditions, choices, default='black')
print(df)","[""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", ""df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})"", ""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", ""df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})"", ""df['color'] = np.select(conditions, choices, default='black')""]","[""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", 'import pandas as pd', 'import numpy as np', ""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", 'print(df)', 'conditions = [', ""    (df['Set'] == 'Z') & (df['Type'] == 'A'),"", ""    (df['Set'] == 'Z') & (df['Type'] == 'B'),"", ""    (df['Type'] == 'B')]"", ""choices = ['yellow', 'blue', 'purple']"", ""df['color'] = np.select(conditions, choices, default='black')"", 'print(df)']","[""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", ""df['color'] = np.where(df['Set']=='Z', 'green', 'red')"", ""df['color'] = np.select(conditions, choices, default='black')""]",,
19915115,"df['newcolumn'] = df.A * df.B
def fab(row):
  return row['A'] * row['B']
df['newcolumn'] = df.apply(fab, axis=1)","[""df['newcolumn'] = df.apply(fab, axis=1)""]","[""df['newcolumn'] = df.A * df.B"", 'def fab(row):', ""  return row['A'] * row['B']"", ""df['newcolumn'] = df.apply(fab, axis=1)""]","[""df['newcolumn'] = df.apply(fab, axis=1)""]",,
19918849,"csvdata_old = csvdata.copy()
from pandas.util.testing import assert_frame_equal
assert_frame_equal(csvdata, csvdata_old)
try:
    assert_frame_equal(csvdata, csvdata_old)
    return True
except:  
    return False",['csvdata_old = csvdata.copy()'],"['csvdata_old = csvdata.copy()', 'from pandas.util.testing import assert_frame_equal', 'assert_frame_equal(csvdata, csvdata_old)', 'try:', '    assert_frame_equal(csvdata, csvdata_old)', '    return True', 'except:  ', '    return False']",['csvdata_old = csvdata.copy()'],,
19922732,,[],[''],[],[],[]
19928288,from pandas.util.testing import assert_frame_equal,[],['from pandas.util.testing import assert_frame_equal'],[],[],[]
19937902,"import pandas as pd
T1 = pd.merge(T1, T2, on=T1.index, how='outer')","[""T1 = pd.merge(T1, T2, on=T1.index, how='outer')""]","['import pandas as pd', ""T1 = pd.merge(T1, T2, on=T1.index, how='outer')""]","[""T1 = pd.merge(T1, T2, on=T1.index, how='outer')""]",,
19960116,"df
countries
['UK', 'China']
df.countries.isin(countries)
df[df.countries.isin(countries)]
df[~df.countries.isin(countries)]","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df', 'countries', ""['UK', 'China']"", 'df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']"
19960136,"criterion = lambda row: row['countries'] not in countries
not_in = df[df.apply(criterion, axis=1)]","['not_in = df[df.apply(criterion, axis=1)]']","[""criterion = lambda row: row['countries'] not in countries"", 'not_in = df[df.apply(criterion, axis=1)]']","['not_in = df[df.apply(criterion, axis=1)]']",,
19961557,"df = pd.DataFrame(data)
df.pivot(index=0, columns=1, values=2)
0               
df.pivot(index=0, columns=1, values=3)
0                   ","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df.pivot(index=0, columns=1, values=2)', '0               ', 'df.pivot(index=0, columns=1, values=3)', '0                   ']","['df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']"
19961872,"df = pandas.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std'])
df = df.set_index(['R_Number', 'C_Number'])
df.set_index(['R_Number', 'C_Number']).Avg.unstack(level=1)","[""df = pandas.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std'])"", ""df = df.set_index(['R_Number', 'C_Number'])"", ""df.set_index(['R_Number', 'C_Number']).Avg.unstack(level=1)""]","[""df = df.set_index(['R_Number', 'C_Number'])"", ""df.set_index(['R_Number', 'C_Number']).Avg.unstack(level=1)""]","[""df = df.set_index(['R_Number', 'C_Number'])"", ""df.set_index(['R_Number', 'C_Number']).Avg.unstack(level=1)""]",,
19966142,"df
df[""value""] = df.groupby(""name"").transform(lambda x: x.fillna(x.mean()))
df","['df[""value""] = df.groupby(""name"").transform(lambda x: x.fillna(x.mean()))']","['df', 'df[""value""] = df.groupby(""name"").transform(lambda x: x.fillna(x.mean()))', 'df']","['df[""value""] = df.groupby(""name"").transform(lambda x: x.fillna(x.mean()))']",,
19969224,"ax2.plot(ax.get_xticks(),df[['sales_gr','net_pft_gr']].values, linestyle='-', marker='o', linewidth=2.0)
ax.set_ylim((-10, 80.))","[""ax2.plot(ax.get_xticks(),df[['sales_gr','net_pft_gr']].values, linestyle='-', marker='o', linewidth=2.0)""]","[""ax2.plot(ax.get_xticks(),df[['sales_gr','net_pft_gr']].values, linestyle='-', marker='o', linewidth=2.0)"", 'ax.set_ylim((-10, 80.))']","[""ax2.plot(ax.get_xticks(),df[['sales_gr','net_pft_gr']].values, linestyle='-', marker='o', linewidth=2.0)""]",,
19973722,,[],[''],[],[],[]
19976286,"import numpy as np
df = pd.DataFrame({""A"": [10,20,30], ""B"": [20, 30, 10]})
df['new_column'] = np.multiply(df['A'], df['B'])
df","['df = pd.DataFrame({""A"": [10,20,30], ""B"": [20, 30, 10]})']","['import numpy as np', ""df['new_column'] = np.multiply(df['A'], df['B'])"", 'df']",[],,
19982756,"df.set_index(['fileName','phrase'],inplace=True)
df.sortlevel(inplace=True)
df.ix[('somePath','somePhrase')]","[""df.set_index(['fileName','phrase'],inplace=True)""]","[""df.set_index(['fileName','phrase'],inplace=True)"", 'df.sortlevel(inplace=True)', ""df.ix[('somePath','somePhrase')]""]","[""df.set_index(['fileName','phrase'],inplace=True)""]",,
19991632,"import pandas as pd
import statsmodels.formula.api as sm
df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})
result = sm.ols(formula=""A ~ B + C"", data=df).fit()
dtype: float64","['df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})']","['import pandas as pd', 'import statsmodels.formula.api as sm', 'result = sm.ols(formula=""A ~ B + C"", data=df).fit()', 'dtype: float64']",[],,
19996208,"from pandas.stats.api import ols
df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})
res = ols(y=df['A'], x=df[['B','C']])
res
Rmse:             14.5108","['df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})']","['from pandas.stats.api import ols', ""res = ols(y=df['A'], x=df[['B','C']])"", 'res', 'Rmse:             14.5108']",[],,
20006954,"df_data['vals'] = df_data['vals'].map(lambda x: '%2.1f' % x)
df_data.to_csv(outfile, index=False, header=False, float_format='%11.6f')","[""df_data['vals'] = df_data['vals'].map(lambda x: '%2.1f' % x)"", ""df_data.to_csv(outfile, index=False, header=False, float_format='%11.6f')""]","[""df_data['vals'] = df_data['vals'].map(lambda x: '%2.1f' % x)"", ""df_data.to_csv(outfile, index=False, header=False, float_format='%11.6f')""]","[""df_data['vals'] = df_data['vals'].map(lambda x: '%2.1f' % x)"", ""df_data.to_csv(outfile, index=False, header=False, float_format='%11.6f')""]",,
20012628,,[],[''],[],[],[]
20015080,"Point = namedtuple('Point', ['x', 'y'])
points = [Point(1, 2), Point(3, 4)]
pd.DataFrame(points, columns=Point._fields)","['pd.DataFrame(points, columns=Point._fields)']","[""Point = namedtuple('Point', ['x', 'y'])"", 'points = [Point(1, 2), Point(3, 4)]']",[],,
20019449,"data = np.asarray(df)
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
X, y = data[:, 1:], data[:, 0]
lr.fit(X, y)
LinearRegression(copy_X=True, fit_intercept=True, normalize=False)
lr.coef_
array([  4.01182386e-01,   3.51587361e-04])
lr.intercept_
14.952479503953672",[],"['data = np.asarray(df)', 'from sklearn.linear_model import LinearRegression', 'lr = LinearRegression()', 'X, y = data[:, 1:], data[:, 0]', 'lr.fit(X, y)', 'LinearRegression(copy_X=True, fit_intercept=True, normalize=False)', 'lr.coef_', 'array([  4.01182386e-01,   3.51587361e-04])', 'lr.intercept_', '14.952479503953672']",[],[],[]
20024879,"df
df.T.to_dict().values()
[{'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}, {'col2': 'foo', 'col1': 'C'}, {'col2': 'bar', 'col1': 'A'}, {'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}]
df = pandas.DataFrame({'col1': ['A', 'B', 'C', 'A', 'A', 'B'], 'col2': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar']})
df
df.to_dict('records')
[{'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}, {'col2': 'foo', 'col1': 'C'}, {'col2': 'bar', 'col1': 'A'}, {'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}]","['df.T.to_dict().values()', ""df = pandas.DataFrame({'col1': ['A', 'B', 'C', 'A', 'A', 'B'], 'col2': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar']})"", ""df.to_dict('records')""]","['df', 'df.T.to_dict().values()', ""[{'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}, {'col2': 'foo', 'col1': 'C'}, {'col2': 'bar', 'col1': 'A'}, {'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}]"", 'df', ""df.to_dict('records')"", ""[{'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}, {'col2': 'foo', 'col1': 'C'}, {'col2': 'bar', 'col1': 'A'}, {'col2': 'foo', 'col1': 'A'}, {'col2': 'bar', 'col1': 'B'}]""]","['df.T.to_dict().values()', ""df.to_dict('records')""]",,
20027386,"df['col'] = 'str' + df['col'].astype(str)
df = pd.DataFrame({'col':['a',0]})
df
df['col'] = 'str' + df['col'].astype(str)
df","[""df['col'] = 'str' + df['col'].astype(str)"", ""df = pd.DataFrame({'col':['a',0]})"", ""df['col'] = 'str' + df['col'].astype(str)""]","[""df['col'] = 'str' + df['col'].astype(str)"", 'df', ""df['col'] = 'str' + df['col'].astype(str)"", 'df']","[""df['col'] = 'str' + df['col'].astype(str)"", ""df['col'] = 'str' + df['col'].astype(str)""]",,
20032254,,[],[''],[],[],[]
20033218,"frame['HighScore'] = frame[['test1','test2','test3']].apply(max, axis=1)
frame","[""frame['HighScore'] = frame[['test1','test2','test3']].apply(max, axis=1)""]","[""frame['HighScore'] = frame[['test1','test2','test3']].apply(max, axis=1)"", 'frame']","[""frame['HighScore'] = frame[['test1','test2','test3']].apply(max, axis=1)""]",,
20033232,"frame['HighScore'] = frame[['test1','test2','test3']].max(axis=1)
frame","[""frame['HighScore'] = frame[['test1','test2','test3']].max(axis=1)""]","[""frame['HighScore'] = frame[['test1','test2','test3']].max(axis=1)"", 'frame']","[""frame['HighScore'] = frame[['test1','test2','test3']].max(axis=1)""]",,
20038973,"'[%s]' % ','.join(test.splitlines())
test_100 = '\n'.join([test] * 100)
test_1000 = '\n'.join([test] * 1000)","[""'[%s]' % ','.join(test.splitlines())"", ""test_100 = '\\n'.join([test] * 100)"", ""test_1000 = '\\n'.join([test] * 1000)""]","[""'[%s]' % ','.join(test.splitlines())"", ""test_100 = '\\n'.join([test] * 100)"", ""test_1000 = '\\n'.join([test] * 1000)""]","[""'[%s]' % ','.join(test.splitlines())"", ""test_100 = '\\n'.join([test] * 100)"", ""test_1000 = '\\n'.join([test] * 1000)""]",,
20039057,"cols = [col for col in df.columns if col not in ['B', 'D']]
df2 = df[cols]",[],"[""cols = [col for col in df.columns if col not in ['B', 'D']]"", 'df2 = df[cols]']",[],[],[]
20043785,"from IPython.display import HTML
df = pd.DataFrame(list(range(5)), columns=['a'])
df['a'] = df['a'].apply(lambda x: '<a href=""http://example.com/{0}"">link</a>'.format(x))
HTML(df.to_html(escape=False))","[""df = pd.DataFrame(list(range(5)), columns=['a'])"", 'df[\'a\'] = df[\'a\'].apply(lambda x: \'<a href=""http://example.com/{0}"">link</a>\'.format(x))', 'HTML(df.to_html(escape=False))']","['from IPython.display import HTML', 'df[\'a\'] = df[\'a\'].apply(lambda x: \'<a href=""http://example.com/{0}"">link</a>\'.format(x))', 'HTML(df.to_html(escape=False))']","['df[\'a\'] = df[\'a\'].apply(lambda x: \'<a href=""http://example.com/{0}"">link</a>\'.format(x))', 'HTML(df.to_html(escape=False))']",,
20051631,"pd.factorize(df.b)
df['c'] = pd.factorize(df.b)[0]
df","['pd.factorize(df.b)', ""df['c'] = pd.factorize(df.b)[0]""]","['pd.factorize(df.b)', ""df['c'] = pd.factorize(df.b)[0]"", 'df']","['pd.factorize(df.b)', ""df['c'] = pd.factorize(df.b)[0]""]",,
20059818,"import pandas
import pyodbc
sql = 'select * from table'
cnn = pyodbc.connect(...)
data = pandas.read_sql(sql, cnn)
import pandas
from pandas.io.sql import read_frame
import pyodbc
sql = 'select * from table'
cnn = pyodbc.connect(...)
data = read_frame(sql, cnn)","['data = pandas.read_sql(sql, cnn)']","['import pandas', 'import pyodbc', ""sql = 'select * from table'"", 'cnn = pyodbc.connect(...)', 'data = pandas.read_sql(sql, cnn)', 'import pandas', 'from pandas.io.sql import read_frame', 'import pyodbc', ""sql = 'select * from table'"", 'cnn = pyodbc.connect(...)', 'data = read_frame(sql, cnn)']","['data = pandas.read_sql(sql, cnn)']",,
20067665,"df.groupby('id').first()
id        
df.groupby('id').first().reset_index()
df.groupby('id').head(2).reset_index(drop=True)","[""df.groupby('id').first()"", ""df.groupby('id').first().reset_index()"", ""df.groupby('id').head(2).reset_index(drop=True)""]","[""df.groupby('id').first()"", 'id        ', ""df.groupby('id').first().reset_index()"", ""df.groupby('id').head(2).reset_index(drop=True)""]","[""df.groupby('id').first()"", ""df.groupby('id').first().reset_index()"", ""df.groupby('id').head(2).reset_index(drop=True)""]",,
20069379,"df.groupby('id').head(2)
id             
df.groupby('id').head(2).reset_index(drop=True)","[""df.groupby('id').head(2)"", ""df.groupby('id').head(2).reset_index(drop=True)""]","[""df.groupby('id').head(2)"", 'id             ', ""df.groupby('id').head(2).reset_index(drop=True)""]","[""df.groupby('id').head(2)"", ""df.groupby('id').head(2).reset_index(drop=True)""]",,
20076611,,[],[''],[],[],[]
20084843,"def f(df):
    store = pd.HDFStore('test.h5','w')
    store['df'] = df
    store.close()
def f2(df):
    store = pd.HDFStore('test.h5','w')
    store.append('df',df,index=False)
    store.close()
def f3(df):
    store = pd.HDFStore('test.h5','w')
    store.append('df',df)
    store.close()
df = concat([DataFrame(np.random.randn(10000000,10)),DataFrame(np.random.randint(0,10,size=50000000).reshape(10000000,5))],axis=1)
df
df = pd.read_hdf('test.h5','df')
df","[""    store.append('df',df,index=False)"", ""    store.append('df',df)"", ""df = pd.read_hdf('test.h5','df')""]","['def f(df):', ""    store = pd.HDFStore('test.h5','w')"", ""    store['df'] = df"", '    store.close()', 'def f2(df):', ""    store = pd.HDFStore('test.h5','w')"", ""    store.append('df',df,index=False)"", '    store.close()', 'def f3(df):', ""    store = pd.HDFStore('test.h5','w')"", ""    store.append('df',df)"", '    store.close()', 'df = concat([DataFrame(np.random.randn(10000000,10)),DataFrame(np.random.randint(0,10,size=50000000).reshape(10000000,5))],axis=1)', 'df', ""df = pd.read_hdf('test.h5','df')"", 'df']","[""    store.append('df',df,index=False)"", ""    store.append('df',df)"", ""df = pd.read_hdf('test.h5','df')""]",,
20084895,"df = DataFrame(np.random.randint(0,10,size=100).reshape(10,10))
df
Series(df.values.ravel()).unique()
df = DataFrame(np.random.randint(0,10,size=10000).reshape(100,100))",['Series(df.values.ravel()).unique()'],"['df = DataFrame(np.random.randint(0,10,size=100).reshape(10,10))', 'df', 'Series(df.values.ravel()).unique()', 'df = DataFrame(np.random.randint(0,10,size=10000).reshape(100,100))']",['Series(df.values.ravel()).unique()'],['Series(df.values.ravel()).unique()'],['Series(df.values.ravel()).unique()']
20096494,date_parser : function,[],['date_parser : function'],[],[],[]
20096827,"df.gdp = df.gdp.shift(-1)
df
df[:-1]                                                                                                                                                                                                                                                                                                               ",['df.gdp = df.gdp.shift(-1)'],"['df.gdp = df.gdp.shift(-1)', 'df', 'df[:-1]                                                                                                                                                                                                                                                                                                               ']",['df.gdp = df.gdp.shift(-1)'],,
20107825,,[],[''],[],[],[]
20120225,"df1 = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)
df2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)
pd.concat((df1, df2), axis=1)
B                    
df3 = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])
df3
B                                        
df3 = df3.ix[:, [('sum', 'D'), ('mean','E')]]
df3.columns = ['D', 'E']
df3
B                    
df.groupby('B').aggregate({'D':np.sum, 'E':np.mean})
B                    ","[""df1 = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)"", ""df2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)"", 'pd.concat((df1, df2), axis=1)', ""df3 = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])"", ""df.groupby('B').aggregate({'D':np.sum, 'E':np.mean})""]","[""df1 = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)"", ""df2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)"", 'pd.concat((df1, df2), axis=1)', 'B                    ', ""df3 = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])"", 'df3', 'B                                        ', ""df3 = df3.ix[:, [('sum', 'D'), ('mean','E')]]"", ""df3.columns = ['D', 'E']"", 'df3', 'B                    ', ""df.groupby('B').aggregate({'D':np.sum, 'E':np.mean})"", 'B                    ']","[""df1 = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)"", ""df2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)"", 'pd.concat((df1, df2), axis=1)', ""df3 = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])"", ""df.groupby('B').aggregate({'D':np.sum, 'E':np.mean})""]",,
20154429,"1,2,1
2,3,4,2,3
1,2,3,3
1,2,3,4,5,6
pd.read_csv(r'D:/Temp/tt.csv')
...
pd.read_csv(r'D:/Temp/tt.csv', names=list('abcdef'))","[""pd.read_csv(r'D:/Temp/tt.csv')"", ""pd.read_csv(r'D:/Temp/tt.csv', names=list('abcdef'))""]","['1,2,1', '2,3,4,2,3', '1,2,3,3', '1,2,3,4,5,6', ""pd.read_csv(r'D:/Temp/tt.csv')"", '...', ""pd.read_csv(r'D:/Temp/tt.csv', names=list('abcdef'))""]","[""pd.read_csv(r'D:/Temp/tt.csv')"", ""pd.read_csv(r'D:/Temp/tt.csv', names=list('abcdef'))""]",,
20159305,"df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])
df
iwantthis
df.groupby('A').sum()
df
df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])
df
A   
df = pd.read_csv('my_secret_file.csv')  ","[""df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])"", ""df.groupby('A').sum()"", ""df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])"", ""df = pd.read_csv('my_secret_file.csv')  ""]","['df', 'iwantthis', ""df.groupby('A').sum()"", 'df', 'df', 'A   ', ""df = pd.read_csv('my_secret_file.csv')  ""]","[""df.groupby('A').sum()"", ""df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])"", ""df = pd.read_csv('my_secret_file.csv')  ""]",,
20167984,"import json
df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})
df
records = json.loads(df.T.to_json()).values()
db.myCollection.insert(records)
df = read_mongo(db, 'myCollection')
df
df.dtypes
dtype: object
df['A'] = pd.to_datetime(df['A'])
df","[""df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})"", 'records = json.loads(df.T.to_json()).values()', 'db.myCollection.insert(records)', 'df.dtypes', ""df['A'] = pd.to_datetime(df['A'])""]","['import json', 'df', 'records = json.loads(df.T.to_json()).values()', 'db.myCollection.insert(records)', ""df = read_mongo(db, 'myCollection')"", 'df', 'df.dtypes', 'dtype: object', ""df['A'] = pd.to_datetime(df['A'])"", 'df']","[""df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})"", 'records = json.loads(df.T.to_json()).values()', 'db.myCollection.insert(records)', 'df.dtypes', ""df['A'] = pd.to_datetime(df['A'])""]",,
20168416,"result.index
Int64Index([0, 1, 2], dtype=int64)
result.index += 1 
result.index
Int64Index([1, 2, 3], dtype=int64)","['result.index', 'result.index += 1 ', 'result.index']","['result.index', 'Int64Index([0, 1, 2], dtype=int64)', 'result.index += 1 ', 'result.index', 'Int64Index([1, 2, 3], dtype=int64)']","['result.index', 'result.index += 1 ', 'result.index']",,
20181686,"df.groupby([""score"", ""type""]).sum()
df.groupby([""score"", ""type""], as_index=False).sum()","['df.groupby([""score"", ""type""]).sum()', 'df.groupby([""score"", ""type""], as_index=False).sum()']","['df.groupby([""score"", ""type""]).sum()', 'df.groupby([""score"", ""type""], as_index=False).sum()']","['df.groupby([""score"", ""type""]).sum()', 'df.groupby([""score"", ""type""], as_index=False).sum()']",,
20199798,df[df.groupby(level=0).transform(len)['type'] > 1],"[""df[df.groupby(level=0).transform(len)['type'] > 1]""]","[""df[df.groupby(level=0).transform(len)['type'] > 1]""]","[""df[df.groupby(level=0).transform(len)['type'] > 1]""]",,
20200594,df.groupby(level=0).filter(lambda x: len(x) > 1)['type'],"[""df.groupby(level=0).filter(lambda x: len(x) > 1)['type']""]","[""df.groupby(level=0).filter(lambda x: len(x) > 1)['type']""]","[""df.groupby(level=0).filter(lambda x: len(x) > 1)['type']""]",,
20206825,"x.merge(x.merge(y, how='left', on='state', sort=False))
x.reset_index().merge(y, how='left', on='state', sort=False).sort('index')","[""x.merge(x.merge(y, how='left', on='state', sort=False))"", ""x.reset_index().merge(y, how='left', on='state', sort=False).sort('index')""]","[""x.merge(x.merge(y, how='left', on='state', sort=False))"", ""x.reset_index().merge(y, how='left', on='state', sort=False).sort('index')""]","[""x.merge(x.merge(y, how='left', on='state', sort=False))"", ""x.reset_index().merge(y, how='left', on='state', sort=False).sort('index')""]",,
20221655,"import pandas
from openpyxl import load_workbook
book = load_workbook('Masterfile.xlsx')
writer = pandas.ExcelWriter('Masterfile.xlsx', engine='openpyxl') 
writer.book = book
writer.sheets = dict((ws.title, ws) for ws in book.worksheets)
data_filtered.to_excel(writer, ""Main"", cols=['Diff1', 'Diff2'])
writer.save()","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['import pandas', 'from openpyxl import load_workbook', ""book = load_workbook('Masterfile.xlsx')"", ""writer = pandas.ExcelWriter('Masterfile.xlsx', engine='openpyxl') "", 'writer.book = book', 'writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])', 'writer.save()']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']"
20228113,"df = pd.concat([df1, df2])
df = df.reset_index(drop=True)
df_gpby = df.groupby(list(df.columns))
idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]
df.reindex(idx)","['df = pd.concat([df1, df2])', 'df = df.reset_index(drop=True)', 'df_gpby = df.groupby(list(df.columns))', 'idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]', 'df.reindex(idx)']","['df = pd.concat([df1, df2])', 'df = df.reset_index(drop=True)', 'df_gpby = df.groupby(list(df.columns))', 'idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]', 'df.reindex(idx)']","['df = pd.concat([df1, df2])', 'df = df.reset_index(drop=True)', 'df_gpby = df.groupby(list(df.columns))', 'idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]', 'df.reindex(idx)']",,
20230859,"df.drop(column_name, axis=1)","['df.drop(column_name, axis=1)']","['df.drop(column_name, axis=1)']","['df.drop(column_name, axis=1)']",,
20231632,"collist = ['col1', 'col2', 'col3']
df1 = df[collist]
collist = df.columns.tolist()
df1 = df[collist[0:1]]
collist.remove('col2')
df1 = df[collist]",['collist = df.columns.tolist()'],"[""collist = ['col1', 'col2', 'col3']"", 'df1 = df[collist]', 'collist = df.columns.tolist()', 'df1 = df[collist[0:1]]', ""collist.remove('col2')"", 'df1 = df[collist]']",['collist = df.columns.tolist()'],,
20233649,,[],[''],[],[],[]
20235451,"s = pd.Series([1,2,3,4,np.NaN,5,np.NaN])
s[~s.isnull()]
s.dropna()","['s = pd.Series([1,2,3,4,np.NaN,5,np.NaN])', 's[~s.isnull()]', 's.dropna()']","['s[~s.isnull()]', 's.dropna()']","['s[~s.isnull()]', 's.dropna()']",,
20250947,"df['col1'].update(pd.Series(di))
import pandas as pd
import numpy as np
df = pd.DataFrame({'col1':['w', 10, 20],
                   'col2': ['a', 30, np.nan]},
                  index=[1,2,0])
di = {0: ""A"", 2: ""B""}
df['col1'].update(pd.Series(di))
print(df)
import pandas as pd
import numpy as np
df = pd.DataFrame({'col1':['w', 10, 20],
                   'col2': ['a', 30, np.nan]},
                  index=[1,2,0])
print(df)
di = {10: ""A"", 20: ""B""}
df['col1'].replace(di, inplace=True)
print(df)
df['col1'].put(di.keys(), di.values())
df = pd.DataFrame({'col1':['w', 10, 20],
                   'col2': ['a', 30, np.nan]},
                  index=[1,2,0])
di = {0: ""A"", 2: ""B""}
df['col1'].put(di.keys(), di.values())
print(df)","[""df['col1'].update(pd.Series(di))"", ""df = pd.DataFrame({'col1':['w', 10, 20],"", ""df['col1'].update(pd.Series(di))"", ""df = pd.DataFrame({'col1':['w', 10, 20],"", ""df['col1'].replace(di, inplace=True)"", ""df['col1'].put(di.keys(), di.values())"", ""df = pd.DataFrame({'col1':['w', 10, 20],"", ""df['col1'].put(di.keys(), di.values())""]","['import pandas as pd', 'import numpy as np', ""                   'col2': ['a', 30, np.nan]},"", '                  index=[1,2,0])', 'di = {0: ""A"", 2: ""B""}', 'print(df)', 'import pandas as pd', 'import numpy as np', ""                   'col2': ['a', 30, np.nan]},"", '                  index=[1,2,0])', 'print(df)', 'di = {10: ""A"", 20: ""B""}', ""df['col1'].replace(di, inplace=True)"", 'print(df)', ""df['col1'].put(di.keys(), di.values())"", ""                   'col2': ['a', 30, np.nan]},"", '                  index=[1,2,0])', 'di = {0: ""A"", 2: ""B""}', ""df['col1'].put(di.keys(), di.values())"", 'print(df)']","[""df['col1'].update(pd.Series(di))"", ""df['col1'].update(pd.Series(di))"", ""df['col1'].replace(di, inplace=True)"", ""df['col1'].put(di.keys(), di.values())"", ""df['col1'].put(di.keys(), di.values())""]",,
20250996,"df = pd.DataFrame({'col2': {0: 'a', 1: 2, 2: np.nan}, 'col1': {0: 'w', 1: 1, 2: 2}})
di = {1: ""A"", 2: ""B""}
df
df.replace({""col1"": di})","[""df = pd.DataFrame({'col2': {0: 'a', 1: 2, 2: np.nan}, 'col1': {0: 'w', 1: 1, 2: 2}})"", 'df.replace({""col1"": di})']","['di = {1: ""A"", 2: ""B""}', 'df', 'df.replace({""col1"": di})']","['df.replace({""col1"": di})']",,
20297639,"import pandas as pd
df = pd.DataFrame({""pear"": [1,2,3], ""apple"": [2,3,4], ""orange"": [3,4,5]})
len(df.columns)
3","['df = pd.DataFrame({""pear"": [1,2,3], ""apple"": [2,3,4], ""orange"": [3,4,5]})']","['import pandas as pd', 'len(df.columns)', '3']",[],,
20301769,"df.drop(df.columns[i], axis=1)
df = df.iloc[:, [j for j, c in enumerate(df.columns) if j != i]]","['df.drop(df.columns[i], axis=1)', 'df = df.iloc[:, [j for j, c in enumerate(df.columns) if j != i]]']","['df.drop(df.columns[i], axis=1)', 'df = df.iloc[:, [j for j, c in enumerate(df.columns) if j != i]]']","['df.drop(df.columns[i], axis=1)', 'df = df.iloc[:, [j for j, c in enumerate(df.columns) if j != i]]']",,
20304311,df.shape[1],['df.shape[1]'],['df.shape[1]'],['df.shape[1]'],,
20312816,x.set_index('name').index.get_duplicates(),"[""x.set_index('name').index.get_duplicates()""]","[""x.set_index('name').index.get_duplicates()""]","[""x.set_index('name').index.get_duplicates()""]",,
20333894,my_df.ix[(my_df.CHUNK_NAME==chunks[0])&(my_df.LAMBDA==lam_beta[0][0])],[],['my_df.ix[(my_df.CHUNK_NAME==chunks[0])&(my_df.LAMBDA==lam_beta[0][0])]'],[],[],[]
20334902,,[],[''],[],[],[]
20341058,"pd.DataFrame(list(my_dict.iteritems()),
                      columns=['business_id','business_code'])","['pd.DataFrame(list(my_dict.iteritems()),']","[""                      columns=['business_id','business_code'])""]","['pd.DataFrame(list(my_dict.iteritems()),']",,
20375692,"pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')
pd.merge(frame_1, frame_2, how = 'left', left_on = 'county_ID', right_on = 'countyid')","[""pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')"", ""pd.merge(frame_1, frame_2, how = 'left', left_on = 'county_ID', right_on = 'countyid')""]","[""pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')"", ""pd.merge(frame_1, frame_2, how = 'left', left_on = 'county_ID', right_on = 'countyid')""]","[""pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')"", ""pd.merge(frame_1, frame_2, how = 'left', left_on = 'county_ID', right_on = 'countyid')""]",,
20384317,"type(df.loc[[3]])
type(df.loc[[1]])
Out[3]: pandas.core.frame.DataFrame","['type(df.loc[[3]])', 'type(df.loc[[1]])', 'Out[3]: pandas.core.frame.DataFrame']","['type(df.loc[[3]])', 'type(df.loc[[1]])']","['type(df.loc[[3]])', 'type(df.loc[[1]])']",,
20410720,"pd.concat([s, s.shift(), s.shift(2)], axis=1)
pd.concat([s, s.shift(), s.shift(2)], axis=1).dropna()","['pd.concat([s, s.shift(), s.shift(2)], axis=1)', 'pd.concat([s, s.shift(), s.shift(2)], axis=1).dropna()']","['pd.concat([s, s.shift(), s.shift(2)], axis=1)', 'pd.concat([s, s.shift(), s.shift(2)], axis=1).dropna()']","['pd.concat([s, s.shift(), s.shift(2)], axis=1)', 'pd.concat([s, s.shift(), s.shift(2)], axis=1).dropna()']",,
20444256,"data.reindex(index=data.index[::-1])
data.iloc[::-1]
for idx in reversed(data.index):
    print(idx, data.loc[idx, 'Even'], data.loc[idx, 'Odd'])
for idx in reversed(data.index):
    print(idx, data.Even[idx], data.Odd[idx])","['data.reindex(index=data.index[::-1])', 'data.iloc[::-1]', 'for idx in reversed(data.index):', ""    print(idx, data.loc[idx, 'Even'], data.loc[idx, 'Odd'])"", 'for idx in reversed(data.index):']","['data.reindex(index=data.index[::-1])', 'data.iloc[::-1]', 'for idx in reversed(data.index):', ""    print(idx, data.loc[idx, 'Even'], data.loc[idx, 'Odd'])"", 'for idx in reversed(data.index):', '    print(idx, data.Even[idx], data.Odd[idx])']","['data.reindex(index=data.index[::-1])', 'data.iloc[::-1]', 'for idx in reversed(data.index):', ""    print(idx, data.loc[idx, 'Even'], data.loc[idx, 'Odd'])"", 'for idx in reversed(data.index):']",,
20455090,,[],[''],[],[],[]
20459839,scipy.sparse.csr_matrix(df.values),['scipy.sparse.csr_matrix(df.values)'],['scipy.sparse.csr_matrix(df.values)'],['scipy.sparse.csr_matrix(df.values)'],,
20461206,"df['index1'] = df.index
df.reset_index(level=0, inplace=True)
df
df.reset_index(level=['tick', 'obs'])
tag                        ","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', 'df', ""df.reset_index(level=['tick', 'obs'])"", 'tag                        ']","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]"
20461929,"import numpy as np
from sklearn.manifold import MDS
from sklearn.metrics import euclidean_distances
from sklearn.datasets import make_classification
data, labels = make_classification()
mds = MDS(n_components=2)
similarities = euclidean_distances(data.astype(np.float64))
mds.fit(data.astype(np.float64))
Succeeds
similarities = euclidean_distances(data.astype(np.float32))
mds.fit(data.astype(np.float32))","['similarities = euclidean_distances(data.astype(np.float64))', 'mds.fit(data.astype(np.float64))', 'similarities = euclidean_distances(data.astype(np.float32))', 'mds.fit(data.astype(np.float32))']","['import numpy as np', 'from sklearn.manifold import MDS', 'from sklearn.metrics import euclidean_distances', 'from sklearn.datasets import make_classification', 'data, labels = make_classification()', 'mds = MDS(n_components=2)', 'similarities = euclidean_distances(data.astype(np.float64))', 'mds.fit(data.astype(np.float64))', 'Succeeds', 'similarities = euclidean_distances(data.astype(np.float32))', 'mds.fit(data.astype(np.float32))']","['similarities = euclidean_distances(data.astype(np.float64))', 'mds.fit(data.astype(np.float64))', 'similarities = euclidean_distances(data.astype(np.float32))', 'mds.fit(data.astype(np.float32))']",,
20481080,"pd.DatetimeIndex(montdist['date']) + pd.DateOffset(1)
df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])
df['date'] = pd.to_datetime(['21-11-2013', '22-11-2013'])
pd.DatetimeIndex(df.date) + pd.DateOffset(1)
pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)","[""df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])"", ""df['date'] = pd.to_datetime(['21-11-2013', '22-11-2013'])"", 'pd.DatetimeIndex(df.date) + pd.DateOffset(1)', 'pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)']","[""pd.DatetimeIndex(montdist['date']) + pd.DateOffset(1)"", ""df['date'] = pd.to_datetime(['21-11-2013', '22-11-2013'])"", 'pd.DatetimeIndex(df.date) + pd.DateOffset(1)', 'pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)']","[""df['date'] = pd.to_datetime(['21-11-2013', '22-11-2013'])"", 'pd.DatetimeIndex(df.date) + pd.DateOffset(1)', 'pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)']",,
20491748,df = df.reset_index(drop=True),['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)']
20496583,mondist['shifted_date']=mondist.date + datetime.timedelta(days=1),"[""mondist['shifted_date']=mondist.date + datetime.timedelta(days=1)""]","[""mondist['shifted_date']=mondist.date + datetime.timedelta(days=1)""]","[""mondist['shifted_date']=mondist.date + datetime.timedelta(days=1)""]",,
20523271,"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from itertools import product
from string import ascii_uppercase
from matplotlib import patheffects
m, n = 4, 7 
df = pd.DataFrame(np.random.randn(m, n),
                  columns=list(ascii_uppercase[:n]),
                  index=list(ascii_uppercase[-m:]))
ax = plt.imshow(df, interpolation='nearest', cmap='Oranges').axes
_ = ax.set_xticks(np.linspace(0, n-1, n))
_ = ax.set_xticklabels(df.columns)
_ = ax.set_yticks(np.linspace(0, m-1, m))
_ = ax.set_yticklabels(df.index)
ax.grid('off')
ax.xaxis.tick_top()
path_effects = [patheffects.withSimplePatchShadow(shadow_rgbFace=(1,1,1))]
for i, j in product(range(m), range(n)):
    _ = ax.text(j, i, '{0:.2f}'.format(df.iloc[i, j]),
                size='medium', ha='center', va='center',
                path_effects=path_effects)","['df = pd.DataFrame(np.random.randn(m, n),', ""ax = plt.imshow(df, interpolation='nearest', cmap='Oranges').axes"", '_ = ax.set_yticklabels(df.index)', ""    _ = ax.text(j, i, '{0:.2f}'.format(df.iloc[i, j]),""]","['import numpy as np', 'import pandas as pd', 'import matplotlib.pyplot as plt', 'from itertools import product', 'from string import ascii_uppercase', 'from matplotlib import patheffects', 'm, n = 4, 7 ', '                  columns=list(ascii_uppercase[:n]),', '                  index=list(ascii_uppercase[-m:]))', ""ax = plt.imshow(df, interpolation='nearest', cmap='Oranges').axes"", '_ = ax.set_xticks(np.linspace(0, n-1, n))', '_ = ax.set_xticklabels(df.columns)', '_ = ax.set_yticks(np.linspace(0, m-1, m))', '_ = ax.set_yticklabels(df.index)', ""ax.grid('off')"", 'ax.xaxis.tick_top()', 'path_effects = [patheffects.withSimplePatchShadow(shadow_rgbFace=(1,1,1))]', 'for i, j in product(range(m), range(n)):', ""    _ = ax.text(j, i, '{0:.2f}'.format(df.iloc[i, j]),"", ""                size='medium', ha='center', va='center',"", '                path_effects=path_effects)']","[""ax = plt.imshow(df, interpolation='nearest', cmap='Oranges').axes"", '_ = ax.set_yticklabels(df.index)', ""    _ = ax.text(j, i, '{0:.2f}'.format(df.iloc[i, j]),""]",,
20557179,,[],[''],[],[],[]
20566408,[list(x) for x in dt.T.itertuples()],['[list(x) for x in dt.T.itertuples()]'],['[list(x) for x in dt.T.itertuples()]'],['[list(x) for x in dt.T.itertuples()]'],,
20574460,"df_asint = df.astype(int)
coocc = df_asint.T.dot(df_asint)
coocc
import numpy as np
np.fill_diagonal(coocc.values, 0)
coocc","['df_asint = df.astype(int)', 'coocc = df_asint.T.dot(df_asint)', 'np.fill_diagonal(coocc.values, 0)']","['df_asint = df.astype(int)', 'coocc = df_asint.T.dot(df_asint)', 'coocc', 'import numpy as np', 'np.fill_diagonal(coocc.values, 0)', 'coocc']","['df_asint = df.astype(int)', 'coocc = df_asint.T.dot(df_asint)', 'np.fill_diagonal(coocc.values, 0)']",,
20603020,"dat1 = pd.DataFrame({'dat1': [9,5]})
dat2 = pd.DataFrame({'dat2': [7,6]})
dat1.join(dat2)","[""dat1 = pd.DataFrame({'dat1': [9,5]})"", ""dat2 = pd.DataFrame({'dat2': [7,6]})"", 'dat1.join(dat2)']",['dat1.join(dat2)'],['dat1.join(dat2)'],,
20612691,"import pandas as pd
pd.__version__
pd.show_versions(as_json=False)
commit: None
OS: Linux
machine: x86_64
processor: x86_64
byteorder: little
LC_ALL: None
LANG: en_US.UTF-8
dateutil: 1.5
bottleneck: None
openpyxl: None
xlsxwriter: None
html5lib: 0.999
httplib2: 0.8
apiclient: None
pymysql: None",[],"['import pandas as pd', 'pd.__version__', 'pd.show_versions(as_json=False)', 'commit: None', 'OS: Linux', 'machine: x86_64', 'processor: x86_64', 'byteorder: little', 'LC_ALL: None', 'LANG: en_US.UTF-8', 'dateutil: 1.5', 'bottleneck: None', 'openpyxl: None', 'xlsxwriter: None', 'html5lib: 0.999', 'httplib2: 0.8', 'apiclient: None', 'pymysql: None']",[],[],[]
20619971,"import pandas as pd
x = pd.DataFrame({'cat':('A','A','B'), 'val':(10,20,30)})
labels, levels = pd.factorize(x['cat'])
x['cat'] = labels
x = x.set_index('cat')
print(x)
cat     
x['cat'] = labels+1","[""x = pd.DataFrame({'cat':('A','A','B'), 'val':(10,20,30)})"", ""labels, levels = pd.factorize(x['cat'])"", ""x = x.set_index('cat')""]","['import pandas as pd', ""labels, levels = pd.factorize(x['cat'])"", ""x['cat'] = labels"", ""x = x.set_index('cat')"", 'print(x)', 'cat     ', ""x['cat'] = labels+1""]","[""labels, levels = pd.factorize(x['cat'])"", ""x = x.set_index('cat')""]",,
20627316,"df[df['A'] > 2]['B'] = new_val  
df.loc[df['A'] > 2, 'B'] = new_val
df = df[df['A'] > 2]
df['B'] = new_val
pd.options.mode.chained_assignment = None  ","[""df.loc[df['A'] > 2, 'B'] = new_val"", 'pd.options.mode.chained_assignment = None  ']","[""df[df['A'] > 2]['B'] = new_val  "", ""df.loc[df['A'] > 2, 'B'] = new_val"", ""df = df[df['A'] > 2]"", ""df['B'] = new_val"", 'pd.options.mode.chained_assignment = None  ']","[""df.loc[df['A'] > 2, 'B'] = new_val"", 'pd.options.mode.chained_assignment = None  ']",,
20637559,"import pandas as pd
from StringIO import StringIO
s = """"""1, 2
3, 4
5, 6""""""
pd.read_csv(StringIO(s), skiprows=[1], header=None)
pd.read_csv(StringIO(s), skiprows=1, header=None)","['pd.read_csv(StringIO(s), skiprows=[1], header=None)', 'pd.read_csv(StringIO(s), skiprows=1, header=None)']","['import pandas as pd', 'from StringIO import StringIO', 's = """"""1, 2', '3, 4', '5, 6""""""', 'pd.read_csv(StringIO(s), skiprows=[1], header=None)', 'pd.read_csv(StringIO(s), skiprows=1, header=None)']","['pd.read_csv(StringIO(s), skiprows=[1], header=None)', 'pd.read_csv(StringIO(s), skiprows=1, header=None)']",,
20638258,pd.DataFrame(d),['pd.DataFrame(d)'],[],[],,
20639234,"com.convert_robj(rdf)
dfrm
rdfrm = com.convert_to_r_dataframe(dfrm)
rdfrm
com.convert_robj(rdfrm)
Type:       function
Definition: com.convert_robj(obj, use_pandas=True)
Parameters
Returns",[],"['com.convert_robj(rdf)', 'dfrm', 'rdfrm = com.convert_to_r_dataframe(dfrm)', 'rdfrm', 'com.convert_robj(rdfrm)', 'Type:       function', 'Definition: com.convert_robj(obj, use_pandas=True)', 'Parameters', 'Returns']",[],[],[]
20644369,"df = DataFrame(np.random.randn(5,2),columns=list('AB'))
dfa = df.ix[:,[1,0]]
dfa.is_copy
dfa['A'] /= 2
dfa.is_copy = False
dfa['A'] /= 2
dfa = df.ix[:,[1,0]].copy()
dfa['A'] /= 2","['dfa = df.ix[:,[1,0]].copy()']","[""df = DataFrame(np.random.randn(5,2),columns=list('AB'))"", 'dfa = df.ix[:,[1,0]]', 'dfa.is_copy', ""dfa['A'] /= 2"", 'dfa.is_copy = False', ""dfa['A'] /= 2"", 'dfa = df.ix[:,[1,0]].copy()', ""dfa['A'] /= 2""]","['dfa = df.ix[:,[1,0]].copy()']",,
20644575,"import pandas as pd
df = pd.DataFrame([[1,2],[3,4]], columns=list('ab'))
df
df['c'] = df['b']**2
df","[""df = pd.DataFrame([[1,2],[3,4]], columns=list('ab'))""]","['import pandas as pd', 'df', ""df['c'] = df['b']**2"", 'df']",[],,
20648462,"df.sort(['ticker', 'date'], inplace=True)
df['diffs'] = df['value'].diff()
mask = df.ticker != df.ticker.shift(1)
df['diffs'][mask] = np.nan
df.filter(['ticker', 'date', 'value'])
df.set_index(['ticker','date'], inplace=True)
df.sort_index(inplace=True)
df['diffs'] = np.nan 
for idx in df.index.levels[0]:
    df.diffs[idx] = df.value[idx].diff()","[""df['diffs'] = df['value'].diff()"", 'mask = df.ticker != df.ticker.shift(1)', ""df.filter(['ticker', 'date', 'value'])"", ""df.set_index(['ticker','date'], inplace=True)"", 'df.sort_index(inplace=True)', 'for idx in df.index.levels[0]:', '    df.diffs[idx] = df.value[idx].diff()']","[""df.sort(['ticker', 'date'], inplace=True)"", ""df['diffs'] = df['value'].diff()"", 'mask = df.ticker != df.ticker.shift(1)', ""df['diffs'][mask] = np.nan"", ""df.filter(['ticker', 'date', 'value'])"", ""df.set_index(['ticker','date'], inplace=True)"", 'df.sort_index(inplace=True)', ""df['diffs'] = np.nan "", 'for idx in df.index.levels[0]:', '    df.diffs[idx] = df.value[idx].diff()']","[""df['diffs'] = df['value'].diff()"", 'mask = df.ticker != df.ticker.shift(1)', ""df.filter(['ticker', 'date', 'value'])"", ""df.set_index(['ticker','date'], inplace=True)"", 'df.sort_index(inplace=True)', 'for idx in df.index.levels[0]:', '    df.diffs[idx] = df.value[idx].diff()']",,
20657592,"s = pd.Series([1,2,3,2,2,3,5,2,3,2,np.nan])
fig, ax = plt.subplots()
ax.hist(s, alpha=0.9, color='blue')
ax.hist(s.dropna(), alpha=0.9, color='blue')
dfj2_MARKET1['VSPD1_perc'].hist(ax=axes[0], alpha=0.9, color='blue')","['s = pd.Series([1,2,3,2,2,3,5,2,3,2,np.nan])', ""ax.hist(s.dropna(), alpha=0.9, color='blue')""]","['fig, ax = plt.subplots()', ""ax.hist(s, alpha=0.9, color='blue')"", ""ax.hist(s.dropna(), alpha=0.9, color='blue')"", ""dfj2_MARKET1['VSPD1_perc'].hist(ax=axes[0], alpha=0.9, color='blue')""]","[""ax.hist(s.dropna(), alpha=0.9, color='blue')""]",,
20670901,"df = pd.read_json(s)
df
df.dtypes
df.apply(lambda x: pd.lib.infer_dtype(x.values))
types = df.apply(lambda x: pd.lib.infer_dtype(x.values))
types[types=='unicode']","['df = pd.read_json(s)', 'df.dtypes', 'df.apply(lambda x: pd.lib.infer_dtype(x.values))', 'types = df.apply(lambda x: pd.lib.infer_dtype(x.values))']","['df = pd.read_json(s)', 'df', 'df.dtypes', 'df.apply(lambda x: pd.lib.infer_dtype(x.values))', 'types = df.apply(lambda x: pd.lib.infer_dtype(x.values))', ""types[types=='unicode']""]","['df = pd.read_json(s)', 'df.dtypes', 'df.apply(lambda x: pd.lib.infer_dtype(x.values))', 'types = df.apply(lambda x: pd.lib.infer_dtype(x.values))']",,
20671047,"data3['diffs'] = data3.groupby('ticker')['value'].transform(Series.diff)
data3.sort_index(inplace=True)
data3","[""data3['diffs'] = data3.groupby('ticker')['value'].transform(Series.diff)"", 'data3.sort_index(inplace=True)']","[""data3['diffs'] = data3.groupby('ticker')['value'].transform(Series.diff)"", 'data3.sort_index(inplace=True)', 'data3']","[""data3['diffs'] = data3.groupby('ticker')['value'].transform(Series.diff)"", 'data3.sort_index(inplace=True)']",,
20687887,,[],[''],[],[],[]
20687984,"similarity = numpy.dot(A, A.T)
square_mag = numpy.diag(similarity)
inv_square_mag = 1 / square_mag
inv_square_mag[numpy.isinf(inv_square_mag)] = 0
inv_mag = numpy.sqrt(inv_square_mag)
cosine = similarity * inv_mag
cosine = cosine.T * inv_mag","['similarity = numpy.dot(A, A.T)', 'cosine = cosine.T * inv_mag']","['similarity = numpy.dot(A, A.T)', 'square_mag = numpy.diag(similarity)', 'inv_square_mag = 1 / square_mag', 'inv_square_mag[numpy.isinf(inv_square_mag)] = 0', 'inv_mag = numpy.sqrt(inv_square_mag)', 'cosine = similarity * inv_mag', 'cosine = cosine.T * inv_mag']","['similarity = numpy.dot(A, A.T)', 'cosine = cosine.T * inv_mag']",,
20690383,,[],[''],[],[],[]
20693013,,[],[''],[],[],[]
20701559,"X = sm.add_constant(X)
sm.OLS(y,X)",[],"['X = sm.add_constant(X)', 'sm.OLS(y,X)']",[],[],[]
20739897,"np.diff(index)/np.timedelta64(1, 's')
array([ 3.6139351 ,  3.39279693,  1.87199821])
np.diff(index)/np.timedelta64(1, 'm')
array([ 0.06023225,  0.05654662,  0.03119997])","[""np.diff(index)/np.timedelta64(1, 's')"", ""np.diff(index)/np.timedelta64(1, 'm')""]","[""np.diff(index)/np.timedelta64(1, 's')"", 'array([ 3.6139351 ,  3.39279693,  1.87199821])', ""np.diff(index)/np.timedelta64(1, 'm')"", 'array([ 0.06023225,  0.05654662,  0.03119997])']","[""np.diff(index)/np.timedelta64(1, 's')"", ""np.diff(index)/np.timedelta64(1, 'm')""]",,
20763459,,[],[''],[],[],[]
20808449,"from rpy2.robjects import pandas2ri
pandas2ri.activate()",[],"['from rpy2.robjects import pandas2ri', 'pandas2ri.activate()']",[],[],[]
20842283,"DataFrame(...).ix[row_indexer,column_indexer]
Series(...).ix[row_indexer]",[],"['DataFrame(...).ix[row_indexer,column_indexer]', 'Series(...).ix[row_indexer]']",[],[],[]
20868446,"df=df.rename(columns = {'two':'new_name'})
df
Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)
Parameters
Series.rename
Returns","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'df', 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Parameters', 'Series.rename', 'Returns']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']"
20869270,,[],[''],[],[],[]
20870801,,[],[''],[],[],[]
20937592,"import pandas as pd
pd.options.display.float_format = '${:,.2f}'.format
df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],
                  index=['foo','bar','baz','quux'],
                  columns=['cost'])
print(df)
import pandas as pd
df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],
                  index=['foo','bar','baz','quux'],
                  columns=['cost'])
df['foo'] = df['cost']
df['cost'] = df['cost'].map('${:,.2f}'.format)
print(df)","[""pd.options.display.float_format = '${:,.2f}'.format"", 'df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', 'df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', ""df['cost'] = df['cost'].map('${:,.2f}'.format)""]","['import pandas as pd', ""pd.options.display.float_format = '${:,.2f}'.format"", ""                  index=['foo','bar','baz','quux'],"", ""                  columns=['cost'])"", 'print(df)', 'import pandas as pd', ""                  index=['foo','bar','baz','quux'],"", ""                  columns=['cost'])"", ""df['foo'] = df['cost']"", ""df['cost'] = df['cost'].map('${:,.2f}'.format)"", 'print(df)']","[""pd.options.display.float_format = '${:,.2f}'.format"", ""df['cost'] = df['cost'].map('${:,.2f}'.format)""]",,
20965090,"df['cum_sum'] = df.val1.cumsum()
df['cum_perc'] = 100*df.cum_sum/df.val1.sum()","[""df['cum_sum'] = df.val1.cumsum()"", ""df['cum_perc'] = 100*df.cum_sum/df.val1.sum()""]","[""df['cum_sum'] = df.val1.cumsum()"", ""df['cum_perc'] = 100*df.cum_sum/df.val1.sum()""]","[""df['cum_sum'] = df.val1.cumsum()"", ""df['cum_perc'] = 100*df.cum_sum/df.val1.sum()""]",,
20970328,"df['StateInitial'] = df['state'].str[:2]
df
df['state'].apply(lambda x: x[len(x)/2-1:len(x)/2+1])","[""df['state'].apply(lambda x: x[len(x)/2-1:len(x)/2+1])""]","[""df['StateInitial'] = df['state'].str[:2]"", 'df', ""df['state'].apply(lambda x: x[len(x)/2-1:len(x)/2+1])""]","[""df['state'].apply(lambda x: x[len(x)/2-1:len(x)/2+1])""]",,
20995313,"df = pd.DataFrame({""class"":[1,1,1,2,2], ""value"":[1,2,3,4,5]})
df[df[""class""]==1].sum()
dtype: int64
df[df[""class""]==1].sum()[""value""]
6
df[df[""class""]==1].count()[""value""]
3","['df = pd.DataFrame({""class"":[1,1,1,2,2], ""value"":[1,2,3,4,5]})', 'df[df[""class""]==1].sum()', 'df[df[""class""]==1].sum()[""value""]', 'df[df[""class""]==1].count()[""value""]']","['df[df[""class""]==1].sum()', 'dtype: int64', 'df[df[""class""]==1].sum()[""value""]', '6', 'df[df[""class""]==1].count()[""value""]', '3']","['df[df[""class""]==1].sum()', 'df[df[""class""]==1].sum()[""value""]', 'df[df[""class""]==1].count()[""value""]']",,
20995428,"df = pd.DataFrame({'a': [1, 2, 3]})
df[df.a > 1].sum()   
dtype: int64
df[(df.a > 1) & (df.a < 3)].sum()
dtype: int64","[""df = pd.DataFrame({'a': [1, 2, 3]})"", 'df[df.a > 1].sum()   ', 'df[(df.a > 1) & (df.a < 3)].sum()']","['df[df.a > 1].sum()   ', 'dtype: int64', 'df[(df.a > 1) & (df.a < 3)].sum()', 'dtype: int64']","['df[df.a > 1].sum()   ', 'df[(df.a > 1) & (df.a < 3)].sum()']",,
21000675,"def assertFrameEqual(df1, df2, **kwds ):
    """""" Assert that two dataframes are equal, ignoring ordering of columns""""""
    from pandas.util.testing import assert_frame_equal
    return assert_frame_equal(df1.sort(axis=1), df2.sort(axis=1), check_names=True, **kwds )",[],"['def assertFrameEqual(df1, df2, **kwds ):', '    """""" Assert that two dataframes are equal, ignoring ordering of columns""""""', '    from pandas.util.testing import assert_frame_equal', '    return assert_frame_equal(df1.sort(axis=1), df2.sort(axis=1), check_names=True, **kwds )']",[],[],[]
21007047,"sorted = df.sort_index(by='data_date')
result = sorted.drop_duplicates('obj_id', take_last=True).values","[""sorted = df.sort_index(by='data_date')"", ""result = sorted.drop_duplicates('obj_id', take_last=True).values""]","[""sorted = df.sort_index(by='data_date')"", ""result = sorted.drop_duplicates('obj_id', take_last=True).values""]","[""sorted = df.sort_index(by='data_date')"", ""result = sorted.drop_duplicates('obj_id', take_last=True).values""]",,
21020411,,[],[''],[],[],[]
21023125,"pd.DataFrame(df.values*df2.values, columns=df.columns, index=df.index)","['pd.DataFrame(df.values*df2.values, columns=df.columns, index=df.index)']",[],"['pd.DataFrame(df.values*df2.values, columns=df.columns, index=df.index)']",,
21032532,"df = pd.DataFrame(['a b c']*100000, columns=['col']);
from scipy import array, concatenate;
df = pd.DataFrame(['a b c']*100000, columns=['col']);
df = pd.DataFrame(['a b c']*100000, columns=['col']);
df = pd.DataFrame(['a b c']*100000, columns=['col']);
df = pd.DataFrame(['a b c']*100000, columns=['col']);","[""df = pd.DataFrame(['a b c']*100000, columns=['col']);"", ""df = pd.DataFrame(['a b c']*100000, columns=['col']);"", ""df = pd.DataFrame(['a b c']*100000, columns=['col']);"", ""df = pd.DataFrame(['a b c']*100000, columns=['col']);"", ""df = pd.DataFrame(['a b c']*100000, columns=['col']);""]","['from scipy import array, concatenate;']",[],,
21033789,"import numpy as np
import matplotlib.pyplot as plt
import pandas
series = pandas.Series(np.random.normal(size=2000))
fig, ax = plt.subplots()
series.hist(ax=ax, bins=100, bottom=0.1)
ax.set_yscale('log')",['series = pandas.Series(np.random.normal(size=2000))'],"['import numpy as np', 'import matplotlib.pyplot as plt', 'import pandas', 'fig, ax = plt.subplots()', 'series.hist(ax=ax, bins=100, bottom=0.1)', ""ax.set_yscale('log')""]",[],,
21055161,"df['A'].str.contains(r'^(?:(?!Hello|World).)*$')
df = pd.DataFrame({""A"": [""Hello"", ""this"", ""World"", ""apple""]})
df['A'].str.contains(r'^(?:(?!Hello|World).)*$')
df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')]","[""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", 'df = pd.DataFrame({""A"": [""Hello"", ""this"", ""World"", ""apple""]})', ""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", ""df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')]""]","[""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", ""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", ""df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')]""]","[""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", ""df['A'].str.contains(r'^(?:(?!Hello|World).)*$')"", ""df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')]""]",,
21055176,"df = pd.DataFrame({""A"": [""Hello"", ""this"", ""World"", ""apple""]})
df.A.str.contains(""Hello|World"")
df[~df.A.str.contains(""Hello|World"")]","['df = pd.DataFrame({""A"": [""Hello"", ""this"", ""World"", ""apple""]})', 'df.A.str.contains(""Hello|World"")', 'df[~df.A.str.contains(""Hello|World"")]']","['df.A.str.contains(""Hello|World"")', 'df[~df.A.str.contains(""Hello|World"")]']","['df.A.str.contains(""Hello|World"")', 'df[~df.A.str.contains(""Hello|World"")]']",,
21059308,"def rolling_max_dd(x, window_size, min_periods=1):
    """"""Compute the rolling maximum drawdown of `x`.
    `x` must be a 1d numpy array.
    `min_periods` should satisfy `1 <= min_periods <= window_size`.
    Returns an 1d array with length `len(x) - min_periods + 1`.
    """"""
    if min_periods < window_size:
        pad = np.empty(window_size - min_periods)
        pad.fill(x[0])
        x = np.concatenate((pad, x))
    y = windowed_view(x, window_size)
    running_max_y = np.maximum.accumulate(y, axis=1)
    dd = y - running_max_y
    return dd.min(axis=1)
import numpy as np
from numpy.lib.stride_tricks import as_strided
import pandas as pd
import matplotlib.pyplot as plt
def windowed_view(x, window_size):
    """"""Creat a 2d windowed view of a 1d array.
    `x` must be a 1d numpy array.
    `numpy.lib.stride_tricks.as_strided` is used to create the view.
    The data is not copied.
    Example:
    >>> x = np.array([1, 2, 3, 4, 5, 6])
    >>> windowed_view(x, 3)
    array([[1, 2, 3],
           [2, 3, 4],
           [3, 4, 5],
           [4, 5, 6]])
    """"""
    y = as_strided(x, shape=(x.size - window_size + 1, window_size),
                   strides=(x.strides[0], x.strides[0]))
    return y
def rolling_max_dd(x, window_size, min_periods=1):
    """"""Compute the rolling maximum drawdown of `x`.
    `x` must be a 1d numpy array.
    `min_periods` should satisfy `1 <= min_periods <= window_size`.
    Returns an 1d array with length `len(x) - min_periods + 1`.
    """"""
    if min_periods < window_size:
        pad = np.empty(window_size - min_periods)
        pad.fill(x[0])
        x = np.concatenate((pad, x))
    y = windowed_view(x, window_size)
    running_max_y = np.maximum.accumulate(y, axis=1)
    dd = y - running_max_y
    return dd.min(axis=1)
def max_dd(ser):
    max2here = pd.expanding_max(ser)
    dd2here = ser - max2here
    return dd2here.min()
if __name__ == ""__main__"":
    np.random.seed(0)
    n = 100
    s = pd.Series(np.random.randn(n).cumsum())
    window_length = 10
    rolling_dd = pd.rolling_apply(s, window_length, max_dd, min_periods=0)
    df = pd.concat([s, rolling_dd], axis=1)
    df.columns = ['s', 'rol_dd_%d' % window_length]
    df.plot(linewidth=3, alpha=0.4)
    my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)
    plt.plot(my_rmdd, 'g.')
    plt.show()","['        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '    y = as_strided(x, shape=(x.size - window_size + 1, window_size),', '                   strides=(x.strides[0], x.strides[0]))', '        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '    return dd2here.min()', '    s = pd.Series(np.random.randn(n).cumsum())', '    df = pd.concat([s, rolling_dd], axis=1)', '    df.plot(linewidth=3, alpha=0.4)', '    my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)', ""    plt.plot(my_rmdd, 'g.')""]","['def rolling_max_dd(x, window_size, min_periods=1):', '    """"""Compute the rolling maximum drawdown of `x`.', '    `x` must be a 1d numpy array.', '    `min_periods` should satisfy `1 <= min_periods <= window_size`.', '    Returns an 1d array with length `len(x) - min_periods + 1`.', '    """"""', '    if min_periods < window_size:', '        pad = np.empty(window_size - min_periods)', '        pad.fill(x[0])', '        x = np.concatenate((pad, x))', '    y = windowed_view(x, window_size)', '    running_max_y = np.maximum.accumulate(y, axis=1)', '    dd = y - running_max_y', '    return dd.min(axis=1)', 'import numpy as np', 'from numpy.lib.stride_tricks import as_strided', 'import pandas as pd', 'import matplotlib.pyplot as plt', 'def windowed_view(x, window_size):', '    """"""Creat a 2d windowed view of a 1d array.', '    `x` must be a 1d numpy array.', '    `numpy.lib.stride_tricks.as_strided` is used to create the view.', '    The data is not copied.', '    Example:', '    >>> x = np.array([1, 2, 3, 4, 5, 6])', '    >>> windowed_view(x, 3)', '    array([[1, 2, 3],', '           [2, 3, 4],', '           [3, 4, 5],', '           [4, 5, 6]])', '    """"""', '    y = as_strided(x, shape=(x.size - window_size + 1, window_size),', '                   strides=(x.strides[0], x.strides[0]))', '    return y', 'def rolling_max_dd(x, window_size, min_periods=1):', '    """"""Compute the rolling maximum drawdown of `x`.', '    `x` must be a 1d numpy array.', '    `min_periods` should satisfy `1 <= min_periods <= window_size`.', '    Returns an 1d array with length `len(x) - min_periods + 1`.', '    """"""', '    if min_periods < window_size:', '        pad = np.empty(window_size - min_periods)', '        pad.fill(x[0])', '        x = np.concatenate((pad, x))', '    y = windowed_view(x, window_size)', '    running_max_y = np.maximum.accumulate(y, axis=1)', '    dd = y - running_max_y', '    return dd.min(axis=1)', 'def max_dd(ser):', '    max2here = pd.expanding_max(ser)', '    dd2here = ser - max2here', '    return dd2here.min()', 'if __name__ == ""__main__"":', '    np.random.seed(0)', '    n = 100', '    window_length = 10', '    rolling_dd = pd.rolling_apply(s, window_length, max_dd, min_periods=0)', '    df = pd.concat([s, rolling_dd], axis=1)', ""    df.columns = ['s', 'rol_dd_%d' % window_length]"", '    df.plot(linewidth=3, alpha=0.4)', '    my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)', ""    plt.plot(my_rmdd, 'g.')"", '    plt.show()']","['        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '    y = as_strided(x, shape=(x.size - window_size + 1, window_size),', '                   strides=(x.strides[0], x.strides[0]))', '        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '    return dd2here.min()', '    s = pd.Series(np.random.randn(n).cumsum())', '    df = pd.concat([s, rolling_dd], axis=1)', '    df.plot(linewidth=3, alpha=0.4)', '    my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)', ""    plt.plot(my_rmdd, 'g.')""]",,
21140339,"pd.set_option('display.float_format', lambda x: '%.3f' % x)
Series(np.random.randn(3))*1000000000
Series(np.random.randn(3)).apply(lambda x: '%.3f' % x)
1    -0.482
2    -0.694
dtype: object","[""pd.set_option('display.float_format', lambda x: '%.3f' % x)"", ""Series(np.random.randn(3)).apply(lambda x: '%.3f' % x)""]","[""pd.set_option('display.float_format', lambda x: '%.3f' % x)"", 'Series(np.random.randn(3))*1000000000', ""Series(np.random.randn(3)).apply(lambda x: '%.3f' % x)"", '1    -0.482', '2    -0.694', 'dtype: object']","[""pd.set_option('display.float_format', lambda x: '%.3f' % x)"", ""Series(np.random.randn(3)).apply(lambda x: '%.3f' % x)""]",,
21165116,"df.loc[:, (df != 0).any(axis=0)]
import pandas as pd
df = pd.DataFrame([[1,0,0,0], [0,0,1,0]])
df
df != 0
(df != 0).any(axis=0)
df.loc[:, (df != 0).any(axis=0)]
df = df.loc[:, (df != 0).any(axis=0)]","['df.loc[:, (df != 0).any(axis=0)]', 'df = pd.DataFrame([[1,0,0,0], [0,0,1,0]])', '(df != 0).any(axis=0)', 'df.loc[:, (df != 0).any(axis=0)]', 'df = df.loc[:, (df != 0).any(axis=0)]']","['df.loc[:, (df != 0).any(axis=0)]', 'import pandas as pd', 'df', 'df != 0', '(df != 0).any(axis=0)', 'df.loc[:, (df != 0).any(axis=0)]', 'df = df.loc[:, (df != 0).any(axis=0)]']","['df.loc[:, (df != 0).any(axis=0)]', '(df != 0).any(axis=0)', 'df.loc[:, (df != 0).any(axis=0)]', 'df = df.loc[:, (df != 0).any(axis=0)]']",,
21175114,"s1 = pd.Series([4,5,6,20,42])
s2 = pd.Series([1,2,3,5,42])
pd.Series(list(set(s1).intersection(set(s2))))
pd.Series(np.intersect1d(s1,s2))
pd.Series(np.intersect1d(s1.values,s2.values))","['s1 = pd.Series([4,5,6,20,42])', 's2 = pd.Series([1,2,3,5,42])', 'pd.Series(list(set(s1).intersection(set(s2))))', 'pd.Series(np.intersect1d(s1,s2))', 'pd.Series(np.intersect1d(s1.values,s2.values))']",[],"['pd.Series(list(set(s1).intersection(set(s2))))', 'pd.Series(np.intersect1d(s1.values,s2.values))']",,
21189441,"def rollBy(what,basis,window,func,*args,**kwargs):
    indexed_what = pd.Series(what.values,index=basis.values)
    def applyToWindow(val):
        indexer = indexed_what.index.slice_indexer(val,val+window,1)
        chunk = indexed_what[indexer]
        return func(chunk,*args,**kwargs)
    rolled = basis.apply(applyToWindow)
    return rolled
df = pd.DataFrame({""RollBasis"":np.random.uniform(0,1000000,100000), ""ToRoll"": np.random.uniform(0,10,100000)})
df = df.sort(""RollBasis"")
timeit(""rollBy_Ian(df.ToRoll,df.RollBasis,10,sum)"",setup=""from __main__ import rollBy_Ian,df"", number =3)
timeit(""rollBy_Bren(df.ToRoll,df.RollBasis,10,sum)"",setup=""from __main__ import rollBy_Bren,df"", number =3)
Out[49]: 515.0221037864685
def rollBy(what,basis,window,func,*args,**kwargs):
    windows_min = basis.min()
    windows_max = basis.max()
    window_starts = np.arange(windows_min, windows_max, window)
    window_starts = pd.Series(window_starts, index = window_starts)
    indexed_what = pd.Series(what.values,index=basis.values)
    def applyToWindow(val):
        indexer = indexed_what.index.slice_indexer(val,val+window,1)
        chunk = indexed_what[indexer]
        return func(chunk,*args,**kwargs)
    rolled = window_starts.apply(applyToWindow)
    return rolled","['    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = basis.apply(applyToWindow)', 'df = pd.DataFrame({""RollBasis"":np.random.uniform(0,1000000,100000), ""ToRoll"": np.random.uniform(0,10,100000)})', '    windows_min = basis.min()', '    windows_max = basis.max()', '    window_starts = pd.Series(window_starts, index = window_starts)', '    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = window_starts.apply(applyToWindow)']","['def rollBy(what,basis,window,func,*args,**kwargs):', '    def applyToWindow(val):', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '        chunk = indexed_what[indexer]', '        return func(chunk,*args,**kwargs)', '    rolled = basis.apply(applyToWindow)', '    return rolled', 'df = df.sort(""RollBasis"")', 'timeit(""rollBy_Ian(df.ToRoll,df.RollBasis,10,sum)"",setup=""from __main__ import rollBy_Ian,df"", number =3)', 'timeit(""rollBy_Bren(df.ToRoll,df.RollBasis,10,sum)"",setup=""from __main__ import rollBy_Bren,df"", number =3)', 'Out[49]: 515.0221037864685', 'def rollBy(what,basis,window,func,*args,**kwargs):', '    windows_min = basis.min()', '    windows_max = basis.max()', '    window_starts = np.arange(windows_min, windows_max, window)', '    def applyToWindow(val):', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '        chunk = indexed_what[indexer]', '        return func(chunk,*args,**kwargs)', '    rolled = window_starts.apply(applyToWindow)', '    return rolled']","['    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = basis.apply(applyToWindow)', '    windows_min = basis.min()', '    windows_max = basis.max()', '    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = window_starts.apply(applyToWindow)']",,
21197863,"df
df.dtypes
df.convert_objects(convert_numeric=True)
df.convert_objects(convert_numeric=True).dtypes
dtype: object","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","['df', 'df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes', 'dtype: object']","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']",,
21204417,"import pandas as pd
import numpy as np
np.random.seed(0)
base = np.array([""2013-01-01 00:00:00""], ""datetime64[ns]"")
a = (np.random.rand(30)*1000000*1000).astype(np.int64)*1000000
t1 = base + a
t1.sort()
b = (np.random.rand(10)*1000000*1000).astype(np.int64)*1000000
t2 = base + b
t2.sort()
idx = np.searchsorted(t1, t2) - 1
mask = idx >= 0
df = pd.DataFrame({""t1"":t1[idx][mask], ""t2"":t2[mask]})
import pylab as pl
pl.figure(figsize=(18, 4))
pl.vlines(pd.Series(t1), 0, 1, colors=""g"", lw=1)
pl.vlines(df.t1, 0.3, 0.7, colors=""r"", lw=2)
pl.vlines(df.t2, 0.3, 0.7, colors=""b"", lw=2)
pl.margins(0.02)","['a = (np.random.rand(30)*1000000*1000).astype(np.int64)*1000000', 'b = (np.random.rand(10)*1000000*1000).astype(np.int64)*1000000', 'idx = np.searchsorted(t1, t2) - 1', 'df = pd.DataFrame({""t1"":t1[idx][mask], ""t2"":t2[mask]})', 'pl.vlines(pd.Series(t1), 0, 1, colors=""g"", lw=1)']","['import pandas as pd', 'import numpy as np', 'np.random.seed(0)', 'base = np.array([""2013-01-01 00:00:00""], ""datetime64[ns]"")', 'a = (np.random.rand(30)*1000000*1000).astype(np.int64)*1000000', 't1 = base + a', 't1.sort()', 'b = (np.random.rand(10)*1000000*1000).astype(np.int64)*1000000', 't2 = base + b', 't2.sort()', 'idx = np.searchsorted(t1, t2) - 1', 'mask = idx >= 0', 'import pylab as pl', 'pl.figure(figsize=(18, 4))', 'pl.vlines(df.t1, 0.3, 0.7, colors=""r"", lw=2)', 'pl.vlines(df.t2, 0.3, 0.7, colors=""b"", lw=2)', 'pl.margins(0.02)']","['a = (np.random.rand(30)*1000000*1000).astype(np.int64)*1000000', 'b = (np.random.rand(10)*1000000*1000).astype(np.int64)*1000000', 'idx = np.searchsorted(t1, t2) - 1']",,
21221138,"import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
mpl.style.available
mpl.style.use('ggplot')
plt.hist(np.random.randn(100000))
...","[""mpl.style.use('ggplot')""]","['import matplotlib as mpl', 'import matplotlib.pyplot as plt', 'import numpy as np', 'mpl.style.available', ""mpl.style.use('ggplot')"", 'plt.hist(np.random.randn(100000))', '...']","[""mpl.style.use('ggplot')""]",,
21232849,"path =r'C:\DRO\DCL_rawdata_files' 
allFiles = glob.glob(path + ""/*.csv"")
frame = pd.DataFrame()
list_ = []
for file_ in allFiles:
    df = pd.read_csv(file_,index_col=None, header=0)
    list_.append(df)
frame = pd.concat(list_)","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","[""path =r'C:\\DRO\\DCL_rawdata_files' "", 'allFiles = glob.glob(path + ""/*.csv"")', 'list_ = []', 'for file_ in allFiles:', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']"
21242140,"pd.concat([df1['c'], df2['c']], axis=1, keys=['df1', 'df2'])","[""pd.concat([df1['c'], df2['c']], axis=1, keys=['df1', 'df2'])""]","[""pd.concat([df1['c'], df2['c']], axis=1, keys=['df1', 'df2'])""]","[""pd.concat([df1['c'], df2['c']], axis=1, keys=['df1', 'df2'])""]",,
21244212,"df[df.apply(lambda x: min(x) == max(x), 1)]","['df[df.apply(lambda x: min(x) == max(x), 1)]']","['df[df.apply(lambda x: min(x) == max(x), 1)]']","['df[df.apply(lambda x: min(x) == max(x), 1)]']",,
21244355,"df
df[df.apply(pd.Series.nunique, axis=1) == 1]
df.apply(pd.Series.nunique, axis=1)
dtype: int64","['df[df.apply(pd.Series.nunique, axis=1) == 1]', 'df.apply(pd.Series.nunique, axis=1)']","['df', 'dtype: int64']","['df[df.apply(pd.Series.nunique, axis=1) == 1]', 'df.apply(pd.Series.nunique, axis=1)']",,
21247312,"pd.crosstab(df.A, df.B).apply(lambda r: r/r.sum(), axis=1)","['pd.crosstab(df.A, df.B).apply(lambda r: r/r.sum(), axis=1)']","['pd.crosstab(df.A, df.B).apply(lambda r: r/r.sum(), axis=1)']","['pd.crosstab(df.A, df.B).apply(lambda r: r/r.sum(), axis=1)']",,
21248050,"mydf.groupby(['cat', ""class""]).val.sum().reset_index()
mydf.groupby(['cat', ""class""]).val.sum().reset_index(level=1)
mydf.groupby(['cat', ""class""], as_index=False).val.sum()","['mydf.groupby([\'cat\', ""class""]).val.sum().reset_index()', 'mydf.groupby([\'cat\', ""class""]).val.sum().reset_index(level=1)', 'mydf.groupby([\'cat\', ""class""], as_index=False).val.sum()']","['mydf.groupby([\'cat\', ""class""]).val.sum().reset_index()', 'mydf.groupby([\'cat\', ""class""]).val.sum().reset_index(level=1)', 'mydf.groupby([\'cat\', ""class""], as_index=False).val.sum()']","['mydf.groupby([\'cat\', ""class""]).val.sum().reset_index()', 'mydf.groupby([\'cat\', ""class""]).val.sum().reset_index(level=1)', 'mydf.groupby([\'cat\', ""class""], as_index=False).val.sum()']",,
21260328,"import MySQLdb as db
from pandas import DataFrame
from pandas.io.sql import frame_query
database = db.connect('localhost','username','password','database')
data     = frame_query(""SELECT * FROM data"", database)",[],"['import MySQLdb as db', 'from pandas import DataFrame', 'from pandas.io.sql import frame_query', ""database = db.connect('localhost','username','password','database')"", 'data     = frame_query(""SELECT * FROM data"", database)']",[],[],[]
21263149,df[ (df.A=='blue') & (df.B=='red') & (df.C=='square') ]['D'] = 'succeed',[],"[""df[ (df.A=='blue') & (df.B=='red') & (df.C=='square') ]['D'] = 'succeed'""]",[],[],[]
21266043,"from urllib2 import Request, urlopen
import json
from pandas.io.json import json_normalize
path1 = '42.974049,-81.205203|42.974298,-81.195755'
request=Request('http://maps.googleapis.com/maps/api/elevation/json?locations='+path1+'&sensor=false')
response = urlopen(request)
elevations = response.read()
data = json.loads(elevations)
json_normalize(data['results'])",[],"['from urllib2 import Request, urlopen', 'import json', 'from pandas.io.json import json_normalize', ""path1 = '42.974049,-81.205203|42.974298,-81.195755'"", ""request=Request('http://maps.googleapis.com/maps/api/elevation/json?locations='+path1+'&sensor=false')"", 'response = urlopen(request)', 'elevations = response.read()', 'data = json.loads(elevations)', ""json_normalize(data['results'])""]",[],[],[]
21271103,"import pandas as pd
from datetime import datetime
headers = ['col1', 'col2', 'col3', 'col4'] 
dtypes = [datetime, datetime, str, float] 
pd.read_csv(file, sep='\t', header=None, names=headers, dtype=dtypes)
pd.read_csv(file, sep='\t', header=None, names=headers, parse_dates=True)","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, parse_dates=True)""]","['import pandas as pd', 'from datetime import datetime', ""headers = ['col1', 'col2', 'col3', 'col4'] "", 'dtypes = [datetime, datetime, str, float] ', ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, parse_dates=True)""]","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, parse_dates=True)""]",,
21272615,"df.loc[:, df.dtypes == np.float64]","['df.loc[:, df.dtypes == np.float64]']","['df.loc[:, df.dtypes == np.float64]']","['df.loc[:, df.dtypes == np.float64]']",,
21275962,pd.options.display.max_colwidth  ,[],['pd.options.display.max_colwidth  '],[],[],[]
21285575,"import pandas as pd
data = {'spike-2': [1,2,3], 'hey spke': [4,5,6], 'spiked-in': [7,8,9], 'no': [10,11,12]}
df = pd.DataFrame(data)
spike_cols = [col for col in df.columns if 'spike' in col]
print(list(df.columns))
print(spike_cols)
['hey spke', 'no', 'spike-2', 'spiked-in']
['spike-2', 'spiked-in']
df2 = df.filter(regex='spike')
print(df2)","['df = pd.DataFrame(data)', ""df2 = df.filter(regex='spike')""]","['import pandas as pd', ""data = {'spike-2': [1,2,3], 'hey spke': [4,5,6], 'spiked-in': [7,8,9], 'no': [10,11,12]}"", ""spike_cols = [col for col in df.columns if 'spike' in col]"", 'print(list(df.columns))', 'print(spike_cols)', ""['hey spke', 'no', 'spike-2', 'spiked-in']"", ""['spike-2', 'spiked-in']"", ""df2 = df.filter(regex='spike')"", 'print(df2)']","[""df2 = df.filter(regex='spike')""]",,
21287539,"df.ix['x','C']=10",[],"[""df.ix['x','C']=10""]",[],[],[]
21290084,,[],[''],[],[],[]
21291383,"df = pd.DataFrame(np.random.rand(3,4), columns=list(""ABCD""))
df
df[list(""ABCD"")] = df[list(""ABCD"")].astype(int)
df
df
df[list(""ABCD"")] = df[list(""ABCD"")].fillna(0.0).astype(int)
df","['df = pd.DataFrame(np.random.rand(3,4), columns=list(""ABCD""))', 'df[list(""ABCD"")] = df[list(""ABCD"")].astype(int)', 'df[list(""ABCD"")] = df[list(""ABCD"")].fillna(0.0).astype(int)']","['df', 'df[list(""ABCD"")] = df[list(""ABCD"")].astype(int)', 'df', 'df', 'df[list(""ABCD"")] = df[list(""ABCD"")].fillna(0.0).astype(int)', 'df']","['df[list(""ABCD"")] = df[list(""ABCD"")].astype(int)', 'df[list(""ABCD"")] = df[list(""ABCD"")].fillna(0.0).astype(int)']",,
21291622,"df= pd.DataFrame(range(5), columns=['a'])
df.a = df.a.astype(float)
df
pd.options.display.float_format = '{:,.0f}'.format
df","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","['df.a = df.a.astype(float)', 'df', ""pd.options.display.float_format = '{:,.0f}'.format"", 'df']","['df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]"
21295630,,[],[''],[],[],[]
21296915,"df.row.str.extract('(?P<fips>\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))')","[""df.row.str.extract('(?P<fips>\\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))')""]","[""df.row.str.extract('(?P<fips>\\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))')""]","[""df.row.str.extract('(?P<fips>\\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))')""]",,
21315199,[column for column in my_dataframe],[],['[column for column in my_dataframe]'],[],[],[]
21317570,"df1
df2
pandas.concat([df1,df2]).drop_duplicates().reset_index(drop=True)","['pandas.concat([df1,df2]).drop_duplicates().reset_index(drop=True)']","['df1', 'df2', 'pandas.concat([df1,df2]).drop_duplicates().reset_index(drop=True)']","['pandas.concat([df1,df2]).drop_duplicates().reset_index(drop=True)']",,
21317700,"from pandas.tools.util import cartesian_product
MultiIndex.from_arrays(cartesian_product([range(3),list('ab')]))
df = DataFrame(dict(A = np.arange(6), 
                             B = ['foo'] * 3 + ['bar'] * 3, 
                             C = np.ones(6)+np.arange(6)%2)
                       ).set_index(['C','B']).sortlevel()
df","[""MultiIndex.from_arrays(cartesian_product([range(3),list('ab')]))"", '                             C = np.ones(6)+np.arange(6)%2)']","['from pandas.tools.util import cartesian_product', ""MultiIndex.from_arrays(cartesian_product([range(3),list('ab')]))"", 'df = DataFrame(dict(A = np.arange(6), ', ""                             B = ['foo'] * 3 + ['bar'] * 3, "", '                             C = np.ones(6)+np.arange(6)%2)', ""                       ).set_index(['C','B']).sortlevel()"", 'df']","[""MultiIndex.from_arrays(cartesian_product([range(3),list('ab')]))"", '                             C = np.ones(6)+np.arange(6)%2)']",,
21320011,"s = pd.Series(list('abc'))
s
1 in s
'a' in s
s.unique()
'a' in s.unique()
set(s)
'a' in set(s)
s.values
'a' in s.values
Out[32]: True","[""s = pd.Series(list('abc'))"", 's.unique()', ""'a' in s.unique()"", 's.values', ""'a' in s.values""]","['s', '1 in s', ""'a' in s"", 's.unique()', ""'a' in s.unique()"", 'set(s)', ""'a' in set(s)"", 's.values', ""'a' in s.values"", 'Out[32]: True']","['s.unique()', ""'a' in s.unique()"", 's.values', ""'a' in s.values""]",,
21324222,"df = pd.read_csv('test.csv', header=[0, 1], skipinitialspace=True, tupleize_cols=True)
df
df.columns = pd.MultiIndex.from_tuples(df.columns)
df","[""df = pd.read_csv('test.csv', header=[0, 1], skipinitialspace=True, tupleize_cols=True)"", 'df.columns = pd.MultiIndex.from_tuples(df.columns)']","[""df = pd.read_csv('test.csv', header=[0, 1], skipinitialspace=True, tupleize_cols=True)"", 'df', 'df.columns = pd.MultiIndex.from_tuples(df.columns)', 'df']","[""df = pd.read_csv('test.csv', header=[0, 1], skipinitialspace=True, tupleize_cols=True)"", 'df.columns = pd.MultiIndex.from_tuples(df.columns)']",,
21361994,"import time
import pylab as pl
from IPython import display
for i in range(10):
    pl.plot(pl.randn(100))
    display.clear_output(wait=True)
    display.display(pl.gcf())
    time.sleep(1.0)",['    pl.plot(pl.randn(100))'],"['import time', 'import pylab as pl', 'from IPython import display', 'for i in range(10):', '    pl.plot(pl.randn(100))', '    display.clear_output(wait=True)', '    display.display(pl.gcf())', '    time.sleep(1.0)']",['    pl.plot(pl.randn(100))'],,
21415990,"(a['x']==1) and (a['y']==10)
(a['x']==1) & (a['y']==10)",[],"[""(a['x']==1) and (a['y']==10)"", ""(a['x']==1) & (a['y']==10)""]",[],[],[]
21441621,"df.groupby(pd.cut(df[""B""], np.arange(0, 1.0+0.155, 0.155))).sum()
B                                ","['df.groupby(pd.cut(df[""B""], np.arange(0, 1.0+0.155, 0.155))).sum()']","['df.groupby(pd.cut(df[""B""], np.arange(0, 1.0+0.155, 0.155))).sum()', 'B                                ']","['df.groupby(pd.cut(df[""B""], np.arange(0, 1.0+0.155, 0.155))).sum()']",,
21463854,"data['amount'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))
data[""amount""] = data['amount'].fillna(mean_avg)
data['amount'] = data['amount'].fillna(mean_avg)*2
pd.set_option('chained_assignment',None)","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]"
21487560,"ax = df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')
ax.set_xlabel(""x label"")
ax.set_ylabel(""y label"")","[""ax = df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')""]","[""ax = df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')"", 'ax.set_xlabel(""x label"")', 'ax.set_ylabel(""y label"")']","[""ax = df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')""]",,
21487868,"import matplotlib.pyplot as plt 
import pandas as pd
plt.figure()
values = [[1,2], [2,5]]
df2 = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])
df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')
plt.xlabel('xlabel')
plt.ylabel('ylabel')
plt.show()","[""df2 = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])"", ""df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')""]","['import matplotlib.pyplot as plt ', 'import pandas as pd', 'plt.figure()', 'values = [[1,2], [2,5]]', ""df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')"", ""plt.xlabel('xlabel')"", ""plt.ylabel('ylabel')"", 'plt.show()']","[""df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')""]",,
21489607,"ax = cum_edits.plot()
ymin, ymax = ax.get_ylim()
ax.vlines(x=dates, ymin=ymin, ymax=ymax-1, color='r')",['ax = cum_edits.plot()'],"['ax = cum_edits.plot()', 'ymin, ymax = ax.get_ylim()', ""ax.vlines(x=dates, ymin=ymin, ymax=ymax-1, color='r')""]",['ax = cum_edits.plot()'],,
21500413,"import sh
jq = sh.jq.bake('-M')  
json_data = ""from above""
rule = """"""[{pivots: .intervals[].pivots, 
            interval_id: .intervals[].series[].interval_id,
            p_value: .intervals[].series[].p_value}]""""""
out = jq(rule, _in=json_data).stdout
res = pd.DataFrame(json.loads(out))
res.drop_duplicates()","['res = pd.DataFrame(json.loads(out))', 'res.drop_duplicates()']","['import sh', ""jq = sh.jq.bake('-M')  "", 'json_data = ""from above""', 'rule = """"""[{pivots: .intervals[].pivots, ', '            interval_id: .intervals[].series[].interval_id,', '            p_value: .intervals[].series[].p_value}]""""""', 'out = jq(rule, _in=json_data).stdout', 'res.drop_duplicates()']",['res.drop_duplicates()'],,
21546823,"data = pd.read_csv('output_list.txt', sep="" "", header=None)
data.columns = [""a"", ""b"", ""c"", ""etc.""]","['data = pd.read_csv(\'output_list.txt\', sep="" "", header=None)']","['data = pd.read_csv(\'output_list.txt\', sep="" "", header=None)', 'data.columns = [""a"", ""b"", ""c"", ""etc.""]']","['data = pd.read_csv(\'output_list.txt\', sep="" "", header=None)']",,
21607530,"df
df.rename(columns=lambda x: x.strip())",['df.rename(columns=lambda x: x.strip())'],"['df', 'df.rename(columns=lambda x: x.strip())']",['df.rename(columns=lambda x: x.strip())'],,
21608417,"df.ix[df.my_channel > 20000, 'my_channel'] = 0",[],"[""df.ix[df.my_channel > 20000, 'my_channel'] = 0""]",[],[],[]
21649359,,[],[''],[],[],[]
21655221,"df = pd.DataFrame(np.random.normal(10,1,30).reshape(10,3), index = pd.date_range('2010-01-01', freq = 'M', periods = 10), columns = ('one', 'two', 'three'))
df['key1'] = (4,4,4,6,6,6,8,8,8,8)
fig1 = plt.figure(1)
ax1 = fig1.add_subplot(111)
x=ax1.scatter(df['one'], df['two'], marker = 'o', c = df['key1'], alpha = 0.8)
ccm=x.get_cmap()
circles=[Line2D(range(1), range(1), color='w', marker='o', markersize=10, markerfacecolor=item) for item in ccm((array([4,6,8])-4.0)/4)]
leg = plt.legend(circles, ['4','6','8'], loc = ""center left"", bbox_to_anchor = (1, 0.5), numpoints = 1)","[""df = pd.DataFrame(np.random.normal(10,1,30).reshape(10,3), index = pd.date_range('2010-01-01', freq = 'M', periods = 10), columns = ('one', 'two', 'three'))""]","[""df['key1'] = (4,4,4,6,6,6,8,8,8,8)"", 'fig1 = plt.figure(1)', 'ax1 = fig1.add_subplot(111)', ""x=ax1.scatter(df['one'], df['two'], marker = 'o', c = df['key1'], alpha = 0.8)"", 'ccm=x.get_cmap()', ""circles=[Line2D(range(1), range(1), color='w', marker='o', markersize=10, markerfacecolor=item) for item in ccm((array([4,6,8])-4.0)/4)]"", 'leg = plt.legend(circles, [\'4\',\'6\',\'8\'], loc = ""center left"", bbox_to_anchor = (1, 0.5), numpoints = 1)']","[""df = pd.DataFrame(np.random.normal(10,1,30).reshape(10,3), index = pd.date_range('2010-01-01', freq = 'M', periods = 10), columns = ('one', 'two', 'three'))""]",,
21655256,"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
np.random.seed(1974)
num = 20
x, y = np.random.random((2, num))
labels = np.random.choice(['a', 'b', 'c'], num)
df = pd.DataFrame(dict(x=x, y=y, label=labels))
groups = df.groupby('label')
Plot
fig, ax = plt.subplots()
ax.margins(0.05) 
for name, group in groups:
    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)
ax.legend()
plt.show()
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
np.random.seed(1974)
num = 20
x, y = np.random.random((2, num))
labels = np.random.choice(['a', 'b', 'c'], num)
df = pd.DataFrame(dict(x=x, y=y, label=labels))
groups = df.groupby('label')
Plot
plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)
colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')
fig, ax = plt.subplots()
ax.set_color_cycle(colors)
ax.margins(0.05)
for name, group in groups:
    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)
ax.legend(numpoints=1, loc='upper left')
plt.show()","['df = pd.DataFrame(dict(x=x, y=y, label=labels))', ""groups = df.groupby('label')"", ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)"", 'df = pd.DataFrame(dict(x=x, y=y, label=labels))', ""groups = df.groupby('label')"", 'plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)', ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)""]","['import matplotlib.pyplot as plt', 'import numpy as np', 'import pandas as pd', 'np.random.seed(1974)', 'num = 20', 'x, y = np.random.random((2, num))', ""labels = np.random.choice(['a', 'b', 'c'], num)"", ""groups = df.groupby('label')"", 'Plot', 'fig, ax = plt.subplots()', 'ax.margins(0.05) ', 'for name, group in groups:', ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)"", 'ax.legend()', 'plt.show()', 'import matplotlib.pyplot as plt', 'import numpy as np', 'import pandas as pd', 'np.random.seed(1974)', 'num = 20', 'x, y = np.random.random((2, num))', ""labels = np.random.choice(['a', 'b', 'c'], num)"", ""groups = df.groupby('label')"", 'Plot', 'plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)', ""colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')"", 'fig, ax = plt.subplots()', 'ax.set_color_cycle(colors)', 'ax.margins(0.05)', 'for name, group in groups:', ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)"", ""ax.legend(numpoints=1, loc='upper left')"", 'plt.show()']","[""groups = df.groupby('label')"", ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)"", ""groups = df.groupby('label')"", 'plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)', ""    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)""]",,
21689542,"df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)",[],"[""df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)""]",[],[],[]
21709413,"df = pd.DataFrame({
    'sp' : ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],
    'mt' : ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],
    'val' : ['a', 'n', 'cb', 'mk', 'bg', 'dgb', 'rd', 'cb', 'uyi'],
    'count' : [3,2,5,8,10,1,2,2,7]
    })
df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})
df_grouped = df_grouped.reset_index()
df_grouped = df_grouped.rename(columns={'count':'count_max'})
df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])
df = df[df['count'] == df['count_max']]","['df = pd.DataFrame({', ""df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})"", 'df_grouped = df_grouped.reset_index()', ""df_grouped = df_grouped.rename(columns={'count':'count_max'})"", ""df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])""]","[""    'sp' : ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],"", ""    'mt' : ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],"", ""    'val' : ['a', 'n', 'cb', 'mk', 'bg', 'dgb', 'rd', 'cb', 'uyi'],"", ""    'count' : [3,2,5,8,10,1,2,2,7]"", '    })', ""df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})"", 'df_grouped = df_grouped.reset_index()', ""df_grouped = df_grouped.rename(columns={'count':'count_max'})"", ""df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])"", ""df = df[df['count'] == df['count_max']]""]","[""df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})"", 'df_grouped = df_grouped.reset_index()', ""df_grouped = df_grouped.rename(columns={'count':'count_max'})"", ""df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])""]",,
21720133,"df = pd.DataFrame([[1, 'a', 2.]])
df
df.dtypes
df.dtypes == object
df.loc[:, df.dtypes == object]
df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('')","[""df = pd.DataFrame([[1, 'a', 2.]])"", 'df.dtypes', 'df.dtypes == object', 'df.loc[:, df.dtypes == object]', ""df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('')""]","['df', 'df.dtypes', 'df.dtypes == object', 'df.loc[:, df.dtypes == object]', ""df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('')""]","['df.dtypes', 'df.dtypes == object', 'df.loc[:, df.dtypes == object]', ""df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('')""]",,
21734254,"df['Age_Group'] = '<40'
df['Age_Group'][df['Age'] > 40] = '>40'
df['Age_Group'][(df['Age'] > 18) & (df['Age'] < 40)] = '>18'
df['Age_Group'][df['Age'] < 18] = '<18'
d = {'Age' : pd.Series([36., 42., 6., 66., 38.]) }
df = pd.DataFrame(d)
df
df['Age_Group'] = '<40'
df['Age_Group'][df['Age'] > 40] = '>40'
df['Age_Group'][(df['Age'] > 18) & (df['Age'] < 40)] = '>18'
df['Age_Group'][df['Age'] < 18] = '<18'
df
df['Age_Group'] = '<40'
df.loc[df['Age'] < 40,'Age_Group'] = '<40'
df.loc[(df['Age'] > 18) & (df['Age'] < 40), 'Age_Group'] = '>18'
df.loc[df['Age'] < 18,'Age_Group'] = '<18'
df","[""d = {'Age' : pd.Series([36., 42., 6., 66., 38.]) }"", 'df = pd.DataFrame(d)', ""df.loc[df['Age'] < 40,'Age_Group'] = '<40'"", ""df.loc[(df['Age'] > 18) & (df['Age'] < 40), 'Age_Group'] = '>18'"", ""df.loc[df['Age'] < 18,'Age_Group'] = '<18'""]","[""df['Age_Group'] = '<40'"", ""df['Age_Group'][df['Age'] > 40] = '>40'"", ""df['Age_Group'][(df['Age'] > 18) & (df['Age'] < 40)] = '>18'"", ""df['Age_Group'][df['Age'] < 18] = '<18'"", 'df', ""df['Age_Group'] = '<40'"", ""df['Age_Group'][df['Age'] > 40] = '>40'"", ""df['Age_Group'][(df['Age'] > 18) & (df['Age'] < 40)] = '>18'"", ""df['Age_Group'][df['Age'] < 18] = '<18'"", 'df', ""df['Age_Group'] = '<40'"", ""df.loc[df['Age'] < 40,'Age_Group'] = '<40'"", ""df.loc[(df['Age'] > 18) & (df['Age'] < 40), 'Age_Group'] = '>18'"", ""df.loc[df['Age'] < 18,'Age_Group'] = '<18'"", 'df']","[""df.loc[df['Age'] < 40,'Age_Group'] = '<40'"", ""df.loc[(df['Age'] > 18) & (df['Age'] < 40), 'Age_Group'] = '>18'"", ""df.loc[df['Age'] < 18,'Age_Group'] = '<18'""]",,
21738682,"dt.datetime.today().strftime(""%m/%d/%Y"")
'02/12/2014'","['dt.datetime.today().strftime(""%m/%d/%Y"")']","['dt.datetime.today().strftime(""%m/%d/%Y"")', ""'02/12/2014'""]","['dt.datetime.today().strftime(""%m/%d/%Y"")']",,
21751529,"from pandas.stats.moments import ewma
import numpy as np
pred_period = 12
def predict(x,span,periods = pred_period):     
    x_predict = np.zeros((span+periods,))
    x_predict[:span] = x[-span:]
    pred =  ewma(x_predict,span)[span:]
    return pred",[],"['from pandas.stats.moments import ewma', 'import numpy as np', 'pred_period = 12', 'def predict(x,span,periods = pred_period):     ', '    x_predict = np.zeros((span+periods,))', '    x_predict[:span] = x[-span:]', '    pred =  ewma(x_predict,span)[span:]', '    return pred']",[],[],[]
21755752,"df.append(df.sum(numeric_only=True), ignore_index=True)
baz = 2*df['qux'].sum() + 3*df['bar'].sum()","['df.append(df.sum(numeric_only=True), ignore_index=True)', ""baz = 2*df['qux'].sum() + 3*df['bar'].sum()""]","['df.append(df.sum(numeric_only=True), ignore_index=True)', ""baz = 2*df['qux'].sum() + 3*df['bar'].sum()""]","['df.append(df.sum(numeric_only=True), ignore_index=True)', ""baz = 2*df['qux'].sum() + 3*df['bar'].sum()""]",,
21768034,"g
g = g.reset_index()
g
g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()
g","['g = g.reset_index()', ""g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()""]","['g', 'g = g.reset_index()', 'g', ""g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()"", 'g']","['g = g.reset_index()', ""g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()""]",,
21771438,"np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))
(array([3]),)","['np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))']","['np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))', '(array([3]),)']","['np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))']",,
21772078,"df.applymap(np.isreal)
df.applymap(np.isreal).all(1)
df[~df.applymap(np.isreal).all(1)]
np.argmin(df.applymap(np.isreal).all(1))
Out[14]: 'd'
df.applymap(lambda x: isinstance(x, (int, float)))","['df.applymap(np.isreal)', 'df.applymap(np.isreal).all(1)', 'df[~df.applymap(np.isreal).all(1)]', 'np.argmin(df.applymap(np.isreal).all(1))', 'df.applymap(lambda x: isinstance(x, (int, float)))']","['df.applymap(np.isreal)', 'df.applymap(np.isreal).all(1)', 'df[~df.applymap(np.isreal).all(1)]', 'np.argmin(df.applymap(np.isreal).all(1))', ""Out[14]: 'd'"", 'df.applymap(lambda x: isinstance(x, (int, float)))']","['df.applymap(np.isreal)', 'df.applymap(np.isreal).all(1)', 'df[~df.applymap(np.isreal).all(1)]', 'np.argmin(df.applymap(np.isreal).all(1))', 'df.applymap(lambda x: isinstance(x, (int, float)))']",,
21787325,"s1 = pd.merge(df1, df2, how='left', on=['Year', 'Week', 'Colour'])
df = pd.merge(s1, df3[['Week', 'Colour', 'Val3']],
                       how='left', on=['Week', 'Colour'])
df","[""s1 = pd.merge(df1, df2, how='left', on=['Year', 'Week', 'Colour'])"", ""df = pd.merge(s1, df3[['Week', 'Colour', 'Val3']],""]","[""s1 = pd.merge(df1, df2, how='left', on=['Year', 'Week', 'Colour'])"", ""df = pd.merge(s1, df3[['Week', 'Colour', 'Val3']],"", ""                       how='left', on=['Week', 'Colour'])"", 'df']","[""s1 = pd.merge(df1, df2, how='left', on=['Year', 'Week', 'Colour'])"", ""df = pd.merge(s1, df3[['Week', 'Colour', 'Val3']],""]",,
21800319,"df[df['BoolCol'] == True].index.tolist()
df[df['BoolCol']].index.tolist()
df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},
       index=[10,20,30,40,50])
df
df[df['BoolCol']].index.tolist()
idx = df[df['BoolCol']].index.tolist()
idx
df.loc[idx]
df.loc[df['BoolCol']]
np.flatnonzero(df['BoolCol'])
df.iloc[np.flatnonzero(df['BoolCol'])]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", '       index=[10,20,30,40,50])', 'df', ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'idx', 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""np.flatnonzero(df['BoolCol'])"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.iloc[np.flatnonzero(df['BoolCol'])]""]"
21869063,"import pandas
pandas.set_option('expand_frame_repr', False)
mydf = pandas.DataFrame.from_csv('myfile.csv', header=1)
pandas.set_option('display.max_columns', 0) 
pandas.set_option('display.max_rows', 0) ","[""pandas.set_option('expand_frame_repr', False)"", ""mydf = pandas.DataFrame.from_csv('myfile.csv', header=1)"", ""pandas.set_option('display.max_columns', 0) "", ""pandas.set_option('display.max_rows', 0) ""]","['import pandas', ""pandas.set_option('expand_frame_repr', False)"", ""pandas.set_option('display.max_columns', 0) "", ""pandas.set_option('display.max_rows', 0) ""]","[""pandas.set_option('expand_frame_repr', False)"", ""mydf = pandas.DataFrame.from_csv('myfile.csv', header=1)"", ""pandas.set_option('display.max_columns', 0) "", ""pandas.set_option('display.max_rows', 0) ""]",,
21902162,"a = pandas.DataFrame.from_csv('st1.csv', sep=' ')
a = pandas.DataFrame.from_csv('st1.csv', index_col=None)","[""a = pandas.DataFrame.from_csv('st1.csv', sep=' ')"", ""a = pandas.DataFrame.from_csv('st1.csv', index_col=None)""]",[],"[""a = pandas.DataFrame.from_csv('st1.csv', sep=' ')"", ""a = pandas.DataFrame.from_csv('st1.csv', index_col=None)""]",,
21916253,,[],[''],[],[],[]
21940107,"px2 = px.reshape((-1,3))
df = pd.DataFrame({'R':px2[:,0],'G':px2[:,1],'B':px2[:,2]})","[""df = pd.DataFrame({'R':px2[:,0],'G':px2[:,1],'B':px2[:,2]})""]","['px2 = px.reshape((-1,3))']",[],,
21942746,,[],[''],[],[],[]
21961491,"df['date_int'] = df.date.astype(np.int64)
color_d = {1: 'k', 2: 'b', 3: 'r'}
training.plot(kind='scatter',x='date',y='rate', color=df.account.map(color_d))","[""df['date_int'] = df.date.astype(np.int64)"", ""training.plot(kind='scatter',x='date',y='rate', color=df.account.map(color_d))""]","[""df['date_int'] = df.date.astype(np.int64)"", ""color_d = {1: 'k', 2: 'b', 3: 'r'}"", ""training.plot(kind='scatter',x='date',y='rate', color=df.account.map(color_d))""]","[""df['date_int'] = df.date.astype(np.int64)"", ""training.plot(kind='scatter',x='date',y='rate', color=df.account.map(color_d))""]",,
21989204,"ax = var.total.plot(label='Variance')
ax = shares.average.plot(secondary_y=True, label='Average Age')
ax.set_ylabel('Variance of log wages')
ax.right_ax.set_ylabel('Average age')
lines = ax.get_lines() + ax.right_ax.get_lines()
ax.legend(lines, [l.get_label() for l in lines], loc='upper center')
ax.set_title('Wage Variance and Mean Age')
plt.show()
fig, ax = plt.subplots()
ax.plot(var.index.to_datetime(), var.total, 'b', label='Variance')
ax.set_ylabel('Variance of log wages')
ax2 = ax.twinx()
ax2.plot(shares.index.to_datetime(), shares.average, 'g' , label='Average Age')
ax2.set_ylabel('Average age')
lines = ax.get_lines() + ax2.get_lines()
ax.legend(lines, [line.get_label() for line in lines], loc='upper center')
ax.set_title('Wage Variance and Mean Age')
plt.show()","[""ax = var.total.plot(label='Variance')"", ""ax = shares.average.plot(secondary_y=True, label='Average Age')"", ""ax.plot(var.index.to_datetime(), var.total, 'b', label='Variance')"", ""ax2.plot(shares.index.to_datetime(), shares.average, 'g' , label='Average Age')""]","[""ax = var.total.plot(label='Variance')"", ""ax = shares.average.plot(secondary_y=True, label='Average Age')"", ""ax.set_ylabel('Variance of log wages')"", ""ax.right_ax.set_ylabel('Average age')"", 'lines = ax.get_lines() + ax.right_ax.get_lines()', ""ax.legend(lines, [l.get_label() for l in lines], loc='upper center')"", ""ax.set_title('Wage Variance and Mean Age')"", 'plt.show()', 'fig, ax = plt.subplots()', ""ax.plot(var.index.to_datetime(), var.total, 'b', label='Variance')"", ""ax.set_ylabel('Variance of log wages')"", 'ax2 = ax.twinx()', ""ax2.plot(shares.index.to_datetime(), shares.average, 'g' , label='Average Age')"", ""ax2.set_ylabel('Average age')"", 'lines = ax.get_lines() + ax2.get_lines()', ""ax.legend(lines, [line.get_label() for line in lines], loc='upper center')"", ""ax.set_title('Wage Variance and Mean Age')"", 'plt.show()']","[""ax = var.total.plot(label='Variance')"", ""ax = shares.average.plot(secondary_y=True, label='Average Age')"", ""ax.plot(var.index.to_datetime(), var.total, 'b', label='Variance')"", ""ax2.plot(shares.index.to_datetime(), shares.average, 'g' , label='Average Age')""]",,
22006514,"total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)
df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])
df.to_json()
df[0].to_json()
Out[13]: '{""0"":""A"",""1"":""A"",""2"":""B""}'","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", 'df.to_json()', 'df[0].to_json()', 'Out[13]: \'{""0"":""A"",""1"":""A"",""2"":""B""}\'']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']"
22018873,"data.iloc[:,[0,3]]","['data.iloc[:,[0,3]]']","['data.iloc[:,[0,3]]']","['data.iloc[:,[0,3]]']",,
22019831,"header = [""InviteTime (Oracle)"", ""Orig Number"", ""Orig IP Address"", ""Dest Number""]
df.to_csv('output.csv', columns = header)","[""df.to_csv('output.csv', columns = header)""]","['header = [""InviteTime (Oracle)"", ""Orig Number"", ""Orig IP Address"", ""Dest Number""]', ""df.to_csv('output.csv', columns = header)""]","[""df.to_csv('output.csv', columns = header)""]",,
22033314,"mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)
arr = arr[~mask]
mask = np.all(np.isnan(arr) | arr == 0, axis=1)
arr = arr[~mask]","['mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)', 'mask = np.all(np.isnan(arr) | arr == 0, axis=1)']","['mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)', 'arr = arr[~mask]', 'mask = np.all(np.isnan(arr) | arr == 0, axis=1)', 'arr = arr[~mask]']","['mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)', 'mask = np.all(np.isnan(arr) | arr == 0, axis=1)']",,
22033364,"import numpy as np
a = np.array([
    [1, 0, 0],
    [0, np.nan, 0],
    [0, 0, 0],
    [np.nan, np.nan, np.nan],
    [2, 3, 4]
])
mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)
a[~mask]","['mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)']","['import numpy as np', 'a = np.array([', '    [1, 0, 0],', '    [0, np.nan, 0],', '    [0, 0, 0],', '    [np.nan, np.nan, np.nan],', '    [2, 3, 4]', '])', 'mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)', 'a[~mask]']","['mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)']",,
22070926,"df = pd.DataFrame(np.random.randn(400, 4), columns=['one', 'two', 'three', 'four'])
ax1 = df.cumsum().plot()
lines, labels = ax1.get_legend_handles_labels()
ax1.legend(lines[:2], labels[:2], loc='best')  ","[""df = pd.DataFrame(np.random.randn(400, 4), columns=['one', 'two', 'three', 'four'])"", 'ax1 = df.cumsum().plot()']","['ax1 = df.cumsum().plot()', 'lines, labels = ax1.get_legend_handles_labels()', ""ax1.legend(lines[:2], labels[:2], loc='best')  ""]",['ax1 = df.cumsum().plot()'],,
22082596,"df1.change.shift(1)
df1.change.shift(1) - df1.change
df.groupby('case')['change'].apply(lambda x: x.shift(1) - x)
dtype: timedelta64[ns]","['df1.change.shift(1)', 'df1.change.shift(1) - df1.change', ""df.groupby('case')['change'].apply(lambda x: x.shift(1) - x)""]","['df1.change.shift(1)', 'df1.change.shift(1) - df1.change', ""df.groupby('case')['change'].apply(lambda x: x.shift(1) - x)"", 'dtype: timedelta64[ns]']","['df1.change.shift(1)', 'df1.change.shift(1) - df1.change', ""df.groupby('case')['change'].apply(lambda x: x.shift(1) - x)""]",,
22084742,"import timeit
f = ['value = dictionary[5][5]', 'value = df.loc[5, 5]', 'value = df.iloc[5, 5]']
f = ['value = [val[5] for col,val in dictionary.items()]', 'value = df.loc[5]', 'value = df.iloc[5]']
for func in f:
    print(func)
    print(min(timeit.Timer(func, setup).repeat(3, 100000)))
value = [val[5] for col,val in dictionary.iteritems()]
25.5416321754
value = df.loc[5]
5.68071913719
value = df.iloc[5]
4.56006002426
df.loc['2000-1-1':'2000-3-31']","['    print(min(timeit.Timer(func, setup).repeat(3, 100000)))', 'value = [val[5] for col,val in dictionary.iteritems()]', 'value = df.loc[5]', 'value = df.iloc[5]', ""df.loc['2000-1-1':'2000-3-31']""]","['import timeit', ""f = ['value = dictionary[5][5]', 'value = df.loc[5, 5]', 'value = df.iloc[5, 5]']"", ""f = ['value = [val[5] for col,val in dictionary.items()]', 'value = df.loc[5]', 'value = df.iloc[5]']"", 'for func in f:', '    print(func)', '    print(min(timeit.Timer(func, setup).repeat(3, 100000)))', 'value = [val[5] for col,val in dictionary.iteritems()]', '25.5416321754', 'value = df.loc[5]', '5.68071913719', 'value = df.iloc[5]', '4.56006002426', ""df.loc['2000-1-1':'2000-3-31']""]","['    print(min(timeit.Timer(func, setup).repeat(3, 100000)))', 'value = [val[5] for col,val in dictionary.iteritems()]', 'value = df.loc[5]', 'value = df.iloc[5]', ""df.loc['2000-1-1':'2000-3-31']""]",,
22086347,"males = df[(df[Gender]=='Male') & (df[Year]==2014)]
from collections import defaultdict
dic={}
for g in ['male', 'female']:
  dic[g]=defaultdict(dict)
  for y in [2013, 2014]:
    dic[g][y]=df[(df[Gender]==g) & (df[Year]==y)] 
def getDF(dic, gender, year):
  return dic[gender][year]",[],"[""males = df[(df[Gender]=='Male') & (df[Year]==2014)]"", 'from collections import defaultdict', 'dic={}', ""for g in ['male', 'female']:"", '  dic[g]=defaultdict(dict)', '  for y in [2013, 2014]:', '    dic[g][y]=df[(df[Gender]==g) & (df[Year]==y)] ', 'def getDF(dic, gender, year):', '  return dic[gender][year]']",[],[],[]
22089870,,[],[''],[],[],[]
22104034,,[],[''],[],[],[]
22127685,"origin.pivot(index='label', columns='type')['value']
label         
origin.pivot_table(values='value', index='label', columns='type')
label             
origin.groupby(['label', 'type'])['value'].aggregate('mean').unstack()
label         ","[""origin.pivot(index='label', columns='type')['value']"", ""origin.pivot_table(values='value', index='label', columns='type')"", ""origin.groupby(['label', 'type'])['value'].aggregate('mean').unstack()""]","[""origin.pivot(index='label', columns='type')['value']"", 'label         ', ""origin.pivot_table(values='value', index='label', columns='type')"", 'label             ', ""origin.groupby(['label', 'type'])['value'].aggregate('mean').unstack()"", 'label         ']","[""origin.pivot(index='label', columns='type')['value']"", ""origin.pivot_table(values='value', index='label', columns='type')"", ""origin.groupby(['label', 'type'])['value'].aggregate('mean').unstack()""]",,
22132649,"df['A'] = pd.to_datetime(df['A'])
df['B'] = pd.to_datetime(df['B'])
df.dtypes  
df['A'] - df['B']
df['C'] = df['A'] - df['B']
df","[""df['A'] = pd.to_datetime(df['A'])"", ""df['B'] = pd.to_datetime(df['B'])"", 'df.dtypes  ']","[""df['A'] = pd.to_datetime(df['A'])"", ""df['B'] = pd.to_datetime(df['B'])"", 'df.dtypes  ', ""df['A'] - df['B']"", ""df['C'] = df['A'] - df['B']"", 'df']","[""df['A'] = pd.to_datetime(df['A'])"", ""df['B'] = pd.to_datetime(df['B'])"", 'df.dtypes  ']",,
22135309,"with open('test.json') as f:
    data = pd.DataFrame(json.loads(line) for line in f)",['    data = pd.DataFrame(json.loads(line) for line in f)'],"[""with open('test.json') as f:""]",[],,
22137890,"import locale
from locale import atof
locale.setlocale(locale.LC_NUMERIC, '')
df.applymap(atof)
df.read_csv('foo.tsv', sep='\t', thousands=',')","['df.applymap(atof)', ""df.read_csv('foo.tsv', sep='\\t', thousands=',')""]","['import locale', 'from locale import atof', ""locale.setlocale(locale.LC_NUMERIC, '')"", 'df.applymap(atof)', ""df.read_csv('foo.tsv', sep='\\t', thousands=',')""]","['df.applymap(atof)', ""df.read_csv('foo.tsv', sep='\\t', thousands=',')""]",,
22149930,,[],[''],[],[],[]
22161058,"import pandas as pd
import numpy as np
class MyDF(pd.DataFrame):
    @property
    def _constructor(self):
        return MyDF
mydf = MyDF(np.random.randn(3,4), columns=['A','B','C','D'])
mydf_sub = mydf[['A','C']]
import pandas as pd
import numpy as np
class MyDF(pd.DataFrame):
    _attributes_ = ""myattr1,myattr2""
    def __init__(self, *args, **kw):
        super(MyDF, self).__init__(*args, **kw)
        if len(args) == 1 and isinstance(args[0], MyDF):
            args[0]._copy_attrs(self)
    def _copy_attrs(self, df):
        for attr in self._attributes_.split("",""):
            df.__dict__[attr] = getattr(self, attr, None)
    @property
    def _constructor(self):
        def f(*args, **kw):
            df = MyDF(*args, **kw)
            self._copy_attrs(df)
            return df
        return f
mydf = MyDF(np.random.randn(3,4), columns=['A','B','C','D'])
mydf_sub = mydf[['A','C']]
mydf.myattr1 = 1
mydf_cp1 = MyDF(mydf)
mydf_cp2 = mydf.copy()","['class MyDF(pd.DataFrame):', 'class MyDF(pd.DataFrame):', '        for attr in self._attributes_.split("",""):', 'mydf_cp2 = mydf.copy()']","['import pandas as pd', 'import numpy as np', '    @property', '    def _constructor(self):', '        return MyDF', ""mydf = MyDF(np.random.randn(3,4), columns=['A','B','C','D'])"", ""mydf_sub = mydf[['A','C']]"", 'import pandas as pd', 'import numpy as np', '    _attributes_ = ""myattr1,myattr2""', '    def __init__(self, *args, **kw):', '        super(MyDF, self).__init__(*args, **kw)', '        if len(args) == 1 and isinstance(args[0], MyDF):', '            args[0]._copy_attrs(self)', '    def _copy_attrs(self, df):', '        for attr in self._attributes_.split("",""):', '            df.__dict__[attr] = getattr(self, attr, None)', '    @property', '    def _constructor(self):', '        def f(*args, **kw):', '            df = MyDF(*args, **kw)', '            self._copy_attrs(df)', '            return df', '        return f', ""mydf = MyDF(np.random.randn(3,4), columns=['A','B','C','D'])"", ""mydf_sub = mydf[['A','C']]"", 'mydf.myattr1 = 1', 'mydf_cp1 = MyDF(mydf)', 'mydf_cp2 = mydf.copy()']","['        for attr in self._attributes_.split("",""):', 'mydf_cp2 = mydf.copy()']",,
22166224,"from pandas.sandbox.qtpandas import DataFrameModel, DataFrameWidget",[],"['from pandas.sandbox.qtpandas import DataFrameModel, DataFrameWidget']",[],[],[]
22181298,"@app.route('/analysis/<filename>')
def analysis(filename):
    x = pd.DataFrame(np.random.randn(20, 5))
    return render_template(""analysis.html"", name=filename, data=x.to_html())
{{data | safe}}","['    x = pd.DataFrame(np.random.randn(20, 5))', '    return render_template(""analysis.html"", name=filename, data=x.to_html())']","[""@app.route('/analysis/<filename>')"", 'def analysis(filename):', '    return render_template(""analysis.html"", name=filename, data=x.to_html())', '{{data | safe}}']","['    return render_template(""analysis.html"", name=filename, data=x.to_html())']",,
22211821,"import pandas as pd
df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150], columns=['A'])
df.sort_index(inplace=True)
print(df.to_string())","[""df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150], columns=['A'])"", 'df.sort_index(inplace=True)', 'print(df.to_string())']","['import pandas as pd', 'df.sort_index(inplace=True)', 'print(df.to_string())']","['df.sort_index(inplace=True)', 'print(df.to_string())']",,
22221272,,[],[''],[],[],[]
22221675,"df = pd.DataFrame( {'a':['A','A','B','B','B','C'], 'b':[1,2,5,5,4,6]})
df
df.groupby('a')['b'].apply(list)
a
A       [1, 2]
B    [5, 5, 4]
C          [6]","[""df = pd.DataFrame( {'a':['A','A','B','B','B','C'], 'b':[1,2,5,5,4,6]})"", ""df.groupby('a')['b'].apply(list)""]","['df', ""df.groupby('a')['b'].apply(list)"", 'a', 'A       [1, 2]', 'B    [5, 5, 4]', 'C          [6]']","[""df.groupby('a')['b'].apply(list)""]",,
22233719,"cols = pd.MultiIndex.from_tuples([(""a"", ""b""), (""a"", ""c"")])
df = pd.DataFrame([[1,2], [3,4]], columns=cols)
df
df.columns = df.columns.droplevel()
df","['cols = pd.MultiIndex.from_tuples([(""a"", ""b""), (""a"", ""c"")])', 'df = pd.DataFrame([[1,2], [3,4]], columns=cols)', 'df.columns = df.columns.droplevel()']","['cols = pd.MultiIndex.from_tuples([(""a"", ""b""), (""a"", ""c"")])', 'df', 'df.columns = df.columns.droplevel()', 'df']","['cols = pd.MultiIndex.from_tuples([(""a"", ""b""), (""a"", ""c"")])', 'df.columns = df.columns.droplevel()']",,
22233851,"@app.route('/analysis/<filename>')
def analysis(filename):
    x = pd.DataFrame(np.random.randn(20, 5))
    return render_template(""analysis.html"", name=filename, data=x)","['    x = pd.DataFrame(np.random.randn(20, 5))']","[""@app.route('/analysis/<filename>')"", 'def analysis(filename):', '    return render_template(""analysis.html"", name=filename, data=x)']",[],,
22235393,"df.describe()
df.describe().transpose()","['df.describe()', 'df.describe().transpose()']","['df.describe()', 'df.describe().transpose()']","['df.describe()', 'df.describe().transpose()']",,
22238380,"data['result'] = data['result'].map(lambda x: str(x)[:-1])
data['result'] = data['result'].map(lambda x: str(x)[2:])","[""data['result'] = data['result'].map(lambda x: str(x)[:-1])"", ""data['result'] = data['result'].map(lambda x: str(x)[2:])""]","[""data['result'] = data['result'].map(lambda x: str(x)[:-1])"", ""data['result'] = data['result'].map(lambda x: str(x)[2:])""]","[""data['result'] = data['result'].map(lambda x: str(x)[:-1])"", ""data['result'] = data['result'].map(lambda x: str(x)[2:])""]",,
22247593,df['x'].str.lower(),"[""df['x'].str.lower()""]","[""df['x'].str.lower()""]","[""df['x'].str.lower()""]",,
22257615,"df = DataFrame(np.random.randn(10,2))
df.iloc[3:6,0] = np.nan
df
df.describe()
df.info()
dtypes: float64(2)
len(df.index)-df.count()
df.isnull().sum()
dtype: int64","['df.iloc[3:6,0] = np.nan', 'df.describe()', 'df.info()', 'len(df.index)-df.count()', 'df.isnull().sum()']","['df = DataFrame(np.random.randn(10,2))', 'df.iloc[3:6,0] = np.nan', 'df', 'df.describe()', 'df.info()', 'dtypes: float64(2)', 'len(df.index)-df.count()', 'df.isnull().sum()', 'dtype: int64']","['df.iloc[3:6,0] = np.nan', 'df.describe()', 'df.info()', 'len(df.index)-df.count()', 'df.isnull().sum()']",,
22258061,"X = np.column_stack((X, AllAlexaAndGoogleInfo))",[],"['X = np.column_stack((X, AllAlexaAndGoogleInfo))']",[],[],[]
22259008,"import pandas
import random
n = 1000000 
s = 10000 
filename = ""data.txt""
skip = sorted(random.sample(xrange(n),n-s))
df = pandas.read_csv(filename, skiprows=skip)
import pandas
import random
filename = ""data.txt""
n = sum(1 for line in open(filename)) - 1 
s = 10000 
skip = sorted(random.sample(xrange(1,n+1),n-s)) 
df = pandas.read_csv(filename, skiprows=skip)","['skip = sorted(random.sample(xrange(n),n-s))', 'df = pandas.read_csv(filename, skiprows=skip)', 'skip = sorted(random.sample(xrange(1,n+1),n-s)) ', 'df = pandas.read_csv(filename, skiprows=skip)']","['import pandas', 'import random', 'n = 1000000 ', 's = 10000 ', 'filename = ""data.txt""', 'skip = sorted(random.sample(xrange(n),n-s))', 'df = pandas.read_csv(filename, skiprows=skip)', 'import pandas', 'import random', 'filename = ""data.txt""', 'n = sum(1 for line in open(filename)) - 1 ', 's = 10000 ', 'skip = sorted(random.sample(xrange(1,n+1),n-s)) ', 'df = pandas.read_csv(filename, skiprows=skip)']","['skip = sorted(random.sample(xrange(n),n-s))', 'df = pandas.read_csv(filename, skiprows=skip)', 'skip = sorted(random.sample(xrange(1,n+1),n-s)) ', 'df = pandas.read_csv(filename, skiprows=skip)']",,
22264337,"import numpy as np
from scipy import sparse
X = sparse.rand(10, 10000)
xt = np.random.random((10, 1))
X = sparse.rand(100, 10000)
xt = np.random.random((100, 1))
xt = xt.astype('object') ","[""xt = xt.astype('object') ""]","['import numpy as np', 'from scipy import sparse', 'X = sparse.rand(10, 10000)', 'xt = np.random.random((10, 1))', 'X = sparse.rand(100, 10000)', 'xt = np.random.random((100, 1))', ""xt = xt.astype('object') ""]","[""xt = xt.astype('object') ""]",,
22276757,,[],[''],[],[],[]
22341390,"from pandas import *
d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),
    'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}
df = DataFrame(d)
dfList = df['one'].tolist()","[""dfList = df['one'].tolist()""]","['from pandas import *', ""d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),"", ""    'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}"", 'df = DataFrame(d)', ""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]"
22365284,"df1.join(df2, how='inner')
merge(df1.reset_index(),
      df2.reset_index(),
      on=['index1'],
      how='inner'
     ).set_index(['index1','index2'])","[""df1.join(df2, how='inner')"", 'merge(df1.reset_index(),', '      df2.reset_index(),']","[""df1.join(df2, how='inner')"", 'merge(df1.reset_index(),', '      df2.reset_index(),', ""      on=['index1'],"", ""      how='inner'"", ""     ).set_index(['index1','index2'])""]","[""df1.join(df2, how='inner')"", 'merge(df1.reset_index(),', '      df2.reset_index(),']",,
22368682,"aggregated = df.groupby(['model', 'training_examples']).aggregate(np.mean)
aggregated.plot(x='training_examples', y='accuracy', label='model')
for index, group in df.groupby(['model']):
    group_agg = group.groupby(['training_examples']).aggregate(np.mean)
    group_agg.plot(y='accuracy', label=index)","[""aggregated = df.groupby(['model', 'training_examples']).aggregate(np.mean)"", ""aggregated.plot(x='training_examples', y='accuracy', label='model')"", ""for index, group in df.groupby(['model']):"", ""    group_agg = group.groupby(['training_examples']).aggregate(np.mean)"", ""    group_agg.plot(y='accuracy', label=index)""]","[""aggregated = df.groupby(['model', 'training_examples']).aggregate(np.mean)"", ""aggregated.plot(x='training_examples', y='accuracy', label='model')"", ""for index, group in df.groupby(['model']):"", ""    group_agg = group.groupby(['training_examples']).aggregate(np.mean)"", ""    group_agg.plot(y='accuracy', label=index)""]","[""aggregated = df.groupby(['model', 'training_examples']).aggregate(np.mean)"", ""aggregated.plot(x='training_examples', y='accuracy', label='model')"", ""for index, group in df.groupby(['model']):"", ""    group_agg = group.groupby(['training_examples']).aggregate(np.mean)"", ""    group_agg.plot(y='accuracy', label=index)""]",,
22391554,"df = pd.DataFrame({'a':list('abssbab')})
df.groupby('a').count()
a   
df['a'].value_counts()
dtype: int64
df['freq'] = df.groupby('a')['a'].transform('count')
df","[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]","[""df.groupby('a').count()"", 'a   ', ""df['a'].value_counts()"", 'dtype: int64', ""df['freq'] = df.groupby('a')['a'].transform('count')"", 'df']","[""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]","[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()""]","[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]"
22455322,,[],[''],[],[],[]
22471217,"df = pd.DataFrame([[1, 2.3456, 'c']])
df.dtypes
msk = df.dtypes == np.float64  
msk
df.loc[:, msk]
np.round(df.loc[:, msk], 2)
df.loc[:, msk] = np.round(df.loc[:, msk], 2)
df","[""df = pd.DataFrame([[1, 2.3456, 'c']])"", 'df.dtypes', 'msk = df.dtypes == np.float64  ', 'df.loc[:, msk]', 'np.round(df.loc[:, msk], 2)', 'df.loc[:, msk] = np.round(df.loc[:, msk], 2)']","['df.dtypes', 'msk = df.dtypes == np.float64  ', 'msk', 'df.loc[:, msk]', 'np.round(df.loc[:, msk], 2)', 'df.loc[:, msk] = np.round(df.loc[:, msk], 2)', 'df']","['df.dtypes', 'msk = df.dtypes == np.float64  ', 'df.loc[:, msk]', 'np.round(df.loc[:, msk], 2)', 'df.loc[:, msk] = np.round(df.loc[:, msk], 2)']",,
22475141,"df = pd.DataFrame([[1, 2.3456, 'c', 'd', 78]], columns=list(""ABCDE""))
df
df.dtypes
dtype: object
g = df.columns.to_series().groupby(df.dtypes).groups
g
{dtype('int64'): ['A', 'E'], dtype('float64'): ['B'], dtype('O'): ['C', 'D']}
{'object': ['C', 'D'], 'int64': ['A', 'E'], 'float64': ['B']}","['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df', 'df.dtypes', 'dtype: object', 'g = df.columns.to_series().groupby(df.dtypes).groups', 'g', ""{dtype('int64'): ['A', 'E'], dtype('float64'): ['B'], dtype('O'): ['C', 'D']}"", ""{'object': ['C', 'D'], 'int64': ['A', 'E'], 'float64': ['B']}""]","['df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']"
22484249,"import matplotlib.pyplot as plt
fig, axes = plt.subplots(nrows=2, ncols=2)
df1.plot(ax=axes[0,0])
df2.plot(ax=axes[0,1])
...","['df1.plot(ax=axes[0,0])', 'df2.plot(ax=axes[0,1])']","['import matplotlib.pyplot as plt', 'fig, axes = plt.subplots(nrows=2, ncols=2)', 'df1.plot(ax=axes[0,0])', 'df2.plot(ax=axes[0,1])', '...']","['df1.plot(ax=axes[0,0])', 'df2.plot(ax=axes[0,1])']",,
22485573,"df['Name'].isin(['Alice', 'Bob'])
df[df.Name.isin(['Alice', 'Bob'])]","[""df['Name'].isin(['Alice', 'Bob'])"", ""df[df.Name.isin(['Alice', 'Bob'])]""]","[""df['Name'].isin(['Alice', 'Bob'])"", ""df[df.Name.isin(['Alice', 'Bob'])]""]","[""df['Name'].isin(['Alice', 'Bob'])"", ""df[df.Name.isin(['Alice', 'Bob'])]""]",,
22487898,"from multiprocessing import Manager
mgr = Manager()
ns = mgr.Namespace()
ns.df = my_dataframe
p = Process(target=worker, args=(ns, work_unit))",[],"['from multiprocessing import Manager', 'mgr = Manager()', 'ns = mgr.Namespace()', 'ns.df = my_dataframe', 'p = Process(target=worker, args=(ns, work_unit))']",[],[],[]
22496075,,[],[''],[],[],[]
22543333,"from matplotlib import pyplot as plt
plt.style.use('ggplot')
pd.options.display.mpl_style = 'default'","[""plt.style.use('ggplot')""]","['from matplotlib import pyplot as plt', ""plt.style.use('ggplot')"", ""pd.options.display.mpl_style = 'default'""]","[""plt.style.use('ggplot')""]",,
22546459,foo = df.ix[(df['column1']==value) | (df['columns2'] == 'b') | (df['column3'] == 'c')],[],"[""foo = df.ix[(df['column1']==value) | (df['columns2'] == 'b') | (df['column3'] == 'c')]""]",[],[],[]
22547347,"n = 10
df = DataFrame(randint(4, size=(n, 2)), columns=list('ab'))
df
df.isin([1, 2])
df.isin([1, 2]).any(1)
df.loc[df.isin([1, 2]).any(1)]","['df.isin([1, 2])', 'df.isin([1, 2]).any(1)', 'df.loc[df.isin([1, 2]).any(1)]']","['n = 10', ""df = DataFrame(randint(4, size=(n, 2)), columns=list('ab'))"", 'df', 'df.isin([1, 2])', 'df.isin([1, 2]).any(1)', 'df.loc[df.isin([1, 2]).any(1)]']","['df.isin([1, 2])', 'df.isin([1, 2]).any(1)', 'df.loc[df.isin([1, 2]).any(1)]']",,
22553757,"nms.dropna(thresh=2)
nms
nms = nms.dropna(thresh=2)
nms[nms.name.notnull()]
nms[nms.name.notnull()]","['nms.dropna(thresh=2)', 'nms = nms.dropna(thresh=2)', 'nms[nms.name.notnull()]', 'nms[nms.name.notnull()]']","['nms.dropna(thresh=2)', 'nms', 'nms = nms.dropna(thresh=2)', 'nms[nms.name.notnull()]', 'nms[nms.name.notnull()]']","['nms.dropna(thresh=2)', 'nms = nms.dropna(thresh=2)', 'nms[nms.name.notnull()]', 'nms[nms.name.notnull()]']",,
22588340,"value = re.sub(r""[^0-9]+"", """", value)","['value = re.sub(r""[^0-9]+"", """", value)']","['value = re.sub(r""[^0-9]+"", """", value)']","['value = re.sub(r""[^0-9]+"", """", value)']",,
22591024,"import pandas as pd
df = pd.DataFrame(['$40,000*','$40000 conditions attached'], columns=['P'])
print(df)
df['P'] = df['P'].str.replace(r'\D+', '').astype('int')
print(df)","[""df = pd.DataFrame(['$40,000*','$40000 conditions attached'], columns=['P'])"", ""df['P'] = df['P'].str.replace(r'\\D+', '').astype('int')""]","['import pandas as pd', 'print(df)', ""df['P'] = df['P'].str.replace(r'\\D+', '').astype('int')"", 'print(df)']","[""df['P'] = df['P'].str.replace(r'\\D+', '').astype('int')""]",,
22591267,"df1 = df[(df.a != -1) & (df.b != -1)]
df2 = df[(df.a != -1) | (df.b != -1)]",[],"['df1 = df[(df.a != -1) & (df.b != -1)]', 'df2 = df[(df.a != -1) | (df.b != -1)]']",[],[],[]
22596982,,[],[''],[],[],[]
22605281,"import sys
if sys.version_info[0] < 3: 
    from StringIO import StringIO
else:
    from io import StringIO
import pandas as pd
TESTDATA=StringIO(""""""col1;col2;col3
    1;4.4;99
    2;4.5;200
    3;4.7;65
    4;3.2;140
    """""")
df = pd.read_csv(TESTDATA, sep="";"")","['df = pd.read_csv(TESTDATA, sep="";"")']","['import sys', 'if sys.version_info[0] < 3: ', '    from StringIO import StringIO', 'else:', '    from io import StringIO', 'import pandas as pd', 'TESTDATA=StringIO(""""""col1;col2;col3', '    1;4.4;99', '    2;4.5;200', '    3;4.7;65', '    4;3.2;140', '    """""")', 'df = pd.read_csv(TESTDATA, sep="";"")']","['df = pd.read_csv(TESTDATA, sep="";"")']",,
22642484,"df = pd.DataFrame([[1., 2.], [3., 4.]], columns=['A', 'B'])
df2 = pd.DataFrame([[5., 10.]], columns=['A', 'B'])
df.div(df2)
df.div(df2.iloc[0])","[""df = pd.DataFrame([[1., 2.], [3., 4.]], columns=['A', 'B'])"", ""df2 = pd.DataFrame([[5., 10.]], columns=['A', 'B'])"", 'df.div(df2)', 'df.div(df2.iloc[0])']","['df.div(df2)', 'df.div(df2.iloc[0])']","['df.div(df2)', 'df.div(df2.iloc[0])']",,
22643040,"import pandas as pd
data1 = {""a"":[1.,3.,5.,2.],
         ""b"":[4.,8.,3.,7.],
         ""c"":[5.,45.,67.,34]}
data2 = {""a"":[4.],
         ""b"":[2.],
         ""c"":[11.]}
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2) 
df1.div(df2.ix[0],axis='columns')","['df1 = pd.DataFrame(data1)', 'df2 = pd.DataFrame(data2) ', ""df1.div(df2.ix[0],axis='columns')""]","['import pandas as pd', 'data1 = {""a"":[1.,3.,5.,2.],', '         ""b"":[4.,8.,3.,7.],', '         ""c"":[5.,45.,67.,34]}', 'data2 = {""a"":[4.],', '         ""b"":[2.],', '         ""c"":[11.]}', ""df1.div(df2.ix[0],axis='columns')""]","[""df1.div(df2.ix[0],axis='columns')""]",,
22650075,"df = pd.DataFrame({'a':[0,0,1,1], 'b':[0,1,0,1]})
df = df[(df.T != 0).any()]
df","[""df = pd.DataFrame({'a':[0,0,1,1], 'b':[0,1,0,1]})"", 'df = df[(df.T != 0).any()]']","['df = df[(df.T != 0).any()]', 'df']",['df = df[(df.T != 0).any()]'],,
22650162,"df.loc[~(df==0).all(axis=1)]
df.loc[(df!=0).any(axis=1)]","['df.loc[~(df==0).all(axis=1)]', 'df.loc[(df!=0).any(axis=1)]']","['df.loc[~(df==0).all(axis=1)]', 'df.loc[(df!=0).any(axis=1)]']","['df.loc[~(df==0).all(axis=1)]', 'df.loc[(df!=0).any(axis=1)]']",,
22651188,,[],[''],[],[],[]
22653050,"df
df.reset_index().values
df.reset_index().values.ravel().view(dtype=[('index', int), ('A', float), ('B', float), ('C', float)])","['df.reset_index().values', ""df.reset_index().values.ravel().view(dtype=[('index', int), ('A', float), ('B', float), ('C', float)])""]","['df', 'df.reset_index().values', ""df.reset_index().values.ravel().view(dtype=[('index', int), ('A', float), ('B', float), ('C', float)])""]","['df.reset_index().values', ""df.reset_index().values.ravel().view(dtype=[('index', int), ('A', float), ('B', float), ('C', float)])""]",,
22657894,"df = df.rename(columns=lambda x: x.replace('$', ''))
df.rename(columns=lambda x: x.replace('$', ''), inplace=True)","[""df = df.rename(columns=lambda x: x.replace('$', ''))"", ""df.rename(columns=lambda x: x.replace('$', ''), inplace=True)""]","[""df = df.rename(columns=lambda x: x.replace('$', ''))"", ""df.rename(columns=lambda x: x.replace('$', ''), inplace=True)""]","[""df = df.rename(columns=lambda x: x.replace('$', ''))"", ""df.rename(columns=lambda x: x.replace('$', ''), inplace=True)""]",,
22674279,"df[(df.Product == p_id) & (df.Time> start_time) & (df.Time < end_time)][['Time','Product']]",[],"[""df[(df.Product == p_id) & (df.Time> start_time) & (df.Time < end_time)][['Time','Product']]""]",[],[],[]
22676213,"import pandas as pd
left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key')
right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key')
left.join(right, lsuffix='_l', rsuffix='_r')
key            
left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]})
right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]})
left.merge(right, on=('key'), suffixes=('_l', '_r'))","[""left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key')"", ""right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key')"", ""left.join(right, lsuffix='_l', rsuffix='_r')"", ""left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]})"", ""right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]})"", ""left.merge(right, on=('key'), suffixes=('_l', '_r'))""]","['import pandas as pd', ""left.join(right, lsuffix='_l', rsuffix='_r')"", 'key            ', ""left.merge(right, on=('key'), suffixes=('_l', '_r'))""]","[""left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key')"", ""right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key')"", ""left.join(right, lsuffix='_l', rsuffix='_r')"", ""left.merge(right, on=('key'), suffixes=('_l', '_r'))""]",,
22677264,,[],[''],[],[],[]
22697903,"for y in agg.columns:
    if(agg[y].dtype == np.float64 or agg[y].dtype == np.int64):
          treat_numeric(agg[y])
    else:
          treat_str(agg[y])",['    if(agg[y].dtype == np.float64 or agg[y].dtype == np.int64):'],"['for y in agg.columns:', '    if(agg[y].dtype == np.float64 or agg[y].dtype == np.int64):', '          treat_numeric(agg[y])', '    else:', '          treat_str(agg[y])']",['    if(agg[y].dtype == np.float64 or agg[y].dtype == np.int64):'],,
22702814,"df[[""A"", ""B""]].multiply(df[""C""], axis=""index"")",[],"['df[[""A"", ""B""]].multiply(df[""C""], axis=""index"")']",[],[],[]
22719983,"df['bar'] = df['bar'].str.cat(df['foo'].values.astype(str), sep=' is ')","[""df['bar'] = df['bar'].str.cat(df['foo'].values.astype(str), sep=' is ')""]","[""df['bar'] = df['bar'].str.cat(df['foo'].values.astype(str), sep=' is ')""]","[""df['bar'] = df['bar'].str.cat(df['foo'].values.astype(str), sep=' is ')""]",,
22720823,"df = pd.DataFrame([[1, 3], [2, 4]], columns=['A', 'B'])
df2 = pd.DataFrame([[1, 5], [1, 6]], columns=['A', 'C'])
df.merge(df2, how='left')  
df2.drop_duplicates(subset=['A'])  
df.merge(df2.drop_duplicates(subset=['A']), how='left')","[""df = pd.DataFrame([[1, 3], [2, 4]], columns=['A', 'B'])"", ""df2 = pd.DataFrame([[1, 5], [1, 6]], columns=['A', 'C'])"", ""df.merge(df2, how='left')  "", ""df2.drop_duplicates(subset=['A'])  "", ""df.merge(df2.drop_duplicates(subset=['A']), how='left')""]","[""df.merge(df2, how='left')  "", ""df2.drop_duplicates(subset=['A'])  "", ""df.merge(df2.drop_duplicates(subset=['A']), how='left')""]","[""df.merge(df2, how='left')  "", ""df2.drop_duplicates(subset=['A'])  "", ""df.merge(df2.drop_duplicates(subset=['A']), how='left')""]",,
22798849,"df.to_csv(filename, date_format='%Y%m%d')","[""df.to_csv(filename, date_format='%Y%m%d')""]","[""df.to_csv(filename, date_format='%Y%m%d')""]","[""df.to_csv(filename, date_format='%Y%m%d')""]",,
22798911,"df = pd.read_clipboard().iloc[1:]
df = pd.melt(df, id_vars=[""date""], var_name=""condition"")
ax = df.groupby([""condition"", ""date""]).mean().unstack(""condition"").plot()
x = np.arange(len(df.date.unique()))
palette = sns.color_palette()
for cond, cond_df in df.groupby(""condition""):
    low = cond_df.groupby(""date"").value.apply(np.percentile, 25)
    high = cond_df.groupby(""date"").value.apply(np.percentile, 75)
    ax.fill_between(x, low, high, alpha=.2, color=palette.pop(0))","['df = pd.read_clipboard().iloc[1:]', 'df = pd.melt(df, id_vars=[""date""], var_name=""condition"")', 'ax = df.groupby([""condition"", ""date""]).mean().unstack(""condition"").plot()', 'x = np.arange(len(df.date.unique()))', 'for cond, cond_df in df.groupby(""condition""):', '    low = cond_df.groupby(""date"").value.apply(np.percentile, 25)', '    high = cond_df.groupby(""date"").value.apply(np.percentile, 75)', '    ax.fill_between(x, low, high, alpha=.2, color=palette.pop(0))']","['df = pd.read_clipboard().iloc[1:]', 'df = pd.melt(df, id_vars=[""date""], var_name=""condition"")', 'ax = df.groupby([""condition"", ""date""]).mean().unstack(""condition"").plot()', 'x = np.arange(len(df.date.unique()))', 'palette = sns.color_palette()', 'for cond, cond_df in df.groupby(""condition""):', '    low = cond_df.groupby(""date"").value.apply(np.percentile, 25)', '    high = cond_df.groupby(""date"").value.apply(np.percentile, 75)', '    ax.fill_between(x, low, high, alpha=.2, color=palette.pop(0))']","['df = pd.read_clipboard().iloc[1:]', 'df = pd.melt(df, id_vars=[""date""], var_name=""condition"")', 'ax = df.groupby([""condition"", ""date""]).mean().unstack(""condition"").plot()', 'x = np.arange(len(df.date.unique()))', 'for cond, cond_df in df.groupby(""condition""):', '    low = cond_df.groupby(""date"").value.apply(np.percentile, 25)', '    high = cond_df.groupby(""date"").value.apply(np.percentile, 75)', '    ax.fill_between(x, low, high, alpha=.2, color=palette.pop(0))']",,
22799358,"pd.DataFrame(out.tolist(), columns=['out-1','out-2'], index=out.index)
y                                ","[""pd.DataFrame(out.tolist(), columns=['out-1','out-2'], index=out.index)""]",['y                                '],"[""pd.DataFrame(out.tolist(), columns=['out-1','out-2'], index=out.index)""]",,
22799830,"pivoted = df.pivot('salesman', 'product', 'price')","[""pivoted = df.pivot('salesman', 'product', 'price')""]","[""pivoted = df.pivot('salesman', 'product', 'price')""]","[""pivoted = df.pivot('salesman', 'product', 'price')""]",,
22799916,"df['idx'] = df.groupby('Salesman').cumcount()
Salesman                                   
df['prod_idx'] = 'product_' + df.idx.astype(str)
df['prc_idx'] = 'price_' + df.idx.astype(str)
product = df.pivot(index='Salesman',columns='prod_idx',values='product')
prc = df.pivot(index='Salesman',columns='prc_idx',values='price')
reshape = pd.concat([product,prc],axis=1)
reshape['Height'] = df.set_index('Salesman')['Height'].drop_duplicates()
Salesman                                                                 
df['idx'] = df.groupby('Salesman').cumcount()
tmp = []
for var in ['product','price']:
    df['tmp_idx'] = var + '_' + df.idx.astype(str)
    tmp.append(df.pivot(index='Salesman',columns='tmp_idx',values=var))
reshape = pd.concat(tmp,axis=1)","[""df['idx'] = df.groupby('Salesman').cumcount()"", ""df['prod_idx'] = 'product_' + df.idx.astype(str)"", ""df['prc_idx'] = 'price_' + df.idx.astype(str)"", ""product = df.pivot(index='Salesman',columns='prod_idx',values='product')"", ""prc = df.pivot(index='Salesman',columns='prc_idx',values='price')"", 'reshape = pd.concat([product,prc],axis=1)', ""reshape['Height'] = df.set_index('Salesman')['Height'].drop_duplicates()"", ""df['idx'] = df.groupby('Salesman').cumcount()"", ""    df['tmp_idx'] = var + '_' + df.idx.astype(str)"", ""    tmp.append(df.pivot(index='Salesman',columns='tmp_idx',values=var))"", 'reshape = pd.concat(tmp,axis=1)']","[""df['idx'] = df.groupby('Salesman').cumcount()"", 'Salesman                                   ', ""df['prod_idx'] = 'product_' + df.idx.astype(str)"", ""df['prc_idx'] = 'price_' + df.idx.astype(str)"", ""product = df.pivot(index='Salesman',columns='prod_idx',values='product')"", ""prc = df.pivot(index='Salesman',columns='prc_idx',values='price')"", 'reshape = pd.concat([product,prc],axis=1)', ""reshape['Height'] = df.set_index('Salesman')['Height'].drop_duplicates()"", 'Salesman                                                                 ', ""df['idx'] = df.groupby('Salesman').cumcount()"", 'tmp = []', ""for var in ['product','price']:"", ""    df['tmp_idx'] = var + '_' + df.idx.astype(str)"", ""    tmp.append(df.pivot(index='Salesman',columns='tmp_idx',values=var))"", 'reshape = pd.concat(tmp,axis=1)']","[""df['idx'] = df.groupby('Salesman').cumcount()"", ""df['prod_idx'] = 'product_' + df.idx.astype(str)"", ""df['prc_idx'] = 'price_' + df.idx.astype(str)"", ""product = df.pivot(index='Salesman',columns='prod_idx',values='product')"", ""prc = df.pivot(index='Salesman',columns='prc_idx',values='price')"", 'reshape = pd.concat([product,prc],axis=1)', ""reshape['Height'] = df.set_index('Salesman')['Height'].drop_duplicates()"", ""df['idx'] = df.groupby('Salesman').cumcount()"", ""    df['tmp_idx'] = var + '_' + df.idx.astype(str)"", ""    tmp.append(df.pivot(index='Salesman',columns='tmp_idx',values=var))"", 'reshape = pd.concat(tmp,axis=1)']",,
22825954,"ts = pd.Timestamp('2014-01-23 00:00:00', tz=None)
ts.to_pydatetime()
rng = pd.date_range('1/10/2011', periods=3, freq='D')
rng.to_pydatetime()
array([datetime.datetime(2011, 1, 10, 0, 0),
       datetime.datetime(2011, 1, 11, 0, 0),
       datetime.datetime(2011, 1, 12, 0, 0)], dtype=object)","[""ts = pd.Timestamp('2014-01-23 00:00:00', tz=None)"", 'ts.to_pydatetime()', ""rng = pd.date_range('1/10/2011', periods=3, freq='D')"", 'rng.to_pydatetime()']","[""ts = pd.Timestamp('2014-01-23 00:00:00', tz=None)"", 'ts.to_pydatetime()', ""rng = pd.date_range('1/10/2011', periods=3, freq='D')"", 'rng.to_pydatetime()', 'array([datetime.datetime(2011, 1, 10, 0, 0),', '       datetime.datetime(2011, 1, 11, 0, 0),', '       datetime.datetime(2011, 1, 12, 0, 0)], dtype=object)']","[""ts = pd.Timestamp('2014-01-23 00:00:00', tz=None)"", 'ts.to_pydatetime()', ""rng = pd.date_range('1/10/2011', periods=3, freq='D')"", 'rng.to_pydatetime()']",,
22836353,"df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])
ax = plt.figure(figsize=(10, 6)).add_subplot(111)
df.plot(ax=ax, kind='bar', legend=False)
bars = ax.patches
hatches = ''.join(h*len(df) for h in 'x/O.')
for bar, hatch in zip(bars, hatches):
    bar.set_hatch(hatch)
ax.legend(loc='center right', bbox_to_anchor=(1, 1), ncol=4)","[""df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])"", ""df.plot(ax=ax, kind='bar', legend=False)"", ""hatches = ''.join(h*len(df) for h in 'x/O.')""]","['ax = plt.figure(figsize=(10, 6)).add_subplot(111)', ""df.plot(ax=ax, kind='bar', legend=False)"", 'bars = ax.patches', ""hatches = ''.join(h*len(df) for h in 'x/O.')"", 'for bar, hatch in zip(bars, hatches):', '    bar.set_hatch(hatch)', ""ax.legend(loc='center right', bbox_to_anchor=(1, 1), ncol=4)""]","[""df.plot(ax=ax, kind='bar', legend=False)"", ""hatches = ''.join(h*len(df) for h in 'x/O.')""]",,
22840737,,[],[''],[],[],[]
22845857,"import pandas as pd
import matplotlib.cm as cm
import numpy as np
import matplotlib.pyplot as plt
def plot_clustered_stacked(dfall, labels=None, title=""multiple stacked bar plot"",  H=""/"", **kwargs):
    """"""Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. 
labels is a list of the names of the dataframe, used for the legend
title is a string for the title of the plot
H is the hatch used for identification of the different dataframe""""""
    n_df = len(dfall)
    n_col = len(dfall[0].columns) 
    n_ind = len(dfall[0].index)
    axe = plt.subplot(111)
    for df in dfall : 
        axe = df.plot(kind=""bar"",
                      linewidth=0,
                      stacked=True,
                      ax=axe,
                      legend=False,
                      grid=False,
                      **kwargs)  
    h,l = axe.get_legend_handles_labels() 
    for i in range(0, n_df * n_col, n_col): 
        for j, pa in enumerate(h[i:i+n_col]):
            for rect in pa.patches: 
                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))
                rect.set_hatch(H * int(i / n_col)) 
                rect.set_width(1 / float(n_df + 1))
    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)
    axe.set_xticklabels(df.index, rotation = 0)
    axe.set_title(title)
    n=[]        
    for i in range(n_df):
        n.append(axe.bar(0, 0, color=""gray"", hatch=H * i))
    l1 = axe.legend(h[:n_col], l[:n_col], loc=[1.01, 0.5])
    if labels is not None:
        l2 = plt.legend(n, labels, loc=[1.01, 0.1]) 
    axe.add_artist(l1)
    return axe
df1 = pd.DataFrame(np.random.rand(4, 5),
                   index=[""A"", ""B"", ""C"", ""D""],
                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])
df2 = pd.DataFrame(np.random.rand(4, 5),
                   index=[""A"", ""B"", ""C"", ""D""],
                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])
df3 = pd.DataFrame(np.random.rand(4, 5),
                   index=[""A"", ""B"", ""C"", ""D""], 
                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])
plot_clustered_stacked([df1, df2, df3],[""df1"", ""df2"", ""df3""])
plot_clustered_stacked([df1, df2, df3],
                       [""df1"", ""df2"", ""df3""],
                       cmap=plt.cm.viridis)
df1[""Name""] = ""df1""
df2[""Name""] = ""df2""
df3[""Name""] = ""df3""
dfall = pd.concat([pd.melt(i.reset_index(),
                           id_vars=[""Name"", ""index""]) 
                   for i in [df1, df2, df3]],
                   ignore_index=True)
dfall.set_index([""Name"", ""index"", ""variable""], inplace=1)
dfall[""vcs""] = dfall.groupby(level=[""Name"", ""index""]).cumsum()
dfall.reset_index(inplace=True) 
dfall.head(6)
c = [""blue"", ""purple"", ""red"", ""green"", ""pink""]
for i, g in enumerate(dfall.groupby(""variable"")):
    ax = sns.barplot(data=g[1],
                     x=""index"",
                     y=""vcs"",
                     hue=""Name"",
                     color=c[i],
                     zorder=-i, 
                     edgecolor=""k"")
ax.legend_.remove() ","['    n_ind = len(dfall[0].index)', '        axe = df.plot(kind=""bar"",', '    axe.set_xticklabels(df.index, rotation = 0)', '        n.append(axe.bar(0, 0, color=""gray"", hatch=H * i))', 'df1 = pd.DataFrame(np.random.rand(4, 5),', 'df2 = pd.DataFrame(np.random.rand(4, 5),', 'df3 = pd.DataFrame(np.random.rand(4, 5),', 'dfall = pd.concat([pd.melt(i.reset_index(),', 'dfall.set_index([""Name"", ""index"", ""variable""], inplace=1)', 'dfall[""vcs""] = dfall.groupby(level=[""Name"", ""index""]).cumsum()', 'dfall.reset_index(inplace=True) ', 'dfall.head(6)', 'for i, g in enumerate(dfall.groupby(""variable"")):']","['import pandas as pd', 'import matplotlib.cm as cm', 'import numpy as np', 'import matplotlib.pyplot as plt', 'def plot_clustered_stacked(dfall, labels=None, title=""multiple stacked bar plot"",  H=""/"", **kwargs):', '    """"""Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. ', 'labels is a list of the names of the dataframe, used for the legend', 'title is a string for the title of the plot', 'H is the hatch used for identification of the different dataframe""""""', '    n_df = len(dfall)', '    n_col = len(dfall[0].columns) ', '    n_ind = len(dfall[0].index)', '    axe = plt.subplot(111)', '    for df in dfall : ', '        axe = df.plot(kind=""bar"",', '                      linewidth=0,', '                      stacked=True,', '                      ax=axe,', '                      legend=False,', '                      grid=False,', '                      **kwargs)  ', '    h,l = axe.get_legend_handles_labels() ', '    for i in range(0, n_df * n_col, n_col): ', '        for j, pa in enumerate(h[i:i+n_col]):', '            for rect in pa.patches: ', '                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))', '                rect.set_hatch(H * int(i / n_col)) ', '                rect.set_width(1 / float(n_df + 1))', '    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)', '    axe.set_xticklabels(df.index, rotation = 0)', '    axe.set_title(title)', '    n=[]        ', '    for i in range(n_df):', '        n.append(axe.bar(0, 0, color=""gray"", hatch=H * i))', '    l1 = axe.legend(h[:n_col], l[:n_col], loc=[1.01, 0.5])', '    if labels is not None:', '        l2 = plt.legend(n, labels, loc=[1.01, 0.1]) ', '    axe.add_artist(l1)', '    return axe', '                   index=[""A"", ""B"", ""C"", ""D""],', '                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])', '                   index=[""A"", ""B"", ""C"", ""D""],', '                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])', '                   index=[""A"", ""B"", ""C"", ""D""], ', '                   columns=[""I"", ""J"", ""K"", ""L"", ""M""])', 'plot_clustered_stacked([df1, df2, df3],[""df1"", ""df2"", ""df3""])', 'plot_clustered_stacked([df1, df2, df3],', '                       [""df1"", ""df2"", ""df3""],', '                       cmap=plt.cm.viridis)', 'df1[""Name""] = ""df1""', 'df2[""Name""] = ""df2""', 'df3[""Name""] = ""df3""', 'dfall = pd.concat([pd.melt(i.reset_index(),', '                           id_vars=[""Name"", ""index""]) ', '                   for i in [df1, df2, df3]],', '                   ignore_index=True)', 'dfall.set_index([""Name"", ""index"", ""variable""], inplace=1)', 'dfall[""vcs""] = dfall.groupby(level=[""Name"", ""index""]).cumsum()', 'dfall.reset_index(inplace=True) ', 'dfall.head(6)', 'c = [""blue"", ""purple"", ""red"", ""green"", ""pink""]', 'for i, g in enumerate(dfall.groupby(""variable"")):', '    ax = sns.barplot(data=g[1],', '                     x=""index"",', '                     y=""vcs"",', '                     hue=""Name"",', '                     color=c[i],', '                     zorder=-i, ', '                     edgecolor=""k"")', 'ax.legend_.remove() ']","['    n_ind = len(dfall[0].index)', '        axe = df.plot(kind=""bar"",', '    axe.set_xticklabels(df.index, rotation = 0)', '        n.append(axe.bar(0, 0, color=""gray"", hatch=H * i))', 'dfall = pd.concat([pd.melt(i.reset_index(),', 'dfall.set_index([""Name"", ""index"", ""variable""], inplace=1)', 'dfall[""vcs""] = dfall.groupby(level=[""Name"", ""index""]).cumsum()', 'dfall.reset_index(inplace=True) ', 'dfall.head(6)', 'for i, g in enumerate(dfall.groupby(""variable"")):']",,
22848472,,[],[''],[],[],[]
22898920,df.ix['2014-01-01':'2014-02-01'],[],"[""df.ix['2014-01-01':'2014-02-01']""]",[],[],[]
22918691,,[],[''],[],[],[]
22920808,,[],[''],[],[],[]
22924683,"import pandas
df = pandas.DataFrame(columns=['to','fr','ans'])
df.to = [pandas.Timestamp('2014-01-24 13:03:12.050000'), pandas.Timestamp('2014-01-27 11:57:18.240000'), pandas.Timestamp('2014-01-23 10:07:47.660000')]
df.fr = [pandas.Timestamp('2014-01-26 23:41:21.870000'), pandas.Timestamp('2014-01-27 15:38:22.540000'), pandas.Timestamp('2014-01-23 18:50:41.420000')]
(df.fr-df.to).astype('timedelta64[h]')
dtype: float64","[""df = pandas.DataFrame(columns=['to','fr','ans'])"", ""df.to = [pandas.Timestamp('2014-01-24 13:03:12.050000'), pandas.Timestamp('2014-01-27 11:57:18.240000'), pandas.Timestamp('2014-01-23 10:07:47.660000')]"", ""df.fr = [pandas.Timestamp('2014-01-26 23:41:21.870000'), pandas.Timestamp('2014-01-27 15:38:22.540000'), pandas.Timestamp('2014-01-23 18:50:41.420000')]"", ""(df.fr-df.to).astype('timedelta64[h]')""]","['import pandas', ""df.to = [pandas.Timestamp('2014-01-24 13:03:12.050000'), pandas.Timestamp('2014-01-27 11:57:18.240000'), pandas.Timestamp('2014-01-23 10:07:47.660000')]"", ""df.fr = [pandas.Timestamp('2014-01-26 23:41:21.870000'), pandas.Timestamp('2014-01-27 15:38:22.540000'), pandas.Timestamp('2014-01-23 18:50:41.420000')]"", ""(df.fr-df.to).astype('timedelta64[h]')"", 'dtype: float64']","[""df.to = [pandas.Timestamp('2014-01-24 13:03:12.050000'), pandas.Timestamp('2014-01-27 11:57:18.240000'), pandas.Timestamp('2014-01-23 10:07:47.660000')]"", ""df.fr = [pandas.Timestamp('2014-01-26 23:41:21.870000'), pandas.Timestamp('2014-01-27 15:38:22.540000'), pandas.Timestamp('2014-01-23 18:50:41.420000')]"", ""(df.fr-df.to).astype('timedelta64[h]')""]",,
22940775,"df.loc[df.groupby('obj_id').data_date.idxmax(),:]","[""df.loc[df.groupby('obj_id').data_date.idxmax(),:]""]","[""df.loc[df.groupby('obj_id').data_date.idxmax(),:]""]","[""df.loc[df.groupby('obj_id').data_date.idxmax(),:]""]",,
22964673,"d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)","['d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)']",[],[],,
22974440,"data=data.where(data=='-', None) ","[""data=data.where(data=='-', None) ""]","[""data=data.where(data=='-', None) ""]","[""data=data.where(data=='-', None) ""]",,
22992568,"df['stridx']=df.index
df[df['stridx'].str.contains(""Hello|Britain"")]","[""df['stridx']=df.index"", 'df[df[\'stridx\'].str.contains(""Hello|Britain"")]']","[""df['stridx']=df.index"", 'df[df[\'stridx\'].str.contains(""Hello|Britain"")]']","[""df['stridx']=df.index"", 'df[df[\'stridx\'].str.contains(""Hello|Britain"")]']",,
23005564,sve2_all.loc[sve2_all['Hgtot ng/l'] > 100] = np.nan,"[""sve2_all.loc[sve2_all['Hgtot ng/l'] > 100] = np.nan""]","[""sve2_all.loc[sve2_all['Hgtot ng/l'] > 100] = np.nan""]","[""sve2_all.loc[sve2_all['Hgtot ng/l'] > 100] = np.nan""]",,
23088780,"import pandas as pd
import io
df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4])
df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])
def report_diff(x):
    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)
my_panel = pd.Panel(dict(df1=df1,df2=df2))
from IPython.display import HTML
pd.options.display.max_colwidth = 500  
def report_diff(x):
    if x[0]==x[1]:
        return unicode(x[0].__str__())
    elif pd.isnull(x[0]) and pd.isnull(x[1]):
            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', 'nan')
    elif pd.isnull(x[0]) and ~pd.isnull(x[1]):
            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', x[1])
    elif ~pd.isnull(x[0]) and pd.isnull(x[1]):
            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0],'nan')
    else:
            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0], x[1])
HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))","['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])', ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", 'my_panel = pd.Panel(dict(df1=df1,df2=df2))', '    elif pd.isnull(x[0]) and pd.isnull(x[1]):', '    elif pd.isnull(x[0]) and ~pd.isnull(x[1]):', '    elif ~pd.isnull(x[0]) and pd.isnull(x[1]):', 'HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))']","['import pandas as pd', 'import io', 'df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])', 'def report_diff(x):', ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", 'from IPython.display import HTML', 'pd.options.display.max_colwidth = 500  ', 'def report_diff(x):', '    if x[0]==x[1]:', '        return unicode(x[0].__str__())', '    elif pd.isnull(x[0]) and pd.isnull(x[1]):', ""            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', 'nan')"", '    elif pd.isnull(x[0]) and ~pd.isnull(x[1]):', ""            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % ('nan', x[1])"", '    elif ~pd.isnull(x[0]) and pd.isnull(x[1]):', ""            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0],'nan')"", '    else:', ""            '<tr><td>%s</td></tr><tr><td>%s</td></tr></table>' % (x[0], x[1])"", 'HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))']","['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])', ""    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)"", '    elif pd.isnull(x[0]) and pd.isnull(x[1]):', '    elif pd.isnull(x[0]) and ~pd.isnull(x[1]):', '    elif ~pd.isnull(x[0]) and pd.isnull(x[1]):', 'HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))']",,
23104436,"from sqlalchemy import create_engine
engine = create_engine('postgresql://scott:tiger@localhost:5432/mydatabase')
df.to_sql('table_name', engine)
import sql  
sql.write_frame(df, 'table_name', con, flavor='postgresql')","[""df.to_sql('table_name', engine)""]","['from sqlalchemy import create_engine', ""engine = create_engine('postgresql://scott:tiger@localhost:5432/mydatabase')"", ""df.to_sql('table_name', engine)"", 'import sql  ', ""sql.write_frame(df, 'table_name', con, flavor='postgresql')""]","[""df.to_sql('table_name', engine)""]",,
23112008,"from ast import literal_eval
literal_eval('[1.23, 2.34]')
[1.23, 2.34]",[],"['from ast import literal_eval', ""literal_eval('[1.23, 2.34]')"", '[1.23, 2.34]']",[],[],[]
23143081,df['dA'] = df['A'] - df['A'].shift(-1),"[""df['dA'] = df['A'] - df['A'].shift(-1)""]","[""df['dA'] = df['A'] - df['A'].shift(-1)""]","[""df['dA'] = df['A'] - df['A'].shift(-1)""]",,
23143110,"df = pd.DataFrame({""A"": [9, 4, 2, 1], ""B"": [12, 7, 5, 4]})
df[""dA""] = df[""A""].diff(-1)
df","['df = pd.DataFrame({""A"": [9, 4, 2, 1], ""B"": [12, 7, 5, 4]})', 'df[""dA""] = df[""A""].diff(-1)']","['df[""dA""] = df[""A""].diff(-1)', 'df']","['df[""dA""] = df[""A""].diff(-1)']",,
23146038,,[],[''],[],[],[]
23151722,"row_iterator = df.iterrows()
last = row_iterator.next()  
for i, row in row_iterator:
    print(row['value'])
    print(last['value'])
    last = row
last = df.irow(0)
for i in range(1, df.shape[0]):
    print(last)
    print(df.irow(i))
    last = df.irow(i)","['row_iterator = df.iterrows()', 'for i in range(1, df.shape[0]):']","['row_iterator = df.iterrows()', 'last = row_iterator.next()  ', 'for i, row in row_iterator:', ""    print(row['value'])"", ""    print(last['value'])"", '    last = row', 'last = df.irow(0)', 'for i in range(1, df.shape[0]):', '    print(last)', '    print(df.irow(i))', '    last = df.irow(i)']","['row_iterator = df.iterrows()', 'for i in range(1, df.shape[0]):']",,
23178185,,[],[''],[],[],[]
23198160,df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1); df,"[""df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1); df""]","[""df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1); df""]","[""df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1); df""]",,
23200666,"df=pd.DataFrame({'Data':np.random.normal(size=200)})  
df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] 
df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] 
S=pd.Series(np.random.normal(size=200))
S[~((S-S.mean()).abs()>3*S.std())]","[""df=pd.DataFrame({'Data':np.random.normal(size=200)})  "", 'df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] ', 'df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] ', 'S=pd.Series(np.random.normal(size=200))', 'S[~((S-S.mean()).abs()>3*S.std())]']","['df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] ', 'df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] ', 'S[~((S-S.mean()).abs()>3*S.std())]']","['df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] ', 'df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] ', 'S[~((S-S.mean()).abs()>3*S.std())]']",,
23202269,"df = pd.DataFrame(np.random.randn(100, 3))
from scipy import stats
df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]","['df = pd.DataFrame(np.random.randn(100, 3))', 'df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]']","['from scipy import stats', 'df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]']",['df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]'],,
23235618,"import pandas as pd
df = df[pd.notnull(df['EPS'])]","[""df = df[pd.notnull(df['EPS'])]""]","['import pandas as pd', ""df = df[pd.notnull(df['EPS'])]""]","[""df = df[pd.notnull(df['EPS'])]""]",,
23282290,"import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))
pca = PCA(n_components=5)
pca.fit(df)
pca.components_ ","['df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))']","['import pandas as pd', 'import numpy as np', 'from sklearn.decomposition import PCA', 'pca = PCA(n_components=5)', 'pca.fit(df)', 'pca.components_ ']",[],,
23296545,"df[df.C <= df.B].ix[:,'B':'E']
df.ix[df.C <= df.B, 'B':'E']",[],"[""df[df.C <= df.B].ix[:,'B':'E']"", ""df.ix[df.C <= df.B, 'B':'E']""]",[],[],[]
23307361,"w['female'] = w['female'].map({'female': 1, 'male': 0})","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]"
23317595,"foo = lambda x: pd.Series([i for i in reversed(x.split(','))])
rev = df['City, State, Country'].apply(foo)
rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)
rev = rev[['City','State','Country']]","[""foo = lambda x: pd.Series([i for i in reversed(x.split(','))])"", ""rev = df['City, State, Country'].apply(foo)"", ""rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)""]","[""rev = df['City, State, Country'].apply(foo)"", ""rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)"", ""rev = rev[['City','State','Country']]""]","[""foo = lambda x: pd.Series([i for i in reversed(x.split(','))])"", ""rev = df['City, State, Country'].apply(foo)"", ""rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)""]",,
23331659,,[],[''],[],[],[]
23331896,"from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Table
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from pandas import DataFrame
import datetime
engine = create_engine('dialect://user:pwd@host:port/db', echo=False)
Session = sessionmaker(bind=engine)
session = Session()
Base = declarative_base()
tablename = Table('tablename', 
    Base.metadata, 
    autoload=True, 
    autoload_with=engine, 
    schema='ownername')
us = tablename.c.country_code.in_(['US','MX'])
dc = tablename.c.locn_name.like('%DC%')
dt = tablename.c.arr_date >= datetime.date.today() 
q = session.query(tablename).\
            filter(us & dc & dt) 
def querydb(query):
    """"""
    Function to execute query and return DataFrame.
    """"""
    df = DataFrame(query.all());
    df.columns = [x['name'] for x in query.column_descriptions]
    return df
querydb(q)","['dt = tablename.c.arr_date >= datetime.date.today() ', 'q = session.query(tablename).\\', '    df = DataFrame(query.all());']","['from sqlalchemy.ext.declarative import declarative_base', 'from sqlalchemy import Table', 'from sqlalchemy import create_engine', 'from sqlalchemy.orm import sessionmaker', 'from pandas import DataFrame', 'import datetime', ""engine = create_engine('dialect://user:pwd@host:port/db', echo=False)"", 'Session = sessionmaker(bind=engine)', 'session = Session()', 'Base = declarative_base()', ""tablename = Table('tablename', "", '    Base.metadata, ', '    autoload=True, ', '    autoload_with=engine, ', ""    schema='ownername')"", ""us = tablename.c.country_code.in_(['US','MX'])"", ""dc = tablename.c.locn_name.like('%DC%')"", 'dt = tablename.c.arr_date >= datetime.date.today() ', 'q = session.query(tablename).\\', '            filter(us & dc & dt) ', 'def querydb(query):', '    """"""', '    Function to execute query and return DataFrame.', '    """"""', '    df = DataFrame(query.all());', ""    df.columns = [x['name'] for x in query.column_descriptions]"", '    return df', 'querydb(q)']","['dt = tablename.c.arr_date >= datetime.date.today() ', 'q = session.query(tablename).\\', '    df = DataFrame(query.all());']",,
23354240,"pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')","[""pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')""]","[""pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')""]","[""pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')""]",,
23377155,"import numpy as np
import pandas as pd
np.random.seed(0)
df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,
               'office_id': list(range(1, 7)) * 2,
               'sales': [np.random.randint(100000, 999999) for _ in range(12)]})
state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})
state = df.groupby(['state']).agg({'sales': 'sum'})
state_office.div(state, level='state') * 100","[""df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,"", ""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", ""state = df.groupby(['state']).agg({'sales': 'sum'})"", ""state_office.div(state, level='state') * 100""]","['import numpy as np', 'import pandas as pd', 'np.random.seed(0)', ""               'office_id': list(range(1, 7)) * 2,"", ""               'sales': [np.random.randint(100000, 999999) for _ in range(12)]})"", ""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", ""state = df.groupby(['state']).agg({'sales': 'sum'})"", ""state_office.div(state, level='state') * 100""]","[""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", ""state = df.groupby(['state']).agg({'sales': 'sum'})"", ""state_office.div(state, level='state') * 100""]",,
23377232,"import numpy as np
import pandas as pd
np.random.seed(0)
df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,
                   'office_id': list(range(1, 7)) * 2,
                   'sales': [np.random.randint(100000, 999999)
                             for _ in range(12)]})
state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})
state_pcts = state_office.groupby(level=0).apply(lambda x:
                                                 100 * x / float(x.sum()))","[""df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,"", ""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", 'state_pcts = state_office.groupby(level=0).apply(lambda x:', '                                                 100 * x / float(x.sum()))']","['import numpy as np', 'import pandas as pd', 'np.random.seed(0)', ""                   'office_id': list(range(1, 7)) * 2,"", ""                   'sales': [np.random.randint(100000, 999999)"", '                             for _ in range(12)]})', ""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", 'state_pcts = state_office.groupby(level=0).apply(lambda x:', '                                                 100 * x / float(x.sum()))']","[""state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})"", 'state_pcts = state_office.groupby(level=0).apply(lambda x:', '                                                 100 * x / float(x.sum()))']",,
23394497,"se = pd.Series([1,2,3])
se
se[5] = 5.
se","['se = pd.Series([1,2,3])']","['se', 'se[5] = 5.', 'se']",[],,
23394706,"df.loc[df.groupby(""item"")[""diff""].idxmin()]
df.sort(""diff"").groupby(""item"", as_index=False).first()","['df.loc[df.groupby(""item"")[""diff""].idxmin()]', 'df.sort(""diff"").groupby(""item"", as_index=False).first()']","['df.loc[df.groupby(""item"")[""diff""].idxmin()]', 'df.sort(""diff"").groupby(""item"", as_index=False).first()']","['df.loc[df.groupby(""item"")[""diff""].idxmin()]', 'df.sort(""diff"").groupby(""item"", as_index=False).first()']",,
23428804,"import pandas as pd
import matplotlib.pyplot as plt
df2 = df.groupby(['Name', 'Abuse/NFF'])['Name'].count().unstack('Abuse/NFF').fillna(0)
df2[['abuse','nff']].plot(kind='bar', stacked=True)","[""df2 = df.groupby(['Name', 'Abuse/NFF'])['Name'].count().unstack('Abuse/NFF').fillna(0)"", ""df2[['abuse','nff']].plot(kind='bar', stacked=True)""]","['import pandas as pd', 'import matplotlib.pyplot as plt', ""df2 = df.groupby(['Name', 'Abuse/NFF'])['Name'].count().unstack('Abuse/NFF').fillna(0)"", ""df2[['abuse','nff']].plot(kind='bar', stacked=True)""]","[""df2 = df.groupby(['Name', 'Abuse/NFF'])['Name'].count().unstack('Abuse/NFF').fillna(0)"", ""df2[['abuse','nff']].plot(kind='bar', stacked=True)""]",,
23451304,df['zscore'] = (df.a - df.a.mean())/df.a.std(ddof=0),"[""df['zscore'] = (df.a - df.a.mean())/df.a.std(ddof=0)""]","[""df['zscore'] = (df.a - df.a.mean())/df.a.std(ddof=0)""]","[""df['zscore'] = (df.a - df.a.mean())/df.a.std(ddof=0)""]",,
23464103,,[],[''],[],[],[]
23478395,"df.index.names = ['Date']
df = df.reindex(df.index.rename(['Date']))","[""df.index.names = ['Date']"", ""df = df.reindex(df.index.rename(['Date']))""]","[""df.index.names = ['Date']"", ""df = df.reindex(df.index.rename(['Date']))""]","[""df.index.names = ['Date']"", ""df = df.reindex(df.index.rename(['Date']))""]",,
23479973,"def balanced_subsample(x,y,subsample_size=1.0):
    class_xs = []
    min_elems = None
    for yi in np.unique(y):
        elems = x[(y == yi)]
        class_xs.append((yi, elems))
        if min_elems == None or elems.shape[0] < min_elems:
            min_elems = elems.shape[0]
    use_elems = min_elems
    if subsample_size < 1:
        use_elems = int(min_elems*subsample_size)
    xs = []
    ys = []
    for ci,this_xs in class_xs:
        if len(this_xs) > use_elems:
            np.random.shuffle(this_xs)
        x_ = this_xs[:use_elems]
        y_ = np.empty(use_elems)
        y_.fill(ci)
        xs.append(x_)
        ys.append(y_)
    xs = np.concatenate(xs)
    ys = np.concatenate(ys)
    return xs,ys","['    for yi in np.unique(y):', '        class_xs.append((yi, elems))', '        if min_elems == None or elems.shape[0] < min_elems:', '            min_elems = elems.shape[0]', '        y_ = np.empty(use_elems)', '        xs.append(x_)', '        ys.append(y_)']","['def balanced_subsample(x,y,subsample_size=1.0):', '    class_xs = []', '    min_elems = None', '    for yi in np.unique(y):', '        elems = x[(y == yi)]', '        class_xs.append((yi, elems))', '        if min_elems == None or elems.shape[0] < min_elems:', '            min_elems = elems.shape[0]', '    use_elems = min_elems', '    if subsample_size < 1:', '        use_elems = int(min_elems*subsample_size)', '    xs = []', '    ys = []', '    for ci,this_xs in class_xs:', '        if len(this_xs) > use_elems:', '            np.random.shuffle(this_xs)', '        x_ = this_xs[:use_elems]', '        y_ = np.empty(use_elems)', '        y_.fill(ci)', '        xs.append(x_)', '        ys.append(y_)', '    xs = np.concatenate(xs)', '    ys = np.concatenate(ys)', '    return xs,ys']","['    for yi in np.unique(y):', '        class_xs.append((yi, elems))', '        if min_elems == None or elems.shape[0] < min_elems:', '            min_elems = elems.shape[0]', '        y_ = np.empty(use_elems)', '        xs.append(x_)', '        ys.append(y_)']",,
23483221,"import pandas as pd
df = pd.DataFrame(
{'id':[2967, 5335, 13950, 6141, 6169],\
 'Player': ['Cedric Hunter', 'Maurice Baker' ,\
            'Ratko Varda' ,'Ryan Bowen' ,'Adrian Caldwell'],\
 'Year': [1991 ,2004 ,2001 ,2009 ,1997],\
 'Age': [27 ,25 ,22 ,34 ,31],\
 'Tm':['CHH' ,'VAN' ,'TOT' ,'OKC' ,'DAL'],\
 'G':[6 ,7 ,60 ,52 ,81]})
sorter = ['TOT', 'ATL', 'BOS', 'BRK', 'CHA', 'CHH', 'CHI', 'CLE', 'DAL','DEN',\
          'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL',\
          'MIN', 'NJN', 'NOH', 'NOK', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI',\
          'PHO', 'POR', 'SAC', 'SAS', 'SEA', 'TOR', 'UTA', 'VAN',\
          'WAS', 'WSB']
sorterIndex = dict(zip(sorter,range(len(sorter))))
df['Tm_Rank'] = df['Tm'].map(sorterIndex)
df.sort(['Player', 'Year', 'Tm_Rank'], \
        ascending = [True, True, True], inplace = True)
df.drop('Tm_Rank', 1, inplace = True)
print(df)
df['Tm_Rank'] = df['Tm'].map(sorterIndex)
df.sort(['Tm_Rank', 'Player', 'Year'], \
        ascending = [True , True, True], inplace = True)
df.drop('Tm_Rank', 1, inplace = True)
print(df)","['df = pd.DataFrame(', ""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.drop('Tm_Rank', 1, inplace = True)"", ""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.drop('Tm_Rank', 1, inplace = True)""]","['import pandas as pd', ""{'id':[2967, 5335, 13950, 6141, 6169],\\"", "" 'Player': ['Cedric Hunter', 'Maurice Baker' ,\\"", ""            'Ratko Varda' ,'Ryan Bowen' ,'Adrian Caldwell'],\\"", "" 'Year': [1991 ,2004 ,2001 ,2009 ,1997],\\"", "" 'Age': [27 ,25 ,22 ,34 ,31],\\"", "" 'Tm':['CHH' ,'VAN' ,'TOT' ,'OKC' ,'DAL'],\\"", "" 'G':[6 ,7 ,60 ,52 ,81]})"", ""sorter = ['TOT', 'ATL', 'BOS', 'BRK', 'CHA', 'CHH', 'CHI', 'CLE', 'DAL','DEN',\\"", ""          'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL',\\"", ""          'MIN', 'NJN', 'NOH', 'NOK', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI',\\"", ""          'PHO', 'POR', 'SAC', 'SAS', 'SEA', 'TOR', 'UTA', 'VAN',\\"", ""          'WAS', 'WSB']"", 'sorterIndex = dict(zip(sorter,range(len(sorter))))', ""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.sort(['Player', 'Year', 'Tm_Rank'], \\"", '        ascending = [True, True, True], inplace = True)', ""df.drop('Tm_Rank', 1, inplace = True)"", 'print(df)', ""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.sort(['Tm_Rank', 'Player', 'Year'], \\"", '        ascending = [True , True, True], inplace = True)', ""df.drop('Tm_Rank', 1, inplace = True)"", 'print(df)']","[""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.drop('Tm_Rank', 1, inplace = True)"", ""df['Tm_Rank'] = df['Tm'].map(sorterIndex)"", ""df.drop('Tm_Rank', 1, inplace = True)""]",,
23509622,"windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -
                       np.timedelta64(30,'D'))
df = df.merge(windows,on='company',how='left')
df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]
windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -
                       np.timedelta64(30,'D'))
def cond_merge(g,windows):
    g = g.merge(windows,on='company',how='left')
    g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]
    return g.groupby('end_date')['measure'].sum()
windows['date'] = windows['end_date']
df = df.merge(windows,on=['company','date'],how='outer')
df['end_date'] = df.groupby('company')['end_date'].apply(lambda x: x.bfill())
df = df[df.end_date.notnull()]
df['beg_date'] = (df['end_date'].values.astype('datetime64[D]') -
                   np.timedelta64(30,'D'))
df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]","[""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""df = df.merge(windows,on='company',how='left')"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]', ""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""    g = g.merge(windows,on='company',how='left')"", '    g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]', ""    return g.groupby('end_date')['measure'].sum()"", ""df = df.merge(windows,on=['company','date'],how='outer')"", ""df['end_date'] = df.groupby('company')['end_date'].apply(lambda x: x.bfill())"", 'df = df[df.end_date.notnull()]', ""df['beg_date'] = (df['end_date'].values.astype('datetime64[D]') -"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]']","[""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""                       np.timedelta64(30,'D'))"", ""df = df.merge(windows,on='company',how='left')"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]', ""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""                       np.timedelta64(30,'D'))"", 'def cond_merge(g,windows):', ""    g = g.merge(windows,on='company',how='left')"", '    g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]', ""    return g.groupby('end_date')['measure'].sum()"", ""windows['date'] = windows['end_date']"", ""df = df.merge(windows,on=['company','date'],how='outer')"", ""df['end_date'] = df.groupby('company')['end_date'].apply(lambda x: x.bfill())"", 'df = df[df.end_date.notnull()]', ""df['beg_date'] = (df['end_date'].values.astype('datetime64[D]') -"", ""                   np.timedelta64(30,'D'))"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]']","[""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""df = df.merge(windows,on='company',how='left')"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]', ""windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -"", ""    g = g.merge(windows,on='company',how='left')"", '    g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]', ""    return g.groupby('end_date')['measure'].sum()"", ""df = df.merge(windows,on=['company','date'],how='outer')"", ""df['end_date'] = df.groupby('company')['end_date'].apply(lambda x: x.bfill())"", 'df = df[df.end_date.notnull()]', ""df['beg_date'] = (df['end_date'].values.astype('datetime64[D]') -"", 'df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]']",,
23522030,"series = [pd.Series(mat[name][:, 1]) for name in Variables]
df = pd.concat(series, axis=1)","['series = [pd.Series(mat[name][:, 1]) for name in Variables]', 'df = pd.concat(series, axis=1)']","['df = pd.concat(series, axis=1)']","['df = pd.concat(series, axis=1)']",,
23534505,"plt.locator_params(nbins=10)
ax.locator_params(nbins=10, axis='x')",[],"['plt.locator_params(nbins=10)', ""ax.locator_params(nbins=10, axis='x')""]",[],[],[]
23544011,"pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')
(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[s]')
(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[D]')
(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')) / np.timedelta64(1,'D')
dtype: float64","[""pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[s]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[D]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')) / np.timedelta64(1,'D')""]","[""pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[s]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[D]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')) / np.timedelta64(1,'D')"", 'dtype: float64']","[""pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[s]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[D]')"", ""(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')) / np.timedelta64(1,'D')""]",,
23549599,'g' in df.index,"[""'g' in df.index""]","[""'g' in df.index""]","[""'g' in df.index""]",,
23600844,"dict = {'ABC' : df1, 'XYZ' : df2}
Date                                                                        
Date                                   ",[],"[""dict = {'ABC' : df1, 'XYZ' : df2}"", 'Date                                                                        ', 'Date                                   ']",[],[],[]
23671390,"df1 = pd.DataFrame(np.array([
    ['a', 5, 9],
    ['b', 4, 61],
    ['c', 24, 9]]),
    columns=['name', 'attr11', 'attr12'])
df2 = pd.DataFrame(np.array([
    ['a', 5, 19],
    ['b', 14, 16],
    ['c', 4, 9]]),
    columns=['name', 'attr21', 'attr22'])
df3 = pd.DataFrame(np.array([
    ['a', 15, 49],
    ['b', 4, 36],
    ['c', 14, 9]]),
    columns=['name', 'attr31', 'attr32'])
pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')
df1.merge(df2,on='name').merge(df3,on='name')","['df1 = pd.DataFrame(np.array([', 'df2 = pd.DataFrame(np.array([', 'df3 = pd.DataFrame(np.array([', ""pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')"", ""df1.merge(df2,on='name').merge(df3,on='name')""]","[""    ['a', 5, 9],"", ""    ['b', 4, 61],"", ""    ['c', 24, 9]]),"", ""    columns=['name', 'attr11', 'attr12'])"", ""    ['a', 5, 19],"", ""    ['b', 14, 16],"", ""    ['c', 4, 9]]),"", ""    columns=['name', 'attr21', 'attr22'])"", ""    ['a', 15, 49],"", ""    ['b', 4, 36],"", ""    ['c', 14, 9]]),"", ""    columns=['name', 'attr31', 'attr32'])"", ""pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')"", ""df1.merge(df2,on='name').merge(df3,on='name')""]","[""pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')"", ""df1.merge(df2,on='name').merge(df3,on='name')""]",,
23691168,"gb = df.groupby('ZZ')    
[gb.get_group(x) for x in gb.groups]","[""gb = df.groupby('ZZ')    "", '[gb.get_group(x) for x in gb.groups]']","[""gb = df.groupby('ZZ')    "", '[gb.get_group(x) for x in gb.groups]']","[""gb = df.groupby('ZZ')    "", '[gb.get_group(x) for x in gb.groups]']",,
23691692,"df = pandas.DataFrame({""a"": np.random.random(100), 
                    ""b"": np.random.random(100) + 10})
groups = df.groupby(pandas.cut(df.a, 10))
print(groups.mean().b)","['df = pandas.DataFrame({""a"": np.random.random(100), ', 'groups = df.groupby(pandas.cut(df.a, 10))', 'print(groups.mean().b)']","['                    ""b"": np.random.random(100) + 10})', 'groups = df.groupby(pandas.cut(df.a, 10))', 'print(groups.mean().b)']","['groups = df.groupby(pandas.cut(df.a, 10))', 'print(groups.mean().b)']",,
23696169,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
data = pd.DataFrame({ ""A"":np.random.normal(0.8,0.2,20),
                      ""B"":np.random.normal(0.8,0.1,20), 
                      ""C"":np.random.normal(0.9,0.1,20)} )
data.boxplot()
for i,d in enumerate(data):
    y = data[d]
    x = np.random.normal(i+1, 0.04, len(y))
    plt.plot(x, y, mfc = [""orange"",""blue"",""yellow""][i], mec='k', ms=7, marker=""o"", linestyle=""None"")
plt.hlines(1,0,4,linestyle=""--"")
import numpy as np
import matplotlib.pyplot as plt
a = np.random.normal(0,2,1000)
b = np.random.normal(-2,7,100)
data = [a,b]
plt.boxplot(data) 
for i in [1,2]:
    y = data[i-1]
    x = np.random.normal(i, 0.02, len(y))
    plt.plot(x, y, 'r.', alpha=0.2)","['data = pd.DataFrame({ ""A"":np.random.normal(0.8,0.2,20),', '    plt.plot(x, y, mfc = [""orange"",""blue"",""yellow""][i], mec=\'k\', ms=7, marker=""o"", linestyle=""None"")', ""    plt.plot(x, y, 'r.', alpha=0.2)""]","['import pandas as pd', 'import numpy as np', 'import matplotlib.pyplot as plt', '                      ""B"":np.random.normal(0.8,0.1,20), ', '                      ""C"":np.random.normal(0.9,0.1,20)} )', 'data.boxplot()', 'for i,d in enumerate(data):', '    y = data[d]', '    x = np.random.normal(i+1, 0.04, len(y))', '    plt.plot(x, y, mfc = [""orange"",""blue"",""yellow""][i], mec=\'k\', ms=7, marker=""o"", linestyle=""None"")', 'plt.hlines(1,0,4,linestyle=""--"")', 'import numpy as np', 'import matplotlib.pyplot as plt', 'a = np.random.normal(0,2,1000)', 'b = np.random.normal(-2,7,100)', 'data = [a,b]', 'plt.boxplot(data) ', 'for i in [1,2]:', '    y = data[i-1]', '    x = np.random.normal(i, 0.02, len(y))', ""    plt.plot(x, y, 'r.', alpha=0.2)""]","['    plt.plot(x, y, mfc = [""orange"",""blue"",""yellow""][i], mec=\'k\', ms=7, marker=""o"", linestyle=""None"")', ""    plt.plot(x, y, 'r.', alpha=0.2)""]",,
23709208,"import pandas as pd
df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})
df.groupby([""A"", ""C""]).filter(lambda df:df.shape[0] == 1)","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', 'df.groupby([""A"", ""C""]).filter(lambda df:df.shape[0] == 1)']","['import pandas as pd', 'df.groupby([""A"", ""C""]).filter(lambda df:df.shape[0] == 1)']","['df.groupby([""A"", ""C""]).filter(lambda df:df.shape[0] == 1)']",,
23732825,"Index([u'?Date', u'Open', u'High', u'Low', u'Close', u'Volume'], dtype='object')",[],"[""Index([u'?Date', u'Open', u'High', u'Low', u'Close', u'Volume'], dtype='object')""]",[],[],[]
23733522,"df = pd.read_csv('values.csv', delimiter=',', encoding=""utf-8-sig"")","['df = pd.read_csv(\'values.csv\', delimiter=\',\', encoding=""utf-8-sig"")']","['df = pd.read_csv(\'values.csv\', delimiter=\',\', encoding=""utf-8-sig"")']","['df = pd.read_csv(\'values.csv\', delimiter=\',\', encoding=""utf-8-sig"")']",,
23739252,,[],[''],[],[],[]
23741480,"df = df[['mean', '0', '1', '2', '3']]
cols = list(df.columns.values)
['0', '1', '2', '3', 'mean']",['cols = list(df.columns.values)'],"[""df = df[['mean', '0', '1', '2', '3']]"", 'cols = list(df.columns.values)', ""['0', '1', '2', '3', 'mean']""]",['cols = list(df.columns.values)'],,
23741704,"df = df[['x', 'y', 'a', 'b']]
cols = list(df.columns.values)
['a', 'b', 'x', 'y']",['cols = list(df.columns.values)'],"[""df = df[['x', 'y', 'a', 'b']]"", 'cols = list(df.columns.values)', ""['a', 'b', 'x', 'y']""]",['cols = list(df.columns.values)'],,
23743582,"from pandas import DataFrame
from numpy import nan
DataFrame().fillna(value=nan, inplace=True)
my_dataframe.fillna(value=nan, inplace=True)","['DataFrame().fillna(value=nan, inplace=True)', 'my_dataframe.fillna(value=nan, inplace=True)']","['from pandas import DataFrame', 'from numpy import nan', 'DataFrame().fillna(value=nan, inplace=True)', 'my_dataframe.fillna(value=nan, inplace=True)']","['DataFrame().fillna(value=nan, inplace=True)', 'my_dataframe.fillna(value=nan, inplace=True)']",,
23747587,"df
df.dtypes
df[df.b.isnull()]","['df.dtypes', 'df[df.b.isnull()]']","['df', 'df.dtypes', 'df[df.b.isnull()]']","['df.dtypes', 'df[df.b.isnull()]']",,
23749057,"import pandas as pd
df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],
                   'b':[3,5,6,2,4,6,7,8,7,8,9]})
df['a'].values.tolist()
[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]
df['a'].tolist()
[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]
df['a'].drop_duplicates().values.tolist()
[1, 3, 5, 7, 4, 6, 8, 9]
list(set(df['a'])) 
[1, 3, 4, 5, 6, 7, 8, 9]","[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","['import pandas as pd', ""                   'b':[3,5,6,2,4,6,7,8,7,8,9]})"", ""df['a'].values.tolist()"", '[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]', ""df['a'].tolist()"", '[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]', ""df['a'].drop_duplicates().values.tolist()"", '[1, 3, 5, 7, 4, 6, 8, 9]', ""list(set(df['a'])) "", '[1, 3, 4, 5, 6, 7, 8, 9]']","[""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]"
23787275,"df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'],index_col='Date')
start = datetime(2010, 2, 5)
end = datetime(2012, 10, 26)
df_train_fly = pd.date_range(start, end, freq=""W-FRI"")
df_train_fly = pd.DataFrame(pd.Series(df_train_fly), columns=['Date'])
merged = df_train_csv.join(df_train_fly.set_index(['Date']), on = ['Date'], how = 'right', lsuffix='_x')
df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'])
merged = df_train_csv.join(df_train_fly, on = ['Date'], how = 'right', lsuffix='_x')
merged = df_train_csv.join(df_train_fly, how = 'right', lsuffix='_x')
merged = df_train_csv.merge(df_train_fly.set_index(['Date']), left_index=True, right_index=True, how = 'right', lsuffix='_x')","[""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'],index_col='Date')"", 'df_train_fly = pd.date_range(start, end, freq=""W-FRI"")', ""df_train_fly = pd.DataFrame(pd.Series(df_train_fly), columns=['Date'])"", ""merged = df_train_csv.join(df_train_fly.set_index(['Date']), on = ['Date'], how = 'right', lsuffix='_x')"", ""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'])"", ""merged = df_train_csv.join(df_train_fly, on = ['Date'], how = 'right', lsuffix='_x')"", ""merged = df_train_csv.join(df_train_fly, how = 'right', lsuffix='_x')"", ""merged = df_train_csv.merge(df_train_fly.set_index(['Date']), left_index=True, right_index=True, how = 'right', lsuffix='_x')""]","[""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'],index_col='Date')"", 'start = datetime(2010, 2, 5)', 'end = datetime(2012, 10, 26)', 'df_train_fly = pd.date_range(start, end, freq=""W-FRI"")', ""merged = df_train_csv.join(df_train_fly.set_index(['Date']), on = ['Date'], how = 'right', lsuffix='_x')"", ""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'])"", ""merged = df_train_csv.join(df_train_fly, on = ['Date'], how = 'right', lsuffix='_x')"", ""merged = df_train_csv.join(df_train_fly, how = 'right', lsuffix='_x')"", ""merged = df_train_csv.merge(df_train_fly.set_index(['Date']), left_index=True, right_index=True, how = 'right', lsuffix='_x')""]","[""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'],index_col='Date')"", 'df_train_fly = pd.date_range(start, end, freq=""W-FRI"")', ""merged = df_train_csv.join(df_train_fly.set_index(['Date']), on = ['Date'], how = 'right', lsuffix='_x')"", ""df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'])"", ""merged = df_train_csv.join(df_train_fly, on = ['Date'], how = 'right', lsuffix='_x')"", ""merged = df_train_csv.join(df_train_fly, how = 'right', lsuffix='_x')"", ""merged = df_train_csv.merge(df_train_fly.set_index(['Date']), left_index=True, right_index=True, how = 'right', lsuffix='_x')""]",,
23787861,"df['bar'].fillna(df['foo'], inplace=True)
del df['foo']
import pandas as pd
df1 = pd.DataFrame({'a':[1,2],'b':[3,4]}, index = [1,2])
df2 = pd.DataFrame({'b':[5,6]}, index = [3,4])
dftot = pd.concat((df1, df2))
filldf = pd.DataFrame({'a':[7,7,7,7]})","[""df['bar'].fillna(df['foo'], inplace=True)"", ""df1 = pd.DataFrame({'a':[1,2],'b':[3,4]}, index = [1,2])"", ""df2 = pd.DataFrame({'b':[5,6]}, index = [3,4])"", 'dftot = pd.concat((df1, df2))', ""filldf = pd.DataFrame({'a':[7,7,7,7]})""]","[""df['bar'].fillna(df['foo'], inplace=True)"", ""del df['foo']"", 'import pandas as pd', 'dftot = pd.concat((df1, df2))']","[""df['bar'].fillna(df['foo'], inplace=True)"", 'dftot = pd.concat((df1, df2))']",,
23807740,"ix = pd.DatetimeIndex(start=date(2012, 1, 1), end=date(2012, 1, 31), freq='D')
df2.reindex(ix)
[...]",['df2.reindex(ix)'],"[""ix = pd.DatetimeIndex(start=date(2012, 1, 1), end=date(2012, 1, 31), freq='D')"", 'df2.reindex(ix)', '[...]']",['df2.reindex(ix)'],,
23836353,"df['ID'] = df['ID'].apply(lambda x: '{0:0>15}'.format(x))
df['ID'] = df['ID'].apply(lambda x: x.zfill(15))","[""df['ID'] = df['ID'].apply(lambda x: '{0:0>15}'.format(x))"", ""df['ID'] = df['ID'].apply(lambda x: x.zfill(15))""]","[""df['ID'] = df['ID'].apply(lambda x: '{0:0>15}'.format(x))"", ""df['ID'] = df['ID'].apply(lambda x: x.zfill(15))""]","[""df['ID'] = df['ID'].apply(lambda x: '{0:0>15}'.format(x))"", ""df['ID'] = df['ID'].apply(lambda x: x.zfill(15))""]",,
23853569,"read_csv(..., nrows=999999)
read_csv(..., skiprows=1000000, nrows=999999)",[],"['read_csv(..., nrows=999999)', 'read_csv(..., skiprows=1000000, nrows=999999)']",[],[],[]
23887956,"pd.concat([x]*5)
pd.concat([x]*5, ignore_index=True)","['pd.concat([x]*5)', 'pd.concat([x]*5, ignore_index=True)']","['pd.concat([x]*5)', 'pd.concat([x]*5, ignore_index=True)']","['pd.concat([x]*5)', 'pd.concat([x]*5, ignore_index=True)']",,
23901625,import matplotlib.pyplot as plt,[],['import matplotlib.pyplot as plt'],[],[],[]
23922119,"import pandas as pd
pd.options.display.float_format = '${:,.2f}'.format
df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],
                  index=['foo','bar','baz','quux'],
                  columns=['cost'])","[""pd.options.display.float_format = '${:,.2f}'.format"", 'df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],']","['import pandas as pd', ""pd.options.display.float_format = '${:,.2f}'.format"", ""                  index=['foo','bar','baz','quux'],"", ""                  columns=['cost'])""]","[""pd.options.display.float_format = '${:,.2f}'.format""]",,
23925229,"import numpy as np
import pandas as pd
import statsmodels.api as sm
my_data = np.array([[5, 'a', 1],
                    [3, 'b', 3],
                    [1, 'b', 2],
                    [3, 'a', 1],
                    [4, 'b', 2],
                    [7, 'c', 1],
                    [7, 'c', 1]])                
df = pd.DataFrame(data=my_data, columns=['y', 'dummy', 'x'])
just_dummies = pd.get_dummies(df['dummy'])
step_1 = pd.concat([df, just_dummies], axis=1)      
step_1.drop(['dummy', 'c'], inplace=True, axis=1)
step_1 = step_1.applymap(np.int) 
result = sm.OLS(step_1['y'], sm.add_constant(step_1[['x', 'a', 'b']])).fit()","[""df = pd.DataFrame(data=my_data, columns=['y', 'dummy', 'x'])"", ""just_dummies = pd.get_dummies(df['dummy'])"", 'step_1 = pd.concat([df, just_dummies], axis=1)      ', ""step_1.drop(['dummy', 'c'], inplace=True, axis=1)"", 'step_1 = step_1.applymap(np.int) ']","['import numpy as np', 'import pandas as pd', 'import statsmodels.api as sm', ""my_data = np.array([[5, 'a', 1],"", ""                    [3, 'b', 3],"", ""                    [1, 'b', 2],"", ""                    [3, 'a', 1],"", ""                    [4, 'b', 2],"", ""                    [7, 'c', 1],"", ""                    [7, 'c', 1]])                "", ""just_dummies = pd.get_dummies(df['dummy'])"", 'step_1 = pd.concat([df, just_dummies], axis=1)      ', ""step_1.drop(['dummy', 'c'], inplace=True, axis=1)"", 'step_1 = step_1.applymap(np.int) ', ""result = sm.OLS(step_1['y'], sm.add_constant(step_1[['x', 'a', 'b']])).fit()""]","[""just_dummies = pd.get_dummies(df['dummy'])"", 'step_1 = pd.concat([df, just_dummies], axis=1)      ', ""step_1.drop(['dummy', 'c'], inplace=True, axis=1)"", 'step_1 = step_1.applymap(np.int) ']",,
23966229,"df.groupby(pd.TimeGrouper('5Min'))['val'].mean()
time
df.groupby(pd.TimeGrouper('5Min'))['val'].apply(lambda x: len(x) > 3)
time
TimeGrouper(self, freq = 'Min', closed = None, label = None,
how = 'mean', nperiods = None, axis = 0, fill_method = None,
limit = None, loffset = None, kind = None, convention = None, base = 0,
**kwargs)
Parameters
convention : {'start', 'end', 'e', 's'}
Notes
new = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['val'])
df['period'] = new.index.get_level_values(0)
df
time
new
Int64Index([0, 0, 1, 1, 1, 2, 2, 2, 2], dtype='int64')","[""df.groupby(pd.TimeGrouper('5Min'))['val'].mean()"", ""df.groupby(pd.TimeGrouper('5Min'))['val'].apply(lambda x: len(x) > 3)"", ""new = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['val'])"", ""df['period'] = new.index.get_level_values(0)""]","[""df.groupby(pd.TimeGrouper('5Min'))['val'].mean()"", 'time', ""df.groupby(pd.TimeGrouper('5Min'))['val'].apply(lambda x: len(x) > 3)"", 'time', ""TimeGrouper(self, freq = 'Min', closed = None, label = None,"", ""how = 'mean', nperiods = None, axis = 0, fill_method = None,"", 'limit = None, loffset = None, kind = None, convention = None, base = 0,', '**kwargs)', 'Parameters', ""convention : {'start', 'end', 'e', 's'}"", 'Notes', ""new = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['val'])"", ""df['period'] = new.index.get_level_values(0)"", 'df', 'time', 'new', ""Int64Index([0, 0, 1, 1, 1, 2, 2, 2, 2], dtype='int64')""]","[""df.groupby(pd.TimeGrouper('5Min'))['val'].mean()"", ""df.groupby(pd.TimeGrouper('5Min'))['val'].apply(lambda x: len(x) > 3)"", ""new = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['val'])"", ""df['period'] = new.index.get_level_values(0)""]",,
24029921,"df.append([df_try]*5,ignore_index=True)","['df.append([df_try]*5,ignore_index=True)']","['df.append([df_try]*5,ignore_index=True)']","['df.append([df_try]*5,ignore_index=True)']",,
24037972,"mydf['Cigarettes'] = mydf['Cigarettes'].str.replace(' ', '')
mydf['CigarNum'] = mydf['Cigarettes'].apply(numcigar.get).astype(float)
mydf['CigarNum'] = mydf['Cigarettes'].replace(numcigar)
mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)
numcigar = {""Never"":0.0 ,""1-5 Cigarettes/day"" :1.0,""10-20 Cigarettes/day"":4.0}
mydf['CigarNum'] = pd.to_numeric(mydf['CigarNum'], errors='coerce')","[""mydf['Cigarettes'] = mydf['Cigarettes'].str.replace(' ', '')"", ""mydf['CigarNum'] = mydf['Cigarettes'].apply(numcigar.get).astype(float)"", ""mydf['CigarNum'] = mydf['Cigarettes'].replace(numcigar)"", ""mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)"", ""mydf['CigarNum'] = pd.to_numeric(mydf['CigarNum'], errors='coerce')""]","[""mydf['Cigarettes'] = mydf['Cigarettes'].str.replace(' ', '')"", ""mydf['CigarNum'] = mydf['Cigarettes'].apply(numcigar.get).astype(float)"", ""mydf['CigarNum'] = mydf['Cigarettes'].replace(numcigar)"", ""mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)"", 'numcigar = {""Never"":0.0 ,""1-5 Cigarettes/day"" :1.0,""10-20 Cigarettes/day"":4.0}', ""mydf['CigarNum'] = pd.to_numeric(mydf['CigarNum'], errors='coerce')""]","[""mydf['Cigarettes'] = mydf['Cigarettes'].str.replace(' ', '')"", ""mydf['CigarNum'] = mydf['Cigarettes'].apply(numcigar.get).astype(float)"", ""mydf['CigarNum'] = mydf['Cigarettes'].replace(numcigar)"", ""mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)"", ""mydf['CigarNum'] = pd.to_numeric(mydf['CigarNum'], errors='coerce')""]",,
24040239,"from pandas import DataFrame
from numpy.random import randint
df = DataFrame({'a': randint(3, size=10)})
df
s = df.a[:5]
dfa, sa = df.align(s, axis=0)
dfa
sa","['dfa, sa = df.align(s, axis=0)']","['from pandas import DataFrame', 'from numpy.random import randint', ""df = DataFrame({'a': randint(3, size=10)})"", 'df', 's = df.a[:5]', 'dfa, sa = df.align(s, axis=0)', 'dfa', 'sa']","['dfa, sa = df.align(s, axis=0)']",,
24041761,"is_none = df.set_index(['Company', 'date'], inplace=True)
df  
is_none 
df = df.set_index(['Company', 'date'], inplace=True)
df.set_index(['Company', 'date'], inplace=True)","[""is_none = df.set_index(['Company', 'date'], inplace=True)"", ""df = df.set_index(['Company', 'date'], inplace=True)"", ""df.set_index(['Company', 'date'], inplace=True)""]","[""is_none = df.set_index(['Company', 'date'], inplace=True)"", 'df  ', 'is_none ', ""df = df.set_index(['Company', 'date'], inplace=True)"", ""df.set_index(['Company', 'date'], inplace=True)""]","[""is_none = df.set_index(['Company', 'date'], inplace=True)"", ""df = df.set_index(['Company', 'date'], inplace=True)"", ""df.set_index(['Company', 'date'], inplace=True)""]",,
24043138,"df.loc[df.filename == 'test2.dat', 'n'] = df2[df2.filename == 'test2.dat'].loc[0]['n']
df
df.set_index('filename', inplace=True)
df2.set_index('filename', inplace=True)
df.update(df2)
df
filename           ","[""df.loc[df.filename == 'test2.dat', 'n'] = df2[df2.filename == 'test2.dat'].loc[0]['n']"", ""df.set_index('filename', inplace=True)"", ""df2.set_index('filename', inplace=True)"", 'df.update(df2)']","[""df.loc[df.filename == 'test2.dat', 'n'] = df2[df2.filename == 'test2.dat'].loc[0]['n']"", 'df', ""df.set_index('filename', inplace=True)"", ""df2.set_index('filename', inplace=True)"", 'df.update(df2)', 'df', 'filename           ']","[""df.loc[df.filename == 'test2.dat', 'n'] = df2[df2.filename == 'test2.dat'].loc[0]['n']"", ""df.set_index('filename', inplace=True)"", ""df2.set_index('filename', inplace=True)"", 'df.update(df2)']",,
24074316,df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green'),"[""df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')""]","[""df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')""]","[""df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')""]",,
24082767,"from pandas import *
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import datetime as dt
date1 = ""20140605""
date2 = ""20140606""
d = {'date': Series([date1]*5 + [date2]*5), 'template': Series(range(5)*2),
'score': Series([random() for i in range(10)]) } 
data = DataFrame(d)
fig, ax = plt.subplots()
for temp in range(5):
    dat = data[data['template']==temp]
    dates =  dat['date']
    dates_f = [dt.datetime.strptime(date,'%Y%m%d') for date in dates]
    ax.plot(dates_f, dat['score'], label = ""Template: {0}"".format(temp))
plt.xlabel(""Date"")
plt.ylabel(""Score"")
ax.legend()
plt.show()","[""    dates_f = [dt.datetime.strptime(date,'%Y%m%d') for date in dates]"", '    ax.plot(dates_f, dat[\'score\'], label = ""Template: {0}"".format(temp))']","['from pandas import *', 'import matplotlib.pyplot as plt', 'import matplotlib.dates as mdates', 'import datetime as dt', 'date1 = ""20140605""', 'date2 = ""20140606""', ""d = {'date': Series([date1]*5 + [date2]*5), 'template': Series(range(5)*2),"", ""'score': Series([random() for i in range(10)]) } "", 'data = DataFrame(d)', 'fig, ax = plt.subplots()', 'for temp in range(5):', ""    dat = data[data['template']==temp]"", ""    dates =  dat['date']"", ""    dates_f = [dt.datetime.strptime(date,'%Y%m%d') for date in dates]"", '    ax.plot(dates_f, dat[\'score\'], label = ""Template: {0}"".format(temp))', 'plt.xlabel(""Date"")', 'plt.ylabel(""Score"")', 'ax.legend()', 'plt.show()']","[""    dates_f = [dt.datetime.strptime(date,'%Y%m%d') for date in dates]"", '    ax.plot(dates_f, dat[\'score\'], label = ""Template: {0}"".format(temp))']",,
24083253,"pd.groupby(b,by=[b.index.month,b.index.year])
df.groupby(pd.TimeGrouper(freq='M'))","['pd.groupby(b,by=[b.index.month,b.index.year])', ""df.groupby(pd.TimeGrouper(freq='M'))""]","['pd.groupby(b,by=[b.index.month,b.index.year])', ""df.groupby(pd.TimeGrouper(freq='M'))""]","['pd.groupby(b,by=[b.index.month,b.index.year])', ""df.groupby(pd.TimeGrouper(freq='M'))""]",,
24098354,"df.groupby(level=[0,1]).apply(lambda x: x.set_index('Date').resample('2D', how='sum'))
df['Date'] = pd.to_datetime(df['Date'])","[""df.groupby(level=[0,1]).apply(lambda x: x.set_index('Date').resample('2D', how='sum'))"", ""df['Date'] = pd.to_datetime(df['Date'])""]","[""df.groupby(level=[0,1]).apply(lambda x: x.set_index('Date').resample('2D', how='sum'))"", ""df['Date'] = pd.to_datetime(df['Date'])""]","[""df.groupby(level=[0,1]).apply(lambda x: x.set_index('Date').resample('2D', how='sum'))"", ""df['Date'] = pd.to_datetime(df['Date'])""]",,
24098903,"data.groupby(""template"").plot(x=""date"", y=""score"")","['data.groupby(""template"").plot(x=""date"", y=""score"")']","['data.groupby(""template"").plot(x=""date"", y=""score"")']","['data.groupby(""template"").plot(x=""date"", y=""score"")']",,
24112443,"import pandas as pd
df = pd.DataFrame( {'A' : [1, 1, 1, 1, 2, 2, 3], 'B' : [10, 12, 11, 10, 11, 12, 14], 'C' : [22, 20,     8, 10, 13, 10, 0]})
df2=df.groupby(['A']).apply(lambda tdf: pd.Series(  dict([[vv,tdf[vv].unique().tolist()] for vv in tdf if vv not in ['A']])  )) 
A                               
1  [10, 12, 11]  [22, 20, 8, 10]
2      [11, 12]         [13, 10]
3          [14]              [0]","[""df = pd.DataFrame( {'A' : [1, 1, 1, 1, 2, 2, 3], 'B' : [10, 12, 11, 10, 11, 12, 14], 'C' : [22, 20,     8, 10, 13, 10, 0]})"", ""df2=df.groupby(['A']).apply(lambda tdf: pd.Series(  dict([[vv,tdf[vv].unique().tolist()] for vv in tdf if vv not in ['A']])  )) ""]","['import pandas as pd', 'A                               ', '1  [10, 12, 11]  [22, 20, 8, 10]', '2      [11, 12]         [13, 10]', '3          [14]              [0]']","[""df2=df.groupby(['A']).apply(lambda tdf: pd.Series(  dict([[vv,tdf[vv].unique().tolist()] for vv in tdf if vv not in ['A']])  )) ""]",,
24147363,"df = pd.DataFrame(np.random.randn(100, 2))
msk = np.random.rand(len(df)) < 0.8
train = df[msk]
test = df[~msk]
len(test)
len(train)
Out[16]: 79","['df = pd.DataFrame(np.random.randn(100, 2))']","['msk = np.random.rand(len(df)) < 0.8', 'train = df[msk]', 'test = df[~msk]', 'len(test)', 'len(train)', 'Out[16]: 79']",[],"['df = pd.DataFrame(np.random.randn(100, 2))']","['df = pd.DataFrame(np.random.randn(100, 2))']"
24151789,"import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
train, test = train_test_split(df, test_size = 0.2)",[],"['import pandas as pd', 'import numpy as np', 'from sklearn.model_selection import train_test_split', 'train, test = train_test_split(df, test_size = 0.2)']",[],[],[]
24196288,"from pandas.stats.plm import PanelOLS
df
reg  = PanelOLS(y=df['y'],x=df[['x']],time_effects=True)
reg
Rmse:              0.1588
PanelOLS(self, y, x, weights = None, intercept = True, nw_lags = None,
entity_effects = False, time_effects = False, x_effects = None,
cluster = None, dropped_dummies = None, verbose = False,
nw_overlap = False)",[],"['from pandas.stats.plm import PanelOLS', 'df', ""reg  = PanelOLS(y=df['y'],x=df[['x']],time_effects=True)"", 'reg', 'Rmse:              0.1588', 'PanelOLS(self, y, x, weights = None, intercept = True, nw_lags = None,', 'entity_effects = False, time_effects = False, x_effects = None,', 'cluster = None, dropped_dummies = None, verbose = False,', 'nw_overlap = False)']",[],[],[]
24216489,"import pandas as pd
equiv = {7001:1, 8001:2, 9001:3}
df = pd.DataFrame( {""A"": [7001, 8001, 9001]} )
df[""B""] = df[""A""].map(equiv)
print(df)
import pandas as pd
equiv = {7001:1, 8001:2, 9001:3}
df = pd.DataFrame( {""A"": [7001, 8001, 9001, 10000]} )
df[""B""] = df[""A""].map(equiv)
print(df)","['df = pd.DataFrame( {""A"": [7001, 8001, 9001]} )', 'df[""B""] = df[""A""].map(equiv)', 'df = pd.DataFrame( {""A"": [7001, 8001, 9001, 10000]} )', 'df[""B""] = df[""A""].map(equiv)']","['import pandas as pd', 'equiv = {7001:1, 8001:2, 9001:3}', 'df[""B""] = df[""A""].map(equiv)', 'print(df)', 'import pandas as pd', 'equiv = {7001:1, 8001:2, 9001:3}', 'df[""B""] = df[""A""].map(equiv)', 'print(df)']","['df[""B""] = df[""A""].map(equiv)', 'df[""B""] = df[""A""].map(equiv)']",,
24222837,"st['a'] = map(lambda path, row: path + 2 * row, st['path'], st['row'])
title_dict = {'male': 'mr.', 'female': 'ms.'}
table['title'] = map(lambda title,
    gender: title if title != None else title_dict[gender],
    table['title'], table['gender'])",[],"[""st['a'] = map(lambda path, row: path + 2 * row, st['path'], st['row'])"", ""title_dict = {'male': 'mr.', 'female': 'ms.'}"", ""table['title'] = map(lambda title,"", '    gender: title if title != None else title_dict[gender],', ""    table['title'], table['gender'])""]",[],[],[]
24242333,,[],[''],[],[],[]
24251426,"dashboard_df = pd.read_csv(p_file, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')","[""dashboard_df = pd.read_csv(p_file, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')""]","[""dashboard_df = pd.read_csv(p_file, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')""]","[""dashboard_df = pd.read_csv(p_file, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')""]",,
24273597,"df = pd.DataFrame([[1, 2], [3, 4]], ['a', 'b'], ['A', 'B'])
df
df.iloc[0]  
df['A'].iloc[0]  
Out[14]: 1","[""df = pd.DataFrame([[1, 2], [3, 4]], ['a', 'b'], ['A', 'B'])"", 'df.iloc[0]  ', ""df['A'].iloc[0]  ""]","['df', 'df.iloc[0]  ', ""df['A'].iloc[0]  "", 'Out[14]: 1']","['df.iloc[0]  ', ""df['A'].iloc[0]  ""]",,
24283087,"def set_color_cycle(self, clist=None):
    if clist is None:
        clist = rcParams['axes.color_cycle']",[],"['def set_color_cycle(self, clist=None):', '    if clist is None:', ""        clist = rcParams['axes.color_cycle']""]",[],[],[]
24284515,"pd.DataFrame(np.array([[2, 3, 4]]), columns=['A', 'B', 'C']).append(df, ignore_index=True)
index = np.array([0, 1, 2])
df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)
df2.loc[0:1] = [list(s1), list(s2)]
df2
df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)
df2.loc[1:] = [list(s1), list(s2)]
df2
df2.loc[0] = np.array([2, 3, 4])
df2","[""pd.DataFrame(np.array([[2, 3, 4]]), columns=['A', 'B', 'C']).append(df, ignore_index=True)"", ""df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)"", 'df2.loc[0:1] = [list(s1), list(s2)]', ""df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)"", 'df2.loc[1:] = [list(s1), list(s2)]', 'df2.loc[0] = np.array([2, 3, 4])']","['index = np.array([0, 1, 2])', 'df2.loc[0:1] = [list(s1), list(s2)]', 'df2', 'df2.loc[1:] = [list(s1), list(s2)]', 'df2', 'df2.loc[0] = np.array([2, 3, 4])', 'df2']","[""pd.DataFrame(np.array([[2, 3, 4]]), columns=['A', 'B', 'C']).append(df, ignore_index=True)"", 'df2.loc[0:1] = [list(s1), list(s2)]', 'df2.loc[1:] = [list(s1), list(s2)]', 'df2.loc[0] = np.array([2, 3, 4])']",,
24284680,,[],[''],[],[],[]
24287210,,[],[''],[],[],[]
24368660,"ptest = p.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) 
ptest
ptest.set_index('id')['value'].to_dict()
{'a': 2, 'b': 3}
dict(zip(ptest.id, ptest.value))
{'a': 2, 'b': 3}
mydict = {}","[""ptest = p.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) "", ""ptest.set_index('id')['value'].to_dict()"", 'dict(zip(ptest.id, ptest.value))']","['ptest', ""ptest.set_index('id')['value'].to_dict()"", ""{'a': 2, 'b': 3}"", 'dict(zip(ptest.id, ptest.value))', ""{'a': 2, 'b': 3}"", 'mydict = {}']","[""ptest.set_index('id')['value'].to_dict()"", 'dict(zip(ptest.id, ptest.value))']",,
24370510,"ptest = pd.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) 
ptest
{'a': [1, 2], 'b': [3]}","[""ptest = pd.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) ""]","['ptest', ""{'a': [1, 2], 'b': [3]}""]",[],,
24386746,"frame['c'] = frame.fillna(0)['a'] + frame.fillna(0)['b']
frame['c'] = frame.a.fillna(0) + frame.b.fillna(0)","[""frame['c'] = frame.fillna(0)['a'] + frame.fillna(0)['b']"", ""frame['c'] = frame.a.fillna(0) + frame.b.fillna(0)""]","[""frame['c'] = frame.fillna(0)['a'] + frame.fillna(0)['b']"", ""frame['c'] = frame.a.fillna(0) + frame.b.fillna(0)""]","[""frame['c'] = frame.fillna(0)['a'] + frame.fillna(0)['b']"", ""frame['c'] = frame.a.fillna(0) + frame.b.fillna(0)""]",,
24387164,"frame[""c""] = frame[[""a"", ""b""]].sum(axis=1)
frame","['frame[""c""] = frame[[""a"", ""b""]].sum(axis=1)']","['frame[""c""] = frame[[""a"", ""b""]].sum(axis=1)', 'frame']","['frame[""c""] = frame[[""a"", ""b""]].sum(axis=1)']",,
24396554,df[sorted(df.columns)],[],['df[sorted(df.columns)]'],[],[],[]
24418294,"df = psql.read_sql(('select ""Timestamp"",""Value"" from ""MyTable"" '
                     'where ""Timestamp"" BETWEEN %(dstart)s AND %(dfinish)s'),
                   db,params={""dstart"":datetime(2014,6,24,16,0),""dfinish"":datetime(2014,6,24,17,0)},
                   index_col=['Timestamp'])","['df = psql.read_sql((\'select ""Timestamp"",""Value"" from ""MyTable"" \'']","['df = psql.read_sql((\'select ""Timestamp"",""Value"" from ""MyTable"" \'', '                     \'where ""Timestamp"" BETWEEN %(dstart)s AND %(dfinish)s\'),', '                   db,params={""dstart"":datetime(2014,6,24,16,0),""dfinish"":datetime(2014,6,24,17,0)},', ""                   index_col=['Timestamp'])""]","['df = psql.read_sql((\'select ""Timestamp"",""Value"" from ""MyTable"" \'']",,
24436783,"df.loc[('at', [1,3,4]), 'Dwell']","[""df.loc[('at', [1,3,4]), 'Dwell']""]","[""df.loc[('at', [1,3,4]), 'Dwell']""]","[""df.loc[('at', [1,3,4]), 'Dwell']""]",,
24446716,"df['date']  = pd.to_datetime(df['date'])
df_masked = df[(df['date'] > datetime.date(2012,4,1)) & (df['date'] < datetime.date(2012,4,4))]","[""df['date']  = pd.to_datetime(df['date'])"", ""df_masked = df[(df['date'] > datetime.date(2012,4,1)) & (df['date'] < datetime.date(2012,4,4))]""]","[""df['date']  = pd.to_datetime(df['date'])"", ""df_masked = df[(df['date'] > datetime.date(2012,4,1)) & (df['date'] < datetime.date(2012,4,4))]""]","[""df['date']  = pd.to_datetime(df['date'])"", ""df_masked = df[(df['date'] > datetime.date(2012,4,1)) & (df['date'] < datetime.date(2012,4,4))]""]",,
24475214,"df.values[[np.arange(5)]*2] = 0
df
np.fill_diagonal(df.values, 0)","['df.values[[np.arange(5)]*2] = 0', 'np.fill_diagonal(df.values, 0)']","['df.values[[np.arange(5)]*2] = 0', 'df', 'np.fill_diagonal(df.values, 0)']","['df.values[[np.arange(5)]*2] = 0', 'np.fill_diagonal(df.values, 0)']",,
24489283,"import pandas as pd
import numpy as np
np.random.seed(0)
idx = pd.MultiIndex.from_product([['John', 'Josh', 'Alex'], list('abcde')], 
                                 names=['Person', 'Letter'])
large = pd.DataFrame(data=np.random.randn(15, 2), 
                     index=idx, 
                     columns=['one', 'two'])
small = large.loc[['Jo'==d[0:2] for d in large.index.get_level_values('Person')]]
Index([u'Alex', u'John', u'Josh'], dtype='object')
Index([u'Alex', u'John', u'Josh'], dtype='object')
Index([u'John', u'Josh'], dtype='object')
Index([u'Alex', u'John', u'Josh'], dtype='object')
small.index.get_level_values('Person').unique()
large.index.get_level_values('Person').unique()","[""idx = pd.MultiIndex.from_product([['John', 'Josh', 'Alex'], list('abcde')], "", 'large = pd.DataFrame(data=np.random.randn(15, 2), ', ""small = large.loc[['Jo'==d[0:2] for d in large.index.get_level_values('Person')]]"", ""small.index.get_level_values('Person').unique()"", ""large.index.get_level_values('Person').unique()""]","['import pandas as pd', 'import numpy as np', 'np.random.seed(0)', ""idx = pd.MultiIndex.from_product([['John', 'Josh', 'Alex'], list('abcde')], "", ""                                 names=['Person', 'Letter'])"", '                     index=idx, ', ""                     columns=['one', 'two'])"", ""small = large.loc[['Jo'==d[0:2] for d in large.index.get_level_values('Person')]]"", ""Index([u'Alex', u'John', u'Josh'], dtype='object')"", ""Index([u'Alex', u'John', u'Josh'], dtype='object')"", ""Index([u'John', u'Josh'], dtype='object')"", ""Index([u'Alex', u'John', u'Josh'], dtype='object')"", ""small.index.get_level_values('Person').unique()"", ""large.index.get_level_values('Person').unique()""]","[""idx = pd.MultiIndex.from_product([['John', 'Josh', 'Alex'], list('abcde')], "", ""small = large.loc[['Jo'==d[0:2] for d in large.index.get_level_values('Person')]]"", ""small.index.get_level_values('Person').unique()"", ""large.index.get_level_values('Person').unique()""]",,
24489602,"df = df[df.line_race != 0]
df = df[df.line_race != None]
df = df[df.line_race.notnull()]",['df = df[df.line_race.notnull()]'],"['df = df[df.line_race != 0]', 'df = df[df.line_race != None]', 'df = df[df.line_race.notnull()]']",['df = df[df.line_race.notnull()]'],,
24496435,"df.index.get_level_values('co').unique()
Out[11]: array(['DE', 'FR'], dtype=object)","[""df.index.get_level_values('co').unique()""]","[""df.index.get_level_values('co').unique()"", ""Out[11]: array(['DE', 'FR'], dtype=object)""]","[""df.index.get_level_values('co').unique()""]",,
24517695,,[],[''],[],[],[]
24537997,"df = pd.DataFrame([ pd.Timestamp('20010101'), pd.Timestamp('20040605') ])
df.ix[0]-df.ix[1]
dtype: timedelta64[ns]
(df.ix[0]-df.ix[1]).astype('timedelta64[Y]')","[""df = pd.DataFrame([ pd.Timestamp('20010101'), pd.Timestamp('20040605') ])"", ""(df.ix[0]-df.ix[1]).astype('timedelta64[Y]')""]","['df.ix[0]-df.ix[1]', 'dtype: timedelta64[ns]', ""(df.ix[0]-df.ix[1]).astype('timedelta64[Y]')""]","[""df = pd.DataFrame([ pd.Timestamp('20010101'), pd.Timestamp('20040605') ])"", ""(df.ix[0]-df.ix[1]).astype('timedelta64[Y]')""]",,
24542540,"pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D':np.sum, 'E':np.mean})","[""pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D':np.sum, 'E':np.mean})""]","[""pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D':np.sum, 'E':np.mean})""]","[""pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D':np.sum, 'E':np.mean})""]",,
24609894,"import numpy as np
import pandas as pd
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt
from PySide.QtGui import QImage
from PySide.QtGui import QPainter
from PySide.QtCore import QSize
from PySide.QtWebKit import QWebPage
arrays = [np.hstack([ ['one']*3, ['two']*3]), ['Dog', 'Bird', 'Cat']*2]
columns = pd.MultiIndex.from_arrays(arrays, names=['foo', 'bar'])
df =pd.DataFrame(np.zeros((3,6)),columns=columns,index=pd.date_range('20000103',periods=3))
h = ""<!DOCTYPE html> <html> <body> <p> "" + df.to_html() + "" </p> </body> </html>"";
page = QWebPage()
page.setViewportSize(QSize(5000,5000))
frame = page.mainFrame()
frame.setHtml(h, ""text/html"")
img = QImage(1000,700, QImage.Format(5))
painter = QPainter(img)
frame.render(painter)
painter.end()
a = img.save(""html.png"")
pp = PdfPages('html.pdf')
fig = plt.figure(figsize=(8,6),dpi=1080) 
ax = fig.add_subplot(1, 1, 1)
img2 = plt.imread(""html.png"")
plt.axis('off')
ax.imshow(img2)
pp.savefig()
pp.close()","[""columns = pd.MultiIndex.from_arrays(arrays, names=['foo', 'bar'])"", ""df =pd.DataFrame(np.zeros((3,6)),columns=columns,index=pd.date_range('20000103',periods=3))"", 'h = ""<!DOCTYPE html> <html> <body> <p> "" + df.to_html() + "" </p> </body> </html>"";', 'frame.render(painter)']","['import numpy as np', 'import pandas as pd', 'from matplotlib.backends.backend_pdf import PdfPages', 'import matplotlib.pyplot as plt', 'from PySide.QtGui import QImage', 'from PySide.QtGui import QPainter', 'from PySide.QtCore import QSize', 'from PySide.QtWebKit import QWebPage', ""arrays = [np.hstack([ ['one']*3, ['two']*3]), ['Dog', 'Bird', 'Cat']*2]"", ""columns = pd.MultiIndex.from_arrays(arrays, names=['foo', 'bar'])"", 'h = ""<!DOCTYPE html> <html> <body> <p> "" + df.to_html() + "" </p> </body> </html>"";', 'page = QWebPage()', 'page.setViewportSize(QSize(5000,5000))', 'frame = page.mainFrame()', 'frame.setHtml(h, ""text/html"")', 'img = QImage(1000,700, QImage.Format(5))', 'painter = QPainter(img)', 'frame.render(painter)', 'painter.end()', 'a = img.save(""html.png"")', ""pp = PdfPages('html.pdf')"", 'fig = plt.figure(figsize=(8,6),dpi=1080) ', 'ax = fig.add_subplot(1, 1, 1)', 'img2 = plt.imread(""html.png"")', ""plt.axis('off')"", 'ax.imshow(img2)', 'pp.savefig()', 'pp.close()']","[""columns = pd.MultiIndex.from_arrays(arrays, names=['foo', 'bar'])"", ""df =pd.DataFrame(np.zeros((3,6)),columns=columns,index=pd.date_range('20000103',periods=3))"", 'h = ""<!DOCTYPE html> <html> <body> <p> "" + df.to_html() + "" </p> </body> </html>"";', 'frame.render(painter)']",,
24674675,"plot = dtf.plot()
fig = plot.get_figure()
fig.savefig(""output.png"")",['plot = dtf.plot()'],"['plot = dtf.plot()', 'fig = plot.get_figure()', 'fig.savefig(""output.png"")']",['plot = dtf.plot()'],,
24775756,,[],[''],[],[],[]
24792087,"df = pd.DataFrame({""t"": pd.date_range('2014-01-01', periods=5, freq='H')})
df
pd.DatetimeIndex(df.t).normalize()
df['date'] = pd.DatetimeIndex(df.t).normalize()
df
df.t.dt.normalize()
pd.DatetimeIndex(df.t).normalize()","['df = pd.DataFrame({""t"": pd.date_range(\'2014-01-01\', periods=5, freq=\'H\')})', 'pd.DatetimeIndex(df.t).normalize()', ""df['date'] = pd.DatetimeIndex(df.t).normalize()"", 'df.t.dt.normalize()', 'pd.DatetimeIndex(df.t).normalize()']","['df', 'pd.DatetimeIndex(df.t).normalize()', ""df['date'] = pd.DatetimeIndex(df.t).normalize()"", 'df', 'df.t.dt.normalize()', 'pd.DatetimeIndex(df.t).normalize()']","['df = pd.DataFrame({""t"": pd.date_range(\'2014-01-01\', periods=5, freq=\'H\')})', 'pd.DatetimeIndex(df.t).normalize()', ""df['date'] = pd.DatetimeIndex(df.t).normalize()"", 'df.t.dt.normalize()', 'pd.DatetimeIndex(df.t).normalize()']",,
24793359,numpyMatrix = df.as_matrix(),['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()']
24804512,"display.clear_output(wait=True)
display.display(pl.gcf())",[],"['display.clear_output(wait=True)', 'display.display(pl.gcf())']",[],[],[]
24826569,"data.groupby(level=[0, 1]).sum()
dtype: int64","['data.groupby(level=[0, 1]).sum()']","['data.groupby(level=[0, 1]).sum()', 'dtype: int64']","['data.groupby(level=[0, 1]).sum()']",,
24828425,df.select_dtypes(include=[np.float64]),['df.select_dtypes(include=[np.float64])'],['df.select_dtypes(include=[np.float64])'],['df.select_dtypes(include=[np.float64])'],,
24870404,,[],[''],[],[],[]
24871316,,[],[''],[],[],[]
24888331,"df = DataFrame(columns=('lib', 'qty1', 'qty2'))",[],"[""df = DataFrame(columns=('lib', 'qty1', 'qty2'))""]",[],[],[]
24902313,"DF.dtypes
[key for key in dict(DF.dtypes) if dict(DF.dtypes)[key] in ['float64', 'int64']]","['DF.dtypes', ""[key for key in dict(DF.dtypes) if dict(DF.dtypes)[key] in ['float64', 'int64']]""]","['DF.dtypes', ""[key for key in dict(DF.dtypes) if dict(DF.dtypes)[key] in ['float64', 'int64']]""]","['DF.dtypes', ""[key for key in dict(DF.dtypes) if dict(DF.dtypes)[key] in ['float64', 'int64']]""]",,
24907560,"df = pd.DataFrame({'a': np.random.randn(1000),
                   'b': range(1000),
                   'c': ['a'] * 1000,
                   'd': pd.date_range('2000-1-1', periods=1000)})
df.select_dtypes(['float64','int64'])
...","[""df = pd.DataFrame({'a': np.random.randn(1000),"", ""                   'd': pd.date_range('2000-1-1', periods=1000)})"", ""df.select_dtypes(['float64','int64'])""]","[""                   'b': range(1000),"", ""                   'c': ['a'] * 1000,"", ""                   'd': pd.date_range('2000-1-1', periods=1000)})"", ""df.select_dtypes(['float64','int64'])"", '...']","[""                   'd': pd.date_range('2000-1-1', periods=1000)})"", ""df.select_dtypes(['float64','int64'])""]",,
24913075,"import pandas as pd
import numpy as np
numberOfRows = 5
df = pd.DataFrame(index=np.arange(0, numberOfRows), columns=('lib', 'qty1', 'qty2') )
for x in np.arange(0, numberOfRows):
    df.loc[x] = [np.random.randint(-1,1) for n in range(3)]
In[23]: df
0   -1    -1    -1","[""df = pd.DataFrame(index=np.arange(0, numberOfRows), columns=('lib', 'qty1', 'qty2') )"", '    df.loc[x] = [np.random.randint(-1,1) for n in range(3)]']","['import pandas as pd', 'import numpy as np', 'numberOfRows = 5', 'for x in np.arange(0, numberOfRows):', '    df.loc[x] = [np.random.randint(-1,1) for n in range(3)]', 'In[23]: df', '0   -1    -1    -1']","['    df.loc[x] = [np.random.randint(-1,1) for n in range(3)]']",,
24933234,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(10000, 4), columns=list('ABCD'))
def empty(df):
    return df.empty
def lenz(df):
    return len(df) == 0
def lenzi(df):
    return len(df.index) == 0","[""df = pd.DataFrame(np.random.randn(10000, 4), columns=list('ABCD'))"", '    return df.empty', '    return len(df.index) == 0']","['import pandas as pd', 'import numpy as np', 'def empty(df):', '    return df.empty', 'def lenz(df):', '    return len(df) == 0', 'def lenzi(df):', '    return len(df.index) == 0']","['    return df.empty', '    return len(df.index) == 0']",,
24980809,"po_grouped_df = poagg_df.groupby(['EID','PCODE'], as_index=False)
pd.merge(acc_df, pol_df, on=['EID','PCODE'], how='inner',suffixes=('_Acc','_Po'))","[""po_grouped_df = poagg_df.groupby(['EID','PCODE'], as_index=False)"", ""pd.merge(acc_df, pol_df, on=['EID','PCODE'], how='inner',suffixes=('_Acc','_Po'))""]","[""po_grouped_df = poagg_df.groupby(['EID','PCODE'], as_index=False)"", ""pd.merge(acc_df, pol_df, on=['EID','PCODE'], how='inner',suffixes=('_Acc','_Po'))""]","[""po_grouped_df = poagg_df.groupby(['EID','PCODE'], as_index=False)"", ""pd.merge(acc_df, pol_df, on=['EID','PCODE'], how='inner',suffixes=('_Acc','_Po'))""]",,
24988227,"reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.iteritems() for innerKey, values in innerDict.iteritems()}
reform
{('A', 'a'): [1, 2, 3, 4, 5],
 ('A', 'b'): [6, 7, 8, 9, 1],
 ('B', 'a'): [2, 3, 4, 5, 6],
 ('B', 'b'): [7, 8, 9, 1, 2]}
pandas.DataFrame(reform)","['reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.iteritems() for innerKey, values in innerDict.iteritems()}', 'pandas.DataFrame(reform)']","['reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.iteritems() for innerKey, values in innerDict.iteritems()}', 'reform', ""{('A', 'a'): [1, 2, 3, 4, 5],"", "" ('A', 'b'): [6, 7, 8, 9, 1],"", "" ('B', 'a'): [2, 3, 4, 5, 6],"", "" ('B', 'b'): [7, 8, 9, 1, 2]}""]","['reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.iteritems() for innerKey, values in innerDict.iteritems()}']",,
25023460,"def order(frame,var):
    varlist =[w for w in frame.columns if w not in var]
    frame = frame[var+varlist]
    return frame 
frame = order(frame,['Total'])
frame = order(frame,['Total','Date'])
frame = order(frame,[v for v in frame.columns if ""VAR"" in v])",[],"['def order(frame,var):', '    varlist =[w for w in frame.columns if w not in var]', '    frame = frame[var+varlist]', '    return frame ', ""frame = order(frame,['Total'])"", ""frame = order(frame,['Total','Date'])"", 'frame = order(frame,[v for v in frame.columns if ""VAR"" in v])']",[],[],[]
25025065,,[],[''],[],[],[]
25030617,"from sqlalchemy import create_engine
import pandas as pd
engine = create_engine('dialect://user:pass@host:port/schema', echo=False)
f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')","[""f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')""]","['from sqlalchemy import create_engine', 'import pandas as pd', ""engine = create_engine('dialect://user:pass@host:port/schema', echo=False)"", ""f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')""]","[""f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')""]",,
25050179,,[],[''],[],[],[]
25057724,"df.iloc[::5, :]","['df.iloc[::5, :]']","['df.iloc[::5, :]']","['df.iloc[::5, :]']",,
25058102,"import numpy as np
import pandas as pd
df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))
df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))
df_concat = pd.concat((df1, df2))
x   -0.163044
dtype: float64
x   -0.192037
dtype: float64
by_row_index = df_concat.groupby(df_concat.index)
df_means = by_row_index.mean()","['df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df_concat = pd.concat((df1, df2))', 'by_row_index = df_concat.groupby(df_concat.index)', 'df_means = by_row_index.mean()']","['import numpy as np', 'import pandas as pd', 'df_concat = pd.concat((df1, df2))', 'x   -0.163044', 'dtype: float64', 'x   -0.192037', 'dtype: float64', 'by_row_index = df_concat.groupby(df_concat.index)', 'df_means = by_row_index.mean()']","['df_concat = pd.concat((df1, df2))', 'by_row_index = df_concat.groupby(df_concat.index)', 'df_means = by_row_index.mean()']",,
25059471,"df = DataFrame(np.random.randn(10, 4), columns=list('abcd'))
df2 = df.copy()
dfs = [df, df2]
df",['df2 = df.copy()'],"[""df = DataFrame(np.random.randn(10, 4), columns=list('abcd'))"", 'df2 = df.copy()', 'dfs = [df, df2]', 'df']",['df2 = df.copy()'],,
25059620,"df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))
df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))
df = pd.concat([df1, df2])
foo = df.groupby(level=0).mean()
foo.head()","['df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df = pd.concat([df1, df2])', 'foo = df.groupby(level=0).mean()', 'foo.head()']","['df = pd.concat([df1, df2])', 'foo = df.groupby(level=0).mean()', 'foo.head()']","['df = pd.concat([df1, df2])', 'foo = df.groupby(level=0).mean()', 'foo.head()']",,
25060811,"fails 
import matplotlib.pylab
import pandas
ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))
ser.plot()
succeeds
import matplotlib.pylab
import pandas
ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))
ser.plot()","[""ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))"", 'ser.plot()', ""ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))"", 'ser.plot()']","['fails ', 'import matplotlib.pylab', 'import pandas', 'ser.plot()', 'succeeds', 'import matplotlib.pylab', 'import pandas', 'ser.plot()']","[""ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))"", 'ser.plot()', ""ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))"", 'ser.plot()']",,
25122293,"cols = list(df)
cols.insert(0, cols.pop(cols.index('Mid')))
cols
['Mid', 'Net', 'Upper', 'Lower', 'Zsore']
df = df.ix[:, cols]
df
Answer_option                                      
mid = df['Mid']
df.drop(labels=['Mid'], axis=1,inplace = True)
df.insert(0, 'Mid', mid)
df
Answer_option                                      
df = df.loc[:, cols]","[""cols.insert(0, cols.pop(cols.index('Mid')))"", ""df.drop(labels=['Mid'], axis=1,inplace = True)"", ""df.insert(0, 'Mid', mid)"", 'df = df.loc[:, cols]']","['cols = list(df)', ""cols.insert(0, cols.pop(cols.index('Mid')))"", 'cols', ""['Mid', 'Net', 'Upper', 'Lower', 'Zsore']"", 'df = df.ix[:, cols]', 'df', 'Answer_option                                      ', ""mid = df['Mid']"", ""df.drop(labels=['Mid'], axis=1,inplace = True)"", ""df.insert(0, 'Mid', mid)"", 'df', 'Answer_option                                      ', 'df = df.loc[:, cols]']","[""cols.insert(0, cols.pop(cols.index('Mid')))"", ""df.drop(labels=['Mid'], axis=1,inplace = True)"", ""df.insert(0, 'Mid', mid)"", 'df = df.loc[:, cols]']",,
25129265,sales['time_hour'] = sales.timestamp.apply(lambda x: x.hour),"[""sales['time_hour'] = sales.timestamp.apply(lambda x: x.hour)""]","[""sales['time_hour'] = sales.timestamp.apply(lambda x: x.hour)""]","[""sales['time_hour'] = sales.timestamp.apply(lambda x: x.hour)""]",,
25129655,,[],[''],[],[],[]
25146337,"t = pandas.tslib.Timestamp.now()
t
t.to_datetime()
t.day
t.month
t.year
df
df.date_time
df.date_time.map(lambda x: x.strftime('%Y-%m-%d'))","['t = pandas.tslib.Timestamp.now()', 't.to_datetime()', 't.day', 't.month', 't.year', ""df.date_time.map(lambda x: x.strftime('%Y-%m-%d'))""]","['t = pandas.tslib.Timestamp.now()', 't', 't.to_datetime()', 't.day', 't.month', 't.year', 'df', 'df.date_time', ""df.date_time.map(lambda x: x.strftime('%Y-%m-%d'))""]","['t = pandas.tslib.Timestamp.now()', 't.to_datetime()', 't.day', 't.month', 't.year', ""df.date_time.map(lambda x: x.strftime('%Y-%m-%d'))""]",,
25149272,"df['year'] = pd.DatetimeIndex(df['ArrivalDate']).year
df['month'] = pd.DatetimeIndex(df['ArrivalDate']).month
df['year'] = df['ArrivalDate'].dt.year
df['month'] = df['ArrivalDate'].dt.month","[""df['year'] = pd.DatetimeIndex(df['ArrivalDate']).year"", ""df['month'] = pd.DatetimeIndex(df['ArrivalDate']).month"", ""df['year'] = df['ArrivalDate'].dt.year"", ""df['month'] = df['ArrivalDate'].dt.month""]","[""df['year'] = pd.DatetimeIndex(df['ArrivalDate']).year"", ""df['month'] = pd.DatetimeIndex(df['ArrivalDate']).month"", ""df['year'] = df['ArrivalDate'].dt.year"", ""df['month'] = df['ArrivalDate'].dt.month""]","[""df['year'] = pd.DatetimeIndex(df['ArrivalDate']).year"", ""df['month'] = pd.DatetimeIndex(df['ArrivalDate']).month"", ""df['year'] = df['ArrivalDate'].dt.year"", ""df['month'] = df['ArrivalDate'].dt.month""]",,
25162895,,[],[''],[],[],[]
25190070,"df = pd.DataFrame(np.random.random((4,4)))
df.columns = pd.MultiIndex.from_product([[1,2],['A','B']])","['df = pd.DataFrame(np.random.random((4,4)))', ""df.columns = pd.MultiIndex.from_product([[1,2],['A','B']])""]","[""df.columns = pd.MultiIndex.from_product([[1,2],['A','B']])""]","[""df.columns = pd.MultiIndex.from_product([[1,2],['A','B']])""]",,
25206286,,[],[''],[],[],[]
25208947,"df
df['label'].str.join(sep='*').str.get_dummies(sep='*')","[""df['label'].str.join(sep='*').str.get_dummies(sep='*')""]","['df', ""df['label'].str.join(sep='*').str.get_dummies(sep='*')""]","[""df['label'].str.join(sep='*').str.get_dummies(sep='*')""]",,
25211834,"data(iris)
head(iris, 10)
tail(iris, 10)
import pandas as pd
from sklearn import datasets
iris = pd.DataFrame(datasets.load_iris().data)
iris.head(10)
iris.tail(10)
iris.ix[:,1:2].head(10)","['iris = pd.DataFrame(datasets.load_iris().data)', 'iris.head(10)', 'iris.tail(10)', 'iris.ix[:,1:2].head(10)']","['data(iris)', 'head(iris, 10)', 'tail(iris, 10)', 'import pandas as pd', 'from sklearn import datasets', 'iris.head(10)', 'iris.tail(10)', 'iris.ix[:,1:2].head(10)']","['iris.head(10)', 'iris.tail(10)', 'iris.ix[:,1:2].head(10)']",,
25213438,"lm = sns.lmplot('X','Y',df,col='Z',sharex=False,sharey=False)
axes = lm.axes
axes[0,0].set_ylim(0,)
axes[0,1].set_ylim(0,)",['axes = lm.axes'],"[""lm = sns.lmplot('X','Y',df,col='Z',sharex=False,sharey=False)"", 'axes = lm.axes', 'axes[0,0].set_ylim(0,)', 'axes[0,1].set_ylim(0,)']",['axes = lm.axes'],,
25213614,"g = sns.lmplot('X', 'Y', df, col='Z', sharex=False, sharey=False)
g.set(ylim=(0, None))",[],"[""g = sns.lmplot('X', 'Y', df, col='Z', sharex=False, sharey=False)"", 'g.set(ylim=(0, None))']",[],[],[]
25217425,"In[20]: my_dict = dict( A = np.array([1,2]), B = np.array([1,2,3,4]) )
In[21]: df = pd.DataFrame.from_dict(my_dict, orient='index')
In[22]: df
In[23]: df.transpose()","[""In[21]: df = pd.DataFrame.from_dict(my_dict, orient='index')"", 'In[23]: df.transpose()']","['In[20]: my_dict = dict( A = np.array([1,2]), B = np.array([1,2,3,4]) )', 'In[22]: df', 'In[23]: df.transpose()']","[""In[21]: df = pd.DataFrame.from_dict(my_dict, orient='index')"", 'In[23]: df.transpose()']",,
25230582,"pd.to_csv('your.csv', index=False)","[""pd.to_csv('your.csv', index=False)""]","[""pd.to_csv('your.csv', index=False)""]","[""pd.to_csv('your.csv', index=False)""]",,
25254087,"df_test.iloc[0]
df_test['Btime'].iloc[0]
df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])
df
df.ix[1, 'foo']
Out[4]: 'C'","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", 'df', ""df.ix[1, 'foo']"", ""Out[4]: 'C'""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]"
25289109,"df_long = pd.melt(df, ""b"", var_name=""a"", value_name=""c"")
sns.factorplot(""a"", hue=""b"", y=""c"", data=df_long, kind=""box"")","['df_long = pd.melt(df, ""b"", var_name=""a"", value_name=""c"")']","['df_long = pd.melt(df, ""b"", var_name=""a"", value_name=""c"")', 'sns.factorplot(""a"", hue=""b"", y=""c"", data=df_long, kind=""box"")']","['df_long = pd.melt(df, ""b"", var_name=""a"", value_name=""c"")']",,
25352191,"pd.set_option('display.max_colwidth', -1)","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]",,
25376997,"df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]"
25401328,"from pandas import DataFrame
import pandas as pd
import matplotlib.pyplot as plt
data = {'ColB': {('A', 4): 3.0,
('C', 2): 0.0,
('B', 4): 51.0,
('B', 1): 0.0,
('C', 3): 0.0,
('B', 2): 7.0,
('Code', 'Month'): '',
('A', 3): 5.0,
('C', 1): 0.0,
('C', 4): 0.0,
('B', 3): 12.0},
'ColA': {('A', 4): 66.0,
('C', 2): 5.0,
('B', 4): 125.0,
('B', 1): 5.0,
('C', 3): 41.0,
('B', 2): 52.0,
('Code', 'Month'): '',
('A', 3): 22.0,
('C', 1): 14.0,
('C', 4): 51.0,
('B', 3): 122.0}}
df = DataFrame(data)
f, a = plt.subplots(3,1)
df.xs('A').plot(kind='bar',ax=a[0])
df.xs('B').plot(kind='bar',ax=a[1])
df.xs('C').plot(kind='bar',ax=a[2])","[""df.xs('A').plot(kind='bar',ax=a[0])"", ""df.xs('B').plot(kind='bar',ax=a[1])"", ""df.xs('C').plot(kind='bar',ax=a[2])""]","['from pandas import DataFrame', 'import pandas as pd', 'import matplotlib.pyplot as plt', ""data = {'ColB': {('A', 4): 3.0,"", ""('C', 2): 0.0,"", ""('B', 4): 51.0,"", ""('B', 1): 0.0,"", ""('C', 3): 0.0,"", ""('B', 2): 7.0,"", ""('Code', 'Month'): '',"", ""('A', 3): 5.0,"", ""('C', 1): 0.0,"", ""('C', 4): 0.0,"", ""('B', 3): 12.0},"", ""'ColA': {('A', 4): 66.0,"", ""('C', 2): 5.0,"", ""('B', 4): 125.0,"", ""('B', 1): 5.0,"", ""('C', 3): 41.0,"", ""('B', 2): 52.0,"", ""('Code', 'Month'): '',"", ""('A', 3): 22.0,"", ""('C', 1): 14.0,"", ""('C', 4): 51.0,"", ""('B', 3): 122.0}}"", 'df = DataFrame(data)', 'f, a = plt.subplots(3,1)', ""df.xs('A').plot(kind='bar',ax=a[0])"", ""df.xs('B').plot(kind='bar',ax=a[1])"", ""df.xs('C').plot(kind='bar',ax=a[2])""]","[""df.xs('A').plot(kind='bar',ax=a[0])"", ""df.xs('B').plot(kind='bar',ax=a[1])"", ""df.xs('C').plot(kind='bar',ax=a[2])""]",,
25412939,"summed_group.unstack(level=0).plot(kind='bar', subplots=True)","[""summed_group.unstack(level=0).plot(kind='bar', subplots=True)""]","[""summed_group.unstack(level=0).plot(kind='bar', subplots=True)""]","[""summed_group.unstack(level=0).plot(kind='bar', subplots=True)""]",,
25415404,"pd.set_option('display.expand_frame_repr', False)","[""pd.set_option('display.expand_frame_repr', False)""]","[""pd.set_option('display.expand_frame_repr', False)""]","[""pd.set_option('display.expand_frame_repr', False)""]",,
25440505,df.values.flatten(),['df.values.flatten()'],['df.values.flatten()'],['df.values.flatten()'],,
25442201,,[],[''],[],[],[]
25442986,"df.to_sql('table', engine, chunksize=20000)","[""df.to_sql('table', engine, chunksize=20000)""]","[""df.to_sql('table', engine, chunksize=20000)""]","[""df.to_sql('table', engine, chunksize=20000)""]",,
25449186,"for p in ax.patches:
    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))",[],"['for p in ax.patches:', '    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))']",[],[],[]
25454051,"class RandomForestClassifierWithCoef(RandomForestClassifier):
    def fit(self, *args, **kwargs):
        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)
        self.coef_ = self.feature_importances_
y=(pd.Series(iris.target, name='target')==2).astype(int)
from sklearn import datasets
import pandas as pd
from pandas import Series
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFECV
class RandomForestClassifierWithCoef(RandomForestClassifier):
    def fit(self, *args, **kwargs):
        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)
        self.coef_ = self.feature_importances_
iris = datasets.load_iris()
x=pd.DataFrame(iris.data, columns=['var1','var2','var3', 'var4'])
y=(pd.Series(iris.target, name='target')==2).astype(int)
rf = RandomForestClassifierWithCoef(n_estimators=500, min_samples_leaf=5, n_jobs=-1)
rfecv = RFECV(estimator=rf, step=1, cv=2, scoring='roc_auc', verbose=2)
selector=rfecv.fit(x, y)","[""y=(pd.Series(iris.target, name='target')==2).astype(int)"", ""x=pd.DataFrame(iris.data, columns=['var1','var2','var3', 'var4'])"", ""y=(pd.Series(iris.target, name='target')==2).astype(int)""]","['class RandomForestClassifierWithCoef(RandomForestClassifier):', '    def fit(self, *args, **kwargs):', '        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)', '        self.coef_ = self.feature_importances_', 'from sklearn import datasets', 'import pandas as pd', 'from pandas import Series', 'from sklearn.ensemble import RandomForestClassifier', 'from sklearn.feature_selection import RFECV', 'class RandomForestClassifierWithCoef(RandomForestClassifier):', '    def fit(self, *args, **kwargs):', '        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)', '        self.coef_ = self.feature_importances_', 'iris = datasets.load_iris()', 'rf = RandomForestClassifierWithCoef(n_estimators=500, min_samples_leaf=5, n_jobs=-1)', ""rfecv = RFECV(estimator=rf, step=1, cv=2, scoring='roc_auc', verbose=2)"", 'selector=rfecv.fit(x, y)']","[""y=(pd.Series(iris.target, name='target')==2).astype(int)"", ""y=(pd.Series(iris.target, name='target')==2).astype(int)""]",,
25478896,"for index, row in rche_df.iterrows():
    if isinstance(row.wgs1984_latitude, float):
        row = row.copy()
        target = row.address_chi        
        dict_temp = geocoding(target)
        rche_df.loc[index, 'wgs1984_latitude'] = dict_temp['lat']
        rche_df.loc[index, 'wgs1984_longitude'] = dict_temp['long']","['for index, row in rche_df.iterrows():', '        row = row.copy()', ""        rche_df.loc[index, 'wgs1984_latitude'] = dict_temp['lat']"", ""        rche_df.loc[index, 'wgs1984_longitude'] = dict_temp['long']""]","['for index, row in rche_df.iterrows():', '    if isinstance(row.wgs1984_latitude, float):', '        row = row.copy()', '        target = row.address_chi        ', '        dict_temp = geocoding(target)', ""        rche_df.loc[index, 'wgs1984_latitude'] = dict_temp['lat']"", ""        rche_df.loc[index, 'wgs1984_longitude'] = dict_temp['long']""]","['for index, row in rche_df.iterrows():', '        row = row.copy()', ""        rche_df.loc[index, 'wgs1984_latitude'] = dict_temp['lat']"", ""        rche_df.loc[index, 'wgs1984_longitude'] = dict_temp['long']""]",,
25479955,"df['Minimum'] = df.loc[:, ['B0', 'B1', 'B2']].min(axis=1)
n_columns = 2
cols_to_use = ['B' + str(i) for i in range(n_columns)]
df['Minimum'] = df.loc[:, cols_to_use].min(axis=1)","[""df['Minimum'] = df.loc[:, ['B0', 'B1', 'B2']].min(axis=1)"", ""df['Minimum'] = df.loc[:, cols_to_use].min(axis=1)""]","[""df['Minimum'] = df.loc[:, ['B0', 'B1', 'B2']].min(axis=1)"", 'n_columns = 2', ""cols_to_use = ['B' + str(i) for i in range(n_columns)]"", ""df['Minimum'] = df.loc[:, cols_to_use].min(axis=1)""]","[""df['Minimum'] = df.loc[:, ['B0', 'B1', 'B2']].min(axis=1)"", ""df['Minimum'] = df.loc[:, cols_to_use].min(axis=1)""]",,
25493765,"df.merge(df1, on='sku', how='left')
df.merge(df1, left_index=True, right_index=True, how='left')
sku                 
df['dept']=df.sku.map(df1.dept)
df","[""df.merge(df1, on='sku', how='left')"", ""df.merge(df1, left_index=True, right_index=True, how='left')"", ""df['dept']=df.sku.map(df1.dept)""]","[""df.merge(df1, on='sku', how='left')"", ""df.merge(df1, left_index=True, right_index=True, how='left')"", 'sku                 ', ""df['dept']=df.sku.map(df1.dept)"", 'df']","[""df.merge(df1, on='sku', how='left')"", ""df.merge(df1, left_index=True, right_index=True, how='left')"", ""df['dept']=df.sku.map(df1.dept)""]",,
25509805,,[],[''],[],[],[]
25535803,,[],[''],[],[],[]
25561094,"temp = pd.DatetimeIndex(data['my_dt'])
data['weekday'] = temp.weekday","[""data['weekday'] = temp.weekday""]","[""temp = pd.DatetimeIndex(data['my_dt'])"", ""data['weekday'] = temp.weekday""]","[""data['weekday'] = temp.weekday""]",,
25562948,"import pandas as pd
import numpy as np
from sklearn.base import TransformerMixin
class DataFrameImputer(TransformerMixin):
    def __init__(self):
        """"""Impute missing values.
        Columns of dtype object are imputed with the most frequent value 
        in column.
        Columns of other types are imputed with mean of column.
        """"""
    def fit(self, X, y=None):
        self.fill = pd.Series([X[c].value_counts().index[0]
            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],
            index=X.columns)
        return self
    def transform(self, X, y=None):
        return X.fillna(self.fill)
data = [
    ['a', 1, 2],
    ['b', 1, 1],
    ['b', 2, 2],
    [np.nan, np.nan, np.nan]
]
X = pd.DataFrame(data)
xt = DataFrameImputer().fit_transform(X)
print('before...')
print(X)
print('after...')
print(xt)","['        self.fill = pd.Series([X[c].value_counts().index[0]', ""            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],"", '        return X.fillna(self.fill)', 'X = pd.DataFrame(data)']","['import pandas as pd', 'import numpy as np', 'from sklearn.base import TransformerMixin', 'class DataFrameImputer(TransformerMixin):', '    def __init__(self):', '        """"""Impute missing values.', '        Columns of dtype object are imputed with the most frequent value ', '        in column.', '        Columns of other types are imputed with mean of column.', '        """"""', '    def fit(self, X, y=None):', ""            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],"", '            index=X.columns)', '        return self', '    def transform(self, X, y=None):', '        return X.fillna(self.fill)', 'data = [', ""    ['a', 1, 2],"", ""    ['b', 1, 1],"", ""    ['b', 2, 2],"", '    [np.nan, np.nan, np.nan]', ']', 'xt = DataFrameImputer().fit_transform(X)', ""print('before...')"", 'print(X)', ""print('after...')"", 'print(xt)']","['        self.fill = pd.Series([X[c].value_counts().index[0]', ""            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],"", '        return X.fillna(self.fill)']",,
25574089,"df.rename(columns={'two':'new_name'}, inplace=True)","[""df.rename(columns={'two':'new_name'}, inplace=True)""]","[""df.rename(columns={'two':'new_name'}, inplace=True)""]","[""df.rename(columns={'two':'new_name'}, inplace=True)""]",,
25588487,"ax = df.plot()
fig = ax.get_figure()
fig.savefig('asdf.png')",['ax = df.plot()'],"['ax = df.plot()', 'fig = ax.get_figure()', ""fig.savefig('asdf.png')""]",['ax = df.plot()'],,
25612064,"import numpy as np
import pandas as pd
df = pd.DataFrame({'M':[1,2,3,4], 'D':[6,7,8,9], 'Y':[1990,1991,1992,1993]})
y = np.array(df['Y']-1970, dtype='<M8[Y]')
m = np.array(df['M']-1, dtype='<m8[M]')
d = np.array(df['D']-1, dtype='<m8[D]')
dates2 = pd.Series(y+m+d)
dtype: datetime64[ns]
df = pd.concat([df]*1000)
def combine64(years, months=1, days=1, weeks=None, hours=None, minutes=None,
              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):
    years = np.asarray(years) - 1970
    months = np.asarray(months) - 1
    days = np.asarray(days) - 1
    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',
             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')
    vals = (years, months, days, weeks, hours, minutes, seconds,
            milliseconds, microseconds, nanoseconds)
    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)
               if v is not None)
combine64(df['Y'], df['M'], df['D'])
Out[437]: array(['1990-01-06', '1991-02-07', '1992-03-08', '1993-04-09'], dtype='datetime64[D]')","[""df = pd.DataFrame({'M':[1,2,3,4], 'D':[6,7,8,9], 'Y':[1990,1991,1992,1993]})"", 'dates2 = pd.Series(y+m+d)', 'df = pd.concat([df]*1000)']","['import numpy as np', 'import pandas as pd', ""y = np.array(df['Y']-1970, dtype='<M8[Y]')"", ""m = np.array(df['M']-1, dtype='<m8[M]')"", ""d = np.array(df['D']-1, dtype='<m8[D]')"", 'dtype: datetime64[ns]', 'df = pd.concat([df]*1000)', 'def combine64(years, months=1, days=1, weeks=None, hours=None, minutes=None,', '              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):', '    years = np.asarray(years) - 1970', '    months = np.asarray(months) - 1', '    days = np.asarray(days) - 1', ""    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',"", ""             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')"", '    vals = (years, months, days, weeks, hours, minutes, seconds,', '            milliseconds, microseconds, nanoseconds)', '    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)', '               if v is not None)', ""combine64(df['Y'], df['M'], df['D'])"", ""Out[437]: array(['1990-01-06', '1991-02-07', '1992-03-08', '1993-04-09'], dtype='datetime64[D]')""]",['df = pd.concat([df]*1000)'],,
25630681,"desired_width = 320    
pd.set_option('display.width', desired_width)","[""pd.set_option('display.width', desired_width)""]","['desired_width = 320    ', ""pd.set_option('display.width', desired_width)""]","[""pd.set_option('display.width', desired_width)""]",,
25643178,"colsToDrop = ['a']
df.drop(colsToDrop, axis=1)","['df.drop(colsToDrop, axis=1)']","[""colsToDrop = ['a']"", 'df.drop(colsToDrop, axis=1)']","['df.drop(colsToDrop, axis=1)']",,
25646414,"import numpy as np
(td / np.timedelta64(1, 'D')).astype(int)","[""(td / np.timedelta64(1, 'D')).astype(int)""]","['import numpy as np', ""(td / np.timedelta64(1, 'D')).astype(int)""]","[""(td / np.timedelta64(1, 'D')).astype(int)""]",,
25698756,"df.replace({'\n': '<br>'}, regex=True)
df = pd.DataFrame({'a': ['1\n', '2\n', '3'], 'b': ['4\n', '5', '6\n']})
df
df.replace({'\n': '<br>'}, regex=True)","[""df.replace({'\\n': '<br>'}, regex=True)"", ""df = pd.DataFrame({'a': ['1\\n', '2\\n', '3'], 'b': ['4\\n', '5', '6\\n']})"", ""df.replace({'\\n': '<br>'}, regex=True)""]","[""df.replace({'\\n': '<br>'}, regex=True)"", 'df', ""df.replace({'\\n': '<br>'}, regex=True)""]","[""df.replace({'\\n': '<br>'}, regex=True)"", ""df.replace({'\\n': '<br>'}, regex=True)""]",,
25701576,"import numpy as np
import pandas as pds
df = pds.DataFrame(np.random.rand(14,4), columns=['a', 'b', 'c', 'd'])
def chunker(seq, size):
    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))
for i in chunker(df,5):
    data = pool.map(myfunction, chunk)
    data.domorestuff()","[""df = pds.DataFrame(np.random.rand(14,4), columns=['a', 'b', 'c', 'd'])"", '    data = pool.map(myfunction, chunk)']","['import numpy as np', 'import pandas as pds', 'def chunker(seq, size):', '    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))', 'for i in chunker(df,5):', '    data = pool.map(myfunction, chunk)', '    data.domorestuff()']","['    data = pool.map(myfunction, chunk)']",,
25703030,"df = pd.DataFrame(np.random.rand(15, 5), index=[0]*15)
df[0] = range(15)
df
[...]
df.groupby(np.arange(len(df))//10)","['df = pd.DataFrame(np.random.rand(15, 5), index=[0]*15)', 'df.groupby(np.arange(len(df))//10)']","['df[0] = range(15)', 'df', '[...]', 'df.groupby(np.arange(len(df))//10)']",['df.groupby(np.arange(len(df))//10)'],,
25715719,,[],[''],[],[],[]
25716383,,[],[''],[],[],[]
25733562,df.reset_index(inplace=True)  ,['df.reset_index(inplace=True)  '],['df.reset_index(inplace=True)  '],['df.reset_index(inplace=True)  '],,
25748741,df['e'] = df.a + df.b + df.d,[],"[""df['e'] = df.a + df.b + df.d""]",[],[],[]
25748826,"df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})
df['e'] = df.sum(axis=1)
df
col_list= list(df)
col_list.remove('d')
col_list
['a', 'b', 'c']
df['e'] = df[col_list].sum(axis=1)
df","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df['e'] = df.sum(axis=1)"", 'df', 'col_list= list(df)', ""col_list.remove('d')"", 'col_list', ""['a', 'b', 'c']"", ""df['e'] = df[col_list].sum(axis=1)"", 'df']","[""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]"
25774395,,[],[''],[],[],[]
25774932,"from pandas import Series, DataFrame
s=Series([2,4,4,3],index=['a','b','c','d'])
s.idxmax()
s[s==s.max()]
dtype: int64","['s.idxmax()', 's[s==s.max()]']","['from pandas import Series, DataFrame', ""s=Series([2,4,4,3],index=['a','b','c','d'])"", 's.idxmax()', 's[s==s.max()]', 'dtype: int64']","['s.idxmax()', 's[s==s.max()]']",,
25789512,"df['New_Sample'] = df.Sample.str[:1]
df['New_Sample'] = df.Sample.apply(lambda x: x[:1])
df","[""df['New_Sample'] = df.Sample.apply(lambda x: x[:1])""]","[""df['New_Sample'] = df.Sample.str[:1]"", ""df['New_Sample'] = df.Sample.apply(lambda x: x[:1])"", 'df']","[""df['New_Sample'] = df.Sample.apply(lambda x: x[:1])""]",,
25797313,"test[1].index + pd.DateOffset(hours=16)
pd.to_timedelta(16, unit='h')
Out[242]: numpy.timedelta64(16,'ns')","['test[1].index + pd.DateOffset(hours=16)', ""pd.to_timedelta(16, unit='h')""]","['test[1].index + pd.DateOffset(hours=16)', ""pd.to_timedelta(16, unit='h')"", ""Out[242]: numpy.timedelta64(16,'ns')""]","['test[1].index + pd.DateOffset(hours=16)', ""pd.to_timedelta(16, unit='h')""]",,
25798359,"data1.groupby(['Bool', 'Dir', 'Date']).sum().groupby(level=[0, 1]).cumsum()
data1.groupby(['Bool', 'Dir']).apply(lambda x: x['Data'].cumsum())","[""data1.groupby(['Bool', 'Dir', 'Date']).sum().groupby(level=[0, 1]).cumsum()"", ""data1.groupby(['Bool', 'Dir']).apply(lambda x: x['Data'].cumsum())""]","[""data1.groupby(['Bool', 'Dir', 'Date']).sum().groupby(level=[0, 1]).cumsum()"", ""data1.groupby(['Bool', 'Dir']).apply(lambda x: x['Data'].cumsum())""]","[""data1.groupby(['Bool', 'Dir', 'Date']).sum().groupby(level=[0, 1]).cumsum()"", ""data1.groupby(['Bool', 'Dir']).apply(lambda x: x['Data'].cumsum())""]",,
25799781,,[],[''],[],[],[]
25916109,"df = DataFrame({""A"":[0,0.5,1.0,3.5,4.0,4.5], ""B"":[1,4,6,2,4,3], ""C"":[3,2,1,0,5,3]})
df.set_index(""A"")
new_index = Index(arange(0,5,0.5), name=""A"")
df.set_index(""A"").reindex(new_index)
df.set_index(""A"").reindex(new_index).reset_index()","['df.set_index(""A"")', 'df.set_index(""A"").reindex(new_index)', 'df.set_index(""A"").reindex(new_index).reset_index()']","['df = DataFrame({""A"":[0,0.5,1.0,3.5,4.0,4.5], ""B"":[1,4,6,2,4,3], ""C"":[3,2,1,0,5,3]})', 'df.set_index(""A"")', 'new_index = Index(arange(0,5,0.5), name=""A"")', 'df.set_index(""A"").reindex(new_index)', 'df.set_index(""A"").reindex(new_index).reset_index()']","['df.set_index(""A"")', 'df.set_index(""A"").reindex(new_index)', 'df.set_index(""A"").reindex(new_index).reset_index()']",,
25935024,,[],[''],[],[],[]
25959539,"df.head(5) 
df.tail(5) ","['df.head(5) ', 'df.tail(5) ']","['df.head(5) ', 'df.tail(5) ']","['df.head(5) ', 'df.tail(5) ']",,
25962187,"chunksize = 10 ** 6
for chunk in pd.read_csv(filename, chunksize=chunksize):
    process(chunk)","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['chunksize = 10 ** 6', 'for chunk in pd.read_csv(filename, chunksize=chunksize):', '    process(chunk)']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']"
26000515,"import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import string
df = pd.DataFrame({'x':np.random.rand(10), 'y':np.random.rand(10)}, 
                  index=list(string.ascii_lowercase[:10]))
fig, ax = plt.subplots()
df.plot('x', 'y', kind='scatter', ax=ax)
for k, v in df.iterrows():
    ax.annotate(k, v)
fig.canvas.draw()
from matplotlib import cm
cmap = cm.get_cmap('Spectral')
df.plot('x', 'y', kind='scatter', ax=ax, s=120, linewidth=0, 
        c=range(len(df)), colormap=cmap)
for k, v in df.iterrows():
    ax.annotate(k, v,
                xytext=(10,-5), textcoords='offset points',
                family='sans-serif', fontsize=18, color='darkslategrey')","[""df = pd.DataFrame({'x':np.random.rand(10), 'y':np.random.rand(10)}, "", ""df.plot('x', 'y', kind='scatter', ax=ax)"", 'for k, v in df.iterrows():', ""df.plot('x', 'y', kind='scatter', ax=ax, s=120, linewidth=0, "", 'for k, v in df.iterrows():']","['import matplotlib.pyplot as plt', 'import pandas as pd', 'import numpy as np', 'import string', '                  index=list(string.ascii_lowercase[:10]))', 'fig, ax = plt.subplots()', ""df.plot('x', 'y', kind='scatter', ax=ax)"", 'for k, v in df.iterrows():', '    ax.annotate(k, v)', 'fig.canvas.draw()', 'from matplotlib import cm', ""cmap = cm.get_cmap('Spectral')"", ""df.plot('x', 'y', kind='scatter', ax=ax, s=120, linewidth=0, "", '        c=range(len(df)), colormap=cmap)', 'for k, v in df.iterrows():', '    ax.annotate(k, v,', ""                xytext=(10,-5), textcoords='offset points',"", ""                family='sans-serif', fontsize=18, color='darkslategrey')""]","[""df.plot('x', 'y', kind='scatter', ax=ax)"", 'for k, v in df.iterrows():', ""df.plot('x', 'y', kind='scatter', ax=ax, s=120, linewidth=0, "", 'for k, v in df.iterrows():']",,
26017289,"chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\
       names=['lat','long','rf','date','slno'],index_col='slno',\
       header=None,parse_dates=['date'])
df=pd.DataFrame()","[""chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\\"", 'df=pd.DataFrame()']","[""chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\\"", ""       names=['lat','long','rf','date','slno'],index_col='slno',\\"", ""       header=None,parse_dates=['date'])""]","[""chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\\""]",,
26042312,"data = pd.read_csv(fname, encoding='cp1252')","[""data = pd.read_csv(fname, encoding='cp1252')""]","[""data = pd.read_csv(fname, encoding='cp1252')""]","[""data = pd.read_csv(fname, encoding='cp1252')""]",,
26064898,"import pandas as pd
fields = ['star_name', 'ra']
df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)","[""df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)""]","['import pandas as pd', ""fields = ['star_name', 'ra']"", ""df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)""]","[""df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)""]",,
26098292,"pd.DataFrame({'email':sf.index, 'list':sf.values})","[""pd.DataFrame({'email':sf.index, 'list':sf.values})""]",[],"[""pd.DataFrame({'email':sf.index, 'list':sf.values})""]",,
26121238,"BabyDataSet = zip(names,births)
BabyDataSet = list(zip(names,births))",[],"['BabyDataSet = zip(names,births)', 'BabyDataSet = list(zip(names,births))']",[],[],[]
26133621,,[],[''],[],[],[]
26139658,"import matplotlib.pyplot as plt
import pandas as pd
carat = [5, 10, 20, 30, 5, 10, 20, 30, 5, 10, 20, 30]
price = [100, 100, 200, 200, 300, 300, 400, 400, 500, 500, 600, 600]
color =['D', 'D', 'D', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G',]
df = pd.DataFrame(dict(carat=carat, price=price, color=color))
fig, ax = plt.subplots()
colors = {'D':'red', 'E':'blue', 'F':'green', 'G':'black'}
ax.scatter(df['carat'], df['price'], c=df['color'].apply(lambda x: colors[x]))
plt.show()
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
carat = [5, 10, 20, 30, 5, 10, 20, 30, 5, 10, 20, 30]
price = [100, 100, 200, 200, 300, 300, 400, 400, 500, 500, 600, 600]
color =['D', 'D', 'D', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G',]
df = pd.DataFrame(dict(carat=carat, price=price, color=color))
sns.lmplot('carat', 'price', data=df, hue='color', fit_reg=False)
plt.show()
fig, ax = plt.subplots()
colors = {'D':'red', 'E':'blue', 'F':'green', 'G':'black'}
grouped = df.groupby('color')
for key, group in grouped:
    group.plot(ax=ax, kind='scatter', x='carat', y='price', label=key, color=colors[key])
plt.show()","['df = pd.DataFrame(dict(carat=carat, price=price, color=color))', ""ax.scatter(df['carat'], df['price'], c=df['color'].apply(lambda x: colors[x]))"", 'df = pd.DataFrame(dict(carat=carat, price=price, color=color))', ""grouped = df.groupby('color')"", ""    group.plot(ax=ax, kind='scatter', x='carat', y='price', label=key, color=colors[key])""]","['import matplotlib.pyplot as plt', 'import pandas as pd', 'carat = [5, 10, 20, 30, 5, 10, 20, 30, 5, 10, 20, 30]', 'price = [100, 100, 200, 200, 300, 300, 400, 400, 500, 500, 600, 600]', ""color =['D', 'D', 'D', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G',]"", 'fig, ax = plt.subplots()', ""colors = {'D':'red', 'E':'blue', 'F':'green', 'G':'black'}"", ""ax.scatter(df['carat'], df['price'], c=df['color'].apply(lambda x: colors[x]))"", 'plt.show()', 'import matplotlib.pyplot as plt', 'import seaborn as sns', 'import pandas as pd', 'carat = [5, 10, 20, 30, 5, 10, 20, 30, 5, 10, 20, 30]', 'price = [100, 100, 200, 200, 300, 300, 400, 400, 500, 500, 600, 600]', ""color =['D', 'D', 'D', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G',]"", ""sns.lmplot('carat', 'price', data=df, hue='color', fit_reg=False)"", 'plt.show()', 'fig, ax = plt.subplots()', ""colors = {'D':'red', 'E':'blue', 'F':'green', 'G':'black'}"", ""grouped = df.groupby('color')"", 'for key, group in grouped:', ""    group.plot(ax=ax, kind='scatter', x='carat', y='price', label=key, color=colors[key])"", 'plt.show()']","[""ax.scatter(df['carat'], df['price'], c=df['color'].apply(lambda x: colors[x]))"", ""grouped = df.groupby('color')"", ""    group.plot(ax=ax, kind='scatter', x='carat', y='price', label=key, color=colors[key])""]",,
26147330,"df = pd.DataFrame([(1,2,3), ('foo','bar','baz'), (4,5,6)])
df
df.columns = df.iloc[1]
df.reindex(df.index.drop(1))","[""df = pd.DataFrame([(1,2,3), ('foo','bar','baz'), (4,5,6)])"", 'df.columns = df.iloc[1]', 'df.reindex(df.index.drop(1))']","['df', 'df.columns = df.iloc[1]', 'df.reindex(df.index.drop(1))']","['df.columns = df.iloc[1]', 'df.reindex(df.index.drop(1))']",,
26206622,"g = df.groupby('Date')
df.value / g.value.transform(""sum"") * df.wt
df['wa'] = df.value / g.value.transform(""sum"") * df.wt
g.wa.sum()
g.wa.transform(""sum"")","[""g = df.groupby('Date')"", 'df.value / g.value.transform(""sum"") * df.wt', 'df[\'wa\'] = df.value / g.value.transform(""sum"") * df.wt', 'g.wa.sum()', 'g.wa.transform(""sum"")']","[""g = df.groupby('Date')"", 'df.value / g.value.transform(""sum"") * df.wt', 'df[\'wa\'] = df.value / g.value.transform(""sum"") * df.wt', 'g.wa.sum()', 'g.wa.transform(""sum"")']","[""g = df.groupby('Date')"", 'df.value / g.value.transform(""sum"") * df.wt', 'df[\'wa\'] = df.value / g.value.transform(""sum"") * df.wt', 'g.wa.sum()', 'g.wa.transform(""sum"")']",,
26240208,,[],[''],[],[],[]
26244925,"frame[frame.duplicated(['key1', 'key2'], keep=False)].groupby(('key1', 'key2')).min()
frame.duplicated(['key1', 'key2'])
frame.duplicated(['key1', 'key2'], take_last=True)
frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])
frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])]
frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])].groupby(('key1', 'key2')).min()","[""frame[frame.duplicated(['key1', 'key2'], keep=False)].groupby(('key1', 'key2')).min()"", ""frame.duplicated(['key1', 'key2'])"", ""frame.duplicated(['key1', 'key2'], take_last=True)"", ""frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])]"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])].groupby(('key1', 'key2')).min()""]","[""frame[frame.duplicated(['key1', 'key2'], keep=False)].groupby(('key1', 'key2')).min()"", ""frame.duplicated(['key1', 'key2'])"", ""frame.duplicated(['key1', 'key2'], take_last=True)"", ""frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])]"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])].groupby(('key1', 'key2')).min()""]","[""frame[frame.duplicated(['key1', 'key2'], keep=False)].groupby(('key1', 'key2')).min()"", ""frame.duplicated(['key1', 'key2'])"", ""frame.duplicated(['key1', 'key2'], take_last=True)"", ""frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])]"", ""frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])].groupby(('key1', 'key2')).min()""]",,
26266031,"df.merge(pd.DataFrame(data = [s.values] * len(s), columns = s.index), left_index=True, right_index=True)
df.merge(pd.DataFrame(data = [s.values] * len(df), columns = s.index, index=df.index), left_index=True, right_index=True)","['df.merge(pd.DataFrame(data = [s.values] * len(s), columns = s.index), left_index=True, right_index=True)', 'df.merge(pd.DataFrame(data = [s.values] * len(df), columns = s.index, index=df.index), left_index=True, right_index=True)']",[],"['df.merge(pd.DataFrame(data = [s.values] * len(s), columns = s.index), left_index=True, right_index=True)', 'df.merge(pd.DataFrame(data = [s.values] * len(df), columns = s.index, index=df.index), left_index=True, right_index=True)']",,
26266439,count_nan = len(df) - df.count(),['count_nan = len(df) - df.count()'],['count_nan = len(df) - df.count()'],['count_nan = len(df) - df.count()'],,
26266451,"s = pd.Series([1,2,3, np.nan, np.nan])
s.isnull().sum()
df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})
df.isnull().sum()
dtype: int64","['s = pd.Series([1,2,3, np.nan, np.nan])', 's.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']","['s.isnull().sum()', 'df.isnull().sum()', 'dtype: int64']","['s.isnull().sum()', 'df.isnull().sum()']","['s = pd.Series([1,2,3, np.nan, np.nan])', 's.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']","['s.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']"
26272425,"import pandas as pd
df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})","[""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})""]",['import pandas as pd'],[],,
26286140,,[],[''],[],[],[]
26301947,"pd.set_option('display.max_colwidth', -1)","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]"
26310294,"import pandas as pd
df = pd.DataFrame(columns=['col1', 'col2'])
df = df.append(pd.Series(['a', 'b'], index=['col1','col2']), ignore_index=True)
df = df.append(pd.Series(['d', 'e'], index=['col1','col2']), ignore_index=True) 
df","[""df = pd.DataFrame(columns=['col1', 'col2'])"", ""df = df.append(pd.Series(['a', 'b'], index=['col1','col2']), ignore_index=True)"", ""df = df.append(pd.Series(['d', 'e'], index=['col1','col2']), ignore_index=True) ""]","['import pandas as pd', 'df']","[""df = df.append(pd.Series(['a', 'b'], index=['col1','col2']), ignore_index=True)"", ""df = df.append(pd.Series(['d', 'e'], index=['col1','col2']), ignore_index=True) ""]",,
26311118,"import pandas as pd
df = pd.DataFrame()
df = df.append({'foo':1, 'bar':2}, ignore_index=True)","['df = pd.DataFrame()', ""df = df.append({'foo':1, 'bar':2}, ignore_index=True)""]","['import pandas as pd', ""df = df.append({'foo':1, 'bar':2}, ignore_index=True)""]","[""df = df.append({'foo':1, 'bar':2}, ignore_index=True)""]",,
26320276,op = df[list(df.columns[0:899]) + list(df.columns[3593:])],[],['op = df[list(df.columns[0:899]) + list(df.columns[3593:])]'],[],[],[]
26332512,"df=pd.DataFrame({'a':[1,2,3],'b':[4,5,6]})
columns=[('c','a'),('c','b')]
df.columns=pd.MultiIndex.from_tuples(columns)","[""df=pd.DataFrame({'a':[1,2,3],'b':[4,5,6]})"", 'df.columns=pd.MultiIndex.from_tuples(columns)']","[""columns=[('c','a'),('c','b')]"", 'df.columns=pd.MultiIndex.from_tuples(columns)']",['df.columns=pd.MultiIndex.from_tuples(columns)'],,
26347456,"df.drop(df.columns[[1, 69]], axis=1, inplace=True)","['df.drop(df.columns[[1, 69]], axis=1, inplace=True)']","['df.drop(df.columns[[1, 69]], axis=1, inplace=True)']","['df.drop(df.columns[[1, 69]], axis=1, inplace=True)']",,
26356675,"df.filter(regex=""[^BD]"")
df.filter(regex=""^(?!(B|D)$).*$"")
exclude_cols = ['B','C']
df.filter(regex=""^(?!({0})$).*$"".format('|'.join(exclude_cols)))","['df.filter(regex=""[^BD]"")', 'df.filter(regex=""^(?!(B|D)$).*$"")', 'df.filter(regex=""^(?!({0})$).*$"".format(\'|\'.join(exclude_cols)))']","['df.filter(regex=""[^BD]"")', 'df.filter(regex=""^(?!(B|D)$).*$"")', ""exclude_cols = ['B','C']"", 'df.filter(regex=""^(?!({0})$).*$"".format(\'|\'.join(exclude_cols)))']","['df.filter(regex=""[^BD]"")', 'df.filter(regex=""^(?!(B|D)$).*$"")', 'df.filter(regex=""^(?!({0})$).*$"".format(\'|\'.join(exclude_cols)))']",,
26394108,"import matplotlib.pyplot as plt
...
...
...
import pandas as pd
import numpy as np
ser = pd.Series(np.random.normal(size=1000))
ser.hist(cumulative=True, normed=1, bins=100)
plt.show()",['ser = pd.Series(np.random.normal(size=1000))'],"['import matplotlib.pyplot as plt', '...', '...', '...', 'import pandas as pd', 'import numpy as np', 'ser.hist(cumulative=True, normed=1, bins=100)', 'plt.show()']",[],,
26415620,"from sklearn import preprocessing
x = df.values 
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df = pandas.DataFrame(x_scaled)","['x = df.values ', 'df = pandas.DataFrame(x_scaled)']","['from sklearn import preprocessing', 'x = df.values ', 'min_max_scaler = preprocessing.MinMaxScaler()', 'x_scaled = min_max_scaler.fit_transform(x)']",['x = df.values '],,
26422495,"def f(s):
    return s/s.max()
frame.apply(f, axis=0)","['    return s/s.max()', 'frame.apply(f, axis=0)']","['def f(s):', '    return s/s.max()', 'frame.apply(f, axis=0)']","['    return s/s.max()', 'frame.apply(f, axis=0)']",,
26457238,"df[:5]['duration'] / np.timedelta64(1, 's')
df[:5]['duration'].values.view('<i8')/10**9
Out[131]: array([1232, 1390, 1495,  797, 1132], dtype=int64)","[""df[:5]['duration'].values.view('<i8')/10**9""]","[""df[:5]['duration'] / np.timedelta64(1, 's')"", ""df[:5]['duration'].values.view('<i8')/10**9"", 'Out[131]: array([1232, 1390, 1495,  797, 1132], dtype=int64)']","[""df[:5]['duration'].values.view('<i8')/10**9""]",,
26465555,"df.sort_index(ascending=False).groupby('A').agg([np.mean, lambda x: x.iloc[1] ])
A                                  ","[""df.sort_index(ascending=False).groupby('A').agg([np.mean, lambda x: x.iloc[1] ])""]","[""df.sort_index(ascending=False).groupby('A').agg([np.mean, lambda x: x.iloc[1] ])"", 'A                                  ']","[""df.sort_index(ascending=False).groupby('A').agg([np.mean, lambda x: x.iloc[1] ])""]",,
26474062,--system-site-packages,[],['--system-site-packages'],[],[],[]
26495839,,[],[''],[],[],[]
26510251,,[],[''],[],[],[]
26521726,"xls = pd.ExcelFile('path_to_file.xls')
df1 = xls.parse('Sheet1')
df2 = xls.parse('Sheet2')","[""df1 = xls.parse('Sheet1')"", ""df2 = xls.parse('Sheet2')""]","[""xls = pd.ExcelFile('path_to_file.xls')"", ""df1 = xls.parse('Sheet1')"", ""df2 = xls.parse('Sheet2')""]","[""df1 = xls.parse('Sheet1')"", ""df2 = xls.parse('Sheet2')""]",,
26535881,"pi = np.pi; nan = np.nan
df = pd.DataFrame({""value"": [3,4,9,10,11,np.nan,12]})
df.query(""(value < 10) and (value > @pi)"")
df.query(""(value < 10) or (value == @nan)"")
df.query(""(value < 10) or (value != value)"")","['df = pd.DataFrame({""value"": [3,4,9,10,11,np.nan,12]})', 'df.query(""(value < 10) and (value > @pi)"")', 'df.query(""(value < 10) or (value == @nan)"")', 'df.query(""(value < 10) or (value != value)"")']","['pi = np.pi; nan = np.nan', 'df.query(""(value < 10) and (value > @pi)"")', 'df.query(""(value < 10) or (value == @nan)"")', 'df.query(""(value < 10) or (value != value)"")']","['df.query(""(value < 10) and (value > @pi)"")', 'df.query(""(value < 10) or (value == @nan)"")', 'df.query(""(value < 10) or (value != value)"")']",,
26538379,"import pandas as pd
df = pd.read_csv(""test.csv"")
df
df[""sum""] = df.sum(axis=1)
df
df_new = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)
df_new
df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)
df
df = pd.read_csv(""test.csv"")
df
df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df.sum(axis=1), axis=0)
df","['df = pd.read_csv(""test.csv"")', 'df[""sum""] = df.sum(axis=1)', 'df_new = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df = pd.read_csv(""test.csv"")', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df.sum(axis=1), axis=0)']","['import pandas as pd', 'df = pd.read_csv(""test.csv"")', 'df', 'df[""sum""] = df.sum(axis=1)', 'df', 'df_new = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df_new', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df', 'df = pd.read_csv(""test.csv"")', 'df', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df.sum(axis=1), axis=0)', 'df']","['df = pd.read_csv(""test.csv"")', 'df[""sum""] = df.sum(axis=1)', 'df_new = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df[""sum""], axis=0)', 'df = pd.read_csv(""test.csv"")', 'df.loc[:,""value1"":""value3""] = df.loc[:,""value1"":""value3""].div(df.sum(axis=1), axis=0)']",,
26544349,"from scipy.spatial.distance import squareform,pdist                                                              
similarities = squareform(pdist(data,'speuclidean'))",[],"['from scipy.spatial.distance import squareform,pdist                                                              ', ""similarities = squareform(pdist(data,'speuclidean'))""]",[],[],[]
26577689,"searchfor = ['og', 'at']
s[s.str.contains('|'.join(searchfor))]
dtype: object
import re
matches = ['$money', 'x^y']
safe_matches = [re.escape(m) for m in matches]
safe_matches
['\\$money', 'x\\^y']","[""s[s.str.contains('|'.join(searchfor))]""]","[""searchfor = ['og', 'at']"", ""s[s.str.contains('|'.join(searchfor))]"", 'dtype: object', 'import re', ""matches = ['$money', 'x^y']"", 'safe_matches = [re.escape(m) for m in matches]', 'safe_matches', ""['\\\\$money', 'x\\\\^y']""]","[""s[s.str.contains('|'.join(searchfor))]""]",,
26599892,"df = pandas.read_csv(fileName, sep='delimiter', header=None)","[""df = pandas.read_csv(fileName, sep='delimiter', header=None)""]","[""df = pandas.read_csv(fileName, sep='delimiter', header=None)""]","[""df = pandas.read_csv(fileName, sep='delimiter', header=None)""]",,
26640189,"df.index
list(df.index)
df.index['Row 2':'Row 5'] ","['df.index', 'list(df.index)', ""df.index['Row 2':'Row 5'] ""]","['df.index', 'list(df.index)', ""df.index['Row 2':'Row 5'] ""]","['df.index', 'list(df.index)', ""df.index['Row 2':'Row 5'] ""]",,
26647211,,[],[''],[],[],[]
26649199,"df1
g.sum()
df
pd.DatetimeIndex(df.Date).to_period(""M"")  
per = df.Date.dt.to_period(""M"")  
g = df.groupby(per)
g.sum()  ","['g.sum()', 'pd.DatetimeIndex(df.Date).to_period(""M"")  ', 'per = df.Date.dt.to_period(""M"")  ', 'g = df.groupby(per)', 'g.sum()  ']","['df1', 'g.sum()', 'df', 'pd.DatetimeIndex(df.Date).to_period(""M"")  ', 'per = df.Date.dt.to_period(""M"")  ', 'g = df.groupby(per)', 'g.sum()  ']","['g.sum()', 'pd.DatetimeIndex(df.Date).to_period(""M"")  ', 'per = df.Date.dt.to_period(""M"")  ', 'g = df.groupby(per)', 'g.sum()  ']",,
26654201,"df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')
index                                          
df_a.merge(df_b, on='mukey', how='left')","[""df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')"", ""df_a.merge(df_b, on='mukey', how='left')""]","[""df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')"", 'index                                          ', ""df_a.merge(df_b, on='mukey', how='left')""]","[""df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')"", ""df_a.merge(df_b, on='mukey', how='left')""]",,
26658301,"df = pd.DataFrame([[1,2,3],[4,5,6]], columns=['a','b','c'])
def rowFunc(row):
    return row['a'] + row['b'] * row['c']
def rowIndex(row):
    return row.name
df['d'] = df.apply(rowFunc, axis=1)
df['rowIndex'] = df.apply(rowIndex, axis=1)
df
df['d'] = df['a'] + df['b'] * df['c']
df","[""df = pd.DataFrame([[1,2,3],[4,5,6]], columns=['a','b','c'])"", ""df['d'] = df.apply(rowFunc, axis=1)"", ""df['rowIndex'] = df.apply(rowIndex, axis=1)""]","['def rowFunc(row):', ""    return row['a'] + row['b'] * row['c']"", 'def rowIndex(row):', '    return row.name', ""df['d'] = df.apply(rowFunc, axis=1)"", ""df['rowIndex'] = df.apply(rowIndex, axis=1)"", 'df', ""df['d'] = df['a'] + df['b'] * df['c']"", 'df']","[""df['d'] = df.apply(rowFunc, axis=1)"", ""df['rowIndex'] = df.apply(rowIndex, axis=1)""]",,
26667043,"m = np.arange(16)*10
m[df.A]
array([  0,  40,  50,  60, 150, 150, 140, 130])
df[""D""] = m[df.A]
df",[],"['m = np.arange(16)*10', 'm[df.A]', 'array([  0,  40,  50,  60, 150, 150, 140, 130])', 'df[""D""] = m[df.A]', 'df']",[],[],[]
26681726,"import pandas as pd
import numpy as np
import subprocess
df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],
                   'c': np.tile(['a', 'b', 'c'], 2),
                   'v': np.arange(1., 7.)})
filename = 'out.tex'
pdffile = 'out.pdf'
outname = 'out.png'
template = r
with open(filename, 'wb') as f:
    f.write(template.format(df.to_latex()))
subprocess.call(['pdflatex', filename])
subprocess.call(['convert', '-density', '300', pdffile, '-quality', '90', outname])
import pandas as pd
import numpy as np
import subprocess
df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],
                   'c': np.tile(['a', 'b', 'c'], 2),
                   'v': np.arange(1., 7.)})
filename = '/tmp/out.html'
outname = '/tmp/out.png'
cropname = '/tmp/cropped.png'
with open(filename, 'wb') as f:
    f.write(df.to_html())
rasterize = '/path/to/phantomjs/examples/rasterize.js'
subprocess.call(['phantomjs', rasterize, filename, outname])
subprocess.call(['convert', outname, '-trim', cropname])","[""df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],"", '    f.write(template.format(df.to_latex()))', ""df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],"", '    f.write(df.to_html())']","['import pandas as pd', 'import numpy as np', 'import subprocess', ""                   'c': np.tile(['a', 'b', 'c'], 2),"", ""                   'v': np.arange(1., 7.)})"", ""filename = 'out.tex'"", ""pdffile = 'out.pdf'"", ""outname = 'out.png'"", 'template = r', ""with open(filename, 'wb') as f:"", '    f.write(template.format(df.to_latex()))', ""subprocess.call(['pdflatex', filename])"", ""subprocess.call(['convert', '-density', '300', pdffile, '-quality', '90', outname])"", 'import pandas as pd', 'import numpy as np', 'import subprocess', ""                   'c': np.tile(['a', 'b', 'c'], 2),"", ""                   'v': np.arange(1., 7.)})"", ""filename = '/tmp/out.html'"", ""outname = '/tmp/out.png'"", ""cropname = '/tmp/cropped.png'"", ""with open(filename, 'wb') as f:"", '    f.write(df.to_html())', ""rasterize = '/path/to/phantomjs/examples/rasterize.js'"", ""subprocess.call(['phantomjs', rasterize, filename, outname])"", ""subprocess.call(['convert', outname, '-trim', cropname])""]","['    f.write(template.format(df.to_latex()))', '    f.write(df.to_html())']",,
26716759,"df = pd.read_csv(""file"")
d= dict([(i,[a,b,c ]) for i, a,b,c in zip(df.ID, df.A,df.B,df.C)])
{'p': [1, 3, 2], 'q': [4, 3, 2], 'r': [4, 0, 9]}","['df = pd.read_csv(""file"")']","['df = pd.read_csv(""file"")', 'd= dict([(i,[a,b,c ]) for i, a,b,c in zip(df.ID, df.A,df.B,df.C)])', ""{'p': [1, 3, 2], 'q': [4, 3, 2], 'r': [4, 0, 9]}""]","['df = pd.read_csv(""file"")']",,
26716774,"df.set_index('ID').T.to_dict('list')
{'p': [1, 3, 2], 'q': [4, 3, 2], 'r': [4, 0, 9]}","[""df.set_index('ID').T.to_dict('list')""]","[""df.set_index('ID').T.to_dict('list')"", ""{'p': [1, 3, 2], 'q': [4, 3, 2], 'r': [4, 0, 9]}""]","[""df.set_index('ID').T.to_dict('list')""]",,
26721808,g in df.index.values,['g in df.index.values'],['g in df.index.values'],['g in df.index.values'],,
26724581,"row_index = df.col1 == 10
df.loc[row_index, 'col1'] = 100","[""df.loc[row_index, 'col1'] = 100""]","['row_index = df.col1 == 10', ""df.loc[row_index, 'col1'] = 100""]","[""df.loc[row_index, 'col1'] = 100""]",,
26724725,"rpt[rpt['STK_ID'].str.contains(r'^600[0-9]{3}$')] 
endstrings = ['01$', '02$', '05$']
str.contains('pandas', case=False)","[""rpt[rpt['STK_ID'].str.contains(r'^600[0-9]{3}$')] "", ""str.contains('pandas', case=False)""]","[""rpt[rpt['STK_ID'].str.contains(r'^600[0-9]{3}$')] "", ""endstrings = ['01$', '02$', '05$']"", ""str.contains('pandas', case=False)""]","[""rpt[rpt['STK_ID'].str.contains(r'^600[0-9]{3}$')] "", ""str.contains('pandas', case=False)""]",,
26763793,"raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')","[""raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')""]","[""raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')""]","[""raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')""]",,
26763810,"df = pd.DataFrame(['05SEP2014:00:00:00.000'],columns=['Mycol'])
df
import datetime as dt
df['Mycol'] = df['Mycol'].apply(lambda x: 
                                    dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))
df","[""df = pd.DataFrame(['05SEP2014:00:00:00.000'],columns=['Mycol'])"", ""df['Mycol'] = df['Mycol'].apply(lambda x: "", ""                                    dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))""]","['df', 'import datetime as dt', ""df['Mycol'] = df['Mycol'].apply(lambda x: "", ""                                    dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))"", 'df']","[""df['Mycol'] = df['Mycol'].apply(lambda x: "", ""                                    dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))""]",,
26778637,"df2 = df.loc[np.repeat(df.index.values,df.n)]
df2
df2 = df2.drop(""n"",axis=1).reset_index(drop=True)
df2","['df2 = df.loc[np.repeat(df.index.values,df.n)]', 'df2 = df2.drop(""n"",axis=1).reset_index(drop=True)']","['df2 = df.loc[np.repeat(df.index.values,df.n)]', 'df2', 'df2 = df2.drop(""n"",axis=1).reset_index(drop=True)', 'df2']","['df2 = df.loc[np.repeat(df.index.values,df.n)]', 'df2 = df2.drop(""n"",axis=1).reset_index(drop=True)']",,
26787032,"df_csv = df0_fa.to_csv('revenue/data/test.csv',mode = 'w', index=False)","[""df_csv = df0_fa.to_csv('revenue/data/test.csv',mode = 'w', index=False)""]","[""df_csv = df0_fa.to_csv('revenue/data/test.csv',mode = 'w', index=False)""]","[""df_csv = df0_fa.to_csv('revenue/data/test.csv',mode = 'w', index=False)""]",,
26803731,"import pandas as pd
d
{'RAY Index': {datetime.date(2014, 11, 3): {'PX_LAST': 1199.46,
'PX_OPEN': 1200.14},
datetime.date(2014, 11, 4): {'PX_LAST': 1195.323, 'PX_OPEN': 1197.69},
datetime.date(2014, 11, 5): {'PX_LAST': 1200.936, 'PX_OPEN': 1195.32},
datetime.date(2014, 11, 6): {'PX_LAST': 1206.061, 'PX_OPEN': 1200.62}},
'SPX Index': {datetime.date(2014, 11, 3): {'PX_LAST': 2017.81,
'PX_OPEN': 2018.21},
datetime.date(2014, 11, 4): {'PX_LAST': 2012.1, 'PX_OPEN': 2015.81},
datetime.date(2014, 11, 5): {'PX_LAST': 2023.57, 'PX_OPEN': 2015.29},
datetime.date(2014, 11, 6): {'PX_LAST': 2031.21, 'PX_OPEN': 2023.33}}}
pd.Panel(d)
pd.Panel(d)['SPX Index']
pd.Panel(d).to_frame().reset_index()
pd.Panel(d).transpose(2,0,1).to_frame().reset_index()","[""{'RAY Index': {datetime.date(2014, 11, 3): {'PX_LAST': 1199.46,"", ""datetime.date(2014, 11, 4): {'PX_LAST': 1195.323, 'PX_OPEN': 1197.69},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 1200.936, 'PX_OPEN': 1195.32},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 1206.061, 'PX_OPEN': 1200.62}},"", ""'SPX Index': {datetime.date(2014, 11, 3): {'PX_LAST': 2017.81,"", ""datetime.date(2014, 11, 4): {'PX_LAST': 2012.1, 'PX_OPEN': 2015.81},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 2023.57, 'PX_OPEN': 2015.29},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 2031.21, 'PX_OPEN': 2023.33}}}"", 'pd.Panel(d)', ""pd.Panel(d)['SPX Index']"", 'pd.Panel(d).to_frame().reset_index()', 'pd.Panel(d).transpose(2,0,1).to_frame().reset_index()']","['import pandas as pd', 'd', ""{'RAY Index': {datetime.date(2014, 11, 3): {'PX_LAST': 1199.46,"", ""'PX_OPEN': 1200.14},"", ""datetime.date(2014, 11, 4): {'PX_LAST': 1195.323, 'PX_OPEN': 1197.69},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 1200.936, 'PX_OPEN': 1195.32},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 1206.061, 'PX_OPEN': 1200.62}},"", ""'SPX Index': {datetime.date(2014, 11, 3): {'PX_LAST': 2017.81,"", ""'PX_OPEN': 2018.21},"", ""datetime.date(2014, 11, 4): {'PX_LAST': 2012.1, 'PX_OPEN': 2015.81},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 2023.57, 'PX_OPEN': 2015.29},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 2031.21, 'PX_OPEN': 2023.33}}}""]","[""{'RAY Index': {datetime.date(2014, 11, 3): {'PX_LAST': 1199.46,"", ""datetime.date(2014, 11, 4): {'PX_LAST': 1195.323, 'PX_OPEN': 1197.69},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 1200.936, 'PX_OPEN': 1195.32},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 1206.061, 'PX_OPEN': 1200.62}},"", ""'SPX Index': {datetime.date(2014, 11, 3): {'PX_LAST': 2017.81,"", ""datetime.date(2014, 11, 4): {'PX_LAST': 2012.1, 'PX_OPEN': 2015.81},"", ""datetime.date(2014, 11, 5): {'PX_LAST': 2023.57, 'PX_OPEN': 2015.29},"", ""datetime.date(2014, 11, 6): {'PX_LAST': 2031.21, 'PX_OPEN': 2023.33}}}"", 'pd.Panel(d).to_frame().reset_index()', 'pd.Panel(d).transpose(2,0,1).to_frame().reset_index()']",,
26816746,df.index.get_values(),['df.index.get_values()'],['df.index.get_values()'],['df.index.get_values()'],,
26838140,"import numpy as np
df1 = df.replace(np.nan, '', regex=True)","[""df1 = df.replace(np.nan, '', regex=True)""]","['import numpy as np', ""df1 = df.replace(np.nan, '', regex=True)""]","[""df1 = df.replace(np.nan, '', regex=True)""]",,
26849064,"df[df['A'].str.contains(""Hello|Britain"")]
""cannot index with vector containing NA / NaN values""
df[df['A'].str.contains(""Hello|Britain"")==True]","['df[df[\'A\'].str.contains(""Hello|Britain"")]', 'df[df[\'A\'].str.contains(""Hello|Britain"")==True]']","['df[df[\'A\'].str.contains(""Hello|Britain"")]', '""cannot index with vector containing NA / NaN values""', 'df[df[\'A\'].str.contains(""Hello|Britain"")==True]']","['df[df[\'A\'].str.contains(""Hello|Britain"")]', 'df[df[\'A\'].str.contains(""Hello|Britain"")==True]']",,
26851412,"df = pd.DataFrame([['hello', 'hello world'], ['abcd', 'defg']], columns=['a','b'])
df
df.apply(lambda x: x['a'] in x['b'], axis=1)
dtype: bool","[""df = pd.DataFrame([['hello', 'hello world'], ['abcd', 'defg']], columns=['a','b'])"", ""df.apply(lambda x: x['a'] in x['b'], axis=1)""]","['df', ""df.apply(lambda x: x['a'] in x['b'], axis=1)"", 'dtype: bool']","[""df.apply(lambda x: x['a'] in x['b'], axis=1)""]",,
26865524,,[],[''],[],[],[]
26873148,"import pandas as pd
pd.options.display.mpl_style = 'default'
new_style = {'grid': False}
matplotlib.rc('axes', **new_style)
data = pd.DataFrame(np.cumsum(np.random.normal(size=(100,2)),axis=0),columns=['A','B'])
data.plot(secondary_y=['B'])","[""data = pd.DataFrame(np.cumsum(np.random.normal(size=(100,2)),axis=0),columns=['A','B'])"", ""data.plot(secondary_y=['B'])""]","['import pandas as pd', ""pd.options.display.mpl_style = 'default'"", ""new_style = {'grid': False}"", ""matplotlib.rc('axes', **new_style)"", ""data.plot(secondary_y=['B'])""]","[""data = pd.DataFrame(np.cumsum(np.random.normal(size=(100,2)),axis=0),columns=['A','B'])"", ""data.plot(secondary_y=['B'])""]",,
26887820,"def label_race (row):
   if row['eri_hispanic'] == 1 :
      return 'Hispanic'
   if row['eri_afr_amer'] + row['eri_asian'] + row['eri_hawaiian'] + row['eri_nat_amer'] + row['eri_white'] > 1 :
      return 'Two Or More'
   if row['eri_nat_amer'] == 1 :
      return 'A/I AK Native'
   if row['eri_asian'] == 1:
      return 'Asian'
   if row['eri_afr_amer']  == 1:
      return 'Black/AA'
   if row['eri_hawaiian'] == 1:
      return 'Haw/Pac Isl.'
   if row['eri_white'] == 1:
      return 'White'
   return 'Other'
df.apply (lambda row: label_race (row),axis=1)
df['race_label'] = df.apply (lambda row: label_race (row),axis=1)","['df.apply (lambda row: label_race (row),axis=1)', ""df['race_label'] = df.apply (lambda row: label_race (row),axis=1)""]","['def label_race (row):', ""   if row['eri_hispanic'] == 1 :"", ""      return 'Hispanic'"", ""   if row['eri_afr_amer'] + row['eri_asian'] + row['eri_hawaiian'] + row['eri_nat_amer'] + row['eri_white'] > 1 :"", ""      return 'Two Or More'"", ""   if row['eri_nat_amer'] == 1 :"", ""      return 'A/I AK Native'"", ""   if row['eri_asian'] == 1:"", ""      return 'Asian'"", ""   if row['eri_afr_amer']  == 1:"", ""      return 'Black/AA'"", ""   if row['eri_hawaiian'] == 1:"", ""      return 'Haw/Pac Isl.'"", ""   if row['eri_white'] == 1:"", ""      return 'White'"", ""   return 'Other'"", 'df.apply (lambda row: label_race (row),axis=1)', ""df['race_label'] = df.apply (lambda row: label_race (row),axis=1)""]","['df.apply (lambda row: label_race (row),axis=1)', ""df['race_label'] = df.apply (lambda row: label_race (row),axis=1)""]",,
26893083,,[],[''],[],[],[]
26893443,yes_records_sample['name'].isnull(),"[""yes_records_sample['name'].isnull()""]","[""yes_records_sample['name'].isnull()""]","[""yes_records_sample['name'].isnull()""]",,
26918510,"Series.apply(func, convert_dtype=True, args=(), **kwds)
args : tuple
x = my_series.apply(my_function, args = (arg1,))","['Series.apply(func, convert_dtype=True, args=(), **kwds)', 'x = my_series.apply(my_function, args = (arg1,))']","['Series.apply(func, convert_dtype=True, args=(), **kwds)', 'args : tuple', 'x = my_series.apply(my_function, args = (arg1,))']","['Series.apply(func, convert_dtype=True, args=(), **kwds)', 'x = my_series.apply(my_function, args = (arg1,))']",,
26977495,"np.unique(df[['Col1', 'Col2']])
array(['Bill', 'Bob', 'Joe', 'Mary', 'Steve'], dtype=object)
np.unique(df[['Col1', 'Col2']].values)
pd.unique(df[['Col1', 'Col2']].values.ravel())
array(['Bob', 'Joe', 'Steve', 'Bill', 'Mary'], dtype=object)
df1 = pd.concat([df]*100000) ","[""np.unique(df[['Col1', 'Col2']])"", ""np.unique(df[['Col1', 'Col2']].values)"", ""pd.unique(df[['Col1', 'Col2']].values.ravel())"", 'df1 = pd.concat([df]*100000) ']","[""np.unique(df[['Col1', 'Col2']])"", ""array(['Bill', 'Bob', 'Joe', 'Mary', 'Steve'], dtype=object)"", ""np.unique(df[['Col1', 'Col2']].values)"", ""pd.unique(df[['Col1', 'Col2']].values.ravel())"", ""array(['Bob', 'Joe', 'Steve', 'Bill', 'Mary'], dtype=object)"", 'df1 = pd.concat([df]*100000) ']","[""np.unique(df[['Col1', 'Col2']])"", ""np.unique(df[['Col1', 'Col2']].values)"", ""pd.unique(df[['Col1', 'Col2']].values.ravel())"", 'df1 = pd.concat([df]*100000) ']",,
27009771,"def sort_pd(key=None,reverse=False,cmp=None):
    def sorter(series):
        series_list = list(series)
        return [series_list.index(i) 
           for i in sorted(series_list,key=key,reverse=reverse,cmp=cmp)]
    return sorter
df = pd.DataFrame([
    [1, 2, 'March'],
    [5, 6, 'Dec'],
    [3, 4, 'April']], 
  columns=['a','b','m'])
custom_dict = {'March':0, 'April':1, 'Dec':3}
sort_by_custom_dict = sort_pd(key=custom_dict.get)
df.iloc[sort_by_custom_dict(df['m'])]
df.iloc[sort_by_month(df.index.get_level_values('month'))]
pd.Series(list(df['sales'])).iloc[sort_by_last_digit(df['sales'])]","['        return [series_list.index(i) ', 'df = pd.DataFrame([', 'sort_by_custom_dict = sort_pd(key=custom_dict.get)', ""df.iloc[sort_by_custom_dict(df['m'])]"", ""df.iloc[sort_by_month(df.index.get_level_values('month'))]"", ""pd.Series(list(df['sales'])).iloc[sort_by_last_digit(df['sales'])]""]","['def sort_pd(key=None,reverse=False,cmp=None):', '    def sorter(series):', '        series_list = list(series)', '        return [series_list.index(i) ', '           for i in sorted(series_list,key=key,reverse=reverse,cmp=cmp)]', '    return sorter', ""    [1, 2, 'March'],"", ""    [5, 6, 'Dec'],"", ""    [3, 4, 'April']], "", ""  columns=['a','b','m'])"", ""custom_dict = {'March':0, 'April':1, 'Dec':3}"", 'sort_by_custom_dict = sort_pd(key=custom_dict.get)', ""df.iloc[sort_by_custom_dict(df['m'])]"", ""df.iloc[sort_by_month(df.index.get_level_values('month'))]""]","['        return [series_list.index(i) ', 'sort_by_custom_dict = sort_pd(key=custom_dict.get)', ""df.iloc[sort_by_custom_dict(df['m'])]"", ""df.iloc[sort_by_month(df.index.get_level_values('month'))]"", ""pd.Series(list(df['sales'])).iloc[sort_by_last_digit(df['sales'])]""]",,
27018394,"cols = ['X', 'Y']
df[cols] = df[cols].ffill()
import pandas as pd
import numpy as np
ts1 = [0, 1, np.nan, np.nan, np.nan, np.nan]
ts2 = [0, 2, np.nan, 3, np.nan, np.nan]
d =  {'X': ts1, 'Y': ts2, 'Z': ts2}
df = pd.DataFrame(data=d)
print(df.head())
col = ['X', 'Y']
df[col] = df[col].ffill()
print(df.head())","['df[cols] = df[cols].ffill()', 'df = pd.DataFrame(data=d)', 'print(df.head())', 'df[col] = df[col].ffill()', 'print(df.head())']","[""cols = ['X', 'Y']"", 'df[cols] = df[cols].ffill()', 'import pandas as pd', 'import numpy as np', 'ts1 = [0, 1, np.nan, np.nan, np.nan, np.nan]', 'ts2 = [0, 2, np.nan, 3, np.nan, np.nan]', ""d =  {'X': ts1, 'Y': ts2, 'Z': ts2}"", 'print(df.head())', ""col = ['X', 'Y']"", 'df[col] = df[col].ffill()', 'print(df.head())']","['df[cols] = df[cols].ffill()', 'print(df.head())', 'df[col] = df[col].ffill()', 'print(df.head())']",,
27023500,"s = Series([""a"",""b"",""c"",""a""], dtype=""category"")
s
dtype: category",[],"['s = Series([""a"",""b"",""c"",""a""], dtype=""category"")', 's', 'dtype: category']",[],[],[]
27026479,"import pandas as pd
np.random.seed(1)
n=10000
df = pd.DataFrame({'mygroup' : np.random.randint(1000, size=n), 
                   'data' : np.random.rand(n)})
grouped = df.groupby('mygroup')
dflist = []
for name, group in grouped:
    dflist.append(group)
from IPython.parallel import Client
rc = Client()
lview = rc.load_balanced_view()
lview.block = True
def myFunc(inDf):
    inDf['newCol'] = inDf.data ** 10
    return inDf
serial_list = map(myFunc, dflist)
parallel_list = lview.map(myFunc, dflist)
combinedDf = pd.concat(parallel_list)","[""df = pd.DataFrame({'mygroup' : np.random.randint(1000, size=n), "", ""grouped = df.groupby('mygroup')"", '    dflist.append(group)', 'parallel_list = lview.map(myFunc, dflist)', 'combinedDf = pd.concat(parallel_list)']","['import pandas as pd', 'np.random.seed(1)', 'n=10000', ""                   'data' : np.random.rand(n)})"", ""grouped = df.groupby('mygroup')"", 'dflist = []', 'for name, group in grouped:', '    dflist.append(group)', 'from IPython.parallel import Client', 'rc = Client()', 'lview = rc.load_balanced_view()', 'lview.block = True', 'def myFunc(inDf):', ""    inDf['newCol'] = inDf.data ** 10"", '    return inDf', 'serial_list = map(myFunc, dflist)', 'parallel_list = lview.map(myFunc, dflist)', 'combinedDf = pd.concat(parallel_list)']","[""grouped = df.groupby('mygroup')"", '    dflist.append(group)', 'parallel_list = lview.map(myFunc, dflist)', 'combinedDf = pd.concat(parallel_list)']",,
27027632,"import pandas as pd
from joblib import Parallel, delayed
import multiprocessing
def tmpFunc(df):
    df['c'] = df.a + df.b
    return df
def applyParallel(dfGrouped, func):
    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)
    return pd.concat(retLst)
if __name__ == '__main__':
    df = pd.DataFrame({'a': [6, 2, 2], 'b': [4, 5, 6]},index= ['g1', 'g1', 'g2'])","['    return pd.concat(retLst)', ""    df = pd.DataFrame({'a': [6, 2, 2], 'b': [4, 5, 6]},index= ['g1', 'g1', 'g2'])""]","['import pandas as pd', 'from joblib import Parallel, delayed', 'import multiprocessing', 'def tmpFunc(df):', ""    df['c'] = df.a + df.b"", '    return df', 'def applyParallel(dfGrouped, func):', '    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)', '    return pd.concat(retLst)', ""if __name__ == '__main__':""]",['    return pd.concat(retLst)'],,
27050186,"import numpy
import json
json.dumps(numpy.int32(685))
class MyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, numpy.integer):
            return int(obj)
        elif isinstance(obj, numpy.floating):
            return float(obj)
        elif isinstance(obj, numpy.ndarray):
            return obj.tolist()
        else:
            return super(MyEncoder, self).default(obj)
json.dumps(numpy.float32(1.2), cls=MyEncoder)
json.dumps(numpy.arange(12), cls=MyEncoder)
json.dumps({'a': numpy.int32(42)})",['            return obj.tolist()'],"['import numpy', 'import json', 'json.dumps(numpy.int32(685))', 'class MyEncoder(json.JSONEncoder):', '    def default(self, obj):', '        if isinstance(obj, numpy.integer):', '            return int(obj)', '        elif isinstance(obj, numpy.floating):', '            return float(obj)', '        elif isinstance(obj, numpy.ndarray):', '            return obj.tolist()', '        else:', '            return super(MyEncoder, self).default(obj)', 'json.dumps(numpy.float32(1.2), cls=MyEncoder)', 'json.dumps(numpy.arange(12), cls=MyEncoder)', ""json.dumps({'a': numpy.int32(42)})""]",['            return obj.tolist()'],,
27060328,"df['BrandName'].replace(['ABC', 'AB'], 'A')
df['BrandName'] = df['BrandName'].replace(['ABC', 'AB'], 'A')","[""df['BrandName'].replace(['ABC', 'AB'], 'A')"", ""df['BrandName'] = df['BrandName'].replace(['ABC', 'AB'], 'A')""]","[""df['BrandName'].replace(['ABC', 'AB'], 'A')"", ""df['BrandName'] = df['BrandName'].replace(['ABC', 'AB'], 'A')""]","[""df['BrandName'].replace(['ABC', 'AB'], 'A')"", ""df['BrandName'] = df['BrandName'].replace(['ABC', 'AB'], 'A')""]",,
27066284,,[],[''],[],[],[]
27117982,"df['col2'] = df['col']
df.loc[df['col'] != 'pre', 'col2'] = 'nonpre'
df","[""df.loc[df['col'] != 'pre', 'col2'] = 'nonpre'""]","[""df['col2'] = df['col']"", ""df.loc[df['col'] != 'pre', 'col2'] = 'nonpre'"", 'df']","[""df.loc[df['col'] != 'pre', 'col2'] = 'nonpre'""]",,
27126593,"import numpy as np
df = pd.DataFrame({'a':np.arange(5)})
df1 = pd.DataFrame({'b':np.arange(4)})
print(df1)
df
pd.concat([df,df1], ignore_index=True, axis=1)","[""df = pd.DataFrame({'a':np.arange(5)})"", ""df1 = pd.DataFrame({'b':np.arange(4)})"", 'pd.concat([df,df1], ignore_index=True, axis=1)']","['import numpy as np', 'print(df1)', 'df', 'pd.concat([df,df1], ignore_index=True, axis=1)']","['pd.concat([df,df1], ignore_index=True, axis=1)']",,
27139421,,[],[''],[],[],[]
27144549,"converters={'column_name': lambda x: str(x)}
project_name,project_id
import csv
from pandas import read_csv
dataframe = read_csv('projects.csv')
import csv
from pandas import read_csv
dataframe = read_csv('projects.csv', converters={'project_id': lambda x: str(x)})",[],"[""converters={'column_name': lambda x: str(x)}"", 'project_name,project_id', 'import csv', 'from pandas import read_csv', ""dataframe = read_csv('projects.csv')"", 'import csv', 'from pandas import read_csv', ""dataframe = read_csv('projects.csv', converters={'project_id': lambda x: str(x)})""]",[],[],[]
27203245,"import numpy as np
import pandas as pd
filename = '/tmp/test.h5'
df = pd.DataFrame(np.arange(10).reshape((5,2)), columns=['A', 'B'])
print(df)
df.to_hdf(filename, 'data', mode='w', format='table')
del df    
df2 = pd.DataFrame(np.arange(10).reshape((5,2))*10, columns=['A', 'B'])
df2.to_hdf(filename, 'data', append=True)
print(pd.read_hdf(filename, 'data'))
import numpy as np
import pandas as pd
filename = '/tmp/test.h5'
store = pd.HDFStore(filename)
for i in range(2):
    df = pd.DataFrame(np.arange(10).reshape((5,2)) * 10**i, columns=['A', 'B'])
    store.append('data', df)
store.close()
store = pd.HDFStore(filename)
data = store['data']
print(data)
store.close()","[""df = pd.DataFrame(np.arange(10).reshape((5,2)), columns=['A', 'B'])"", ""df.to_hdf(filename, 'data', mode='w', format='table')"", ""df2 = pd.DataFrame(np.arange(10).reshape((5,2))*10, columns=['A', 'B'])"", ""df2.to_hdf(filename, 'data', append=True)"", ""print(pd.read_hdf(filename, 'data'))"", ""    df = pd.DataFrame(np.arange(10).reshape((5,2)) * 10**i, columns=['A', 'B'])"", ""    store.append('data', df)""]","['import numpy as np', 'import pandas as pd', ""filename = '/tmp/test.h5'"", 'print(df)', ""df.to_hdf(filename, 'data', mode='w', format='table')"", 'del df    ', ""df2.to_hdf(filename, 'data', append=True)"", ""print(pd.read_hdf(filename, 'data'))"", 'import numpy as np', 'import pandas as pd', ""filename = '/tmp/test.h5'"", 'store = pd.HDFStore(filename)', 'for i in range(2):', ""    store.append('data', df)"", 'store.close()', 'store = pd.HDFStore(filename)', ""data = store['data']"", 'print(data)', 'store.close()']","[""df.to_hdf(filename, 'data', mode='w', format='table')"", ""df2.to_hdf(filename, 'data', append=True)"", ""print(pd.read_hdf(filename, 'data'))"", ""    store.append('data', df)""]",,
27203304,"import numpy
import tables
import os
training_data = tables.open_file('nn_training.h5', mode='w')
a = tables.Float64Atom()
bl_filter = tables.Filters(5, 'blosc')   
training_input =  training_data.create_earray(training_data.root, 'X', a,
                                             (0, 1323), 'Training Input',
                                             bl_filter, 4000000)
training_output = training_data.create_earray(training_data.root, 'Y', a,
                                             (0, 27), 'Training Output',
                                             bl_filter, 4000000)
for filename in os.listdir('input'):
    a = numpy.load(os.path.join('input', filename))
    training_input.append(a)
for filename in os.listdir('output'):
    training_output.append(numpy.load(os.path.join('output', filename)))","[""    a = numpy.load(os.path.join('input', filename))"", '    training_input.append(a)', ""    training_output.append(numpy.load(os.path.join('output', filename)))""]","['import numpy', 'import tables', 'import os', ""training_data = tables.open_file('nn_training.h5', mode='w')"", 'a = tables.Float64Atom()', ""bl_filter = tables.Filters(5, 'blosc')   "", ""training_input =  training_data.create_earray(training_data.root, 'X', a,"", ""                                             (0, 1323), 'Training Input',"", '                                             bl_filter, 4000000)', ""training_output = training_data.create_earray(training_data.root, 'Y', a,"", ""                                             (0, 27), 'Training Output',"", '                                             bl_filter, 4000000)', ""for filename in os.listdir('input'):"", ""    a = numpy.load(os.path.join('input', filename))"", '    training_input.append(a)', ""for filename in os.listdir('output'):"", ""    training_output.append(numpy.load(os.path.join('output', filename)))""]","[""    a = numpy.load(os.path.join('input', filename))"", '    training_input.append(a)', ""    training_output.append(numpy.load(os.path.join('output', filename)))""]",,
27232309,"dtype={'user_id': int}
import pandas as pd
from StringIO import StringIO
csvdata = """"""user_id,username
1,Alice
3,Bob
foobar,Caesar""""""
sio = StringIO(csvdata)
pd.read_csv(sio, dtype={""user_id"": int, ""username"": object})","['pd.read_csv(sio, dtype={""user_id"": int, ""username"": object})']","[""dtype={'user_id': int}"", 'import pandas as pd', 'from StringIO import StringIO', 'csvdata = """"""user_id,username', '1,Alice', '3,Bob', 'foobar,Caesar""""""', 'sio = StringIO(csvdata)', 'pd.read_csv(sio, dtype={""user_id"": int, ""username"": object})']","['pd.read_csv(sio, dtype={""user_id"": int, ""username"": object})']",,
27236748,,[],[''],[],[],[]
27242735,,[],[''],[],[],[]
27255567,"import pandas as pd
df = pd.DataFrame(
{'id':[2967, 5335, 13950, 6141, 6169],\
 'Player': ['Cedric Hunter', 'Maurice Baker' ,\
            'Ratko Varda' ,'Ryan Bowen' ,'Adrian Caldwell'],\
 'Year': [1991 ,2004 ,2001 ,2009 ,1997],\
 'Age': [27 ,25 ,22 ,34 ,31],\
 'Tm':['CHH' ,'VAN' ,'TOT' ,'OKC' ,'DAL'],\
 'G':[6 ,7 ,60 ,52 ,81]})
sorter = ['TOT', 'ATL', 'BOS', 'BRK', 'CHA', 'CHH', 'CHI', 'CLE', 'DAL','DEN',\
          'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL',\
          'MIN', 'NJN', 'NOH', 'NOK', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI',\
          'PHO', 'POR', 'SAC', 'SAS', 'SEA', 'TOR', 'UTA', 'VAN',\
          'WAS', 'WSB']
df.Tm = df.Tm.astype(""category"")
df.Tm.cat.set_categories(sorter, inplace=True)
print(df.Tm)
df.sort_values([""Tm""])  ","['df = pd.DataFrame(', 'df.Tm = df.Tm.astype(""category"")', 'df.Tm.cat.set_categories(sorter, inplace=True)', 'df.sort_values([""Tm""])  ']","['import pandas as pd', ""{'id':[2967, 5335, 13950, 6141, 6169],\\"", "" 'Player': ['Cedric Hunter', 'Maurice Baker' ,\\"", ""            'Ratko Varda' ,'Ryan Bowen' ,'Adrian Caldwell'],\\"", "" 'Year': [1991 ,2004 ,2001 ,2009 ,1997],\\"", "" 'Age': [27 ,25 ,22 ,34 ,31],\\"", "" 'Tm':['CHH' ,'VAN' ,'TOT' ,'OKC' ,'DAL'],\\"", "" 'G':[6 ,7 ,60 ,52 ,81]})"", ""sorter = ['TOT', 'ATL', 'BOS', 'BRK', 'CHA', 'CHH', 'CHI', 'CLE', 'DAL','DEN',\\"", ""          'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL',\\"", ""          'MIN', 'NJN', 'NOH', 'NOK', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI',\\"", ""          'PHO', 'POR', 'SAC', 'SAS', 'SEA', 'TOR', 'UTA', 'VAN',\\"", ""          'WAS', 'WSB']"", 'df.Tm = df.Tm.astype(""category"")', 'df.Tm.cat.set_categories(sorter, inplace=True)', 'print(df.Tm)', 'df.sort_values([""Tm""])  ']","['df.Tm = df.Tm.astype(""category"")', 'df.Tm.cat.set_categories(sorter, inplace=True)', 'df.sort_values([""Tm""])  ']",,
27266225,"df
s = df.apply(lambda x: pd.Series(x['samples']),axis=1).stack().reset_index(level=1, drop=True)
s.name = 'sample'
df.drop('samples', axis=1).join(s)
res = df.set_index(['subject', 'trial_num'])['samples'].apply(pd.Series).stack()
res = res.reset_index()
res.columns = ['subject','trial_num','sample_num','sample']
res","[""s = df.apply(lambda x: pd.Series(x['samples']),axis=1).stack().reset_index(level=1, drop=True)"", ""df.drop('samples', axis=1).join(s)"", ""res = df.set_index(['subject', 'trial_num'])['samples'].apply(pd.Series).stack()"", 'res = res.reset_index()']","['df', ""s.name = 'sample'"", ""df.drop('samples', axis=1).join(s)"", 'res = res.reset_index()', ""res.columns = ['subject','trial_num','sample_num','sample']"", 'res']","[""s = df.apply(lambda x: pd.Series(x['samples']),axis=1).stack().reset_index(level=1, drop=True)"", ""df.drop('samples', axis=1).join(s)"", ""res = df.set_index(['subject', 'trial_num'])['samples'].apply(pd.Series).stack()"", 'res = res.reset_index()']",,
27275344,"filter_col = [col for col in df if col.startswith('foo')]
filter_col
['foo.aa', 'foo.bars', 'foo.fighters', 'foo.fox', 'foo.manchu']
df[filter_col]
df[df.columns[pd.Series(df.columns).str.startswith('foo')]]
df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]]==1]
df.loc[df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]] == 1].dropna(how='all', axis=0).index]","[""filter_col = [col for col in df if col.startswith('foo')]"", ""df[df.columns[pd.Series(df.columns).str.startswith('foo')]]"", ""df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]]==1]"", ""df.loc[df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]] == 1].dropna(how='all', axis=0).index]""]","[""filter_col = [col for col in df if col.startswith('foo')]"", 'filter_col', ""['foo.aa', 'foo.bars', 'foo.fighters', 'foo.fox', 'foo.manchu']"", 'df[filter_col]']","[""filter_col = [col for col in df if col.startswith('foo')]"", ""df[df.columns[pd.Series(df.columns).str.startswith('foo')]]"", ""df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]]==1]"", ""df.loc[df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]] == 1].dropna(how='all', axis=0).index]""]",,
27275479,"df.loc[:, df.columns.str.startswith('foo')]
df.filter(regex=r'^foo\.', axis=1)
df.loc[(df == 1).any(axis=1), df.filter(regex=r'^foo\.', axis=1).columns]","[""df.loc[:, df.columns.str.startswith('foo')]"", ""df.filter(regex=r'^foo\\.', axis=1)"", ""df.loc[(df == 1).any(axis=1), df.filter(regex=r'^foo\\.', axis=1).columns]""]","[""df.loc[:, df.columns.str.startswith('foo')]"", ""df.filter(regex=r'^foo\\.', axis=1)"", ""df.loc[(df == 1).any(axis=1), df.filter(regex=r'^foo\\.', axis=1).columns]""]","[""df.loc[:, df.columns.str.startswith('foo')]"", ""df.filter(regex=r'^foo\\.', axis=1)"", ""df.loc[(df == 1).any(axis=1), df.filter(regex=r'^foo\\.', axis=1).columns]""]",,
27282644,,[],[''],[],[],[]
27321764,"df.plot(kind='bar', stacked=True, width=1)","[""df.plot(kind='bar', stacked=True, width=1)""]","[""df.plot(kind='bar', stacked=True, width=1)""]","[""df.plot(kind='bar', stacked=True, width=1)""]",,
27325729,"pd.read_csv('test.csv', sep='|', skiprows=range(1, 10))","[""pd.read_csv('test.csv', sep='|', skiprows=range(1, 10))""]","[""pd.read_csv('test.csv', sep='|', skiprows=range(1, 10))""]","[""pd.read_csv('test.csv', sep='|', skiprows=range(1, 10))""]",,
27360130,,[],[''],[],[],[]
27361326,"df.sort_index(axis=1, inplace=True)","['df.sort_index(axis=1, inplace=True)']","['df.sort_index(axis=1, inplace=True)']","['df.sort_index(axis=1, inplace=True)']",,
27362540,,[],[''],[],[],[]
27368948,"p=pd.Series([1,2,3])
p.apply(lambda x: pd.Series([x, x]))
p.map(lambda x: pd.Series([x, x]))
p=pd.Series([1,0,3,4,2])
p.map(p)
dtype: int64","['p=pd.Series([1,2,3])', 'p.apply(lambda x: pd.Series([x, x]))', 'p.map(lambda x: pd.Series([x, x]))', 'p=pd.Series([1,0,3,4,2])', 'p.map(p)']","['p.map(p)', 'dtype: int64']","['p.apply(lambda x: pd.Series([x, x]))', 'p.map(lambda x: pd.Series([x, x]))', 'p.map(p)']",,
27385043,"df = pd.DataFrame([[i] for i in range(10)], columns=['num'])
df","[""df = pd.DataFrame([[i] for i in range(10)], columns=['num'])""]",['df'],[],,
27412913,,[],[''],[],[],[]
27422749,"grouped = df.groupby('A')
for name, group in grouped:
    ...","[""grouped = df.groupby('A')""]","[""grouped = df.groupby('A')"", 'for name, group in grouped:', '    ...']","[""grouped = df.groupby('A')""]",,
27475029,"df['que'] = df.apply(lambda x : x['one'] if x['one'] >= x['two'] and x['one'] <= x['three'] else """", axis=1)
def que(x):
    if x['one'] >= x['two'] and x['one'] <= x['three']:
        return x['one']
    else:
        ''
df['que'] = df.apply(que, axis=1)","['df[\'que\'] = df.apply(lambda x : x[\'one\'] if x[\'one\'] >= x[\'two\'] and x[\'one\'] <= x[\'three\'] else """", axis=1)', ""df['que'] = df.apply(que, axis=1)""]","['df[\'que\'] = df.apply(lambda x : x[\'one\'] if x[\'one\'] >= x[\'two\'] and x[\'one\'] <= x[\'three\'] else """", axis=1)', 'def que(x):', ""    if x['one'] >= x['two'] and x['one'] <= x['three']:"", ""        return x['one']"", '    else:', ""        ''"", ""df['que'] = df.apply(que, axis=1)""]","['df[\'que\'] = df.apply(lambda x : x[\'one\'] if x[\'one\'] >= x[\'two\'] and x[\'one\'] <= x[\'three\'] else """", axis=1)', ""df['que'] = df.apply(que, axis=1)""]",,
27475046,"df['que'] = df['one'][(df['one'] >= df['two']) & (df['one'] <= df['three'])]
df
df['que'] = df['que'].fillna(0)
df","[""df['que'] = df['que'].fillna(0)""]","[""df['que'] = df['one'][(df['one'] >= df['two']) & (df['one'] <= df['three'])]"", 'df', ""df['que'] = df['que'].fillna(0)"", 'df']","[""df['que'] = df['que'].fillna(0)""]",,
27475514,"C = np.where(cond, A, B)
import numpy as np
import pandas as pd
a = [['10', '1.2', '4.2'], ['15', '70', '0.03'], ['8', '5', '0']]
df = pd.DataFrame(a, columns=['one', 'two', 'three'])
df['que'] = np.where((df['one'] >= df['two']) & (df['one'] <= df['three'])
                     , df['one'], np.nan)
conditions = [
    (df['one'] >= df['two']) & (df['one'] <= df['three']), 
    df['one'] < df['two']]
choices = [df['one'], df['two']]
df['que'] = np.select(conditions, choices, default=np.nan)
conditions = [
    df['one'] < df['two'],
    df['one'] <= df['three']]
choices = [df['two'], df['one']]
a = [['10', '1.2', '4.2'], ['15', '70', '0.03'], ['8', '5', '0']]
df = pd.DataFrame(a, columns=['one', 'two', 'three'])
df2 = df.astype(float)
'10' <= '4.2'
10 <= 4.2
Out[62]: False","['C = np.where(cond, A, B)', ""df = pd.DataFrame(a, columns=['one', 'two', 'three'])"", ""df['que'] = np.where((df['one'] >= df['two']) & (df['one'] <= df['three'])"", ""df['que'] = np.select(conditions, choices, default=np.nan)"", ""df = pd.DataFrame(a, columns=['one', 'two', 'three'])"", 'df2 = df.astype(float)']","['C = np.where(cond, A, B)', 'import numpy as np', 'import pandas as pd', ""a = [['10', '1.2', '4.2'], ['15', '70', '0.03'], ['8', '5', '0']]"", ""df['que'] = np.where((df['one'] >= df['two']) & (df['one'] <= df['three'])"", ""                     , df['one'], np.nan)"", 'conditions = [', ""    (df['one'] >= df['two']) & (df['one'] <= df['three']), "", ""    df['one'] < df['two']]"", ""choices = [df['one'], df['two']]"", ""df['que'] = np.select(conditions, choices, default=np.nan)"", 'conditions = [', ""    df['one'] < df['two'],"", ""    df['one'] <= df['three']]"", ""choices = [df['two'], df['one']]"", ""a = [['10', '1.2', '4.2'], ['15', '70', '0.03'], ['8', '5', '0']]"", 'df2 = df.astype(float)', ""'10' <= '4.2'"", '10 <= 4.2', 'Out[62]: False']","['C = np.where(cond, A, B)', ""df['que'] = np.where((df['one'] >= df['two']) & (df['one'] <= df['three'])"", ""df['que'] = np.select(conditions, choices, default=np.nan)"", 'df2 = df.astype(float)']",,
27489248,"import pandas
from io import StringIO
csv = StringIO(""""""index,A,B
0,1,0.0
1,1,3.0
2,1,6.0
3,2,0.0
4,2,5.0
5,2,7.0"""""")
df = pandas.read_csv(csv, index_col='index')
groups = df.groupby(by=['A'])
print(groups.apply(lambda g: g[g['B'] == g['B'].max()]))","[""df = pandas.read_csv(csv, index_col='index')"", ""groups = df.groupby(by=['A'])"", ""print(groups.apply(lambda g: g[g['B'] == g['B'].max()]))""]","['import pandas', 'from io import StringIO', 'csv = StringIO(""""""index,A,B', '0,1,0.0', '1,1,3.0', '2,1,6.0', '3,2,0.0', '4,2,5.0', '5,2,7.0"""""")', ""df = pandas.read_csv(csv, index_col='index')"", ""groups = df.groupby(by=['A'])"", ""print(groups.apply(lambda g: g[g['B'] == g['B'].max()]))""]","[""df = pandas.read_csv(csv, index_col='index')"", ""groups = df.groupby(by=['A'])"", ""print(groups.apply(lambda g: g[g['B'] == g['B'].max()]))""]",,
27520877,"import pandas as pd
values = [[1,2], [2,5]]
df = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])
df.columns.name = 'Type'
df.index.name = 'Index'
df.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Video streaming dropout by category')","[""df = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])"", ""df.index.name = 'Index'"", ""df.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Video streaming dropout by category')""]","['import pandas as pd', 'values = [[1,2], [2,5]]', ""df.columns.name = 'Type'"", ""df.index.name = 'Index'"", ""df.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Video streaming dropout by category')""]","[""df.index.name = 'Index'"", ""df.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Video streaming dropout by category')""]",,
27579192,"from pandas import  DataFrame
df1 = DataFrame({'col1':[1,2,3], 'col2':[2,3,4]})
df2 = DataFrame({'col1':[4,2,5], 'col2':[6,3,5]})",[],"['from pandas import  DataFrame', ""df1 = DataFrame({'col1':[1,2,3], 'col2':[2,3,4]})"", ""df2 = DataFrame({'col1':[4,2,5], 'col2':[6,3,5]})""]",[],[],[]
27617290,"import pymongo
import pandas as pd
from pymongo import MongoClient
client = MongoClient()
db = client.database_name
collection = db.collection_name
data = pd.DataFrame(list(collection.find()))",['data = pd.DataFrame(list(collection.find()))'],"['import pymongo', 'import pandas as pd', 'from pymongo import MongoClient', 'client = MongoClient()', 'db = client.database_name', 'collection = db.collection_name']",['data = pd.DataFrame(list(collection.find()))'],,
27667801,,[],[''],[],[],[]
27680109,"df = DataFrame({'x': [1,2]})
df_sub = df[0:1]
df_sub.x = -1
print(df)
x
0 -1
df_sub_copy = df[0:1].copy()
df_sub_copy.x = -1",['df_sub_copy = df[0:1].copy()'],"[""df = DataFrame({'x': [1,2]})"", 'df_sub = df[0:1]', 'df_sub.x = -1', 'print(df)', 'x', '0 -1', 'df_sub_copy = df[0:1].copy()', 'df_sub_copy.x = -1']",['df_sub_copy = df[0:1].copy()'],,
27747726,"import pandas as pd
from datetime import datetime
headers = ['col1', 'col2', 'col3', 'col4'] 
dtypes = [datetime, datetime, str, float] 
pd.read_csv(file, sep='\t', header=None, names=headers, dtype=dtypes)
import pandas as pd
from datetime import datetime
headers = ['col1', 'col2', 'col3', 'col4'] 
dtypes = [datetime.datetime, datetime.datetime, str, float] 
pd.read_csv(file, sep='\t', header=None, names=headers, dtype=dtypes)","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)""]","['import pandas as pd', 'from datetime import datetime', ""headers = ['col1', 'col2', 'col3', 'col4'] "", 'dtypes = [datetime, datetime, str, float] ', ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", 'import pandas as pd', 'from datetime import datetime', ""headers = ['col1', 'col2', 'col3', 'col4'] "", 'dtypes = [datetime.datetime, datetime.datetime, str, float] ', ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)""]","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes)""]",,
27759140,"import pandas as pd
df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1]})
df
df[df < 0] = 0
df
import pandas as pd
df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1],
                           'c': ['foo', 'goo', 'bar']})
df
num = df._get_numeric_data()
num[num < 0] = 0
df
import pandas as pd","[""df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1]})"", ""df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1],""]","['import pandas as pd', 'df', 'df[df < 0] = 0', 'df', 'import pandas as pd', ""                           'c': ['foo', 'goo', 'bar']})"", 'df', 'num = df._get_numeric_data()', 'num[num < 0] = 0', 'df', 'import pandas as pd']",[],,
27769102,"df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)",[],"[""df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)""]",[],[],[]
27787977,,[],[''],[],[],[]
27791362,"import pandas as pd
from StringIO import StringIO
csv = r""""""dummy,date,loc,x
bar,20090101,a,1
bar,20090102,a,3
bar,20090103,a,5
bar,20090101,b,1
bar,20090102,b,3
bar,20090103,b,5""""""
df = pd.read_csv(StringIO(csv),
        header=0,
        index_col=[""date"", ""loc""], 
        usecols=[""date"", ""loc"", ""x""],
        parse_dates=[""date""])","['df = pd.read_csv(StringIO(csv),']","['import pandas as pd', 'from StringIO import StringIO', 'csv = r""""""dummy,date,loc,x', 'bar,20090101,a,1', 'bar,20090102,a,3', 'bar,20090103,a,5', 'bar,20090101,b,1', 'bar,20090102,b,3', 'bar,20090103,b,5""""""', 'df = pd.read_csv(StringIO(csv),', '        header=0,', '        index_col=[""date"", ""loc""], ', '        usecols=[""date"", ""loc"", ""x""],', '        parse_dates=[""date""])']","['df = pd.read_csv(StringIO(csv),']","['df = pd.read_csv(StringIO(csv),']","['df = pd.read_csv(StringIO(csv),']"
27802006,"grouped = (df
    .groupby('col1')                
    .apply(lambda g:               
        g.set_index('date')        
        [['amount']]
        .resample('W', how='sum')  
    )
    .unstack(level=0)              
    .fillna(0)
)
grouped.columns=grouped.columns.droplevel()   
grouped.plot(kind='bar')
date                                      ","['grouped = (df', ""        g.set_index('date')        "", 'grouped.columns=grouped.columns.droplevel()   ', ""grouped.plot(kind='bar')""]","['grouped = (df', ""    .groupby('col1')                "", '    .apply(lambda g:               ', ""        g.set_index('date')        "", ""        [['amount']]"", ""        .resample('W', how='sum')  "", '    )', '    .unstack(level=0)              ', '    .fillna(0)', ')', 'grouped.columns=grouped.columns.droplevel()   ', ""grouped.plot(kind='bar')"", 'date                                      ']","['grouped = (df', ""        g.set_index('date')        "", 'grouped.columns=grouped.columns.droplevel()   ', ""grouped.plot(kind='bar')""]",,
27844045,"df_agg = df.groupby(['job','source']).agg({'count':sum})
g = df_agg['count'].groupby(level=0, group_keys=False)
res = g.apply(lambda x: x.order(ascending=False).head(3))
g.nlargest(3)
dtype: int64","[""df_agg = df.groupby(['job','source']).agg({'count':sum})"", ""g = df_agg['count'].groupby(level=0, group_keys=False)"", 'res = g.apply(lambda x: x.order(ascending=False).head(3))', 'g.nlargest(3)']","[""df_agg = df.groupby(['job','source']).agg({'count':sum})"", ""g = df_agg['count'].groupby(level=0, group_keys=False)"", 'res = g.apply(lambda x: x.order(ascending=False).head(3))', 'g.nlargest(3)', 'dtype: int64']","[""df_agg = df.groupby(['job','source']).agg({'count':sum})"", ""g = df_agg['count'].groupby(level=0, group_keys=False)"", 'res = g.apply(lambda x: x.order(ascending=False).head(3))', 'g.nlargest(3)']",,
27889133,,[],[''],[],[],[]
27889674,"df = pd.read_sql_query('select * from ""Stat_Table""',con=engine)","['df = pd.read_sql_query(\'select * from ""Stat_Table""\',con=engine)']","['df = pd.read_sql_query(\'select * from ""Stat_Table""\',con=engine)']","['df = pd.read_sql_query(\'select * from ""Stat_Table""\',con=engine)']",,
27905350,"df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])
df.fillna(method='ffill')
df.fillna(method='ffill', inplace=True)","['df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])', ""df.fillna(method='ffill')"", ""df.fillna(method='ffill', inplace=True)""]","[""df.fillna(method='ffill')"", ""df.fillna(method='ffill', inplace=True)""]","[""df.fillna(method='ffill')"", ""df.fillna(method='ffill', inplace=True)""]",,
27905354,"import pandas as pd
df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])
df = df.fillna(method='ffill')
print(df)","['df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])', ""df = df.fillna(method='ffill')""]","['import pandas as pd', ""df = df.fillna(method='ffill')"", 'print(df)']","[""df = df.fillna(method='ffill')""]",,
27951930,"df.groupby('A').transform(lambda x: (x['C'] - x['D']))
df.groupby('A').transform(lambda x: (x['C'] - x['D']).mean())
zscore = lambda x: (x - x.mean()) / x.std() 
df.groupby('A').transform(zscore)
3 -0.671 -1.150
6 -1.404 -0.907
df.groupby('A')['C'].transform(zscore)
1   -0.478
3   -0.671
6   -1.404
7   -0.509
df.groupby('A').apply(zscore)
df['sum_C'] = df.groupby('A')['C'].transform(sum)
df.sort('A') 
df.groupby('A')['C'].apply(sum)
A
df[df.groupby(['B'])['D'].transform(sum) < -1]","[""df.groupby('A').transform(lambda x: (x['C'] - x['D']))"", ""df.groupby('A').transform(lambda x: (x['C'] - x['D']).mean())"", 'zscore = lambda x: (x - x.mean()) / x.std() ', ""df.groupby('A').transform(zscore)"", ""df.groupby('A')['C'].transform(zscore)"", ""df.groupby('A').apply(zscore)"", ""df['sum_C'] = df.groupby('A')['C'].transform(sum)"", ""df.groupby('A')['C'].apply(sum)"", ""df[df.groupby(['B'])['D'].transform(sum) < -1]""]","[""df.groupby('A').transform(lambda x: (x['C'] - x['D']))"", ""df.groupby('A').transform(lambda x: (x['C'] - x['D']).mean())"", 'zscore = lambda x: (x - x.mean()) / x.std() ', ""df.groupby('A').transform(zscore)"", '3 -0.671 -1.150', '6 -1.404 -0.907', ""df.groupby('A')['C'].transform(zscore)"", '1   -0.478', '3   -0.671', '6   -1.404', '7   -0.509', ""df.groupby('A').apply(zscore)"", ""df['sum_C'] = df.groupby('A')['C'].transform(sum)"", ""df.sort('A') "", ""df.groupby('A')['C'].apply(sum)"", 'A', ""df[df.groupby(['B'])['D'].transform(sum) < -1]""]","[""df.groupby('A').transform(lambda x: (x['C'] - x['D']))"", ""df.groupby('A').transform(lambda x: (x['C'] - x['D']).mean())"", 'zscore = lambda x: (x - x.mean()) / x.std() ', ""df.groupby('A').transform(zscore)"", ""df.groupby('A')['C'].transform(zscore)"", ""df.groupby('A').apply(zscore)"", ""df['sum_C'] = df.groupby('A')['C'].transform(sum)"", ""df.groupby('A')['C'].apply(sum)"", ""df[df.groupby(['B'])['D'].transform(sum) < -1]""]",,
27954411,"df = pd.DataFrame({'NAME': list('abcdef'),
    'On_Time': [True, False] * 3,
    'On_Budget': [False, True] * 3})
df.select_dtypes(include=['bool'])
mylist = list(df.select_dtypes(include=['bool']).columns)
mylist
Out[5]: ['On_Budget', 'On_Time']","[""df = pd.DataFrame({'NAME': list('abcdef'),"", ""df.select_dtypes(include=['bool'])"", ""mylist = list(df.select_dtypes(include=['bool']).columns)""]","[""    'On_Time': [True, False] * 3,"", ""    'On_Budget': [False, True] * 3})"", ""df.select_dtypes(include=['bool'])"", ""mylist = list(df.select_dtypes(include=['bool']).columns)"", 'mylist', ""Out[5]: ['On_Budget', 'On_Time']""]","[""df.select_dtypes(include=['bool'])"", ""mylist = list(df.select_dtypes(include=['bool']).columns)""]",,
27975191,"mask = df['ids'].str.contains('ball')    
mask
df[mask]","[""mask = df['ids'].str.contains('ball')    ""]","[""mask = df['ids'].str.contains('ball')    "", 'mask', 'df[mask]']","[""mask = df['ids'].str.contains('ball')    ""]",,
27975230,"df[df['ids'].str.contains(""ball"")]","['df[df[\'ids\'].str.contains(""ball"")]']","['df[df[\'ids\'].str.contains(""ball"")]']","['df[df[\'ids\'].str.contains(""ball"")]']",,
27975789,"df[df['ids'].str.contains('ball', na = False)] ","[""df[df['ids'].str.contains('ball', na = False)] ""]","[""df[df['ids'].str.contains('ball', na = False)] ""]","[""df[df['ids'].str.contains('ball', na = False)] ""]",,
27987908,"def get_max_rows(df):
    B_maxes = df.groupby('A').B.transform(max)
    return df[df.B == B_maxes] 
import numpy as np
import pandas as pd","[""    B_maxes = df.groupby('A').B.transform(max)""]","['def get_max_rows(df):', ""    B_maxes = df.groupby('A').B.transform(max)"", '    return df[df.B == B_maxes] ', 'import numpy as np', 'import pandas as pd']","[""    B_maxes = df.groupby('A').B.transform(max)""]",,
27999688,,[],[''],[],[],[]
28006809,"df = pd.DataFrame([[1,2,3],[3,4,5]])
lol = df.values.tolist()
lol","['df = pd.DataFrame([[1,2,3],[3,4,5]])', 'lol = df.values.tolist()']","['lol = df.values.tolist()', 'lol']",['lol = df.values.tolist()'],,
28009526,"df['weekday'] = df['Timestamp'].dt.dayofweek
df
df = df.reset_index()
df['weekday'] = df['Timestamp'].dt.dayofweek
df
df['weekday'] = pd.Series(df.index).dt.dayofweek
df
Timestamp                          
df['weekday'] = df.reset_index()['Timestamp'].dt.dayofweek
df
Timestamp                          ","[""df['weekday'] = df['Timestamp'].dt.dayofweek"", 'df = df.reset_index()', ""df['weekday'] = df['Timestamp'].dt.dayofweek"", ""df['weekday'] = pd.Series(df.index).dt.dayofweek"", ""df['weekday'] = df.reset_index()['Timestamp'].dt.dayofweek""]","[""df['weekday'] = df['Timestamp'].dt.dayofweek"", 'df', 'df = df.reset_index()', ""df['weekday'] = df['Timestamp'].dt.dayofweek"", 'df', 'df', 'Timestamp                          ', ""df['weekday'] = df.reset_index()['Timestamp'].dt.dayofweek"", 'df', 'Timestamp                          ']","[""df['weekday'] = df['Timestamp'].dt.dayofweek"", 'df = df.reset_index()', ""df['weekday'] = df['Timestamp'].dt.dayofweek"", ""df['weekday'] = pd.Series(df.index).dt.dayofweek"", ""df['weekday'] = df.reset_index()['Timestamp'].dt.dayofweek""]",,
28020783,"dataset_array = dataset.values
print(dataset_array.dtype)
print(dataset_array)","['dataset_array = dataset.values', 'print(dataset_array.dtype)']","['dataset_array = dataset.values', 'print(dataset_array.dtype)', 'print(dataset_array)']","['dataset_array = dataset.values', 'print(dataset_array.dtype)']",,
28135445,"pd.concat([df_a,df_b], axis=1)
df_a.merge(df_b, left_index=True, right_index=True)
df_a.join(df_b)","['pd.concat([df_a,df_b], axis=1)', 'df_a.merge(df_b, left_index=True, right_index=True)', 'df_a.join(df_b)']","['pd.concat([df_a,df_b], axis=1)', 'df_a.merge(df_b, left_index=True, right_index=True)', 'df_a.join(df_b)']","['pd.concat([df_a,df_b], axis=1)', 'df_a.merge(df_b, left_index=True, right_index=True)', 'df_a.join(df_b)']",,
28142820,"df.loc[df['column_name'] == some_value]
df.loc[df['column_name'].isin(some_values)]
import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
               'B': 'one one two three two two one three'.split(),
               'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
print(df.loc[df['A'] == 'foo'])
print(df.loc[df['B'].isin(['one','three'])])
df = df.set_index(['A'])
print(df.loc['foo'])","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""               'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['A'])"", ""print(df.loc['foo'])""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", 'import pandas as pd', 'import numpy as np', ""               'B': 'one one two three two two one three'.split(),"", ""               'C': np.arange(8), 'D': np.arange(8) * 2})"", 'print(df)', ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['A'])"", ""print(df.loc['foo'])""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""               'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['A'])"", ""print(df.loc['foo'])""]",,
28150450,"len(df.columns)
len(df.index)
df.shape","['len(df.index)', 'df.shape']","['len(df.columns)', 'len(df.index)', 'df.shape']","['len(df.index)', 'df.shape']",,
28155580,"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
newdf = df.select_dtypes(include=numerics)",['newdf = df.select_dtypes(include=numerics)'],"[""numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']"", 'newdf = df.select_dtypes(include=numerics)']",['newdf = df.select_dtypes(include=numerics)'],,
28159296,"df = pd.DataFrame( np.random.randn(30,3), columns = ['a','b','c'])
df_filtered = df.query('a>0').query('0<b<2')
df_filtered = df.query('a>0 and 0<b<2')","[""df = pd.DataFrame( np.random.randn(30,3), columns = ['a','b','c'])"", ""df_filtered = df.query('a>0').query('0<b<2')"", ""df_filtered = df.query('a>0 and 0<b<2')""]","[""df_filtered = df.query('a>0').query('0<b<2')"", ""df_filtered = df.query('a>0 and 0<b<2')""]","[""df_filtered = df.query('a>0').query('0<b<2')"", ""df_filtered = df.query('a>0 and 0<b<2')""]",,
28161433,"import pandas as pd
df = pd.DataFrame( {'Symbol':['A','A','A'] ,
    'Date':['02/20/2015','01/15/2016','08/21/2015']})
df
df['Date'] =pd.to_datetime(df.Date)
df.sort('Date') 
df.sort_values(by='Date') ","[""df = pd.DataFrame( {'Symbol':['A','A','A'] ,"", ""df['Date'] =pd.to_datetime(df.Date)"", ""df.sort_values(by='Date') ""]","['import pandas as pd', ""    'Date':['02/20/2015','01/15/2016','08/21/2015']})"", 'df', ""df['Date'] =pd.to_datetime(df.Date)"", ""df.sort('Date') "", ""df.sort_values(by='Date') ""]","[""df['Date'] =pd.to_datetime(df.Date)"", ""df.sort_values(by='Date') ""]",,
28182629,"b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack()
b = b.reset_index()[[0, 'var2']] 
b.columns = ['var1', 'var2'] ","[""b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack()"", ""b = b.reset_index()[[0, 'var2']] ""]","[""b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack()"", ""b = b.reset_index()[[0, 'var2']] "", ""b.columns = ['var1', 'var2'] ""]","[""b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack()"", ""b = b.reset_index()[[0, 'var2']] ""]",,
28192263,"[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)]
my_series.select_dtypes(include=['O']) 
list(my_series.select_dtypes(include=['O']).columns) 
[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)] ","[""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)]"", ""my_series.select_dtypes(include=['O']) "", ""list(my_series.select_dtypes(include=['O']).columns) "", ""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)] ""]","[""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)]"", ""my_series.select_dtypes(include=['O']) "", ""list(my_series.select_dtypes(include=['O']).columns) "", ""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)] ""]","[""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)]"", ""my_series.select_dtypes(include=['O']) "", ""list(my_series.select_dtypes(include=['O']).columns) "", ""[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)] ""]",,
28199556,"from numpy.random import randn
df = pd.DataFrame(randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],
               columns=['one', 'two', 'three'])
df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])
df
h -0.224695 -0.025628 -0.703680
df.shape[0] - df.dropna().shape[0]
3
df.isnull().values.ravel().sum()
9","[""df = pd.DataFrame(randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],"", ""df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])"", 'df.shape[0] - df.dropna().shape[0]', 'df.isnull().values.ravel().sum()']","['from numpy.random import randn', ""               columns=['one', 'two', 'three'])"", ""df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])"", 'df', 'h -0.224695 -0.025628 -0.703680', 'df.shape[0] - df.dropna().shape[0]', '3', 'df.isnull().values.ravel().sum()', '9']","[""df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])"", 'df.shape[0] - df.dropna().shape[0]', 'df.isnull().values.ravel().sum()']",,
28200127,,[],[''],[],[],[]
28202781,"M.iloc[index][col]
M.set_value(index,column,new_value)","['M.iloc[index][col]', 'M.set_value(index,column,new_value)']","['M.iloc[index][col]', 'M.set_value(index,column,new_value)']","['M.iloc[index][col]', 'M.set_value(index,column,new_value)']",,
28218909,"df1.ix[:,1]
df1.ix[0,]
df1.ix[:,1]
df1.ix[0,1]",[],"['df1.ix[:,1]', 'df1.ix[0,]', 'df1.ix[:,1]', 'df1.ix[0,1]']",[],[],[]
28227679,"import pandas as pd
import numpy as np
rows = [(u'KY', [u'McConnell'], [u'Grimes'], [u'Rep']),
        (u'AR', [u'Cotton'], [u'Pryor'], [u'Dem']),
        (u'MI', [u'Land'], [u'Peters'], [])]
def get(r, nth):
    return r[nth][0] if r[nth] else np.nan
def remove_list_items(list_of_records):
    for r in list_of_records:
        yield r[0], get(r, 1), get(r, 2), get(r, 3)
def remove_list_items(list_of_records):
    result = []
    for r in list_of_records:
        result.append((r[0], get(r, 1), get(r, 2), get(r, 3)))
    return result
df = pd.DataFrame.from_records(
        remove_list_items(rows), 
        columns=[""State"", ""R"", ""D"", ""incumbent""])
df
df = pd.DataFrame.from_records(
      ((r[0], get(r, 1), get(r, 2), get(r, 3)) for r in rows), 
      columns=[""State"", ""R"", ""D"", ""incumbent""])","['        result.append((r[0], get(r, 1), get(r, 2), get(r, 3)))', 'df = pd.DataFrame.from_records(', 'df = pd.DataFrame.from_records(']","['import pandas as pd', 'import numpy as np', ""rows = [(u'KY', [u'McConnell'], [u'Grimes'], [u'Rep']),"", ""        (u'AR', [u'Cotton'], [u'Pryor'], [u'Dem']),"", ""        (u'MI', [u'Land'], [u'Peters'], [])]"", 'def get(r, nth):', '    return r[nth][0] if r[nth] else np.nan', 'def remove_list_items(list_of_records):', '    for r in list_of_records:', '        yield r[0], get(r, 1), get(r, 2), get(r, 3)', 'def remove_list_items(list_of_records):', '    result = []', '    for r in list_of_records:', '        result.append((r[0], get(r, 1), get(r, 2), get(r, 3)))', '    return result', '        remove_list_items(rows), ', '        columns=[""State"", ""R"", ""D"", ""incumbent""])', 'df', '      ((r[0], get(r, 1), get(r, 2), get(r, 3)) for r in rows), ', '      columns=[""State"", ""R"", ""D"", ""incumbent""])']","['        result.append((r[0], get(r, 1), get(r, 2), get(r, 3)))', 'df = pd.DataFrame.from_records(', 'df = pd.DataFrame.from_records(']",,
28229188,"merged = pd.merge(DataFrameA,DataFrameB, on=['Code','Date'])
import pandas as pd
i = pd.to_datetime(pd.date_range('20140601',periods=2))
df = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col1': [10,100]})
df2 = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col2': [10,200]})
pd.merge(df, df2, on =['code','date'])","[""merged = pd.merge(DataFrameA,DataFrameB, on=['Code','Date'])"", ""i = pd.to_datetime(pd.date_range('20140601',periods=2))"", ""df = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col1': [10,100]})"", ""df2 = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col2': [10,200]})"", ""pd.merge(df, df2, on =['code','date'])""]","[""merged = pd.merge(DataFrameA,DataFrameB, on=['Code','Date'])"", 'import pandas as pd', ""i = pd.to_datetime(pd.date_range('20140601',periods=2))"", ""pd.merge(df, df2, on =['code','date'])""]","[""merged = pd.merge(DataFrameA,DataFrameB, on=['Code','Date'])"", ""i = pd.to_datetime(pd.date_range('20140601',periods=2))"", ""pd.merge(df, df2, on =['code','date'])""]",,
28236391,"df.loc[df['a'] == 1, 'b'].sum()
15
df.groupby('a')['b'].sum()[1]
15","[""df.loc[df['a'] == 1, 'b'].sum()"", ""df.groupby('a')['b'].sum()[1]""]","[""df.loc[df['a'] == 1, 'b'].sum()"", '15', ""df.groupby('a')['b'].sum()[1]"", '15']","[""df.loc[df['a'] == 1, 'b'].sum()"", ""df.groupby('a')['b'].sum()[1]""]",,
28252957,"data['result'].replace(regex=True,inplace=True,to_replace=r'\D',value=r'')","[""data['result'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')""]","[""data['result'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')""]","[""data['result'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')""]",,
28267291,"import pandas as pd
import xml.etree.ElementTree as ET
def iter_docs(author):
    author_attr = author.attrib
    for doc in author.iterfind('.//document'):
        doc_dict = author_attr.copy()
        doc_dict.update(doc.attrib)
        doc_dict['data'] = doc.text
        yield doc_dict
etree = ET.fromstring(xml_data) 
doc_df = pd.DataFrame(list(iter_docs(etree)))
def iter_author(etree):
    for author in etree.iterfind('.//author'):
        for row in iter_docs(author):
            yield row","['        doc_dict = author_attr.copy()', '        doc_dict.update(doc.attrib)', 'doc_df = pd.DataFrame(list(iter_docs(etree)))']","['import pandas as pd', 'import xml.etree.ElementTree as ET', 'def iter_docs(author):', '    author_attr = author.attrib', ""    for doc in author.iterfind('.//document'):"", '        doc_dict = author_attr.copy()', '        doc_dict.update(doc.attrib)', ""        doc_dict['data'] = doc.text"", '        yield doc_dict', 'etree = ET.fromstring(xml_data) ', 'def iter_author(etree):', ""    for author in etree.iterfind('.//author'):"", '        for row in iter_docs(author):', '            yield row']","['        doc_dict = author_attr.copy()', '        doc_dict.update(doc.attrib)']",,
28272238,"import pandas as pd
test = {
383:    3.000000,
663:    1.000000,
726:    1.000000,
737:    9.000000,
833:    8.166667
}
s = pd.Series(test)
s = s[s != 1]
s
dtype: float64",['s = pd.Series(test)'],"['import pandas as pd', 'test = {', '383:    3.000000,', '663:    1.000000,', '726:    1.000000,', '737:    9.000000,', '833:    8.166667', '}', 's = s[s != 1]', 's', 'dtype: float64']",[],,
28299215,"import matplotlib.pyplot as plt
p_df = pd.DataFrame({""class"": [1,1,2,2,1], ""a"": [2,3,2,3,2]})
fig, ax = plt.subplots(figsize=(8,6))
bp = p_df.groupby('class').plot(kind='kde', ax=ax)
classes = [""class 1""] * 5 + [""class 2""] * 5
vals = [1,3,5,1,3] + [2,6,7,5,2]
p_df = pd.DataFrame({""class"": classes, ""vals"": vals})
fig, ax = plt.subplots(figsize=(8,6))
for label, df in p_df.groupby('class'):
    df.vals.plot(kind=""kde"", ax=ax, label=label)
plt.legend()","['p_df = pd.DataFrame({""class"": [1,1,2,2,1], ""a"": [2,3,2,3,2]})', ""bp = p_df.groupby('class').plot(kind='kde', ax=ax)"", 'p_df = pd.DataFrame({""class"": classes, ""vals"": vals})', ""for label, df in p_df.groupby('class'):"", '    df.vals.plot(kind=""kde"", ax=ax, label=label)']","['import matplotlib.pyplot as plt', 'fig, ax = plt.subplots(figsize=(8,6))', ""bp = p_df.groupby('class').plot(kind='kde', ax=ax)"", 'classes = [""class 1""] * 5 + [""class 2""] * 5', 'vals = [1,3,5,1,3] + [2,6,7,5,2]', 'fig, ax = plt.subplots(figsize=(8,6))', ""for label, df in p_df.groupby('class'):"", '    df.vals.plot(kind=""kde"", ax=ax, label=label)', 'plt.legend()']","[""bp = p_df.groupby('class').plot(kind='kde', ax=ax)"", ""for label, df in p_df.groupby('class'):"", '    df.vals.plot(kind=""kde"", ax=ax, label=label)']",,
28312011,"df = pd.DataFrame([[""foo1""], [""foo2""], [""bar""], [np.nan]], columns=['a'])
df.a.str.contains(""foo"")
df.a.str.contains(""foo"", na=False)
df.loc[df.a.str.contains(""foo"", na=False)]","['df = pd.DataFrame([[""foo1""], [""foo2""], [""bar""], [np.nan]], columns=[\'a\'])', 'df.a.str.contains(""foo"")', 'df.a.str.contains(""foo"", na=False)', 'df.loc[df.a.str.contains(""foo"", na=False)]']","['df.a.str.contains(""foo"")', 'df.a.str.contains(""foo"", na=False)', 'df.loc[df.a.str.contains(""foo"", na=False)]']","['df.a.str.contains(""foo"")', 'df.a.str.contains(""foo"", na=False)', 'df.loc[df.a.str.contains(""foo"", na=False)]']",,
28371611,,[],[''],[],[],[]
28371706,"import pandas as pd
import sqlite3
from pandas.io import sql
import subprocess
in_csv = '../data/my_large.csv'
out_sqlite = '../data/my.sqlite'
table_name = 'my_table' 
chunksize = 100000 
columns = ['molecule_id','charge','db','drugsnow','hba','hbd','loc','nrb','smiles']
nlines = subprocess.check_output('wc -l %s' % in_csv, shell=True)
nlines = int(nlines.split()[0]) 
cnx = sqlite3.connect(out_sqlite)
for i in range(0, nlines, chunksize):
    df = pd.read_csv(in_csv,  
            header=None,  
            nrows=chunksize, 
            skiprows=i)   
    df.columns = columns
    sql.to_sql(df, 
                name=table_name, 
                con=cnx, 
                index=False, 
                index_label='molecule_id', 
                if_exists='append') 
cnx.close()    ","['nlines = int(nlines.split()[0]) ', '    df = pd.read_csv(in_csv,  ', '    sql.to_sql(df, ']","['import pandas as pd', 'import sqlite3', 'from pandas.io import sql', 'import subprocess', ""in_csv = '../data/my_large.csv'"", ""out_sqlite = '../data/my.sqlite'"", ""table_name = 'my_table' "", 'chunksize = 100000 ', ""columns = ['molecule_id','charge','db','drugsnow','hba','hbd','loc','nrb','smiles']"", ""nlines = subprocess.check_output('wc -l %s' % in_csv, shell=True)"", 'nlines = int(nlines.split()[0]) ', 'cnx = sqlite3.connect(out_sqlite)', 'for i in range(0, nlines, chunksize):', '    df = pd.read_csv(in_csv,  ', '            header=None,  ', '            nrows=chunksize, ', '            skiprows=i)   ', '    df.columns = columns', '    sql.to_sql(df, ', '                name=table_name, ', '                con=cnx, ', '                index=False, ', ""                index_label='molecule_id', "", ""                if_exists='append') "", 'cnx.close()    ']","['nlines = int(nlines.split()[0]) ', '    df = pd.read_csv(in_csv,  ', '    sql.to_sql(df, ']",,
28384887,"class DenseTransformer(TransformerMixin):
    def transform(self, X, y=None, **fit_params):
        return X.todense()
    def fit_transform(self, X, y=None, **fit_params):
        self.fit(X, y, **fit_params)
        return self.transform(X)
    def fit(self, X, y=None, **fit_params):
        return self
pipeline = Pipeline([
     ('vectorizer', CountVectorizer()), 
     ('to_dense', DenseTransformer()), 
     ('classifier', RandomForestClassifier())
])
from sklearn.svm import LinearSVC
pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])",['        return self.transform(X)'],"['class DenseTransformer(TransformerMixin):', '    def transform(self, X, y=None, **fit_params):', '        return X.todense()', '    def fit_transform(self, X, y=None, **fit_params):', '        self.fit(X, y, **fit_params)', '        return self.transform(X)', '    def fit(self, X, y=None, **fit_params):', '        return self', 'pipeline = Pipeline([', ""     ('vectorizer', CountVectorizer()), "", ""     ('to_dense', DenseTransformer()), "", ""     ('classifier', RandomForestClassifier())"", '])', 'from sklearn.svm import LinearSVC', ""pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])""]",['        return self.transform(X)'],,
28390992,"df = df.fillna('')
df.column1 = df.column1.fillna('')","[""df = df.fillna('')"", ""df.column1 = df.column1.fillna('')""]","[""df = df.fillna('')"", ""df.column1 = df.column1.fillna('')""]","[""df = df.fillna('')"", ""df.column1 = df.column1.fillna('')""]",,
28417338,"from rpy2.robjects import r, pandas2ri
pandas2ri.activate()
r['iris'].head()
import pandas.rpy.common as rcom
iris = rcom.load_data('iris')
print(iris.head())
import pandas as pd
import rpy2.robjects as ro
import rpy2.robjects.conversion as conversion
from rpy2.robjects import pandas2ri
pandas2ri.activate()
R = ro.r
df = conversion.ri2py(R['mtcars'])
print(df.head())","[""r['iris'].head()"", 'print(iris.head())', 'print(df.head())']","['from rpy2.robjects import r, pandas2ri', 'pandas2ri.activate()', ""r['iris'].head()"", 'import pandas.rpy.common as rcom', ""iris = rcom.load_data('iris')"", 'print(iris.head())', 'import pandas as pd', 'import rpy2.robjects as ro', 'import rpy2.robjects.conversion as conversion', 'from rpy2.robjects import pandas2ri', 'pandas2ri.activate()', 'R = ro.r', ""df = conversion.ri2py(R['mtcars'])"", 'print(df.head())']","[""r['iris'].head()"", 'print(iris.head())', 'print(df.head())']",,
28419871,"import pandas as pd
file_name = ""http://www.ats.ucla.edu/stat/data/binary.csv""
df = pd.read_csv(file_name)
df.head()","['df = pd.read_csv(file_name)', 'df.head()']","['import pandas as pd', 'file_name = ""http://www.ats.ucla.edu/stat/data/binary.csv""', 'df = pd.read_csv(file_name)', 'df.head()']","['df = pd.read_csv(file_name)', 'df.head()']",,
28466662,"import pandas as pd
df = pd.DataFrame({'cat':['a','b','c','d'],'val':[1,2,5,10]})
df1 = pd.get_dummies(pd.DataFrame({'cat':['a'],'val':[1]}))
dummies_frame = pd.get_dummies(df)
df1.reindex(columns = dummies_frame.columns, fill_value=0)","[""df = pd.DataFrame({'cat':['a','b','c','d'],'val':[1,2,5,10]})"", ""df1 = pd.get_dummies(pd.DataFrame({'cat':['a'],'val':[1]}))"", 'dummies_frame = pd.get_dummies(df)', 'df1.reindex(columns = dummies_frame.columns, fill_value=0)']","['import pandas as pd', 'dummies_frame = pd.get_dummies(df)', 'df1.reindex(columns = dummies_frame.columns, fill_value=0)']","[""df1 = pd.get_dummies(pd.DataFrame({'cat':['a'],'val':[1]}))"", 'dummies_frame = pd.get_dummies(df)', 'df1.reindex(columns = dummies_frame.columns, fill_value=0)']",,
28479181,"dfTest = pd.DataFrame({
           'A':[14.00,90.20,90.95,96.27,91.21],
           'B':[103.02,107.26,110.35,114.23,114.68], 
           'C':['big','small','big','small','small']
         })
dfTest[['A','B']] = dfTest[['A','B']].apply(
                           lambda x: MinMaxScaler().fit_transform(x))
dfTest","['dfTest = pd.DataFrame({', ""dfTest[['A','B']] = dfTest[['A','B']].apply(""]","[""           'A':[14.00,90.20,90.95,96.27,91.21],"", ""           'B':[103.02,107.26,110.35,114.23,114.68], "", ""           'C':['big','small','big','small','small']"", '         })', ""dfTest[['A','B']] = dfTest[['A','B']].apply("", '                           lambda x: MinMaxScaler().fit_transform(x))', 'dfTest']","[""dfTest[['A','B']] = dfTest[['A','B']].apply(""]",,
28507257,"from IPython.display import display
display(df)  ",[],"['from IPython.display import display', 'display(df)  ']",[],[],[]
28538738,"df = df[cols_of_interest]
df.drop(df.ix[:,'Unnamed: 24':'Unnamed: 60'].head(0).columns, axis=1)
df = pd.DataFrame(columns=['a','Unnamed: 1', 'Unnamed: 1','foo'])
df
Index: []
~df.columns.str.contains('Unnamed:')
array([ True, False, False,  True], dtype=bool)
df[df.columns[~df.columns.str.contains('Unnamed:')]]
Columns: [a, foo]
Index: []","[""df.drop(df.ix[:,'Unnamed: 24':'Unnamed: 60'].head(0).columns, axis=1)"", ""df = pd.DataFrame(columns=['a','Unnamed: 1', 'Unnamed: 1','foo'])"", ""~df.columns.str.contains('Unnamed:')"", ""df[df.columns[~df.columns.str.contains('Unnamed:')]]""]","['df = df[cols_of_interest]', ""df.drop(df.ix[:,'Unnamed: 24':'Unnamed: 60'].head(0).columns, axis=1)"", 'df', 'Index: []', ""~df.columns.str.contains('Unnamed:')"", 'array([ True, False, False,  True], dtype=bool)', ""df[df.columns[~df.columns.str.contains('Unnamed:')]]"", 'Columns: [a, foo]', 'Index: []']","[""df.drop(df.ix[:,'Unnamed: 24':'Unnamed: 60'].head(0).columns, axis=1)"", ""~df.columns.str.contains('Unnamed:')"", ""df[df.columns[~df.columns.str.contains('Unnamed:')]]""]",,
28540395,"for col in df.columns:
    if 'Unnamed' in col:
        del df[col]",[],"['for col in df.columns:', ""    if 'Unnamed' in col:"", '        del df[col]']",[],[],[]
28541443,"w.loc[w.female != 'female', 'female'] = 0
w.loc[w.female == 'female', 'female'] = 1","[""w.loc[w.female != 'female', 'female'] = 0"", ""w.loc[w.female == 'female', 'female'] = 1""]","[""w.loc[w.female != 'female', 'female'] = 0"", ""w.loc[w.female == 'female', 'female'] = 1""]","[""w.loc[w.female != 'female', 'female'] = 0"", ""w.loc[w.female == 'female', 'female'] = 1""]",,
28565940,"import seaborn as sns
tips = sns.load_dataset(""tips"")
sns.boxplot(x=""day"", y=""total_bill"", data=tips)
sns.stripplot(x=""day"", y=""total_bill"", data=tips,
              size=4, jitter=True, edgecolor=""gray"")",[],"['import seaborn as sns', 'tips = sns.load_dataset(""tips"")', 'sns.boxplot(x=""day"", y=""total_bill"", data=tips)', 'sns.stripplot(x=""day"", y=""total_bill"", data=tips,', '              size=4, jitter=True, edgecolor=""gray"")']",[],[],[]
28590865,"[
     {""id"":0,""location"":""[50, 50]""},
     {""id"":1,""location"":""[60, 60]""},
     {""id"":2,""location"":""[70, 70]""},
     {""id"":3,""location"":""[80, 80]""}
]",[],"['[', '     {""id"":0,""location"":""[50, 50]""},', '     {""id"":1,""location"":""[60, 60]""},', '     {""id"":2,""location"":""[70, 70]""},', '     {""id"":3,""location"":""[80, 80]""}', ']']",[],[],[]
28595765,"test3 = pd.concat([test1, test2], axis=1)
test3.columns = ['a','b']","['test3 = pd.concat([test1, test2], axis=1)']","['test3 = pd.concat([test1, test2], axis=1)', ""test3.columns = ['a','b']""]","['test3 = pd.concat([test1, test2], axis=1)']",,
28611938,"from rpy2.robjects import pandas2ri
pd_df = pandas2ri.ri2py_dataframe(rdf)",[],"['from rpy2.robjects import pandas2ri', 'pd_df = pandas2ri.ri2py_dataframe(rdf)']",[],[],[]
28648525,,[],[''],[],[],[]
28648923,"s = pd.Series(['1', '2', '4.7', 'pandas', '10'])
s
dtype: object
pd.to_numeric(s) 
pd.to_numeric(s, errors='coerce')
dtype: float64
pd.to_numeric(s, errors='ignore')
a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]
df = pd.DataFrame(a, columns=['col1','col2','col3'])
df
df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)
df.apply(pd.to_numeric, errors='ignore')
df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')
df.dtypes
dtype: object
df = df.infer_objects()
df.dtypes
dtype: object","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","['s', 'dtype: object', 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", 'dtype: float64', ""pd.to_numeric(s, errors='ignore')"", ""a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]"", 'df', ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", 'df.dtypes', 'dtype: object', 'df = df.infer_objects()', 'df.dtypes', 'dtype: object']","['pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']"
28652153,"df
df.pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')  
df1 = df.set_index([0, 1, 2])
df1
df1.unstack(2)
df1.reset_index().pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')","[""df.pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')  "", 'df1 = df.set_index([0, 1, 2])', 'df1.unstack(2)', ""df1.reset_index().pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')""]","['df', ""df.pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')  "", 'df1 = df.set_index([0, 1, 2])', 'df1', 'df1.unstack(2)', ""df1.reset_index().pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')""]","[""df.pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')  "", 'df1 = df.set_index([0, 1, 2])', 'df1.unstack(2)', ""df1.reset_index().pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')""]",,
28677342,"import math
c = values.cumsum() - ALLOWANCE
c[c < 0] = 0 
c.diff().fillna(math.max(0, values[0] - ALLOWANCE))","['c = values.cumsum() - ALLOWANCE', 'c.diff().fillna(math.max(0, values[0] - ALLOWANCE))']","['import math', 'c = values.cumsum() - ALLOWANCE', 'c[c < 0] = 0 ', 'c.diff().fillna(math.max(0, values[0] - ALLOWANCE))']","['c = values.cumsum() - ALLOWANCE', 'c.diff().fillna(math.max(0, values[0] - ALLOWANCE))']",,
28677358,"dtype: float64
s = (values.cumsum() - ALLOWANCE).clip_lower(0)
desired = s.diff().fillna(s)","['s = (values.cumsum() - ALLOWANCE).clip_lower(0)', 'desired = s.diff().fillna(s)']","['dtype: float64', 's = (values.cumsum() - ALLOWANCE).clip_lower(0)', 'desired = s.diff().fillna(s)']","['s = (values.cumsum() - ALLOWANCE).clip_lower(0)', 'desired = s.diff().fillna(s)']",,
28680078,"df = pd.DataFrame(dict(A=[5,3,5,6], C=[""foo"",""bar"",""fooXYZbar"", ""bat""]))
df
df[df.C.str.contains(""XYZ"") == False]","['df = pd.DataFrame(dict(A=[5,3,5,6], C=[""foo"",""bar"",""fooXYZbar"", ""bat""]))', 'df[df.C.str.contains(""XYZ"") == False]']","['df', 'df[df.C.str.contains(""XYZ"") == False]']","['df[df.C.str.contains(""XYZ"") == False]']",,
28731311,"xls = pd.ExcelFile('path_to_file.xls')
sheet1 = xls.parse(0)
sheet2 = xls.parse(1)","['sheet1 = xls.parse(0)', 'sheet2 = xls.parse(1)']","[""xls = pd.ExcelFile('path_to_file.xls')"", 'sheet1 = xls.parse(0)', 'sheet2 = xls.parse(1)']","['sheet1 = xls.parse(0)', 'sheet2 = xls.parse(1)']",,
28756099,"import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols
cw = pd.read_csv('ChickWeight.csv')
cw_lm=ols('weight ~ Time + C(Diet)', data=cw).fit() 
print(sm.stats.anova_lm(cw_lm, typ=2))","[""cw = pd.read_csv('ChickWeight.csv')""]","['import pandas as pd', 'import statsmodels.api as sm', 'from statsmodels.formula.api import ols', ""cw = pd.read_csv('ChickWeight.csv')"", ""cw_lm=ols('weight ~ Time + C(Diet)', data=cw).fit() "", 'print(sm.stats.anova_lm(cw_lm, typ=2))']","[""cw = pd.read_csv('ChickWeight.csv')""]",,
28783971,"df['dt'].values.astype('<M8[h]')
df
df['dt2'] = df['dt'].values.astype('<M8[h]')
df
df.dtypes","[""df['dt'].values.astype('<M8[h]')"", ""df['dt2'] = df['dt'].values.astype('<M8[h]')"", 'df.dtypes']","[""df['dt'].values.astype('<M8[h]')"", 'df', ""df['dt2'] = df['dt'].values.astype('<M8[h]')"", 'df', 'df.dtypes']","[""df['dt'].values.astype('<M8[h]')"", ""df['dt2'] = df['dt'].values.astype('<M8[h]')"", 'df.dtypes']",,
28847219,"gb.get_group('foo')
df.loc[gb.groups['foo']]
df.loc[gb.groups['foo'],('A','B')]","[""gb.get_group('foo')"", ""df.loc[gb.groups['foo']]"", ""df.loc[gb.groups['foo'],('A','B')]""]","[""gb.get_group('foo')"", ""df.loc[gb.groups['foo']]"", ""df.loc[gb.groups['foo'],('A','B')]""]","[""gb.get_group('foo')"", ""df.loc[gb.groups['foo']]"", ""df.loc[gb.groups['foo'],('A','B')]""]",,
28881373,"df['col_3'] = df.col_1.combine(df.col_2, func=get_sublist)
df['col_3'] = df.col_1.astype(object).combine(df.col_2, func=get_sublist)
df","[""df['col_3'] = df.col_1.combine(df.col_2, func=get_sublist)"", ""df['col_3'] = df.col_1.astype(object).combine(df.col_2, func=get_sublist)""]","[""df['col_3'] = df.col_1.combine(df.col_2, func=get_sublist)"", ""df['col_3'] = df.col_1.astype(object).combine(df.col_2, func=get_sublist)"", 'df']","[""df['col_3'] = df.col_1.combine(df.col_2, func=get_sublist)"", ""df['col_3'] = df.col_1.astype(object).combine(df.col_2, func=get_sublist)""]",,
28882020,"def splitDataFrameIntoSmaller(df, chunkSize = 10000): 
    listOfDf = list()
    numberChunks = len(df) // chunkSize + 1
    for i in range(numberChunks):
        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])
    return listOfDf",['        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])'],"['def splitDataFrameIntoSmaller(df, chunkSize = 10000): ', '    listOfDf = list()', '    numberChunks = len(df) // chunkSize + 1', '    for i in range(numberChunks):', '        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])', '    return listOfDf']",['        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])'],,
28900208,"In[2]: df = pd.DataFrame([ pd.Timestamp('20150111'), 
                           pd.Timestamp('20150301') ], columns=['date'])
In[3]: df['today'] = pd.Timestamp('20150315')
In[4]: df
In[5]: (df['today'] - df['date']).dt.days
dtype: int64","[""In[2]: df = pd.DataFrame([ pd.Timestamp('20150111'), "", ""                           pd.Timestamp('20150301') ], columns=['date'])"", ""In[3]: df['today'] = pd.Timestamp('20150315')"", ""In[5]: (df['today'] - df['date']).dt.days""]","[""                           pd.Timestamp('20150301') ], columns=['date'])"", ""In[3]: df['today'] = pd.Timestamp('20150315')"", 'In[4]: df', ""In[5]: (df['today'] - df['date']).dt.days"", 'dtype: int64']","[""In[2]: df = pd.DataFrame([ pd.Timestamp('20150111'), "", ""                           pd.Timestamp('20150301') ], columns=['date'])"", ""In[3]: df['today'] = pd.Timestamp('20150315')"", ""In[5]: (df['today'] - df['date']).dt.days""]",,
28902170,"common = df1.merge(df2,on=['col1','col2'])
print(common)
df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]
df1[~df1.isin(df2)].dropna()
df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})
df1[~df1.isin(df2)].dropna()","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'print(common)', 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']"
28917065,"x.plot(kind=""bar"").legend(bbox_to_anchor=(1.2, 0.5))
x.plot(kind=""bar"").legend(*args, **kwargs)","['x.plot(kind=""bar"").legend(bbox_to_anchor=(1.2, 0.5))', 'x.plot(kind=""bar"").legend(*args, **kwargs)']","['x.plot(kind=""bar"").legend(bbox_to_anchor=(1.2, 0.5))', 'x.plot(kind=""bar"").legend(*args, **kwargs)']","['x.plot(kind=""bar"").legend(bbox_to_anchor=(1.2, 0.5))', 'x.plot(kind=""bar"").legend(*args, **kwargs)']",,
28931750,"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
frequencies = [6, 16, 75, 160, 244, 260, 145, 73, 16, 4, 1]   
freq_series = pd.Series.from_array(frequencies)   
x_labels = [108300.0, 110540.0, 112780.0, 115020.0, 117260.0, 119500.0, 121740.0, 123980.0, 126220.0, 128460.0, 130700.0]
plt.figure(figsize=(12, 8))
ax = freq_series.plot(kind='bar')
ax.set_title(""Amount Frequency"")
ax.set_xlabel(""Amount ($)"")
ax.set_ylabel(""Frequency"")
ax.set_xticklabels(x_labels)
rects = ax.patches
labels = [""label%d"" % i for i in xrange(len(rects))]
for rect, label in zip(rects, labels):
    height = rect.get_height()
    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')
plt.savefig(""image.png"")","['freq_series = pd.Series.from_array(frequencies)   ', ""ax = freq_series.plot(kind='bar')""]","['import numpy as np', 'import pandas as pd', 'import matplotlib.pyplot as plt', 'frequencies = [6, 16, 75, 160, 244, 260, 145, 73, 16, 4, 1]   ', 'x_labels = [108300.0, 110540.0, 112780.0, 115020.0, 117260.0, 119500.0, 121740.0, 123980.0, 126220.0, 128460.0, 130700.0]', 'plt.figure(figsize=(12, 8))', ""ax = freq_series.plot(kind='bar')"", 'ax.set_title(""Amount Frequency"")', 'ax.set_xlabel(""Amount ($)"")', 'ax.set_ylabel(""Frequency"")', 'ax.set_xticklabels(x_labels)', 'rects = ax.patches', 'labels = [""label%d"" % i for i in xrange(len(rects))]', 'for rect, label in zip(rects, labels):', '    height = rect.get_height()', ""    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')"", 'plt.savefig(""image.png"")']","[""ax = freq_series.plot(kind='bar')""]",,
28986536,"df['range'] = df['range'].str.replace(',','-')
df
0    (2-30)
1  (50-290)
df['range'].replace(',','-',inplace=True)
df = pd.DataFrame({'range':['(2,30)',',']})
df['range'].replace(',','-', inplace=True)
df['range']
0    (2,30)","[""df['range'] = df['range'].str.replace(',','-')"", ""df['range'].replace(',','-',inplace=True)"", ""df = pd.DataFrame({'range':['(2,30)',',']})"", ""df['range'].replace(',','-', inplace=True)""]","[""df['range'] = df['range'].str.replace(',','-')"", 'df', '0    (2-30)', '1  (50-290)', ""df['range'].replace(',','-',inplace=True)"", ""df['range'].replace(',','-', inplace=True)"", ""df['range']"", '0    (2,30)']","[""df['range'] = df['range'].str.replace(',','-')"", ""df['range'].replace(',','-',inplace=True)"", ""df['range'].replace(',','-', inplace=True)""]",,
28991603,"dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]
df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)","[""dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)""]","[""dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)""]","[""dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]"", ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)""]",,
29036738,"df[""date""] = df[""date""].astype(""datetime64"")
df.groupby(df[""date""].dt.month).count().plot(kind=""bar"")
df.groupby([df[""date""].dt.year, df[""date""].dt.month]).count().plot(kind=""bar"")","['df[""date""] = df[""date""].astype(""datetime64"")', 'df.groupby(df[""date""].dt.month).count().plot(kind=""bar"")', 'df.groupby([df[""date""].dt.year, df[""date""].dt.month]).count().plot(kind=""bar"")']","['df[""date""] = df[""date""].astype(""datetime64"")', 'df.groupby(df[""date""].dt.month).count().plot(kind=""bar"")', 'df.groupby([df[""date""].dt.year, df[""date""].dt.month]).count().plot(kind=""bar"")']","['df[""date""] = df[""date""].astype(""datetime64"")', 'df.groupby(df[""date""].dt.month).count().plot(kind=""bar"")', 'df.groupby([df[""date""].dt.year, df[""date""].dt.month]).count().plot(kind=""bar"")']",,
29039484,ts = df.set_index('DateTime'),"[""ts = df.set_index('DateTime')""]","[""ts = df.set_index('DateTime')""]","[""ts = df.set_index('DateTime')""]",,
29074073,"pd.set_option('display.width', pd.util.terminal.get_terminal_size()[0])","[""pd.set_option('display.width', pd.util.terminal.get_terminal_size()[0])""]","[""pd.set_option('display.width', pd.util.terminal.get_terminal_size()[0])""]","[""pd.set_option('display.width', pd.util.terminal.get_terminal_size()[0])""]",,
29108799,"rpt.query('STK_ID in (600809,600141,600329)')
rpt.query('60000 < STK_ID < 70000')","[""rpt.query('STK_ID in (600809,600141,600329)')"", ""rpt.query('60000 < STK_ID < 70000')""]","[""rpt.query('STK_ID in (600809,600141,600329)')"", ""rpt.query('60000 < STK_ID < 70000')""]","[""rpt.query('STK_ID in (600809,600141,600329)')"", ""rpt.query('60000 < STK_ID < 70000')""]",,
29177664,"df.Temp_Rating.fillna(df.Farheit, inplace=True)
del df['Farheit']
df.columns = 'File heat Observations'.split()","['df.Temp_Rating.fillna(df.Farheit, inplace=True)', ""df.columns = 'File heat Observations'.split()""]","['df.Temp_Rating.fillna(df.Farheit, inplace=True)', ""del df['Farheit']"", ""df.columns = 'File heat Observations'.split()""]","['df.Temp_Rating.fillna(df.Farheit, inplace=True)', ""df.columns = 'File heat Observations'.split()""]",,
29218694,"np.dtype('datetime64[ns]') == np.dtype('<M8[ns]')
Out[6]: True","[""np.dtype('datetime64[ns]') == np.dtype('<M8[ns]')""]","[""np.dtype('datetime64[ns]') == np.dtype('<M8[ns]')"", 'Out[6]: True']","[""np.dtype('datetime64[ns]') == np.dtype('<M8[ns]')""]",,
29233885,"for key, grp in df.groupby(['color']):
    ax = grp.plot(ax=ax, kind='line', x='x', y='y', c=key)
    labels.append(key)
lines, _ = ax.get_legend_handles_labels()
ax.legend(lines, labels, loc='best')
plt.show()","[""for key, grp in df.groupby(['color']):"", ""    ax = grp.plot(ax=ax, kind='line', x='x', y='y', c=key)"", '    labels.append(key)']","[""for key, grp in df.groupby(['color']):"", ""    ax = grp.plot(ax=ax, kind='line', x='x', y='y', c=key)"", '    labels.append(key)', 'lines, _ = ax.get_legend_handles_labels()', ""ax.legend(lines, labels, loc='best')"", 'plt.show()']","[""for key, grp in df.groupby(['color']):"", ""    ax = grp.plot(ax=ax, kind='line', x='x', y='y', c=key)"", '    labels.append(key)']",,
29233999,,[],[''],[],[],[]
29242900,"cols = list(df.loc[:,'A':'C']) + ['E'] + list(df.loc[:,'G':'I'])
df[cols]
df.filter(regex='[A-CEG-I]')","[""cols = list(df.loc[:,'A':'C']) + ['E'] + list(df.loc[:,'G':'I'])"", ""df.filter(regex='[A-CEG-I]')""]","[""cols = list(df.loc[:,'A':'C']) + ['E'] + list(df.loc[:,'G':'I'])"", 'df[cols]', ""df.filter(regex='[A-CEG-I]')""]","[""cols = list(df.loc[:,'A':'C']) + ['E'] + list(df.loc[:,'G':'I'])"", ""df.filter(regex='[A-CEG-I]')""]",,
29247205,"df
df[(df.A == 1) & (df.D == 6)]
df[((df.A==1) == True) | ((df.D==6) == True)]",[],"['df', 'df[(df.A == 1) & (df.D == 6)]', 'df[((df.A==1) == True) | ((df.D==6) == True)]']",[],[],[]
29262040,"for i, row in df.iterrows():
  ifor_val = something
  df.set_value(i,'ifor',ifor_val)","['for i, row in df.iterrows():', ""  df.set_value(i,'ifor',ifor_val)""]","['for i, row in df.iterrows():', '  ifor_val = something', ""  df.set_value(i,'ifor',ifor_val)""]","['for i, row in df.iterrows():', ""  df.set_value(i,'ifor',ifor_val)""]",,
29281494,"from multiprocessing import Pool, cpu_count
def applyParallel(dfGrouped, func):
    with Pool(cpu_count()) as p:
        ret_list = p.map(func, [group for name, group in dfGrouped])
    return pandas.concat(ret_list)","['        ret_list = p.map(func, [group for name, group in dfGrouped])', '    return pandas.concat(ret_list)']","['from multiprocessing import Pool, cpu_count', 'def applyParallel(dfGrouped, func):', '    with Pool(cpu_count()) as p:', '        ret_list = p.map(func, [group for name, group in dfGrouped])', '    return pandas.concat(ret_list)']","['        ret_list = p.map(func, [group for name, group in dfGrouped])', '    return pandas.concat(ret_list)']",,
29287549,"df = pd.read_csv(file_path, header=None, usecols=[3,6])","['df = pd.read_csv(file_path, header=None, usecols=[3,6])']","['df = pd.read_csv(file_path, header=None, usecols=[3,6])']","['df = pd.read_csv(file_path, header=None, usecols=[3,6])']",,
29314880,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(10, 2), columns=list('AB'))
df['Tenant'] = np.random.choice(['Babar', 'Rataxes', ''], 10)
df['Tenant'].replace('', np.nan, inplace=True)
df.dropna(subset=['Tenant'], inplace=True)","[""df = pd.DataFrame(np.random.randn(10, 2), columns=list('AB'))"", ""df['Tenant'].replace('', np.nan, inplace=True)"", ""df.dropna(subset=['Tenant'], inplace=True)""]","['import pandas as pd', 'import numpy as np', ""df['Tenant'] = np.random.choice(['Babar', 'Rataxes', ''], 10)"", ""df['Tenant'].replace('', np.nan, inplace=True)"", ""df.dropna(subset=['Tenant'], inplace=True)""]","[""df['Tenant'].replace('', np.nan, inplace=True)"", ""df.dropna(subset=['Tenant'], inplace=True)""]",,
29319200,,[],[''],[],[],[]
29319460,"filter = df[""Tenant""] != """"
dfNew = df[filter]",[],"['filter = df[""Tenant""] != """"', 'dfNew = df[filter]']",[],[],[]
29321298,"python
import numpy
numpy.__file__
'/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/__init__.pyc'
numpy.version.version
'1.8.0rc1'
mv /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy_bak
python
import numpy
numpy.__file__
'/Library/Python/2.7/site-packages/numpy/__init__.pyc'
numpy.version.version
'1.9.2'",[],"['python', 'import numpy', 'numpy.__file__', ""'/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/__init__.pyc'"", 'numpy.version.version', ""'1.8.0rc1'"", 'mv /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy_bak', 'python', 'import numpy', 'numpy.__file__', ""'/Library/Python/2.7/site-packages/numpy/__init__.pyc'"", 'numpy.version.version', ""'1.9.2'""]",[],[],[]
29334672,,[],[''],[],[],[]
29370182,"df['date'] = pd.to_datetime(df['date'])  
mask = (df['date'] > start_date) & (df['date'] <= end_date)
df.loc[mask]
df = df.loc[mask]
import numpy as np
import pandas as pd
df = pd.DataFrame(np.random.random((200,3)))
df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')
mask = (df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10')
print(df.loc[mask])
import numpy as np
import pandas as pd
df = pd.DataFrame(np.random.random((200,3)))
df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')
df = df.set_index(['date'])
print(df.loc['2000-6-1':'2000-6-10'])
date                                    ","[""df['date'] = pd.to_datetime(df['date'])  "", 'df.loc[mask]', 'df = df.loc[mask]', 'df = pd.DataFrame(np.random.random((200,3)))', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", 'print(df.loc[mask])', 'df = pd.DataFrame(np.random.random((200,3)))', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", ""df = df.set_index(['date'])"", ""print(df.loc['2000-6-1':'2000-6-10'])""]","[""df['date'] = pd.to_datetime(df['date'])  "", ""mask = (df['date'] > start_date) & (df['date'] <= end_date)"", 'df.loc[mask]', 'df = df.loc[mask]', 'import numpy as np', 'import pandas as pd', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", ""mask = (df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10')"", 'print(df.loc[mask])', 'import numpy as np', 'import pandas as pd', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", ""df = df.set_index(['date'])"", ""print(df.loc['2000-6-1':'2000-6-10'])"", 'date                                    ']","[""df['date'] = pd.to_datetime(df['date'])  "", 'df.loc[mask]', 'df = df.loc[mask]', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", 'print(df.loc[mask])', ""df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')"", ""df = df.set_index(['date'])"", ""print(df.loc['2000-6-1':'2000-6-10'])""]",,
29370709,"df['stats'].str[1:-1].str.split(',', expand=True).astype(float)
df['stats'].apply(pd.Series)
df['stats'].str[1:-1].str.split(',').apply(pd.Series).astype(float)","[""df['stats'].str[1:-1].str.split(',', expand=True).astype(float)"", ""df['stats'].apply(pd.Series)"", ""df['stats'].str[1:-1].str.split(',').apply(pd.Series).astype(float)""]","[""df['stats'].str[1:-1].str.split(',', expand=True).astype(float)""]","[""df['stats'].str[1:-1].str.split(',', expand=True).astype(float)"", ""df['stats'].apply(pd.Series)"", ""df['stats'].str[1:-1].str.split(',').apply(pd.Series).astype(float)""]",,
29383624,"data=pd.read_csv(""File_path"", sep='\t')","['data=pd.read_csv(""File_path"", sep=\'\\t\')']","['data=pd.read_csv(""File_path"", sep=\'\\t\')']","['data=pd.read_csv(""File_path"", sep=\'\\t\')']",,
29432741,,[],[''],[],[],[]
29442936,"df = pd.DataFrame([[1, 2.2, 'three']], columns=['A', 'B', 'C'])
df.select_dtypes(include=['int'])
df.select_dtypes(include=[np.number])
df.select_dtypes(exclude=[object])","[""df = pd.DataFrame([[1, 2.2, 'three']], columns=['A', 'B', 'C'])"", ""df.select_dtypes(include=['int'])"", 'df.select_dtypes(include=[np.number])', 'df.select_dtypes(exclude=[object])']","[""df.select_dtypes(include=['int'])"", 'df.select_dtypes(include=[np.number])', 'df.select_dtypes(exclude=[object])']","[""df.select_dtypes(include=['int'])"", 'df.select_dtypes(include=[np.number])', 'df.select_dtypes(exclude=[object])']",,
29461151,"from pandas import ExcelWriter
writer = ExcelWriter('PythonExport.xlsx')
yourdf.to_excel(writer,'Sheet5')
writer.save()
yourdf.to_csv('PythonExport.csv', sep=',')
import os
import win32com.client
from pandas import ExcelWriter
if os.path.exists(""C:\Full Location\To\excelsheet.xlsm""):
  xlApp=win32com.client.Dispatch(""Excel.Application"")
  wb = xlApp.Workbooks.Open(Filename=""C:\Full Location\To\excelsheet.xlsm"")
  xlApp.Run(""ClearExistingContent"")
  wb.Save() 
  xlApp.Quit()
  del xl
  writer = ExcelWriter('C:\Full Location\To\excelsheet.xlsm')
  yourdf.to_excel(writer,'Sheet5')
  writer.save() ","[""yourdf.to_excel(writer,'Sheet5')"", ""yourdf.to_csv('PythonExport.csv', sep=',')"", ""  yourdf.to_excel(writer,'Sheet5')""]","['from pandas import ExcelWriter', ""writer = ExcelWriter('PythonExport.xlsx')"", ""yourdf.to_excel(writer,'Sheet5')"", 'writer.save()', ""yourdf.to_csv('PythonExport.csv', sep=',')"", 'import os', 'import win32com.client', 'from pandas import ExcelWriter', 'if os.path.exists(""C:\\Full Location\\To\\excelsheet.xlsm""):', '  xlApp=win32com.client.Dispatch(""Excel.Application"")', '  wb = xlApp.Workbooks.Open(Filename=""C:\\Full Location\\To\\excelsheet.xlsm"")', '  xlApp.Run(""ClearExistingContent"")', '  wb.Save() ', '  xlApp.Quit()', '  del xl', ""  writer = ExcelWriter('C:\\Full Location\\To\\excelsheet.xlsm')"", ""  yourdf.to_excel(writer,'Sheet5')"", '  writer.save() ']","[""yourdf.to_excel(writer,'Sheet5')"", ""yourdf.to_csv('PythonExport.csv', sep=',')"", ""  yourdf.to_excel(writer,'Sheet5')""]",,
29464365,"pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')
df1 = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'))
df2 = df1.ix[4:8]
df2.reset_index(drop=True,inplace=True)
df2.loc[-1] = [2, 3, 4, 5]
df2.loc[-2] = [14, 15, 16, 17]
df2.reset_index(drop=True,inplace=True)
df2 = df2[['A', 'B', 'C']] 
pd.merge(df1, df2, on=common_cols, how='inner')
ds1 = set(tuple(line) for line in df1.values)
ds2 = set(tuple(line) for line in df2.values)
df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)
df12['key'] = 'x'
temp_df = pd.merge(df2, df12, on=df2.columns.tolist(), how='left')
temp_df[temp_df['key'].isnull()].drop('key', axis=1)","[""pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')"", ""df1 = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'))"", 'df2.reset_index(drop=True,inplace=True)', 'df2.loc[-1] = [2, 3, 4, 5]', 'df2.loc[-2] = [14, 15, 16, 17]', 'df2.reset_index(drop=True,inplace=True)', ""pd.merge(df1, df2, on=common_cols, how='inner')"", 'ds1 = set(tuple(line) for line in df1.values)', 'ds2 = set(tuple(line) for line in df2.values)', 'df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)', ""temp_df = pd.merge(df2, df12, on=df2.columns.tolist(), how='left')"", ""temp_df[temp_df['key'].isnull()].drop('key', axis=1)""]","[""pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')"", 'df2 = df1.ix[4:8]', 'df2.reset_index(drop=True,inplace=True)', 'df2.loc[-1] = [2, 3, 4, 5]', 'df2.loc[-2] = [14, 15, 16, 17]', 'df2.reset_index(drop=True,inplace=True)', ""df2 = df2[['A', 'B', 'C']] "", ""pd.merge(df1, df2, on=common_cols, how='inner')"", 'ds1 = set(tuple(line) for line in df1.values)', 'ds2 = set(tuple(line) for line in df2.values)', ""df12['key'] = 'x'"", ""temp_df = pd.merge(df2, df12, on=df2.columns.tolist(), how='left')"", ""temp_df[temp_df['key'].isnull()].drop('key', axis=1)""]","[""pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')"", 'df2.reset_index(drop=True,inplace=True)', 'df2.loc[-1] = [2, 3, 4, 5]', 'df2.loc[-2] = [14, 15, 16, 17]', 'df2.reset_index(drop=True,inplace=True)', ""pd.merge(df1, df2, on=common_cols, how='inner')"", 'ds1 = set(tuple(line) for line in df1.values)', 'ds2 = set(tuple(line) for line in df2.values)', 'df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)', ""temp_df = pd.merge(df2, df12, on=df2.columns.tolist(), how='left')"", ""temp_df[temp_df['key'].isnull()].drop('key', axis=1)""]",,
29465238,"df.replace({'\n': '<br>'}, regex=True)
df = pd.DataFrame({'a': ['1\n', '2\n', '3'], 'b': ['4\n', '5', '6\n']})
df
df.replace({'\n': '<br>'}, regex=True)","[""df.replace({'\\n': '<br>'}, regex=True)"", ""df = pd.DataFrame({'a': ['1\\n', '2\\n', '3'], 'b': ['4\\n', '5', '6\\n']})"", ""df.replace({'\\n': '<br>'}, regex=True)""]","[""df.replace({'\\n': '<br>'}, regex=True)"", 'df', ""df.replace({'\\n': '<br>'}, regex=True)""]","[""df.replace({'\\n': '<br>'}, regex=True)"", ""df.replace({'\\n': '<br>'}, regex=True)""]",,
29494537,df.columns.tolist(),['df.columns.tolist()'],['df.columns.tolist()'],['df.columns.tolist()'],,
29499109,"ax = df[['V1','V2']].plot(kind='bar', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)
import matplotlib.pyplot as plt
ax = df[['V1','V2']].plot(kind='bar', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)
ax.set_xlabel(""Hour"", fontsize=12)
ax.set_ylabel(""V"", fontsize=12)
plt.show()","['ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)', 'ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)']","['ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)', 'import matplotlib.pyplot as plt', 'ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)', 'ax.set_xlabel(""Hour"", fontsize=12)', 'ax.set_ylabel(""V"", fontsize=12)', 'plt.show()']","['ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)', 'ax = df[[\'V1\',\'V2\']].plot(kind=\'bar\', title =""V comp"", figsize=(15, 10), legend=True, fontsize=12)']",,
29500330,"grouped = df.groupby('A')
df = grouped.aggregate(lambda x: tuple(x))
df['grouped'] = df['B'] + df['C']","[""grouped = df.groupby('A')"", 'df = grouped.aggregate(lambda x: tuple(x))']","[""grouped = df.groupby('A')"", 'df = grouped.aggregate(lambda x: tuple(x))', ""df['grouped'] = df['B'] + df['C']""]","[""grouped = df.groupby('A')"", 'df = grouped.aggregate(lambda x: tuple(x))']",,
29517089,"df
df['Name'] = 'abc'
df",[],"['df', ""df['Name'] = 'abc'"", 'df']",[],[],[]
29517102,df['Name'] = 'abc',[],"[""df['Name'] = 'abc'""]",[],[],[]
29522443,"sql = ""SELECT * FROM My_Table""
for chunk in pd.read_sql_query(sql , engine, chunksize=5):
    print(chunk)","['for chunk in pd.read_sql_query(sql , engine, chunksize=5):']","['sql = ""SELECT * FROM My_Table""', 'for chunk in pd.read_sql_query(sql , engine, chunksize=5):', '    print(chunk)']","['for chunk in pd.read_sql_query(sql , engine, chunksize=5):']",,
29528483,"import numpy as np 
from pandas import DataFrame
import seaborn as sns
Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']
Cols = ['A', 'B', 'C', 'D']
df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)
sns.heatmap(df)",[],"['import numpy as np ', 'from pandas import DataFrame', 'import seaborn as sns', ""Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']"", ""Cols = ['A', 'B', 'C', 'D']"", 'df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)', 'sns.heatmap(df)']",[],[],[]
29528804,"df = pd.read_sql(query.statement, query.session.bind)","['df = pd.read_sql(query.statement, query.session.bind)']","['df = pd.read_sql(query.statement, query.session.bind)']","['df = pd.read_sql(query.statement, query.session.bind)']",,
29530303,,[],[''],[],[],[]
29530559,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(10,6))
df.iloc[1:3,1] = np.nan
df.iloc[5,3] = np.nan
df.iloc[7:9,5] = np.nan
dtype: bool
df.isnull().any().any()
True
df.isnull().sum()
dtype: int64
df.isnull().sum().sum()
5","['df = pd.DataFrame(np.random.randn(10,6))', 'df.iloc[1:3,1] = np.nan', 'df.iloc[5,3] = np.nan', 'df.iloc[7:9,5] = np.nan', 'df.isnull().any().any()', 'df.isnull().sum()', 'df.isnull().sum().sum()']","['import pandas as pd', 'import numpy as np', 'df.iloc[1:3,1] = np.nan', 'df.iloc[5,3] = np.nan', 'df.iloc[7:9,5] = np.nan', 'dtype: bool', 'df.isnull().any().any()', 'True', 'df.isnull().sum()', 'dtype: int64', 'df.isnull().sum().sum()', '5']","['df.iloc[1:3,1] = np.nan', 'df.iloc[5,3] = np.nan', 'df.iloc[7:9,5] = np.nan', 'df.isnull().any().any()', 'df.isnull().sum()', 'df.isnull().sum().sum()']",,
29530601,"df.isnull().values.any()
df = pd.DataFrame(np.random.randn(1000,1000))
df[df > 0.9] = pd.np.nan","['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']","['df.isnull().values.any()', 'df[df > 0.9] = pd.np.nan']",['df.isnull().values.any()'],"['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']","['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']"
29533502,"from pandas import *
import matplotlib.pyplot as plt
ys = [[0,1,2,3,4],[4,3,2,1,0]]
x_ax = [0,1,2,3,4]
for y_ax in ys:
    ts = Series(y_ax,index=x_ax)
    ts.plot(kind='bar', figsize=(15,5))
    plt.show()","[""    ts.plot(kind='bar', figsize=(15,5))""]","['from pandas import *', 'import matplotlib.pyplot as plt', 'ys = [[0,1,2,3,4],[4,3,2,1,0]]', 'x_ax = [0,1,2,3,4]', 'for y_ax in ys:', '    ts = Series(y_ax,index=x_ax)', ""    ts.plot(kind='bar', figsize=(15,5))"", '    plt.show()']","[""    ts.plot(kind='bar', figsize=(15,5))""]",,
29533687,"import pandas as pd
import matplotlib.pyplot as plt
ys = [[0,1,2,3,4],[4,3,2,1,0]]
x_ax = [0,1,2,3,4]
fig, axs = plt.subplots(ncols=2, figsize=(10, 4))
for i, y_ax in enumerate(ys):
    pd.Series(y_ax, index=x_ax).plot(kind='bar', ax=axs[i])
    axs[i].set_title('Plot number {}'.format(i+1))","[""    pd.Series(y_ax, index=x_ax).plot(kind='bar', ax=axs[i])"", ""    axs[i].set_title('Plot number {}'.format(i+1))""]","['import pandas as pd', 'import matplotlib.pyplot as plt', 'ys = [[0,1,2,3,4],[4,3,2,1,0]]', 'x_ax = [0,1,2,3,4]', 'fig, axs = plt.subplots(ncols=2, figsize=(10, 4))', 'for i, y_ax in enumerate(ys):', ""    axs[i].set_title('Plot number {}'.format(i+1))""]","[""    pd.Series(y_ax, index=x_ax).plot(kind='bar', ax=axs[i])"", ""    axs[i].set_title('Plot number {}'.format(i+1))""]",,
29541211,df['Total'] = df.sum(axis=1),"[""df['Total'] = df.sum(axis=1)""]","[""df['Total'] = df.sum(axis=1)""]","[""df['Total'] = df.sum(axis=1)""]",,
29546836,"import numpy as np
def haversine_np(lon1, lat1, lon2, lat2):
    """"""
    Calculate the great circle distance between two points
    on the earth (specified in decimal degrees)
    All args must be of equal length.    
    """"""
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2
    c = 2 * np.arcsin(np.sqrt(a))
    km = 6367 * c
    return km
import numpy as np
import pandas
lon1, lon2, lat1, lat2 = np.random.randn(4, 1000000)
df = pandas.DataFrame(data={'lon1':lon1,'lon2':lon2,'lat1':lat1,'lat2':lat2})
km = haversine_np(df['lon1'],df['lat1'],df['lon2'],df['lat2'])","[""df = pandas.DataFrame(data={'lon1':lon1,'lon2':lon2,'lat1':lat1,'lat2':lat2})""]","['import numpy as np', 'def haversine_np(lon1, lat1, lon2, lat2):', '    """"""', '    Calculate the great circle distance between two points', '    on the earth (specified in decimal degrees)', '    All args must be of equal length.    ', '    """"""', '    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', '    dlon = lon2 - lon1', '    dlat = lat2 - lat1', '    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2', '    c = 2 * np.arcsin(np.sqrt(a))', '    km = 6367 * c', '    return km', 'import numpy as np', 'import pandas', 'lon1, lon2, lat1, lat2 = np.random.randn(4, 1000000)', ""km = haversine_np(df['lon1'],df['lat1'],df['lon2'],df['lat2'])""]",[],,
29548349,"import time
import ctypes
import numpy as np
from math import radians, cos, sin, asin, sqrt
def haversine(lon1, lat1, lon2, lat2):
    """"""
    Calculate the great circle distance between two points 
    on the earth (specified in decimal degrees)
    """"""
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1 
    dlat = lat2 - lat1 
    a = (np.sin(dlat/2)**2 
         + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2)
    c = 2 * np.arcsin(np.sqrt(a)) 
    km = 6367 * c
    return km
if __name__ == ""__main__"":
    lat1 = 50.0 * np.random.rand(1000000)
    lon1 = 50.0 * np.random.rand(1000000)
    lat2 = 50.0 * np.random.rand(1000000)
    lon2 = 50.0 * np.random.rand(1000000)
    t0 = time.time()
    r1 = haversine(lon1, lat1, lon2, lat2)
    t1 = time.time()
0
1964.322, 835.278, 
lib_path = ""/path/to/haversine.so"" 
haversine_lib = ctypes.CDLL(lib_path)
arr_1d_double = np.ctypeslib.ndpointer(dtype=np.double, 
                                       ndim=1, 
                                       flags='CONTIGUOUS')
haversine_lib.haversine.restype = ctypes.c_int
haversine_lib.haversine.argtypes = [ctypes.c_size_t,
                                    arr_1d_double, 
                                    arr_1d_double,
                                    arr_1d_double,
                                    arr_1d_double,
                                    arr_1d_double] 
size = len(lat1)
output = np.empty(size, dtype=np.double)
t2 = time.time()
res = haversine_lib.haversine(size, lon1, lat1, lon2, lat2, output)
t3 = time.time()
import time
import ctypes
import numpy as np
from math import radians, cos, sin, asin, sqrt
def haversine(lon1, lat1, lon2, lat2):
    """"""
    Calculate the great circle distance between two points 
    on the earth (specified in decimal degrees)
    """"""
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1 
    dlat = lat2 - lat1 
    a = (np.sin(dlat/2)**2 
         + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2)
    c = 2 * np.arcsin(np.sqrt(a)) 
    km = 6367 * c
    return km
if __name__ == ""__main__"":
    lat1 = 50.0 * np.random.rand(1000000)
    lon1 = 50.0 * np.random.rand(1000000)
    lat2 = 50.0 * np.random.rand(1000000)
    lon2 = 50.0 * np.random.rand(1000000)
    t0 = time.time()
    r1 = haversine(lon1, lat1, lon2, lat2)
    t1 = time.time()
    lib_path = ""/home/ely/programming/python/numpy_ctypes/haversine.so""
    haversine_lib = ctypes.CDLL(lib_path)
    arr_1d_double = np.ctypeslib.ndpointer(dtype=np.double, 
                                           ndim=1, 
                                           flags='CONTIGUOUS')
    haversine_lib.haversine.restype = ctypes.c_int
    haversine_lib.haversine.argtypes = [ctypes.c_size_t,
                                        arr_1d_double, 
                                        arr_1d_double,
                                        arr_1d_double,
                                        arr_1d_double,
                                        arr_1d_double]
    size = len(lat1)
    output = np.empty(size, dtype=np.double)
    t2 = time.time()
    res = haversine_lib.haversine(size, lon1, lat1, lon2, lat2, output)
    t3 = time.time()
from math import radians, cos, sin, asin, sqrt
def slow_haversine(lon1, lat1, lon2, lat2):
    n = len(lon1)
    kms = np.empty(n, dtype=np.double)
    for i in range(n):
       lon1_v, lat1_v, lon2_v, lat2_v = map(
           radians, 
           [lon1[i], lat1[i], lon2[i], lat2[i]]
       )
       dlon = lon2_v - lon1_v 
       dlat = lat2_v - lat1_v 
       a = (sin(dlat/2)**2 
            + cos(lat1_v) * cos(lat2_v) * sin(dlon/2)**2)
       c = 2 * asin(sqrt(a)) 
       kms[i] = 6367 * c
    return kms","['    t0 = time.time()', '    t1 = time.time()', 'output = np.empty(size, dtype=np.double)', 't2 = time.time()', 't3 = time.time()', '    t0 = time.time()', '    t1 = time.time()', '    output = np.empty(size, dtype=np.double)', '    t2 = time.time()', '    t3 = time.time()', '    kms = np.empty(n, dtype=np.double)']","['import time', 'import ctypes', 'import numpy as np', 'from math import radians, cos, sin, asin, sqrt', 'def haversine(lon1, lat1, lon2, lat2):', '    """"""', '    Calculate the great circle distance between two points ', '    on the earth (specified in decimal degrees)', '    """"""', '    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', '    dlon = lon2 - lon1 ', '    dlat = lat2 - lat1 ', '    a = (np.sin(dlat/2)**2 ', '         + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2)', '    c = 2 * np.arcsin(np.sqrt(a)) ', '    km = 6367 * c', '    return km', 'if __name__ == ""__main__"":', '    lat1 = 50.0 * np.random.rand(1000000)', '    lon1 = 50.0 * np.random.rand(1000000)', '    lat2 = 50.0 * np.random.rand(1000000)', '    lon2 = 50.0 * np.random.rand(1000000)', '    t0 = time.time()', '    r1 = haversine(lon1, lat1, lon2, lat2)', '    t1 = time.time()', '0', '1964.322, 835.278, ', 'lib_path = ""/path/to/haversine.so"" ', 'haversine_lib = ctypes.CDLL(lib_path)', 'arr_1d_double = np.ctypeslib.ndpointer(dtype=np.double, ', '                                       ndim=1, ', ""                                       flags='CONTIGUOUS')"", 'haversine_lib.haversine.restype = ctypes.c_int', 'haversine_lib.haversine.argtypes = [ctypes.c_size_t,', '                                    arr_1d_double, ', '                                    arr_1d_double,', '                                    arr_1d_double,', '                                    arr_1d_double,', '                                    arr_1d_double] ', 'size = len(lat1)', 'output = np.empty(size, dtype=np.double)', 't2 = time.time()', 'res = haversine_lib.haversine(size, lon1, lat1, lon2, lat2, output)', 't3 = time.time()', 'import time', 'import ctypes', 'import numpy as np', 'from math import radians, cos, sin, asin, sqrt', 'def haversine(lon1, lat1, lon2, lat2):', '    """"""', '    Calculate the great circle distance between two points ', '    on the earth (specified in decimal degrees)', '    """"""', '    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', '    dlon = lon2 - lon1 ', '    dlat = lat2 - lat1 ', '    a = (np.sin(dlat/2)**2 ', '         + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2)', '    c = 2 * np.arcsin(np.sqrt(a)) ', '    km = 6367 * c', '    return km', 'if __name__ == ""__main__"":', '    lat1 = 50.0 * np.random.rand(1000000)', '    lon1 = 50.0 * np.random.rand(1000000)', '    lat2 = 50.0 * np.random.rand(1000000)', '    lon2 = 50.0 * np.random.rand(1000000)', '    t0 = time.time()', '    r1 = haversine(lon1, lat1, lon2, lat2)', '    t1 = time.time()', '    lib_path = ""/home/ely/programming/python/numpy_ctypes/haversine.so""', '    haversine_lib = ctypes.CDLL(lib_path)', '    arr_1d_double = np.ctypeslib.ndpointer(dtype=np.double, ', '                                           ndim=1, ', ""                                           flags='CONTIGUOUS')"", '    haversine_lib.haversine.restype = ctypes.c_int', '    haversine_lib.haversine.argtypes = [ctypes.c_size_t,', '                                        arr_1d_double, ', '                                        arr_1d_double,', '                                        arr_1d_double,', '                                        arr_1d_double,', '                                        arr_1d_double]', '    size = len(lat1)', '    output = np.empty(size, dtype=np.double)', '    t2 = time.time()', '    res = haversine_lib.haversine(size, lon1, lat1, lon2, lat2, output)', '    t3 = time.time()', 'from math import radians, cos, sin, asin, sqrt', 'def slow_haversine(lon1, lat1, lon2, lat2):', '    n = len(lon1)', '    kms = np.empty(n, dtype=np.double)', '    for i in range(n):', '       lon1_v, lat1_v, lon2_v, lat2_v = map(', '           radians, ', '           [lon1[i], lat1[i], lon2[i], lat2[i]]', '       )', '       dlon = lon2_v - lon1_v ', '       dlat = lat2_v - lat1_v ', '       a = (sin(dlat/2)**2 ', '            + cos(lat1_v) * cos(lat2_v) * sin(dlon/2)**2)', '       c = 2 * asin(sqrt(a)) ', '       kms[i] = 6367 * c', '    return kms']","['    t0 = time.time()', '    t1 = time.time()', 'output = np.empty(size, dtype=np.double)', 't2 = time.time()', 't3 = time.time()', '    t0 = time.time()', '    t1 = time.time()', '    output = np.empty(size, dtype=np.double)', '    t2 = time.time()', '    t3 = time.time()', '    kms = np.empty(n, dtype=np.double)']",,
29550458,"df = pd.DataFrame({'a':[1,2], 'b':[(1,2), (3,4)]})
df
df['b'].apply(pd.Series)
df[['b1', 'b2']] = df['b'].apply(pd.Series)
df","[""df = pd.DataFrame({'a':[1,2], 'b':[(1,2), (3,4)]})"", ""df['b'].apply(pd.Series)"", ""df[['b1', 'b2']] = df['b'].apply(pd.Series)""]","['df', 'df']","[""df['b'].apply(pd.Series)"", ""df[['b1', 'b2']] = df['b'].apply(pd.Series)""]",,
29576803,"df = pd.read_csv(StringIO(s), sep=""\s+"")
df
df.iloc[np.random.permutation(len(df))]","['df = pd.read_csv(StringIO(s), sep=""\\s+"")', 'df.iloc[np.random.permutation(len(df))]']","['df = pd.read_csv(StringIO(s), sep=""\\s+"")', 'df', 'df.iloc[np.random.permutation(len(df))]']","['df = pd.read_csv(StringIO(s), sep=""\\s+"")', 'df.iloc[np.random.permutation(len(df))]']",,
29585283,"flights.groupby(['year', 'month', 'day'])","[""flights.groupby(['year', 'month', 'day'])""]","[""flights.groupby(['year', 'month', 'day'])""]","[""flights.groupby(['year', 'month', 'day'])""]",,
29651514,"def normalize(df):
    result = df.copy()
    for feature_name in df.columns:
        max_value = df[feature_name].max()
        min_value = df[feature_name].min()
        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
    return result","['    result = df.copy()', '        max_value = df[feature_name].max()', '        min_value = df[feature_name].min()']","['def normalize(df):', '    result = df.copy()', '    for feature_name in df.columns:', '        max_value = df[feature_name].max()', '        min_value = df[feature_name].min()', '        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)', '    return result']","['    result = df.copy()', '        max_value = df[feature_name].max()', '        min_value = df[feature_name].min()']",,
29657079,"import igraph
conn_indices = np.where(a_numpy)
weights = a_numpy[conn_indices]
edges = zip(*conn_indices)
G = igraph.Graph(edges=edges, directed=True)
respectively
G.vs['label'] = node_names
G.es['weight'] = weights
weights
G.es['width'] = weights
igraph.plot(G, layout=""rt"", labels=True, margin=80)","['conn_indices = np.where(a_numpy)', 'igraph.plot(G, layout=""rt"", labels=True, margin=80)']","['import igraph', 'conn_indices = np.where(a_numpy)', 'weights = a_numpy[conn_indices]', 'edges = zip(*conn_indices)', 'G = igraph.Graph(edges=edges, directed=True)', 'respectively', ""G.vs['label'] = node_names"", ""G.es['weight'] = weights"", 'weights', ""G.es['width'] = weights"", 'igraph.plot(G, layout=""rt"", labels=True, margin=80)']","['conn_indices = np.where(a_numpy)', 'igraph.plot(G, layout=""rt"", labels=True, margin=80)']",,
29665452,"from IPython.display import display, HTML
display(df1)
HTML(df2.to_html())",['HTML(df2.to_html())'],"['from IPython.display import display, HTML', 'display(df1)', 'HTML(df2.to_html())']",['HTML(df2.to_html())'],,
29673192,"import igraph
import pandas as pd
node_names = ['A', 'B', 'C']
a = pd.DataFrame([[1,2,3],[3,1,1],[4,0,2]], index=node_names, columns=node_names)
A = a.values
g = igraph.Graph.Adjacency((A > 0).tolist())
g.es['weight'] = A[A.nonzero()]
g.vs['label'] = node_names  
df_from_g = pd.DataFrame(g.get_adjacency(attribute='weight').data,
                         columns=g.vs['label'], index=g.vs['label'])
(df_from_g == a).all().all()  ","['a = pd.DataFrame([[1,2,3],[3,1,1],[4,0,2]], index=node_names, columns=node_names)', 'A = a.values', 'g = igraph.Graph.Adjacency((A > 0).tolist())', ""df_from_g = pd.DataFrame(g.get_adjacency(attribute='weight').data,"", '(df_from_g == a).all().all()  ']","['import igraph', 'import pandas as pd', ""node_names = ['A', 'B', 'C']"", 'A = a.values', 'g = igraph.Graph.Adjacency((A > 0).tolist())', ""g.es['weight'] = A[A.nonzero()]"", ""g.vs['label'] = node_names  "", ""                         columns=g.vs['label'], index=g.vs['label'])"", '(df_from_g == a).all().all()  ']","['A = a.values', 'g = igraph.Graph.Adjacency((A > 0).tolist())', '(df_from_g == a).all().all()  ']",,
29675706,"import matplotlib.pylab as plt
import pandas as pd
import numpy as np
import time
from IPython import display
i = pd.date_range('2013-1-1',periods=100,freq='s')
while True:
    try:
        plt.plot(pd.Series(data=np.random.randn(100), index=i))
        display.display(plt.gcf())
        display.clear_output(wait=True)
        time.sleep(1)
    except KeyboardInterrupt:
        break","[""i = pd.date_range('2013-1-1',periods=100,freq='s')"", '        plt.plot(pd.Series(data=np.random.randn(100), index=i))']","['import matplotlib.pylab as plt', 'import pandas as pd', 'import numpy as np', 'import time', 'from IPython import display', ""i = pd.date_range('2013-1-1',periods=100,freq='s')"", 'while True:', '    try:', '        display.display(plt.gcf())', '        display.clear_output(wait=True)', '        time.sleep(1)', '    except KeyboardInterrupt:', '        break']","[""i = pd.date_range('2013-1-1',periods=100,freq='s')"", '        plt.plot(pd.Series(data=np.random.randn(100), index=i))']",,
29737663,"df.plot(x='x', y='y', style=""."")","['df.plot(x=\'x\', y=\'y\', style=""."")']","['df.plot(x=\'x\', y=\'y\', style=""."")']","['df.plot(x=\'x\', y=\'y\', style=""."")']",,
29763653,"df.ix[:, df.columns != 'b']",[],"[""df.ix[:, df.columns != 'b']""]",[],[],[]
29765839,"df
del df.index.name
df",['del df.index.name'],"['df', 'del df.index.name', 'df']",['del df.index.name'],,
29766187,"df.index.name = None
df",['df.index.name = None'],"['df.index.name = None', 'df']",['df.index.name = None'],,
29774704,df.index.get_level_values('name_sub_index'),"[""df.index.get_level_values('name_sub_index')""]","[""df.index.get_level_values('name_sub_index')""]","[""df.index.get_level_values('name_sub_index')""]",,
29794993,"d = {112: 'en', 113: 'es', 114: 'es', 111: 'en'}
df['D'] = df['U'].map(d)
df","[""df['D'] = df['U'].map(d)""]","[""d = {112: 'en', 113: 'es', 114: 'es', 111: 'en'}"", ""df['D'] = df['U'].map(d)"", 'df']","[""df['D'] = df['U'].map(d)""]",,
29815523,"df
df.T.to_dict().values()",['df.T.to_dict().values()'],"['df', 'df.T.to_dict().values()']",['df.T.to_dict().values()'],,
29816143,df.to_dict('records'),"[""df.to_dict('records')""]","[""df.to_dict('records')""]","[""df.to_dict('records')""]",,
29836852,"df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])
df
df.groupby(""A"").filter(lambda x: len(x) > 1)","[""df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])"", 'df.groupby(""A"").filter(lambda x: len(x) > 1)']","['df', 'df.groupby(""A"").filter(lambda x: len(x) > 1)']","['df.groupby(""A"").filter(lambda x: len(x) > 1)']",,
29837754,"import pandas as pd
def sublst(row):
    return lst[row['J1']:row['J2']]
df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})
lst = ['a','b','c','d','e','f']
df['J3'] = df.apply(sublst,axis=1)
import pandas as pd
df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})
lst = ['a','b','c','d','e','f']
df['J3'] = df.apply(lambda row:lst[row['J1']:row['J2']],axis=1)","[""df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})"", ""df['J3'] = df.apply(sublst,axis=1)"", ""df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})"", ""df['J3'] = df.apply(lambda row:lst[row['J1']:row['J2']],axis=1)""]","['import pandas as pd', 'def sublst(row):', ""    return lst[row['J1']:row['J2']]"", ""lst = ['a','b','c','d','e','f']"", ""df['J3'] = df.apply(sublst,axis=1)"", 'import pandas as pd', ""lst = ['a','b','c','d','e','f']"", ""df['J3'] = df.apply(lambda row:lst[row['J1']:row['J2']],axis=1)""]","[""df['J3'] = df.apply(sublst,axis=1)"", ""df['J3'] = df.apply(lambda row:lst[row['J1']:row['J2']],axis=1)""]",,
29902819,"df
pd.options.display.max_colwidth
pd.options.display.max_colwidth = 100
df
df.iloc[2,0]    
Out[7]: 'This is very long string very long string very long string veryvery long string'","['df.iloc[2,0]    ']","['df', 'pd.options.display.max_colwidth', 'pd.options.display.max_colwidth = 100', 'df', 'df.iloc[2,0]    ', ""Out[7]: 'This is very long string very long string very long string veryvery long string'""]","['df.iloc[2,0]    ']",,
29910919,,[],[''],[],[],[]
29916004,df = df[['mean'] + df.columns[:-1].tolist()],"[""df = df[['mean'] + df.columns[:-1].tolist()]""]","[""df = df[['mean'] + df.columns[:-1].tolist()]""]","[""df = df[['mean'] + df.columns[:-1].tolist()]""]",,
29919489,"df.idxmax(axis=1)
dtype: object",['df.idxmax(axis=1)'],"['df.idxmax(axis=1)', 'dtype: object']",['df.idxmax(axis=1)'],,
29922207,"df
df = df[['mean', 4,3,2,1]]
df",[],"['df', ""df = df[['mean', 4,3,2,1]]"", 'df']",[],[],[]
29930255,"import numpy as np
import pandas as pd
import pandas.core.algorithms as algos
from pandas import Series
zs = np.zeros(300)
rs = np.random.randint(1, 100, size=300)
arr=np.concatenate((zs, rs))
ser = Series(arr)
bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))
result = pd.tools.tile._bins_to_cuts(ser, bins, include_lowest=True)
In[61]: result.value_counts()
dtype: int64
mx = np.ma.masked_equal(arr, 0, copy=True)
bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))
bins = np.insert(bins, 0, 0)
bins[1] = bins[1]-(bins[1]/2)
result = pd.tools.tile._bins_to_cuts(arr, bins, include_lowest=True)
In[133]: result.value_counts()
dtype: int64","['bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))', 'In[61]: result.value_counts()', 'bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))', 'bins = np.insert(bins, 0, 0)', 'In[133]: result.value_counts()']","['import numpy as np', 'import pandas as pd', 'import pandas.core.algorithms as algos', 'from pandas import Series', 'zs = np.zeros(300)', 'rs = np.random.randint(1, 100, size=300)', 'arr=np.concatenate((zs, rs))', 'ser = Series(arr)', 'bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))', 'result = pd.tools.tile._bins_to_cuts(ser, bins, include_lowest=True)', 'In[61]: result.value_counts()', 'dtype: int64', 'mx = np.ma.masked_equal(arr, 0, copy=True)', 'bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))', 'bins = np.insert(bins, 0, 0)', 'bins[1] = bins[1]-(bins[1]/2)', 'result = pd.tools.tile._bins_to_cuts(arr, bins, include_lowest=True)', 'In[133]: result.value_counts()', 'dtype: int64']","['bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))', 'In[61]: result.value_counts()', 'bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))', 'bins = np.insert(bins, 0, 0)', 'In[133]: result.value_counts()']",,
29955358,"s = pd.Series(np.arange(5))
s
s * 10
df = pd.DataFrame({'a':np.random.randn(4), 'b':np.random.randn(4)})
df
df * 10
df.iloc[0]
df + df.iloc[0]
df + pd.Series(np.arange(4))
df[['a']] + df.iloc[0]
df[['a']].values + df.iloc[0].values
array([[ 0.24414608, -1.05605392, -1.4091805 ],
       [ 0.13341899, -1.166781  , -1.51990758],
       [ 0.10235701, -1.19784299, -1.55096957],
       [ 0.33792013, -0.96227987, -1.31540645]])","['s = pd.Series(np.arange(5))', ""df = pd.DataFrame({'a':np.random.randn(4), 'b':np.random.randn(4)})"", 'df.iloc[0]', 'df + df.iloc[0]', 'df + pd.Series(np.arange(4))', ""df[['a']] + df.iloc[0]"", ""df[['a']].values + df.iloc[0].values""]","['s', 's * 10', 'df', 'df * 10', 'df.iloc[0]', 'df + df.iloc[0]', ""df[['a']] + df.iloc[0]"", ""df[['a']].values + df.iloc[0].values"", 'array([[ 0.24414608, -1.05605392, -1.4091805 ],', '       [ 0.13341899, -1.166781  , -1.51990758],', '       [ 0.10235701, -1.19784299, -1.55096957],', '       [ 0.33792013, -0.96227987, -1.31540645]])']","['df.iloc[0]', 'df + df.iloc[0]', ""df[['a']] + df.iloc[0]"", ""df[['a']].values + df.iloc[0].values""]",,
29956221,"import seaborn.apionly as sns
iris = sns.load_dataset('iris')
print(iris.head())
iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')","['print(iris.head())', ""iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')""]","['import seaborn.apionly as sns', ""iris = sns.load_dataset('iris')"", 'print(iris.head())', ""iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')""]","['print(iris.head())', ""iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')""]",,
29971188,"df1.count()
dtype: int64",['df1.count()'],"['df1.count()', 'dtype: int64']",['df1.count()'],,
29990874,"class MyModel(models.Model):
    full_name = models.CharField(max_length=25)
    age = models.IntegerField()
    department = models.CharField(max_length=3)
    wage = models.FloatField()
from django_pandas.io import read_frame
qs = MyModel.objects.all()
df = read_frame(qs)",['qs = MyModel.objects.all()'],"['class MyModel(models.Model):', '    full_name = models.CharField(max_length=25)', '    age = models.IntegerField()', '    department = models.CharField(max_length=3)', '    wage = models.FloatField()', 'from django_pandas.io import read_frame', 'qs = MyModel.objects.all()', 'df = read_frame(qs)']",['qs = MyModel.objects.all()'],,
29999590,,[],[''],[],[],[]
30010004,"df.reindex([""Z"", ""C"", ""A""])
df.sort_index(ascending=False)
df = df.sort_index(ascending=False)","['df.reindex([""Z"", ""C"", ""A""])', 'df.sort_index(ascending=False)', 'df = df.sort_index(ascending=False)']","['df.reindex([""Z"", ""C"", ""A""])', 'df.sort_index(ascending=False)', 'df = df.sort_index(ascending=False)']","['df.reindex([""Z"", ""C"", ""A""])', 'df.sort_index(ascending=False)', 'df = df.sort_index(ascending=False)']",,
30022658,,[],[''],[],[],[]
30025025,"data_array = data.values
for train_index, test_index in sss:
    xtrain, xtest = data_array[train_index], data_array[test_index]
    ytrain, ytest = target[train_index], target[test_index]
for train_index, test_index in sss:
    xtrain, xtest = data.iloc[train_index], data.iloc[test_index]
    ytrain, ytest = target[train_index], target[test_index]","['data_array = data.values', '    xtrain, xtest = data.iloc[train_index], data.iloc[test_index]']","['data_array = data.values', 'for train_index, test_index in sss:', '    xtrain, xtest = data_array[train_index], data_array[test_index]', '    ytrain, ytest = target[train_index], target[test_index]', 'for train_index, test_index in sss:', '    xtrain, xtest = data.iloc[train_index], data.iloc[test_index]', '    ytrain, ytest = target[train_index], target[test_index]']","['data_array = data.values', '    xtrain, xtest = data.iloc[train_index], data.iloc[test_index]']",,
30027273,"df
lambdafunc = lambda x: pd.Series([x['mytime'].hour,
                                           x['mydate'].isocalendar()[1],
                                           x['mydate'].weekday()])
df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)
df","[""lambdafunc = lambda x: pd.Series([x['mytime'].hour,"", ""                                           x['mydate'].isocalendar()[1],"", ""                                           x['mydate'].weekday()])"", ""df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)""]","['df', ""                                           x['mydate'].isocalendar()[1],"", ""                                           x['mydate'].weekday()])"", ""df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)"", 'df']","[""lambdafunc = lambda x: pd.Series([x['mytime'].hour,"", ""                                           x['mydate'].isocalendar()[1],"", ""                                           x['mydate'].weekday()])"", ""df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)""]",,
30053435,"df = pd.DataFrame(index=range(0,4),columns=['A'], dtype='float')
df.dtypes
dtype: object","[""df = pd.DataFrame(index=range(0,4),columns=['A'], dtype='float')"", 'df.dtypes']","['df.dtypes', 'dtype: object']",['df.dtypes'],,
30053507,,[],[''],[],[],[]
30059290,"df.isnull().sum(axis=1)
df.isnull().sum(axis=1).tolist()
Out[196]: [0, 0, 0, 3, 0, 0]","['df.isnull().sum(axis=1)', 'df.isnull().sum(axis=1).tolist()']","['df.isnull().sum(axis=1)', 'df.isnull().sum(axis=1).tolist()', 'Out[196]: [0, 0, 0, 3, 0, 0]']","['df.isnull().sum(axis=1)', 'df.isnull().sum(axis=1).tolist()']",,
30063996,"from scipy.stats import mode
from numpy import nan
df = DataFrame({""a"": [1,2,2,4,2], ""b"": [nan, nan, nan, 3, 3]})
(array([[ 2.,  3.]]), array([[ 3.,  2.]]))",[],"['from scipy.stats import mode', 'from numpy import nan', 'df = DataFrame({""a"": [1,2,2,4,2], ""b"": [nan, nan, nan, 3, 3]})', '(array([[ 2.,  3.]]), array([[ 3.,  2.]]))']",[],[],[]
30065040,"def most_informative_feature_for_class_svm(vectorizer, classifier,  classlabel, n=10):
    feature_names = vectorizer.get_feature_names()
    svm_coef = classifier.coef_.toarray() 
    topn = sorted(zip(svm_coef[labelid], feature_names))[-n:]",[],"['def most_informative_feature_for_class_svm(vectorizer, classifier,  classlabel, n=10):', '    feature_names = vectorizer.get_feature_names()', '    svm_coef = classifier.coef_.toarray() ', '    topn = sorted(zip(svm_coef[labelid], feature_names))[-n:]']",[],[],[]
30087487,"df.to_html(classes = 'my_class"" id = ""my_id')
'<table border=""1"" class=""dataframe my_class"" id = ""my_id"">...'","['df.to_html(classes = \'my_class"" id = ""my_id\')']","['df.to_html(classes = \'my_class"" id = ""my_id\')', '\'<table border=""1"" class=""dataframe my_class"" id = ""my_id"">...\'']","['df.to_html(classes = \'my_class"" id = ""my_id\')']",,
30111487,"mat = dataset.as_matrix()
km = sklearn.cluster.KMeans(n_clusters=5)
km.fit(mat)
labels = km.labels_
results = pandas.DataFrame([dataset.index,labels]).T","['mat = dataset.as_matrix()', 'results = pandas.DataFrame([dataset.index,labels]).T']","['mat = dataset.as_matrix()', 'km = sklearn.cluster.KMeans(n_clusters=5)', 'km.fit(mat)', 'labels = km.labels_']","['mat = dataset.as_matrix()', 'results = pandas.DataFrame([dataset.index,labels]).T']",,
30132313,"dates = pd.to_datetime(pd.Series(['20010101', '20010331']), format = '%Y%m%d')
dates.apply(lambda x: x.strftime('%Y-%m-%d'))
dtype: object
dates.dt.strftime('%Y-%m-%d')","[""dates = pd.to_datetime(pd.Series(['20010101', '20010331']), format = '%Y%m%d')"", ""dates.apply(lambda x: x.strftime('%Y-%m-%d'))"", ""dates.dt.strftime('%Y-%m-%d')""]","[""dates.apply(lambda x: x.strftime('%Y-%m-%d'))"", 'dtype: object', ""dates.dt.strftime('%Y-%m-%d')""]","[""dates = pd.to_datetime(pd.Series(['20010101', '20010331']), format = '%Y%m%d')"", ""dates.apply(lambda x: x.strftime('%Y-%m-%d'))"", ""dates.dt.strftime('%Y-%m-%d')""]",,
30135182,"ax.xaxis.set_major_formatter(formatter)
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import matplotlib.ticker as ticker
start = pd.to_datetime(""5-1-2012"")
idx = pd.date_range(start, periods= 365)
df = pd.DataFrame({'A':np.random.random(365), 'B':np.random.random(365)})
df.index = idx
df_ts = df.resample('W', how= 'max')
ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)
ticklabels = ['']*len(df_ts.index)
ticklabels[::4] = [item.strftime('%b %d') for item in df_ts.index[::4]]
ticklabels[::12] = [item.strftime('%b %d\n%Y') for item in df_ts.index[::12]]
ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))
plt.gcf().autofmt_xdate()
plt.show()","['start = pd.to_datetime(""5-1-2012"")', 'idx = pd.date_range(start, periods= 365)', ""df = pd.DataFrame({'A':np.random.random(365), 'B':np.random.random(365)})"", 'df.index = idx', ""df_ts = df.resample('W', how= 'max')"", ""ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)"", ""ticklabels = ['']*len(df_ts.index)"", ""ticklabels[::4] = [item.strftime('%b %d') for item in df_ts.index[::4]]"", ""ticklabels[::12] = [item.strftime('%b %d\\n%Y') for item in df_ts.index[::12]]""]","['ax.xaxis.set_major_formatter(formatter)', 'import numpy as np', 'import matplotlib.pyplot as plt', 'import pandas as pd', 'import matplotlib.ticker as ticker', 'start = pd.to_datetime(""5-1-2012"")', 'idx = pd.date_range(start, periods= 365)', 'df.index = idx', ""df_ts = df.resample('W', how= 'max')"", ""ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)"", ""ticklabels = ['']*len(df_ts.index)"", ""ticklabels[::4] = [item.strftime('%b %d') for item in df_ts.index[::4]]"", ""ticklabels[::12] = [item.strftime('%b %d\\n%Y') for item in df_ts.index[::12]]"", 'ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))', 'plt.gcf().autofmt_xdate()', 'plt.show()']","['start = pd.to_datetime(""5-1-2012"")', 'idx = pd.date_range(start, periods= 365)', 'df.index = idx', ""df_ts = df.resample('W', how= 'max')"", ""ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)"", ""ticklabels = ['']*len(df_ts.index)"", ""ticklabels[::4] = [item.strftime('%b %d') for item in df_ts.index[::4]]"", ""ticklabels[::12] = [item.strftime('%b %d\\n%Y') for item in df_ts.index[::12]]""]",,
30201213,"data = read_table('sample.txt', skiprows=3, header=None, delim_whitespace=True)",[],"[""data = read_table('sample.txt', skiprows=3, header=None, delim_whitespace=True)""]",[],[],[]
30208749,"d.loc[(d.day== 'sun') & (d.flavour== 'banana') & (d.year== 2009),'sales'] = 100","[""d.loc[(d.day== 'sun') & (d.flavour== 'banana') & (d.year== 2009),'sales'] = 100""]","[""d.loc[(d.day== 'sun') & (d.flavour== 'banana') & (d.year== 2009),'sales'] = 100""]","[""d.loc[(d.day== 'sun') & (d.flavour== 'banana') & (d.year== 2009),'sales'] = 100""]",,
30214901,"pd.qcut(factors, 5).value_counts()
pd.cut(factors, 5).value_counts()","['pd.qcut(factors, 5).value_counts()', 'pd.cut(factors, 5).value_counts()']","['pd.qcut(factors, 5).value_counts()', 'pd.cut(factors, 5).value_counts()']","['pd.qcut(factors, 5).value_counts()', 'pd.cut(factors, 5).value_counts()']",,
30222759,"import pandas as pd
df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})
df['my_dates'] = pd.to_datetime(df['my_dates'])
df['day_of_week'] = df['my_dates'].dt.weekday_name
import pandas as pd
df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})
df['my_dates'] = pd.to_datetime(df['my_dates'])
df['day_of_week'] = df['my_dates'].dt.dayofweek
days = {0:'Mon',1:'Tues',2:'Weds',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}
df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])","[""df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})"", ""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.weekday_name"", ""df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})"", ""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.dayofweek"", ""df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])""]","['import pandas as pd', ""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.weekday_name"", 'import pandas as pd', ""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.dayofweek"", ""days = {0:'Mon',1:'Tues',2:'Weds',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}"", ""df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])""]","[""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.weekday_name"", ""df['my_dates'] = pd.to_datetime(df['my_dates'])"", ""df['day_of_week'] = df['my_dates'].dt.dayofweek"", ""df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])""]",,
30267328,"import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
fruit_data = pd.DataFrame({
    'fruit':  ['apple','orange','pear','orange'],
    'color':  ['red','orange','green','green'],
    'weight': [5,6,3,4]
})
class MultiColumnLabelEncoder:
    def __init__(self,columns = None):
        self.columns = columns 
    def fit(self,X,y=None):
        return self 
    def transform(self,X):
        output = X.copy()
        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname,col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)
        return output
    def fit_transform(self,X,y=None):
        return self.fit(X,y).transform(X)
MultiColumnLabelEncoder(columns = ['fruit','color']).fit_transform(fruit_data)
MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))
encoding_pipeline = Pipeline([
    ('encoding',MultiColumnLabelEncoder(columns=['fruit','color']))
])
encoding_pipeline.fit_transform(fruit_data)","['fruit_data = pd.DataFrame({', '        output = X.copy()', '            for colname,col in output.iteritems():', '        return self.fit(X,y).transform(X)', ""MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))""]","['import pandas as pd', 'from sklearn.preprocessing import LabelEncoder', 'from sklearn.pipeline import Pipeline', ""    'fruit':  ['apple','orange','pear','orange'],"", ""    'color':  ['red','orange','green','green'],"", ""    'weight': [5,6,3,4]"", '})', 'class MultiColumnLabelEncoder:', '    def __init__(self,columns = None):', '        self.columns = columns ', '    def fit(self,X,y=None):', '        return self ', '    def transform(self,X):', '        output = X.copy()', '        if self.columns is not None:', '            for col in self.columns:', '                output[col] = LabelEncoder().fit_transform(output[col])', '        else:', '            for colname,col in output.iteritems():', '                output[colname] = LabelEncoder().fit_transform(col)', '        return output', '    def fit_transform(self,X,y=None):', '        return self.fit(X,y).transform(X)', ""MultiColumnLabelEncoder(columns = ['fruit','color']).fit_transform(fruit_data)"", ""MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))"", 'encoding_pipeline = Pipeline([', ""    ('encoding',MultiColumnLabelEncoder(columns=['fruit','color']))"", '])', 'encoding_pipeline.fit_transform(fruit_data)']","['        output = X.copy()', '            for colname,col in output.iteritems():', '        return self.fit(X,y).transform(X)', ""MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))""]",,
30292938,"def appendDFToCSV_void(df, csvFilePath, sep="",""):
    import os
    if not os.path.isfile(csvFilePath):
        df.to_csv(csvFilePath, mode='a', index=False, sep=sep)
    elif len(df.columns) != len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns):
        raise Exception(""Columns do not match!! Dataframe has "" + str(len(df.columns)) + "" columns. CSV file has "" + str(len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns)) + "" columns."")
    elif not (df.columns == pd.read_csv(csvFilePath, nrows=1, sep=sep).columns).all():
        raise Exception(""Columns and column order of dataframe and csv file do not match!!"")
    else:
        df.to_csv(csvFilePath, mode='a', index=False, sep=sep, header=False)","[""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep)"", '    elif len(df.columns) != len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns):', '        raise Exception(""Columns do not match!! Dataframe has "" + str(len(df.columns)) + "" columns. CSV file has "" + str(len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns)) + "" columns."")', '    elif not (df.columns == pd.read_csv(csvFilePath, nrows=1, sep=sep).columns).all():', ""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep, header=False)""]","['def appendDFToCSV_void(df, csvFilePath, sep="",""):', '    import os', '    if not os.path.isfile(csvFilePath):', ""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep)"", '    elif len(df.columns) != len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns):', '        raise Exception(""Columns do not match!! Dataframe has "" + str(len(df.columns)) + "" columns. CSV file has "" + str(len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns)) + "" columns."")', '    elif not (df.columns == pd.read_csv(csvFilePath, nrows=1, sep=sep).columns).all():', '        raise Exception(""Columns and column order of dataframe and csv file do not match!!"")', '    else:', ""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep, header=False)""]","[""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep)"", '    elif len(df.columns) != len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns):', '        raise Exception(""Columns do not match!! Dataframe has "" + str(len(df.columns)) + "" columns. CSV file has "" + str(len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns)) + "" columns."")', '    elif not (df.columns == pd.read_csv(csvFilePath, nrows=1, sep=sep).columns).all():', ""        df.to_csv(csvFilePath, mode='a', index=False, sep=sep, header=False)""]",,
30304735,"xcell.style = xcell.style.copy(**style_kwargs)
pass",['xcell.style = xcell.style.copy(**style_kwargs)'],"['xcell.style = xcell.style.copy(**style_kwargs)', 'pass']",['xcell.style = xcell.style.copy(**style_kwargs)'],,
30319249,"from __future__ import print_function
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import Imputer
X_train = [[0, 0, np.nan], [np.nan, 1, 1]]
Y_train = [0, 1]
X_test_1 = [0, 0, np.nan]
X_test_2 = [0, np.nan, np.nan]
X_test_3 = [np.nan, 1, 1]
imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
imp = imp.fit(X_train)
X_train_imp = imp.transform(X_train)
clf = RandomForestClassifier(n_estimators=10)
clf = clf.fit(X_train_imp, Y_train)
for X_test in [X_test_1, X_test_2, X_test_3]:
    X_test_imp = imp.transform(X_test)
    print(X_test, '->', clf.predict(X_test_imp))
Results","['X_train_imp = imp.transform(X_train)', '    X_test_imp = imp.transform(X_test)']","['from __future__ import print_function', 'import numpy as np', 'from sklearn.ensemble import RandomForestClassifier', 'from sklearn.preprocessing import Imputer', 'X_train = [[0, 0, np.nan], [np.nan, 1, 1]]', 'Y_train = [0, 1]', 'X_test_1 = [0, 0, np.nan]', 'X_test_2 = [0, np.nan, np.nan]', 'X_test_3 = [np.nan, 1, 1]', ""imp = Imputer(missing_values='NaN', strategy='mean', axis=0)"", 'imp = imp.fit(X_train)', 'X_train_imp = imp.transform(X_train)', 'clf = RandomForestClassifier(n_estimators=10)', 'clf = clf.fit(X_train_imp, Y_train)', 'for X_test in [X_test_1, X_test_2, X_test_3]:', '    X_test_imp = imp.transform(X_test)', ""    print(X_test, '->', clf.predict(X_test_imp))"", 'Results']","['X_train_imp = imp.transform(X_train)', '    X_test_imp = imp.transform(X_test)']",,
30327470,"import numpy as np
df1['randomNumCol'] = np.random.choice(range(1, 6), df1.shape[0])","[""df1['randomNumCol'] = np.random.choice(range(1, 6), df1.shape[0])""]","['import numpy as np', ""df1['randomNumCol'] = np.random.choice(range(1, 6), df1.shape[0])""]","[""df1['randomNumCol'] = np.random.choice(range(1, 6), df1.shape[0])""]",,
30328738,"(df.groupby(['cluster', 'org'], as_index=False).mean()
            .groupby('cluster')['time'].mean())
df.groupby(['cluster']).mean()
df.groupby(['cluster', 'org']).mean()","[""(df.groupby(['cluster', 'org'], as_index=False).mean()"", ""df.groupby(['cluster']).mean()"", ""df.groupby(['cluster', 'org']).mean()""]","[""(df.groupby(['cluster', 'org'], as_index=False).mean()"", ""            .groupby('cluster')['time'].mean())"", ""df.groupby(['cluster']).mean()"", ""df.groupby(['cluster', 'org']).mean()""]","[""(df.groupby(['cluster', 'org'], as_index=False).mean()"", ""df.groupby(['cluster']).mean()"", ""df.groupby(['cluster', 'org']).mean()""]",,
30355286,"df2 = pd.DataFrame(data=None, columns=df1.columns,index=df1.index)","['df2 = pd.DataFrame(data=None, columns=df1.columns,index=df1.index)']",[],"['df2 = pd.DataFrame(data=None, columns=df1.columns,index=df1.index)']",,
30357382,df['Cat1'].fillna(df['Cat2']),"[""df['Cat1'].fillna(df['Cat2'])""]","[""df['Cat1'].fillna(df['Cat2'])""]","[""df['Cat1'].fillna(df['Cat2'])""]",,
30370897,"import pandas as pd
import para_group_demo
df = pd.DataFrame({'a': [1, 2, 1, 2, 1, 1, 0], 'b': range(7)})
key     
from cython.parallel import prange
import pandas as pd
def sum(crit, vals):
    counts = counts_vec_t(num_threads)
    counts.resize(num_threads)
    with cython.boundscheck(False):
        for i in prange(num_threads, nogil=True): 
            j = i * s
            e = j + s
            if e > l:
                e = l
            while j < e:
                counts[i][crit_view[j]] += vals_view[j]
                inc(j)
    for i in range(num_threads):
        it = counts[i].begin()
        e_it = counts[i].end()
        while it != e_it:
            total[deref(it).first] += deref(it).second
            inc(it)        
    key, sum_ = [], []
    it = total.begin()
    e_it = total.end()
    while it != e_it:
        key.append(deref(it).first)
        sum_.append(deref(it).second)
        inc(it)
    df = pd.DataFrame({'key': key, 'sum': sum_})
    df.set_index('key', inplace=True)
    return df","[""df = pd.DataFrame({'a': [1, 2, 1, 2, 1, 1, 0], 'b': range(7)})"", '            total[deref(it).first] += deref(it).second', '        key.append(deref(it).first)', '        sum_.append(deref(it).second)', ""    df = pd.DataFrame({'key': key, 'sum': sum_})"", ""    df.set_index('key', inplace=True)""]","['import pandas as pd', 'import para_group_demo', 'key     ', 'from cython.parallel import prange', 'import pandas as pd', 'def sum(crit, vals):', '    counts = counts_vec_t(num_threads)', '    counts.resize(num_threads)', '    with cython.boundscheck(False):', '        for i in prange(num_threads, nogil=True): ', '            j = i * s', '            e = j + s', '            if e > l:', '                e = l', '            while j < e:', '                counts[i][crit_view[j]] += vals_view[j]', '                inc(j)', '    for i in range(num_threads):', '        it = counts[i].begin()', '        e_it = counts[i].end()', '        while it != e_it:', '            total[deref(it).first] += deref(it).second', '            inc(it)        ', '    key, sum_ = [], []', '    it = total.begin()', '    e_it = total.end()', '    while it != e_it:', '        key.append(deref(it).first)', '        sum_.append(deref(it).second)', '        inc(it)', ""    df.set_index('key', inplace=True)"", '    return df']","['            total[deref(it).first] += deref(it).second', '        key.append(deref(it).first)', '        sum_.append(deref(it).second)', ""    df.set_index('key', inplace=True)""]",,
30378303,,[],[''],[],[],[]
30380922,"old_names = ['$a', '$b', '$c', '$d', '$e'] 
new_names = ['a', 'b', 'c', 'd', 'e']
df.rename(columns=dict(zip(old_names, new_names)), inplace=True)","['df.rename(columns=dict(zip(old_names, new_names)), inplace=True)']","[""old_names = ['$a', '$b', '$c', '$d', '$e'] "", ""new_names = ['a', 'b', 'c', 'd', 'e']"", 'df.rename(columns=dict(zip(old_names, new_names)), inplace=True)']","['df.rename(columns=dict(zip(old_names, new_names)), inplace=True)']",,
30424537,"import numpy as np
import pandas as pd
np.random.seed(123)
df = pd.DataFrame({ 
    'a':np.random.randn(6),
    'b':np.random.choice( [5,7,np.nan], 6),
    'c':np.random.choice( ['panda','python','shark'], 6),
    'd':np.repeat( range(3), 2 ),
    'e':np.tile(   range(2), 3 ),
    'f':pd.date_range('1/1/2011', periods=6, freq='D'),
    'g':np.random.choice( pd.date_range('1/1/2011', periods=365, 
                          freq='D'), 6, replace=False) 
    })
stocks = pd.DataFrame({ 
    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),
    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),
    'price':(np.random.randn(100).cumsum() + 10) })
stocks.head(5)
stocks.groupby('ticker').head(2)","['df = pd.DataFrame({ ', ""    'd':np.repeat( range(3), 2 ),"", ""    'f':pd.date_range('1/1/2011', periods=6, freq='D'),"", ""    'g':np.random.choice( pd.date_range('1/1/2011', periods=365, "", 'stocks = pd.DataFrame({ ', ""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5)', ""stocks.groupby('ticker').head(2)""]","['import numpy as np', 'import pandas as pd', 'np.random.seed(123)', ""    'a':np.random.randn(6),"", ""    'b':np.random.choice( [5,7,np.nan], 6),"", ""    'c':np.random.choice( ['panda','python','shark'], 6),"", ""    'd':np.repeat( range(3), 2 ),"", ""    'e':np.tile(   range(2), 3 ),"", ""    'f':pd.date_range('1/1/2011', periods=6, freq='D'),"", ""    'g':np.random.choice( pd.date_range('1/1/2011', periods=365, "", ""                          freq='D'), 6, replace=False) "", '    })', ""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5)', ""stocks.groupby('ticker').head(2)""]","[""    'd':np.repeat( range(3), 2 ),"", ""    'f':pd.date_range('1/1/2011', periods=6, freq='D'),"", ""    'g':np.random.choice( pd.date_range('1/1/2011', periods=365, "", ""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5)', ""stocks.groupby('ticker').head(2)""]",,
30454743,"from sklearn.cross_validation import train_test_split
y = df.pop('output')
X = df
X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)
X.iloc[X_train] ","[""y = df.pop('output')"", 'X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)', 'X.iloc[X_train] ']","['from sklearn.cross_validation import train_test_split', ""y = df.pop('output')"", 'X = df', 'X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)', 'X.iloc[X_train] ']","[""y = df.pop('output')"", 'X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)', 'X.iloc[X_train] ']",,
30470630,,[],[''],[],[],[]
30511605,"list(my_dataframe)
['y', 'gdp', 'cap']
['y', 'gdp', 'cap']",[],"['list(my_dataframe)', ""['y', 'gdp', 'cap']"", ""['y', 'gdp', 'cap']""]",[],[],[]
30512931,"import pandas as pd
dfs = [df0, df1, df2, dfN]
df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","['import pandas as pd', 'dfs = [df0, df1, df2, dfN]', ""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]"
30514678,"df1.columns = [c.replace(' ', '_') for c in df1.columns]","[""df1.columns = [c.replace(' ', '_') for c in df1.columns]""]","[""df1.columns = [c.replace(' ', '_') for c in df1.columns]""]","[""df1.columns = [c.replace(' ', '_') for c in df1.columns]""]",,
30522778,"lst1 = range(100)
lst2 = range(100)
lst3 = range(100)
percentile_list = pd.DataFrame(
    {'lst1Tite': lst1,
     'lst2Tite': lst2,
     'lst3Tite': lst3
    })
percentile_list
...
percentile_list = pd.DataFrame(np.column_stack([lst1, lst2, lst3]), 
                               columns=['lst1tite', 'lst2itie', 'lst3tite'])","['percentile_list = pd.DataFrame(', 'percentile_list = pd.DataFrame(np.column_stack([lst1, lst2, lst3]), ']","['lst1 = range(100)', 'lst2 = range(100)', 'lst3 = range(100)', ""    {'lst1Tite': lst1,"", ""     'lst2Tite': lst2,"", ""     'lst3Tite': lst3"", '    })', 'percentile_list', '...', ""                               columns=['lst1tite', 'lst2itie', 'lst3tite'])""]",[],,
30523225,,[],[''],[],[],[]
30525128,,[],[''],[],[],[]
30531939,"df = pd.DataFrame({'a':[1,2,1,2], 'b':[3,4,3,5]})
df
df.drop_duplicates()","[""df = pd.DataFrame({'a':[1,2,1,2], 'b':[3,4,3,5]})"", 'df.drop_duplicates()']","['df', 'df.drop_duplicates()']",['df.drop_duplicates()'],,
30535957,"s1 = pd.merge(df1, df2, how='inner', on=['user_id'])","[""s1 = pd.merge(df1, df2, how='inner', on=['user_id'])""]","[""s1 = pd.merge(df1, df2, how='inner', on=['user_id'])""]","[""s1 = pd.merge(df1, df2, how='inner', on=['user_id'])""]",,
30546734,"df.columns = df.columns.str.replace('$','')","[""df.columns = df.columns.str.replace('$','')""]","[""df.columns = df.columns.str.replace('$','')""]","[""df.columns = df.columns.str.replace('$','')""]",,
30557040,"bigdata = pd.concat([data1, data2], ignore_index=True)","['bigdata = pd.concat([data1, data2], ignore_index=True)']","['bigdata = pd.concat([data1, data2], ignore_index=True)']","['bigdata = pd.concat([data1, data2], ignore_index=True)']",,
30566899,"def valuation_formula(x, y):
    return x * y * 0.5
df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)","[""df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)""]","['def valuation_formula(x, y):', '    return x * y * 0.5', ""df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)""]","[""df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)""]",,
30587837,"idx = pd.IndexSlice
df.loc[idx[:,mask_1],idx[mask_2,:]].fillna(value=0,inplace=True)
df.update(df.loc[idx[:,mask_1],idx[[mask_2],:]].fillna(value=0))","['df.loc[idx[:,mask_1],idx[mask_2,:]].fillna(value=0,inplace=True)', 'df.update(df.loc[idx[:,mask_1],idx[[mask_2],:]].fillna(value=0))']","['idx = pd.IndexSlice', 'df.loc[idx[:,mask_1],idx[mask_2,:]].fillna(value=0,inplace=True)', 'df.update(df.loc[idx[:,mask_1],idx[[mask_2],:]].fillna(value=0))']","['df.loc[idx[:,mask_1],idx[mask_2,:]].fillna(value=0,inplace=True)', 'df.update(df.loc[idx[:,mask_1],idx[[mask_2],:]].fillna(value=0))']",,
30590280,"df = pd.DataFrame({'d': [1, 2, 3]}, index=['FOO', 'BAR', 'BAZ'])
df
df.index = df.index.map(str.lower)
df
pd.Series(df.index.map(str.lower))
df.index.str.lower()","[""df = pd.DataFrame({'d': [1, 2, 3]}, index=['FOO', 'BAR', 'BAZ'])"", 'df.index = df.index.map(str.lower)', 'pd.Series(df.index.map(str.lower))', 'df.index.str.lower()']","['df', 'df.index = df.index.map(str.lower)', 'df', 'df.index.str.lower()']","['df.index = df.index.map(str.lower)', 'pd.Series(df.index.map(str.lower))', 'df.index.str.lower()']",,
30633167,"df.columns.name = 'foo'
df.index.name = 'foo'","[""df.index.name = 'foo'""]","[""df.columns.name = 'foo'"", ""df.index.name = 'foo'""]","[""df.index.name = 'foo'""]",,
30647987,"df.plot(subplots=True, layout=(1,2))","['df.plot(subplots=True, layout=(1,2))']","['df.plot(subplots=True, layout=(1,2))']","['df.plot(subplots=True, layout=(1,2))']",,
30652445,,[],[''],[],[],[]
30653988,"import pandas as pd
import mysql.connector
from sqlalchemy import create_engine
engine = create_engine('mysql+mysqlconnector://[user]:[pass]@[host]:[port]/[schema]', echo=False)
data.to_sql(name='sample_table2', con=engine, if_exists = 'append', index=False)","[""data.to_sql(name='sample_table2', con=engine, if_exists = 'append', index=False)""]","['import pandas as pd', 'import mysql.connector', 'from sqlalchemy import create_engine', ""engine = create_engine('mysql+mysqlconnector://[user]:[pass]@[host]:[port]/[schema]', echo=False)"", ""data.to_sql(name='sample_table2', con=engine, if_exists = 'append', index=False)""]","[""data.to_sql(name='sample_table2', con=engine, if_exists = 'append', index=False)""]",,
30691921,"with pd.option_context('display.max_rows', None, 'display.max_columns', 3):
    print(df)","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):"", '    print(df)']","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]"
30717361,,[],[''],[],[],[]
30733959,"import pandas
from   numpy import nan
import numpy
dataGrid = pandas.DataFrame({1: {1: 1, 3: 2},
                             2: {1: 3, 3: 4}})
def getExtrapolatedInterpolatedValue(x, y):
    global dataGrid
    if x not in dataGrid.index:
        dataGrid.ix[x] = nan
        dataGrid = dataGrid.sort()
        dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)
    if y not in dataGrid.columns.values:
        dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))
        dataGrid = dataGrid.sort_index(axis=1)
        dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)
    return dataGrid[y][x]","['dataGrid = pandas.DataFrame({1: {1: 1, 3: 2},', '    if x not in dataGrid.index:', ""        dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)"", '    if y not in dataGrid.columns.values:', '        dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))', '        dataGrid = dataGrid.sort_index(axis=1)', ""        dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)""]","['import pandas', 'from   numpy import nan', 'import numpy', '                             2: {1: 3, 3: 4}})', 'def getExtrapolatedInterpolatedValue(x, y):', '    global dataGrid', '    if x not in dataGrid.index:', '        dataGrid.ix[x] = nan', '        dataGrid = dataGrid.sort()', ""        dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)"", '    if y not in dataGrid.columns.values:', '        dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))', '        dataGrid = dataGrid.sort_index(axis=1)', ""        dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)"", '    return dataGrid[y][x]']","['    if x not in dataGrid.index:', ""        dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)"", '    if y not in dataGrid.columns.values:', '        dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))', '        dataGrid = dataGrid.sort_index(axis=1)', ""        dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)""]",,
30740087,"df_num = df.select_dtypes(include=[np.float])
df_num = df.select_dtypes(exclude=[np.number])","['df_num = df.select_dtypes(include=[np.float])', 'df_num = df.select_dtypes(exclude=[np.number])']","['df_num = df.select_dtypes(include=[np.float])', 'df_num = df.select_dtypes(exclude=[np.number])']","['df_num = df.select_dtypes(include=[np.float])', 'df_num = df.select_dtypes(exclude=[np.number])']",,
30777185,"df.insert(len(df.columns), 'e', pd.Series(np.random.randn(sLength),  index=df.index))","[""df.insert(len(df.columns), 'e', pd.Series(np.random.randn(sLength),  index=df.index))""]",[],"[""df.insert(len(df.columns), 'e', pd.Series(np.random.randn(sLength),  index=df.index))""]",,
30778300,"import numpy as np
import functools
def conjunction(*conditions):
    return functools.reduce(np.logical_and, conditions)
c_1 = data.col1 == True
c_2 = data.col2 < 64
c_3 = data.col3 != 4
data_filtered = data[conjunction(c1,c2,c3)]",[],"['import numpy as np', 'import functools', 'def conjunction(*conditions):', '    return functools.reduce(np.logical_and, conditions)', 'c_1 = data.col1 == True', 'c_2 = data.col2 < 64', 'c_3 = data.col3 != 4', 'data_filtered = data[conjunction(c1,c2,c3)]']",[],[],[]
30781664,"idx = pd.IndexSlice
df.loc[idx[:, :, 'C1', :],:]","[""df.loc[idx[:, :, 'C1', :],:]""]","['idx = pd.IndexSlice', ""df.loc[idx[:, :, 'C1', :],:]""]","[""df.loc[idx[:, :, 'C1', :],:]""]",,
30788360,df[df.Letters=='C'].Letters.item(),[],"[""df[df.Letters=='C'].Letters.item()""]",[],[],[]
30788555,"df.loc[df.Letters=='C','Letters'].values[0]
'C'
df.loc[df['Letters'] == 'C', 'Letters'].values[0]","[""df.loc[df.Letters=='C','Letters'].values[0]"", ""df.loc[df['Letters'] == 'C', 'Letters'].values[0]""]","[""df.loc[df.Letters=='C','Letters'].values[0]"", ""'C'"", ""df.loc[df['Letters'] == 'C', 'Letters'].values[0]""]","[""df.loc[df.Letters=='C','Letters'].values[0]"", ""df.loc[df['Letters'] == 'C', 'Letters'].values[0]""]",,
30808571,"import pandas as pd
df = pd.DataFrame(np.array([[2,4,4],[4,3,3],[5,9,1]]),columns=['d','t','didi'])
df.filter(regex=(""d.*""))","[""df = pd.DataFrame(np.array([[2,4,4],[4,3,3],[5,9,1]]),columns=['d','t','didi'])"", 'df.filter(regex=(""d.*""))']","['import pandas as pd', 'df.filter(regex=(""d.*""))']","['df.filter(regex=(""d.*""))']",,
30808690,"import pandas as pd
df = pd.DataFrame([[10, 14, 12, 44, 45, 78]], columns=['a', 'b', 'c', 'd1', 'd2', 'd3'])
df.select(lambda col: col.startswith('d'), axis=1)","[""df = pd.DataFrame([[10, 14, 12, 44, 45, 78]], columns=['a', 'b', 'c', 'd1', 'd2', 'd3'])"", ""df.select(lambda col: col.startswith('d'), axis=1)""]","['import pandas as pd', ""df.select(lambda col: col.startswith('d'), axis=1)""]","[""df.select(lambda col: col.startswith('d'), axis=1)""]",,
30858753,,[],[''],[],[],[]
30926717,"df = pd.DataFrame(columns=['A'])
df
pd.concat([df,pd.DataFrame(columns=list('BCD'))])
Columns: [A, B, C, D]
Index: []","[""df = pd.DataFrame(columns=['A'])"", ""pd.concat([df,pd.DataFrame(columns=list('BCD'))])""]","['df', 'Columns: [A, B, C, D]', 'Index: []']","[""pd.concat([df,pd.DataFrame(columns=list('BCD'))])""]",,
30943503,"df = pd.DataFrame(np.random.randint(10, size=(5,1)), columns=['A'])
df
df.reindex(columns=list('ABCD'))
df.reindex(columns=list('DCBA'))
df.reindex(columns=list('ABCD'), fill_value=0)","[""df = pd.DataFrame(np.random.randint(10, size=(5,1)), columns=['A'])"", ""df.reindex(columns=list('ABCD'))"", ""df.reindex(columns=list('DCBA'))"", ""df.reindex(columns=list('ABCD'), fill_value=0)""]","['df', ""df.reindex(columns=list('ABCD'))"", ""df.reindex(columns=list('DCBA'))"", ""df.reindex(columns=list('ABCD'), fill_value=0)""]","[""df.reindex(columns=list('ABCD'))"", ""df.reindex(columns=list('DCBA'))"", ""df.reindex(columns=list('ABCD'), fill_value=0)""]",,
30971633,,[],[''],[],[],[]
30991980,,[],[''],[],[],[]
31017785,"import pandas as pd
df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],
                  index=['foo','bar','baz','quux'],
                  columns=['cost'])
df = df.applymap(""${0:.2f}"".format)","['df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', 'df = df.applymap(""${0:.2f}"".format)']","['import pandas as pd', ""                  index=['foo','bar','baz','quux'],"", ""                  columns=['cost'])"", 'df = df.applymap(""${0:.2f}"".format)']","['df = df.applymap(""${0:.2f}"".format)']",,
31026736,,[],[''],[],[],[]
31029857,df['colour'].value_counts().plot(kind='bar'),"[""df['colour'].value_counts().plot(kind='bar')""]","[""df['colour'].value_counts().plot(kind='bar')""]","[""df['colour'].value_counts().plot(kind='bar')""]",,
31029861,df.groupby('colour').size().plot(kind='bar'),"[""df.groupby('colour').size().plot(kind='bar')""]","[""df.groupby('colour').size().plot(kind='bar')""]","[""df.groupby('colour').size().plot(kind='bar')""]",,
31033603,"from statsmodels.graphics.mosaicplot import mosaic
plt.rcParams['font.size'] = 16.0
mosaic(df, ['direction', 'colour']);",[],"['from statsmodels.graphics.mosaicplot import mosaic', ""plt.rcParams['font.size'] = 16.0"", ""mosaic(df, ['direction', 'colour']);""]",[],[],[]
31036962,"a=pd.DataFrame({""var1"":""a,b,c d,e,f"".split(),""var2"":[1,2]})
s = a.var1.str.split("","").apply(pd.Series, 1).stack()
s.index = s.index.droplevel(-1)
del a['var1']
a.join(s)","['a=pd.DataFrame({""var1"":""a,b,c d,e,f"".split(),""var2"":[1,2]})', 's = a.var1.str.split("","").apply(pd.Series, 1).stack()', 's.index = s.index.droplevel(-1)', 'a.join(s)']","['s.index = s.index.droplevel(-1)', ""del a['var1']"", 'a.join(s)']","['a=pd.DataFrame({""var1"":""a,b,c d,e,f"".split(),""var2"":[1,2]})', 's = a.var1.str.split("","").apply(pd.Series, 1).stack()', 's.index = s.index.droplevel(-1)', 'a.join(s)']",,
31037040,"mycolumns = ['A', 'B']
df = pd.DataFrame(columns=mycolumns)
rows = [[1,2],[3,4],[5,6]]
for row in rows:
    df.loc[len(df)] = row","['df = pd.DataFrame(columns=mycolumns)', '    df.loc[len(df)] = row']","[""mycolumns = ['A', 'B']"", 'rows = [[1,2],[3,4],[5,6]]', 'for row in rows:', '    df.loc[len(df)] = row']",['    df.loc[len(df)] = row'],,
31037360,"df
df[""weight""].mean()
Out[480]: 0.83982437500000007","['df[""weight""].mean()']","['df', 'df[""weight""].mean()', 'Out[480]: 0.83982437500000007']","['df[""weight""].mean()']",,
31061820,"writer = pd.ExcelWriter(excel_file, engine='openpyxl')",[],"[""writer = pd.ExcelWriter(excel_file, engine='openpyxl')""]",[],[],[]
31075478,df['si_name'] = R.index.get_level_values('si_name') ,"[""df['si_name'] = R.index.get_level_values('si_name') ""]","[""df['si_name'] = R.index.get_level_values('si_name') ""]","[""df['si_name'] = R.index.get_level_values('si_name') ""]",,
31076657,frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\test\test.txt')],"[""frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\\test\\test.txt')]""]","[""frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\\test\\test.txt')]""]","[""frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\\test\\test.txt')]""]",,
31097813,"series = pd.Series([1,2], index=['a','b'])
df = pd.DataFrame([series])
cols = ['a','b']
list_of_series = [pd.Series([1,2],index=cols), pd.Series([3,4],index=cols)]
df = pd.DataFrame(list_of_series, columns=cols)
list_of_series = [pd.Series([1,2],index=['a','b']), pd.Series([3,4],index=['a','c'])]
df = pd.concat(list_of_series, axis=1).transpose()","[""series = pd.Series([1,2], index=['a','b'])"", 'df = pd.DataFrame([series])', 'list_of_series = [pd.Series([1,2],index=cols), pd.Series([3,4],index=cols)]', 'df = pd.DataFrame(list_of_series, columns=cols)', ""list_of_series = [pd.Series([1,2],index=['a','b']), pd.Series([3,4],index=['a','c'])]"", 'df = pd.concat(list_of_series, axis=1).transpose()']","[""cols = ['a','b']"", 'df = pd.concat(list_of_series, axis=1).transpose()']","['df = pd.concat(list_of_series, axis=1).transpose()']",,
31105951,"from rpy2.robjects import pandas2ri
pandas2ri.activate()
robjects.globalenv['dataframe'] = dataframe
M = stats.lm('y~x', data=base.as_symbol('dataframe'))
print(base.summary(M).rx2('coefficients'))",[],"['from rpy2.robjects import pandas2ri', 'pandas2ri.activate()', ""robjects.globalenv['dataframe'] = dataframe"", ""M = stats.lm('y~x', data=base.as_symbol('dataframe'))"", ""print(base.summary(M).rx2('coefficients'))""]",[],[],[]
31173785,"df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]
import pandas as pd
import numpy as np
df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})","[""df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})""]","[""df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]"", 'import pandas as pd', 'import numpy as np']",[],,
31206596,"M = R.lm('y~x', data=df)
robjects.globalenv['dataframe'] = dataframe
M = stats.lm('y~x', data=base.as_symbol('dataframe'))
import pandas as pd
from rpy2 import robjects as ro
from rpy2.robjects import pandas2ri
pandas2ri.activate()
R = ro.r
df = pd.DataFrame({'x': [1,2,3,4,5], 
                   'y': [2,1,3,5,4]})
M = R.lm('y~x', data=df)
print(R.summary(M).rx2('coefficients'))","[""df = pd.DataFrame({'x': [1,2,3,4,5], ""]","[""M = R.lm('y~x', data=df)"", ""robjects.globalenv['dataframe'] = dataframe"", ""M = stats.lm('y~x', data=base.as_symbol('dataframe'))"", 'import pandas as pd', 'from rpy2 import robjects as ro', 'from rpy2.robjects import pandas2ri', 'pandas2ri.activate()', 'R = ro.r', ""                   'y': [2,1,3,5,4]})"", ""M = R.lm('y~x', data=df)"", ""print(R.summary(M).rx2('coefficients'))""]",[],,
31247247,"np.savetxt(r'c:\data\np.txt', df.values, fmt='%d')
df.to_csv(r'c:\data\pandas.txt', header=None, index=None, sep=' ', mode='a')","[""np.savetxt(r'c:\\data\\np.txt', df.values, fmt='%d')"", ""df.to_csv(r'c:\\data\\pandas.txt', header=None, index=None, sep=' ', mode='a')""]","[""np.savetxt(r'c:\\data\\np.txt', df.values, fmt='%d')"", ""df.to_csv(r'c:\\data\\pandas.txt', header=None, index=None, sep=' ', mode='a')""]","[""np.savetxt(r'c:\\data\\np.txt', df.values, fmt='%d')"", ""df.to_csv(r'c:\\data\\pandas.txt', header=None, index=None, sep=' ', mode='a')""]",,
31247279,,[],[''],[],[],[]
31257931,"import warnings
warnings.simplefilter(action = ""ignore"", category = RuntimeWarning)",[],"['import warnings', 'warnings.simplefilter(action = ""ignore"", category = RuntimeWarning)']",[],[],[]
31296878,"table[table.column_name == some_value]
table((table.column_name == some_value) | (table.column_name2 == some_value2))
table.query('column_name == some_value | column_name2 == some_value2')
import pandas as pd
d = {'foo':[100, 111, 222], 
     'bar':[333, 444, 555]}
df = pd.DataFrame(d)
df
df[df.foo == 222]
df[(df.foo == 222) | (df.bar == 444)]
df.query('foo == 222 | bar == 444')","[""table.query('column_name == some_value | column_name2 == some_value2')"", 'df = pd.DataFrame(d)', 'df[(df.foo == 222) | (df.bar == 444)]', ""df.query('foo == 222 | bar == 444')""]","['table[table.column_name == some_value]', 'table((table.column_name == some_value) | (table.column_name2 == some_value2))', ""table.query('column_name == some_value | column_name2 == some_value2')"", 'import pandas as pd', ""d = {'foo':[100, 111, 222], "", ""     'bar':[333, 444, 555]}"", 'df', 'df[df.foo == 222]', 'df[(df.foo == 222) | (df.bar == 444)]', ""df.query('foo == 222 | bar == 444')""]","[""table.query('column_name == some_value | column_name2 == some_value2')"", 'df[(df.foo == 222) | (df.bar == 444)]', ""df.query('foo == 222 | bar == 444')""]",,
31297540,"import matplotlib.pyplot as plt    
plt.hist(df['column_name'], log=True) ",[],"['import matplotlib.pyplot as plt    ', ""plt.hist(df['column_name'], log=True) ""]",[],[],[]
31331100,,[],[''],[],[],[]
31331449,"df.to_csv('path', header=True, index=False, encoding='utf-8')","[""df.to_csv('path', header=True, index=False, encoding='utf-8')""]","[""df.to_csv('path', header=True, index=False, encoding='utf-8')""]","[""df.to_csv('path', header=True, index=False, encoding='utf-8')""]",,
31351465,"tokenized=map(lambda msg, ft1, ft2: features([msg,ft1,ft2]), posts.message,posts.feature_1, posts.feature_2)
import scipy as sp
posts = pd.read_csv('post.csv')
vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))
y = posts[""score""].values.astype(np.float32) 
X = sp.sparse.hstack((vectorizer.fit_transform(posts.message),posts[['feature_1','feature_2']].values),format='csr')
X_columns=vectorizer.get_feature_names()+posts[['feature_1','feature_2']].columns.tolist()
posts
X_columns
[u'is',
 u'is more',
 u'is the',
 u'more',
 u'more random',
 u'more text',
 u'random',
 u'random text',
 u'text',
 u'the',
 u'the text',
 u'this',
 u'this is',
 'feature_1',
 'feature_2']
X.toarray()
array([[1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 4, 7],
       [1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 3, 2],
       [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 3, 2]])
from sklearn_pandas import DataFrameMapper
mapper = DataFrameMapper([
    (['feature_1', 'feature_2'], None),
    ('message',CountVectorizer(binary=True, ngram_range=(1, 2)))
])
X=mapper.fit_transform(posts)
X
array([[4, 7, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],
       [3, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1],
       [3, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]])
X_columns=mapper.features[0][0]+mapper.features[1][1].get_feature_names()
X_columns
['feature_1',
 'feature_2',
 u'is',
 u'is more',
 u'is the',
 u'more',
 u'more random',
 u'more text',
 u'random',
 u'random text',
 u'text',
 u'the',
 u'the text',
 u'this',
 u'this is']","[""posts = pd.read_csv('post.csv')"", 'y = posts[""score""].values.astype(np.float32) ', ""X = sp.sparse.hstack((vectorizer.fit_transform(posts.message),posts[['feature_1','feature_2']].values),format='csr')"", ""X_columns=vectorizer.get_feature_names()+posts[['feature_1','feature_2']].columns.tolist()""]","['tokenized=map(lambda msg, ft1, ft2: features([msg,ft1,ft2]), posts.message,posts.feature_1, posts.feature_2)', 'import scipy as sp', ""posts = pd.read_csv('post.csv')"", 'vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))', 'y = posts[""score""].values.astype(np.float32) ', ""X = sp.sparse.hstack((vectorizer.fit_transform(posts.message),posts[['feature_1','feature_2']].values),format='csr')"", ""X_columns=vectorizer.get_feature_names()+posts[['feature_1','feature_2']].columns.tolist()"", 'posts', 'X_columns', ""[u'is',"", "" u'is more',"", "" u'is the',"", "" u'more',"", "" u'more random',"", "" u'more text',"", "" u'random',"", "" u'random text',"", "" u'text',"", "" u'the',"", "" u'the text',"", "" u'this',"", "" u'this is',"", "" 'feature_1',"", "" 'feature_2']"", 'X.toarray()', 'array([[1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 4, 7],', '       [1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 3, 2],', '       [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 3, 2]])', 'from sklearn_pandas import DataFrameMapper', 'mapper = DataFrameMapper([', ""    (['feature_1', 'feature_2'], None),"", ""    ('message',CountVectorizer(binary=True, ngram_range=(1, 2)))"", '])', 'X=mapper.fit_transform(posts)', 'X', 'array([[4, 7, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],', '       [3, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1],', '       [3, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]])', 'X_columns=mapper.features[0][0]+mapper.features[1][1].get_feature_names()', 'X_columns', ""['feature_1',"", "" 'feature_2',"", "" u'is',"", "" u'is more',"", "" u'is the',"", "" u'more',"", "" u'more random',"", "" u'more text',"", "" u'random',"", "" u'random text',"", "" u'text',"", "" u'the',"", "" u'the text',"", "" u'this',"", "" u'this is']""]","[""posts = pd.read_csv('post.csv')"", 'y = posts[""score""].values.astype(np.float32) ', ""X = sp.sparse.hstack((vectorizer.fit_transform(posts.message),posts[['feature_1','feature_2']].values),format='csr')"", ""X_columns=vectorizer.get_feature_names()+posts[['feature_1','feature_2']].columns.tolist()""]",,
31357733,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(100,5))
ax = df.plot()
type(ax)  
manipulate
vals = ax.get_yticks()
ax.set_yticklabels(['{:3.2f}%'.format(x*100) for x in vals])","['df = pd.DataFrame(np.random.randn(100,5))', 'ax = df.plot()', ""ax.set_yticklabels(['{:3.2f}%'.format(x*100) for x in vals])""]","['import pandas as pd', 'import numpy as np', 'ax = df.plot()', 'type(ax)  ', 'manipulate', 'vals = ax.get_yticks()', ""ax.set_yticklabels(['{:3.2f}%'.format(x*100) for x in vals])""]","['ax = df.plot()', ""ax.set_yticklabels(['{:3.2f}%'.format(x*100) for x in vals])""]",,
31364094,"plt.figure(1)
plt.subplot(2,2,1)
df.A.plot() 
plt.subplot(2,2,2)
df.B.plot(ax=plt.gca())
plt.subplot(2,2,3)
df.C.plot(ax=plt.gca())","['df.A.plot() ', 'df.B.plot(ax=plt.gca())', 'df.C.plot(ax=plt.gca())']","['plt.figure(1)', 'plt.subplot(2,2,1)', 'df.A.plot() ', 'plt.subplot(2,2,2)', 'df.B.plot(ax=plt.gca())', 'plt.subplot(2,2,3)', 'df.C.plot(ax=plt.gca())']","['df.A.plot() ', 'df.B.plot(ax=plt.gca())', 'df.C.plot(ax=plt.gca())']",,
31364127,"df.map_partitions(func, columns=...)
df.mycolumn.map(func)
df.apply(func, axis=1)
df = dd.read_csv(...)
from dask.multiprocessing import get
df.map_partitions(func, columns=...).compute(get=get)
import numpy as np
import pandas as pd
s = pd.Series([10000]*120)
def slow_func(k):
    A = np.random.normal(size = k) 
    s = 0
    for a in A:
        if a > 0:
            s += 1
        else:
            s -= 1
    return s
import numba
fast_func = numba.jit(slow_func)","['df.mycolumn.map(func)', 'df.apply(func, axis=1)', 'df = dd.read_csv(...)', 's = pd.Series([10000]*120)']","['df.map_partitions(func, columns=...)', 'df.mycolumn.map(func)', 'df.apply(func, axis=1)', 'df = dd.read_csv(...)', 'from dask.multiprocessing import get', 'df.map_partitions(func, columns=...).compute(get=get)', 'import numpy as np', 'import pandas as pd', 'def slow_func(k):', '    A = np.random.normal(size = k) ', '    s = 0', '    for a in A:', '        if a > 0:', '            s += 1', '        else:', '            s -= 1', '    return s', 'import numba', 'fast_func = numba.jit(slow_func)']","['df.mycolumn.map(func)', 'df.apply(func, axis=1)', 'df = dd.read_csv(...)']",,
31384328,"def plot_corr(df,size=10):
    corr = df.corr()
    fig, ax = plt.subplots(figsize=(size, size))
    ax.matshow(corr)
    plt.xticks(range(len(corr.columns)), corr.columns);
    plt.yticks(range(len(corr.columns)), corr.columns);",['    corr = df.corr()'],"['def plot_corr(df,size=10):', '    corr = df.corr()', '    fig, ax = plt.subplots(figsize=(size, size))', '    ax.matshow(corr)', '    plt.xticks(range(len(corr.columns)), corr.columns);', '    plt.yticks(range(len(corr.columns)), corr.columns);']",['    corr = df.corr()'],,
31396042,"cols = df.columns.tolist()
cols
Out[13]: ['Net', 'Upper', 'Lower', 'Mid', 'Zsore']
cols.insert(0, cols.pop(cols.index('Mid')))
cols
Out[16]: ['Mid', 'Net', 'Upper', 'Lower', 'Zsore']
df = df.reindex(columns= cols)","['cols = df.columns.tolist()', ""cols.insert(0, cols.pop(cols.index('Mid')))"", 'df = df.reindex(columns= cols)']","['cols = df.columns.tolist()', 'cols', ""Out[13]: ['Net', 'Upper', 'Lower', 'Mid', 'Zsore']"", ""cols.insert(0, cols.pop(cols.index('Mid')))"", 'cols', ""Out[16]: ['Mid', 'Net', 'Upper', 'Lower', 'Zsore']"", 'df = df.reindex(columns= cols)']","['cols = df.columns.tolist()', ""cols.insert(0, cols.pop(cols.index('Mid')))"", 'df = df.reindex(columns= cols)']",,
31431997,"df.drop(df.columns[[0,1,3]], axis=1, inplace=True)
df.drop(df.columns[[0]], axis=1, inplace=True)
df.pop('column-name')
df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])","['df.drop(df.columns[[0,1,3]], axis=1, inplace=True)', 'df.drop(df.columns[[0]], axis=1, inplace=True)', ""df.pop('column-name')"", ""df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])""]","['df.drop(df.columns[[0,1,3]], axis=1, inplace=True)', 'df.drop(df.columns[[0]], axis=1, inplace=True)', ""df.pop('column-name')"", ""df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])""]","['df.drop(df.columns[[0,1,3]], axis=1, inplace=True)', 'df.drop(df.columns[[0]], axis=1, inplace=True)', ""df.pop('column-name')"", ""df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])""]",,
31458385,"import pandas as pd
with open('your.json', 'rb') as f:
    data = f.readlines()
data = map(lambda x: x.rstrip(), data)
data_json_str = ""["" + ','.join(data) + ""]""
data_df = pd.read_json(data_json_str)","['data = map(lambda x: x.rstrip(), data)', 'data_json_str = ""["" + \',\'.join(data) + ""]""', 'data_df = pd.read_json(data_json_str)']","['import pandas as pd', ""with open('your.json', 'rb') as f:"", '    data = f.readlines()', 'data = map(lambda x: x.rstrip(), data)', 'data_json_str = ""["" + \',\'.join(data) + ""]""', 'data_df = pd.read_json(data_json_str)']","['data = map(lambda x: x.rstrip(), data)', 'data_json_str = ""["" + \',\'.join(data) + ""]""', 'data_df = pd.read_json(data_json_str)']",,
31480994,,[],[''],[],[],[]
31502974,"df = pd.DataFrame(np.random.randn(100, 3), columns=list('ABC'))
df[df.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]
df[((df.B - df.B.mean()) / df.B.std()).abs() < 3]","[""df = pd.DataFrame(np.random.randn(100, 3), columns=list('ABC'))"", 'df[df.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]', 'df[((df.B - df.B.mean()) / df.B.std()).abs() < 3]']","['df[df.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]', 'df[((df.B - df.B.mean()) / df.B.std()).abs() < 3]']","['df[df.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]', 'df[((df.B - df.B.mean()) / df.B.std()).abs() < 3]']",,
31512025,"df.loc[df['First Season'] > 1990, 'First Season'] = 1
df
df['First Season'] = (df['First Season'] > 1990).astype(int)
df","[""df.loc[df['First Season'] > 1990, 'First Season'] = 1"", ""df['First Season'] = (df['First Season'] > 1990).astype(int)""]","[""df.loc[df['First Season'] > 1990, 'First Season'] = 1"", 'df', ""df['First Season'] = (df['First Season'] > 1990).astype(int)"", 'df']","[""df.loc[df['First Season'] > 1990, 'First Season'] = 1"", ""df['First Season'] = (df['First Season'] > 1990).astype(int)""]",,
31541600,"name, age, birthday
name, age, birthday
df = pd.DataFrame(pd.np.random.choice(['1.0', '0.6666667', '150000.1'],(100000, 10)))
resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
df = pd.DataFrame(pd.np.random.choice([1.0, 0.6666667, 150000.1],(100000, 10)))
resource.getrusage(resource.RUSAGE_SELF).ru_maxrss","[""df = pd.DataFrame(pd.np.random.choice(['1.0', '0.6666667', '150000.1'],(100000, 10)))"", 'df = pd.DataFrame(pd.np.random.choice([1.0, 0.6666667, 150000.1],(100000, 10)))']","['name, age, birthday', 'name, age, birthday', 'resource.getrusage(resource.RUSAGE_SELF).ru_maxrss', 'resource.getrusage(resource.RUSAGE_SELF).ru_maxrss']",[],,
31543407,,[],[''],[],[],[]
31549924,"import pandas as pd
import numpy as np
from bokeh.charts import TimeSeries
from bokeh.models import HoverTool
from bokeh.plotting import show
toy_df = pd.DataFrame(data=np.random.rand(5,3), columns = ('a', 'b' ,'c'), index = pd.DatetimeIndex(start='01-01-2015',periods=5, freq='d'))       
p = figure(width=1200, height=900, x_axis_type=""datetime"", tools=_tools_to_show)
ts_list_of_list = []
for i in range(0,len(toy_df.columns)):
    ts_list_of_list.append(toy_df.index.T)
vals_list_of_list = toy_df.values.T.tolist()
cols_to_use =  ['Black', 'Red', 'Lime']
p.multi_line(ts_list_of_list, vals_list_of_list, line_color=cols_to_use)
for (name, series) in toy_df.iteritems():
    name_for_display = np.tile(name, [len(toy_df.index),1])
    source = ColumnDataSource({'x': toy_df.index, 'y': series.values, 'series_name': name_for_display, 'Date': toy_df.index.format()})
    p.scatter('x', 'y', source = source, fill_alpha=0, line_alpha=0.3, line_color=""grey"")     
    hover = p.select(dict(type=HoverTool))
    hover.tooltips = [(""Series"", ""@series_name""), (""Date"", ""@Date""),  (""Value"", ""@y{0.00%}""),]
    hover.mode = 'mouse'
show(p)","[""toy_df = pd.DataFrame(data=np.random.rand(5,3), columns = ('a', 'b' ,'c'), index = pd.DatetimeIndex(start='01-01-2015',periods=5, freq='d'))       "", '    ts_list_of_list.append(toy_df.index.T)', 'vals_list_of_list = toy_df.values.T.tolist()', 'for (name, series) in toy_df.iteritems():', '    name_for_display = np.tile(name, [len(toy_df.index),1])', ""    source = ColumnDataSource({'x': toy_df.index, 'y': series.values, 'series_name': name_for_display, 'Date': toy_df.index.format()})"", '    hover = p.select(dict(type=HoverTool))', ""    hover.mode = 'mouse'""]","['import pandas as pd', 'import numpy as np', 'from bokeh.charts import TimeSeries', 'from bokeh.models import HoverTool', 'from bokeh.plotting import show', 'p = figure(width=1200, height=900, x_axis_type=""datetime"", tools=_tools_to_show)', 'ts_list_of_list = []', 'for i in range(0,len(toy_df.columns)):', '    ts_list_of_list.append(toy_df.index.T)', 'vals_list_of_list = toy_df.values.T.tolist()', ""cols_to_use =  ['Black', 'Red', 'Lime']"", 'p.multi_line(ts_list_of_list, vals_list_of_list, line_color=cols_to_use)', 'for (name, series) in toy_df.iteritems():', '    name_for_display = np.tile(name, [len(toy_df.index),1])', ""    source = ColumnDataSource({'x': toy_df.index, 'y': series.values, 'series_name': name_for_display, 'Date': toy_df.index.format()})"", '    p.scatter(\'x\', \'y\', source = source, fill_alpha=0, line_alpha=0.3, line_color=""grey"")     ', '    hover = p.select(dict(type=HoverTool))', '    hover.tooltips = [(""Series"", ""@series_name""), (""Date"", ""@Date""),  (""Value"", ""@y{0.00%}""),]', ""    hover.mode = 'mouse'"", 'show(p)']","['    ts_list_of_list.append(toy_df.index.T)', 'vals_list_of_list = toy_df.values.T.tolist()', 'for (name, series) in toy_df.iteritems():', '    name_for_display = np.tile(name, [len(toy_df.index),1])', ""    source = ColumnDataSource({'x': toy_df.index, 'y': series.values, 'series_name': name_for_display, 'Date': toy_df.index.format()})"", '    hover = p.select(dict(type=HoverTool))', ""    hover.mode = 'mouse'""]",,
31553791,df['ID'] = df['ID'].str.zfill(15),"[""df['ID'] = df['ID'].str.zfill(15)""]","[""df['ID'] = df['ID'].str.zfill(15)""]","[""df['ID'] = df['ID'].str.zfill(15)""]",,
31569866,"df.groupby(['Name','Type','ID']).count().reset_index()
df['Count'] = df.groupby(['Name'])['ID'].transform('count')
df.drop_duplicates()","[""df.groupby(['Name','Type','ID']).count().reset_index()"", ""df['Count'] = df.groupby(['Name'])['ID'].transform('count')"", 'df.drop_duplicates()']","[""df.groupby(['Name','Type','ID']).count().reset_index()"", ""df['Count'] = df.groupby(['Name'])['ID'].transform('count')"", 'df.drop_duplicates()']","[""df.groupby(['Name','Type','ID']).count().reset_index()"", ""df['Count'] = df.groupby(['Name'])['ID'].transform('count')"", 'df.drop_duplicates()']",,
31570270,,[],[''],[],[],[]
31573180,,[],[''],[],[],[]
31585881,"df['Age_fill'][(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1)] \
                                                          = median_ages[i,j]","[""df['Age_fill'][(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1)] \\""]","[""df['Age_fill'][(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1)] \\"", '                                                          = median_ages[i,j]']","[""df['Age_fill'][(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1)] \\""]",,
31593712,"s = pd.Series(np.nan, index=[49,48,47,46,45, 1, 2, 3, 4, 5])
s
s.iloc[:3] 
s.loc[:3] 
s.ix[:3] 
s.iloc[:6]
s.loc[:6]
KeyError: 6
s.ix[:6]
KeyError: 6
s2 = pd.Series(np.nan, index=['a','b','c','d','e', 1, 2, 3, 4, 5])
s2.index.is_mixed() 
True
s2.ix[:6] 
s2.ix[:'c'] 
df = pd.DataFrame(np.nan, 
                      index=list('abcde'),
                      columns=['x','y','z', 8, 9])
df
df.ix[:'c', :4]
df.iloc[:df.index.get_loc('c') + 1, :4]","['s = pd.Series(np.nan, index=[49,48,47,46,45, 1, 2, 3, 4, 5])', 's.iloc[:3] ', 's.loc[:3] ', 's.iloc[:6]', 's.loc[:6]', ""s2 = pd.Series(np.nan, index=['a','b','c','d','e', 1, 2, 3, 4, 5])"", 's2.index.is_mixed() ', 'df = pd.DataFrame(np.nan, ', ""df.iloc[:df.index.get_loc('c') + 1, :4]""]","['s', 's.iloc[:3] ', 's.loc[:3] ', 's.ix[:3] ', 's.iloc[:6]', 's.loc[:6]', 'KeyError: 6', 's.ix[:6]', 'KeyError: 6', 's2.index.is_mixed() ', 'True', 's2.ix[:6] ', ""s2.ix[:'c'] "", ""                      index=list('abcde'),"", ""                      columns=['x','y','z', 8, 9])"", 'df', ""df.ix[:'c', :4]"", ""df.iloc[:df.index.get_loc('c') + 1, :4]""]","['s.iloc[:3] ', 's.loc[:3] ', 's.iloc[:6]', 's.loc[:6]', 's2.index.is_mixed() ', ""df.iloc[:df.index.get_loc('c') + 1, :4]""]",,
31594055,"df.iloc[0]
df.iloc[-5:]
df.iloc[:, 2]    
df.iloc[:3, :3] 
df = pd.DataFrame(index=['a', 'b', 'c'], columns=['time', 'date', 'name'])
df.loc['a']     
df.loc['b':, 'date']   
df['time']    
df.ix[:2, 'time']    
df.loc[b, 'name'] = 'Mary', 'John'","['df.iloc[0]', 'df.iloc[-5:]', 'df.iloc[:, 2]    ', 'df.iloc[:3, :3] ', ""df = pd.DataFrame(index=['a', 'b', 'c'], columns=['time', 'date', 'name'])"", ""df.loc['a']     "", ""df.loc['b':, 'date']   "", ""df.loc[b, 'name'] = 'Mary', 'John'""]","['df.iloc[0]', 'df.iloc[-5:]', 'df.iloc[:, 2]    ', 'df.iloc[:3, :3] ', ""df.loc['a']     "", ""df.loc['b':, 'date']   "", ""df['time']    "", ""df.ix[:2, 'time']    "", ""df.loc[b, 'name'] = 'Mary', 'John'""]","['df.iloc[0]', 'df.iloc[-5:]', 'df.iloc[:, 2]    ', 'df.iloc[:3, :3] ', ""df.loc['a']     "", ""df.loc['b':, 'date']   "", ""df.loc[b, 'name'] = 'Mary', 'John'""]",,
31610890,"import pandas as pd
df = pd.read_clipboard()
df",['df = pd.read_clipboard()'],"['import pandas as pd', 'df = pd.read_clipboard()', 'df']",['df = pd.read_clipboard()'],,
31611678,,[],[''],[],[],[]
31617974,df = df[(df['closing_price'] >= 99) & (df['closing_price'] <= 101)],[],"[""df = df[(df['closing_price'] >= 99) & (df['closing_price'] <= 101)]""]",[],[],[]
31679396,"from scipy.sparse import csr_matrix
person_u = list(sort(frame.person.unique()))
thing_u = list(sort(frame.thing.unique()))
data = frame['count'].tolist()
row = frame.person.astype('category', categories=person_u).cat.codes
col = frame.thing.astype('category', categories=thing_u).cat.codes
sparse_matrix = csr_matrix((data, (row, col)), shape=(len(person_u), len(thing_u)))
sparse_matrix 
sparse_matrix.todense()
matrix([[0, 1, 0, 1],
        [1, 0, 0, 1],
        [1, 0, 1, 0]])
dfs=pd.SparseDataFrame([ pd.SparseSeries(sparse_matrix[i].toarray().ravel(), fill_value=0) 
                              for i in np.arange(sparse_matrix.shape[0]) ], index=person_u, columns=thing_u, default_fill_value=0)
dfs
type(dfs)
pandas.sparse.frame.SparseDataFrame","['person_u = list(sort(frame.person.unique()))', 'thing_u = list(sort(frame.thing.unique()))', ""data = frame['count'].tolist()"", ""row = frame.person.astype('category', categories=person_u).cat.codes"", ""col = frame.thing.astype('category', categories=thing_u).cat.codes"", '                              for i in np.arange(sparse_matrix.shape[0]) ], index=person_u, columns=thing_u, default_fill_value=0)']","['from scipy.sparse import csr_matrix', 'person_u = list(sort(frame.person.unique()))', 'thing_u = list(sort(frame.thing.unique()))', ""data = frame['count'].tolist()"", ""row = frame.person.astype('category', categories=person_u).cat.codes"", ""col = frame.thing.astype('category', categories=thing_u).cat.codes"", 'sparse_matrix = csr_matrix((data, (row, col)), shape=(len(person_u), len(thing_u)))', 'sparse_matrix ', 'sparse_matrix.todense()', 'matrix([[0, 1, 0, 1],', '        [1, 0, 0, 1],', '        [1, 0, 1, 0]])', 'dfs=pd.SparseDataFrame([ pd.SparseSeries(sparse_matrix[i].toarray().ravel(), fill_value=0) ', '                              for i in np.arange(sparse_matrix.shape[0]) ], index=person_u, columns=thing_u, default_fill_value=0)', 'dfs', 'type(dfs)', 'pandas.sparse.frame.SparseDataFrame']","['person_u = list(sort(frame.person.unique()))', 'thing_u = list(sort(frame.thing.unique()))', ""data = frame['count'].tolist()"", ""row = frame.person.astype('category', categories=person_u).cat.codes"", ""col = frame.thing.astype('category', categories=thing_u).cat.codes"", '                              for i in np.arange(sparse_matrix.shape[0]) ], index=person_u, columns=thing_u, default_fill_value=0)']",,
31839240,"df = pd.DataFrame()
df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)","['df = pd.DataFrame()', ""df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)""]","[""df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)""]","[""df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)""]",,
31859215,"df = pd.DataFrame({'A':['a', 'b', 'c'], 'B':[54, 67, 89]}, index=[100, 200, 300])
df
df.loc[100]
df.iloc[0]
df2 = df.set_index([df.index,'A'])
df2
df2.ix[100, 'a']","[""df = pd.DataFrame({'A':['a', 'b', 'c'], 'B':[54, 67, 89]}, index=[100, 200, 300])"", 'df.loc[100]', 'df.iloc[0]', ""df2 = df.set_index([df.index,'A'])""]","['df', 'df.loc[100]', 'df.iloc[0]', ""df2 = df.set_index([df.index,'A'])"", 'df2', ""df2.ix[100, 'a']""]","['df.loc[100]', 'df.iloc[0]', ""df2 = df.set_index([df.index,'A'])""]",,
31885295,"from tabulate import tabulate
import pandas as pd
df = pd.DataFrame({'col_two' : [0.0001, 1e-005 , 1e-006, 1e-007],
                   'column_3' : ['ABCD', 'ABCD', 'long string', 'ABCD']})","[""df = pd.DataFrame({'col_two' : [0.0001, 1e-005 , 1e-006, 1e-007],""]","['from tabulate import tabulate', 'import pandas as pd', ""                   'column_3' : ['ABCD', 'ABCD', 'long string', 'ABCD']})""]",[],,
31907749,"pd.date_range('2011-01-05', '2011-01-09', freq=BDay())
pd.bdate_range('2011-01-05', '2011-01-09')
Out[7]: DatetimeIndex(['2011-01-05', '2011-01-06', '2011-01-07'], dtype='datetime64[ns]', freq='B', tz=None)","[""pd.date_range('2011-01-05', '2011-01-09', freq=BDay())"", ""pd.bdate_range('2011-01-05', '2011-01-09')""]","[""pd.date_range('2011-01-05', '2011-01-09', freq=BDay())"", ""pd.bdate_range('2011-01-05', '2011-01-09')"", ""Out[7]: DatetimeIndex(['2011-01-05', '2011-01-06', '2011-01-07'], dtype='datetime64[ns]', freq='B', tz=None)""]","[""pd.date_range('2011-01-05', '2011-01-09', freq=BDay())"", ""pd.bdate_range('2011-01-05', '2011-01-09')""]",,
31931208,,[],[''],[],[],[]
31939145,"df.apply(LabelEncoder().fit_transform)
from collections import defaultdict
d = defaultdict(LabelEncoder)
fit = df.apply(lambda x: d[x.name].fit_transform(x))
fit.apply(lambda x: d[x.name].inverse_transform(x))
df.apply(lambda x: d[x.name].transform(x))","['df.apply(LabelEncoder().fit_transform)', 'fit = df.apply(lambda x: d[x.name].fit_transform(x))', 'fit.apply(lambda x: d[x.name].inverse_transform(x))', 'df.apply(lambda x: d[x.name].transform(x))']","['df.apply(LabelEncoder().fit_transform)', 'from collections import defaultdict', 'd = defaultdict(LabelEncoder)', 'fit = df.apply(lambda x: d[x.name].fit_transform(x))', 'fit.apply(lambda x: d[x.name].inverse_transform(x))', 'df.apply(lambda x: d[x.name].transform(x))']","['df.apply(LabelEncoder().fit_transform)', 'fit = df.apply(lambda x: d[x.name].fit_transform(x))', 'fit.apply(lambda x: d[x.name].inverse_transform(x))', 'df.apply(lambda x: d[x.name].transform(x))']",,
31971245,"import pandas as pd
import numpy as np
ser = pd.Series(np.random.normal(size=100))
ser = ser.sort_values()
ser[len(ser)] = ser.iloc[-1]
cum_dist = np.linspace(0.,1.,len(ser))
ser_cdf = pd.Series(cum_dist, index=ser)
ser_cdf.plot(drawstyle='steps')","['ser = pd.Series(np.random.normal(size=100))', 'ser = ser.sort_values()', 'ser[len(ser)] = ser.iloc[-1]', 'ser_cdf = pd.Series(cum_dist, index=ser)', ""ser_cdf.plot(drawstyle='steps')""]","['import pandas as pd', 'import numpy as np', 'ser = ser.sort_values()', 'ser[len(ser)] = ser.iloc[-1]', 'cum_dist = np.linspace(0.,1.,len(ser))', ""ser_cdf.plot(drawstyle='steps')""]","['ser = ser.sort_values()', 'ser[len(ser)] = ser.iloc[-1]', ""ser_cdf.plot(drawstyle='steps')""]",,
32000194,"dataf = (DataFrame(mtcars).
         filter('gear>3').
         mutate(powertoweight='hp*36/wt').
         group_by('gear').
         summarize(mean_ptw='mean(powertoweight)'))
(DataFrame(flights).
 group_by('year', 'month', 'day').
 select('arr_delay', 'dep_delay').
 summarize(arr = 'mean(arr_delay, na.rm=TRUE)',
           dep = 'mean(dep_delay, na.rm=TRUE)').
 filter('arr > 30 | dep > 30'))","['dataf = (DataFrame(mtcars).', '(DataFrame(flights).']","['dataf = (DataFrame(mtcars).', ""         filter('gear>3')."", ""         mutate(powertoweight='hp*36/wt')."", ""         group_by('gear')."", ""         summarize(mean_ptw='mean(powertoweight)'))"", '(DataFrame(flights).', "" group_by('year', 'month', 'day')."", "" select('arr_delay', 'dep_delay')."", "" summarize(arr = 'mean(arr_delay, na.rm=TRUE)',"", ""           dep = 'mean(dep_delay, na.rm=TRUE)')."", "" filter('arr > 30 | dep > 30'))""]","['dataf = (DataFrame(mtcars).', '(DataFrame(flights).']",,
32011969,"df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':list('abcab'),  'col3':list('ababb')})
df['col2'] = df['col2'].astype('category')
df['col3'] = df['col3'].astype('category')
df.dtypes
cat_columns = df.select_dtypes(['category']).columns
cat_columns
df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)
df","[""df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':list('abcab'),  'col3':list('ababb')})"", ""df['col2'] = df['col2'].astype('category')"", ""df['col3'] = df['col3'].astype('category')"", 'df.dtypes', ""cat_columns = df.select_dtypes(['category']).columns"", 'df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)']","[""df['col2'] = df['col2'].astype('category')"", ""df['col3'] = df['col3'].astype('category')"", 'df.dtypes', ""cat_columns = df.select_dtypes(['category']).columns"", 'cat_columns', 'df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)', 'df']","[""df['col2'] = df['col2'].astype('category')"", ""df['col3'] = df['col3'].astype('category')"", 'df.dtypes', ""cat_columns = df.select_dtypes(['category']).columns"", 'df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)']",,
32012129,"grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])
grouper['Event'].count()
grouper['Event'].count().unstack()
grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])
result = grouper['Event'].count().unstack('Location').fillna(0)","[""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""grouper['Event'].count()"", ""grouper['Event'].count().unstack()"", ""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""result = grouper['Event'].count().unstack('Location').fillna(0)""]","[""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""grouper['Event'].count()"", ""grouper['Event'].count().unstack()"", ""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""result = grouper['Event'].count().unstack('Location').fillna(0)""]","[""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""grouper['Event'].count()"", ""grouper['Event'].count().unstack()"", ""grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])"", ""result = grouper['Event'].count().unstack('Location').fillna(0)""]",,
32066997,"grp = data.groupby(by=[data.datetime_col.map(lambda x : (x.hour, x.minute))])
grp.count()
grp = data.groupby(by=[data.datetime_col.map(lambda x : x.hour),
                       data.datetime_col.map(lambda x : x.minute)])","['grp = data.groupby(by=[data.datetime_col.map(lambda x : (x.hour, x.minute))])', 'grp.count()', 'grp = data.groupby(by=[data.datetime_col.map(lambda x : x.hour),', '                       data.datetime_col.map(lambda x : x.minute)])']","['grp = data.groupby(by=[data.datetime_col.map(lambda x : (x.hour, x.minute))])', 'grp.count()', 'grp = data.groupby(by=[data.datetime_col.map(lambda x : x.hour),', '                       data.datetime_col.map(lambda x : x.minute)])']","['grp = data.groupby(by=[data.datetime_col.map(lambda x : (x.hour, x.minute))])', 'grp.count()', 'grp = data.groupby(by=[data.datetime_col.map(lambda x : x.hour),', '                       data.datetime_col.map(lambda x : x.minute)])']",,
32094352,"c_maxes = df.groupby(['A', 'B']).C.transform(max)
df = df[df.C == c_maxes]
df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)","[""c_maxes = df.groupby(['A', 'B']).C.transform(max)"", ""df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)""]","[""c_maxes = df.groupby(['A', 'B']).C.transform(max)"", 'df = df[df.C == c_maxes]', ""df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)""]","[""c_maxes = df.groupby(['A', 'B']).C.transform(max)"", ""df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)""]",,
32103253,"df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])
df['bar'] = 100
df['bar'].iloc[0] = 99
df.loc[df.index[0], 'foo']
df.loc[df.index[0], 'bar'] = 99
df","[""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])"", ""df['bar'].iloc[0] = 99"", ""df.loc[df.index[0], 'foo']"", ""df.loc[df.index[0], 'bar'] = 99""]","[""df['bar'] = 100"", ""df['bar'].iloc[0] = 99"", ""df.loc[df.index[0], 'foo']"", ""df.loc[df.index[0], 'bar'] = 99"", 'df']","[""df['bar'].iloc[0] = 99"", ""df.loc[df.index[0], 'foo']"", ""df.loc[df.index[0], 'bar'] = 99""]",,
32103678,"total_rows=len(df.axes[0])
total_cols=len(df.axes[1])","['total_rows=len(df.axes[0])', 'total_cols=len(df.axes[1])']","['total_rows=len(df.axes[0])', 'total_cols=len(df.axes[1])']","['total_rows=len(df.axes[0])', 'total_cols=len(df.axes[1])']",,
32107505,"from datetime import datetime
import pandas as pd
pd.core.format.header_style = None  
dt = datetime.now()
d = datetime.date(datetime.now())
df1 = pd.DataFrame([{'c1': 'alpha', 'c2': 1}, {'c1': 'beta', 'c2': 2}])
df2 = pd.DataFrame([{'c1': dt, 'c2': d}, {'c1': dt, 'c2': d}])
with pd.ExcelWriter('output.xlsx') as writer:
    writer.date_format = None 
    writer.datetime_format = None  
    df1.to_excel(writer,'Sheet1')
    df2.to_excel(writer,'Sheet2')","['pd.core.format.header_style = None  ', 'dt = datetime.now()', 'd = datetime.date(datetime.now())', ""df1 = pd.DataFrame([{'c1': 'alpha', 'c2': 1}, {'c1': 'beta', 'c2': 2}])"", ""df2 = pd.DataFrame([{'c1': dt, 'c2': d}, {'c1': dt, 'c2': d}])"", ""    df1.to_excel(writer,'Sheet1')"", ""    df2.to_excel(writer,'Sheet2')""]","['from datetime import datetime', 'import pandas as pd', 'pd.core.format.header_style = None  ', 'dt = datetime.now()', 'd = datetime.date(datetime.now())', ""with pd.ExcelWriter('output.xlsx') as writer:"", '    writer.date_format = None ', '    writer.datetime_format = None  ', ""    df1.to_excel(writer,'Sheet1')"", ""    df2.to_excel(writer,'Sheet2')""]","['pd.core.format.header_style = None  ', 'dt = datetime.now()', 'd = datetime.date(datetime.now())', ""    df1.to_excel(writer,'Sheet1')"", ""    df2.to_excel(writer,'Sheet2')""]",,
32131398,"cols = ['mean']  + [col for col in df if col != 'mean']
df = df[cols]
cols = [df.columns[-1]] + [col for col in df if col != df.columns[-1]]
df = df[cols]
inserted_cols = ['a', 'b', 'c']",[],"[""cols = ['mean']  + [col for col in df if col != 'mean']"", 'df = df[cols]', 'cols = [df.columns[-1]] + [col for col in df if col != df.columns[-1]]', 'df = df[cols]', ""inserted_cols = ['a', 'b', 'c']""]",[],[],[]
32152755,"exclude = ['bad col1', 'bad col2']
df.ix[:, df.columns.difference(exclude)].hist() ","['df.ix[:, df.columns.difference(exclude)].hist() ']","[""exclude = ['bad col1', 'bad col2']"", 'df.ix[:, df.columns.difference(exclude)].hist() ']","['df.ix[:, df.columns.difference(exclude)].hist() ']",,
32244161,"import matplotlib
matplotlib.style.use('ggplot')
import matplotlib.pyplot as plt
import pandas as pd
df = pd.DataFrame({ 'celltype':[""foo"",""bar"",""qux"",""woz""], 's1':[5,9,1,7], 's2':[12,90,13,87]})
df = df[[""celltype"",""s1"",""s2""]]
df.set_index([""celltype""],inplace=True)
df.plot(kind='bar',alpha=0.75, rot=0)
plt.xlabel("""")
plt.show()","[""matplotlib.style.use('ggplot')"", 'df = pd.DataFrame({ \'celltype\':[""foo"",""bar"",""qux"",""woz""], \'s1\':[5,9,1,7], \'s2\':[12,90,13,87]})', 'df.set_index([""celltype""],inplace=True)', ""df.plot(kind='bar',alpha=0.75, rot=0)""]","['import matplotlib', ""matplotlib.style.use('ggplot')"", 'import matplotlib.pyplot as plt', 'import pandas as pd', 'df = df[[""celltype"",""s1"",""s2""]]', 'df.set_index([""celltype""],inplace=True)', ""df.plot(kind='bar',alpha=0.75, rot=0)"", 'plt.xlabel("""")', 'plt.show()']","[""matplotlib.style.use('ggplot')"", 'df.set_index([""celltype""],inplace=True)', ""df.plot(kind='bar',alpha=0.75, rot=0)""]",,
32245025,"sns_plot.savefig(""output.png"")
fig = sns_plot.fig",[],"['sns_plot.savefig(""output.png"")', 'fig = sns_plot.fig']",[],[],[]
32245026,"df = sns.load_dataset('iris')
sns_plot = sns.pairplot(df, hue='species', size=2.5)
sns_plot.savefig(""output.png"")",[],"[""df = sns.load_dataset('iris')"", ""sns_plot = sns.pairplot(df, hue='species', size=2.5)"", 'sns_plot.savefig(""output.png"")']",[],[],[]
32307259,"import pandas as pd
df1 = pd.DataFrame({""Name"":[""Alice"", ""Bob"", ""Mallory"", ""Mallory"", ""Bob"" , ""Mallory""],
                    ""City"":[""Seattle"",""Seattle"",""Portland"",""Seattle"",""Seattle"",""Portland""]})
g1 = df1.groupby([""Name"", ""City""], as_index=False).count()","['df1 = pd.DataFrame({""Name"":[""Alice"", ""Bob"", ""Mallory"", ""Mallory"", ""Bob"" , ""Mallory""],', 'g1 = df1.groupby([""Name"", ""City""], as_index=False).count()']","['import pandas as pd', '                    ""City"":[""Seattle"",""Seattle"",""Portland"",""Seattle"",""Seattle"",""Portland""]})', 'g1 = df1.groupby([""Name"", ""City""], as_index=False).count()']","['g1 = df1.groupby([""Name"", ""City""], as_index=False).count()']",,
32322596,"columns = df.columns
columns = [row.replace(""$"","""") for row in columns]
df.rename(columns=dict(zip(columns, things)), inplace=True)
df.head() 
import pandas as pd
import cProfile, pstats, re
old_names = ['$a', '$b', '$c', '$d', '$e']
new_names = ['a', 'b', 'c', 'd', 'e']
col_dict = {'$a': 'a', '$b': 'b','$c':'c','$d':'d','$e':'e'}
df = pd.DataFrame({'$a':[1,2], '$b': [10,20],'$c':['bleep','blorp'],'$d':[1,2],'$e':['texa$','']})
df.head()
def eumiro(df,nn):
    df.columns = nn
    return df
def lexual1(df):
    return df.rename(columns=col_dict)
def lexual2(df,col_dict):
    return df.rename(columns=col_dict, inplace=True)
def Panda_Master_Hayden(df):
    return df.rename(columns=lambda x: x[1:], inplace=True)
def paulo1(df):
    return df.rename(columns=lambda x: x.replace('$', ''))
def paulo2(df):
    return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)
def migloo(df,on,nn):
    return df.rename(columns=dict(zip(on, nn)), inplace=True)
def kadee(df):
    return df.columns.str.replace('$','')
def awo(df):
    columns = df.columns
    columns = [row.replace(""$"","""") for row in columns]
    return df.rename(columns=dict(zip(columns, '')), inplace=True)
def kaitlyn(df):
    df.columns = [col.strip('$') for col in df.columns]
    return df
cProfile.run('eumiro(df,new_names)')
cProfile.run('lexual1(df)')
cProfile.run('lexual2(df,col_dict)')
cProfile.run('Panda_Master_Hayden(df)')
cProfile.run('paulo1(df)')
cProfile.run('paulo2(df)')
cProfile.run('migloo(df,old_names,new_names)')
cProfile.run('kadee(df)')
cProfile.run('awo(df)')
cProfile.run('kaitlyn(df)')","['columns = [row.replace(""$"","""") for row in columns]', 'df.rename(columns=dict(zip(columns, things)), inplace=True)', 'df.head() ', ""df = pd.DataFrame({'$a':[1,2], '$b': [10,20],'$c':['bleep','blorp'],'$d':[1,2],'$e':['texa$','']})"", 'df.head()', '    return df.rename(columns=col_dict)', '    return df.rename(columns=col_dict, inplace=True)', '    return df.rename(columns=lambda x: x[1:], inplace=True)', ""    return df.rename(columns=lambda x: x.replace('$', ''))"", ""    return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)"", '    return df.rename(columns=dict(zip(on, nn)), inplace=True)', ""    return df.columns.str.replace('$','')"", '    columns = [row.replace(""$"","""") for row in columns]', ""    return df.rename(columns=dict(zip(columns, '')), inplace=True)"", ""    df.columns = [col.strip('$') for col in df.columns]""]","['columns = df.columns', 'columns = [row.replace(""$"","""") for row in columns]', 'df.rename(columns=dict(zip(columns, things)), inplace=True)', 'df.head() ', 'import pandas as pd', 'import cProfile, pstats, re', ""old_names = ['$a', '$b', '$c', '$d', '$e']"", ""new_names = ['a', 'b', 'c', 'd', 'e']"", ""col_dict = {'$a': 'a', '$b': 'b','$c':'c','$d':'d','$e':'e'}"", 'df.head()', 'def eumiro(df,nn):', '    df.columns = nn', '    return df', 'def lexual1(df):', '    return df.rename(columns=col_dict)', 'def lexual2(df,col_dict):', '    return df.rename(columns=col_dict, inplace=True)', 'def Panda_Master_Hayden(df):', '    return df.rename(columns=lambda x: x[1:], inplace=True)', 'def paulo1(df):', ""    return df.rename(columns=lambda x: x.replace('$', ''))"", 'def paulo2(df):', ""    return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)"", 'def migloo(df,on,nn):', '    return df.rename(columns=dict(zip(on, nn)), inplace=True)', 'def kadee(df):', ""    return df.columns.str.replace('$','')"", 'def awo(df):', '    columns = df.columns', '    columns = [row.replace(""$"","""") for row in columns]', ""    return df.rename(columns=dict(zip(columns, '')), inplace=True)"", 'def kaitlyn(df):', ""    df.columns = [col.strip('$') for col in df.columns]"", '    return df', ""cProfile.run('eumiro(df,new_names)')"", ""cProfile.run('lexual1(df)')"", ""cProfile.run('lexual2(df,col_dict)')"", ""cProfile.run('Panda_Master_Hayden(df)')"", ""cProfile.run('paulo1(df)')"", ""cProfile.run('paulo2(df)')"", ""cProfile.run('migloo(df,old_names,new_names)')"", ""cProfile.run('kadee(df)')"", ""cProfile.run('awo(df)')"", ""cProfile.run('kaitlyn(df)')""]","['columns = [row.replace(""$"","""") for row in columns]', 'df.rename(columns=dict(zip(columns, things)), inplace=True)', 'df.head() ', 'df.head()', '    return df.rename(columns=col_dict)', '    return df.rename(columns=col_dict, inplace=True)', '    return df.rename(columns=lambda x: x[1:], inplace=True)', ""    return df.rename(columns=lambda x: x.replace('$', ''))"", ""    return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)"", '    return df.rename(columns=dict(zip(on, nn)), inplace=True)', ""    return df.columns.str.replace('$','')"", '    columns = [row.replace(""$"","""") for row in columns]', ""    return df.rename(columns=dict(zip(columns, '')), inplace=True)"", ""    df.columns = [col.strip('$') for col in df.columns]""]",,
32344037,"In[7]: pandas.DataFrame.from_dict({u'2012-06-08': 388,
 u'2012-06-09': 388,
 u'2012-06-10': 388,
 u'2012-06-11': 389,
 u'2012-06-12': 389,
 u'2012-06-13': 389,
 u'2012-06-14': 389,
 u'2012-06-15': 389,
 u'2012-06-16': 389,
 u'2012-06-17': 389,
 u'2012-06-18': 390,
 u'2012-06-19': 390,
 u'2012-06-20': 390,
 u'2012-06-21': 390,
 u'2012-06-22': 390,
 u'2012-06-23': 390,
 u'2012-06-24': 390,
 u'2012-06-25': 391,
 u'2012-06-26': 391,
 u'2012-06-27': 391,
 u'2012-06-28': 391,
 u'2012-06-29': 391,
 u'2012-06-30': 391,
 u'2012-07-01': 391,
 u'2012-07-02': 392,
 u'2012-07-03': 392,
 u'2012-07-04': 392,
 u'2012-07-05': 392,
 u'2012-07-06': 392}, orient='index')","[""In[7]: pandas.DataFrame.from_dict({u'2012-06-08': 388,""]","["" u'2012-06-09': 388,"", "" u'2012-06-10': 388,"", "" u'2012-06-11': 389,"", "" u'2012-06-12': 389,"", "" u'2012-06-13': 389,"", "" u'2012-06-14': 389,"", "" u'2012-06-15': 389,"", "" u'2012-06-16': 389,"", "" u'2012-06-17': 389,"", "" u'2012-06-18': 390,"", "" u'2012-06-19': 390,"", "" u'2012-06-20': 390,"", "" u'2012-06-21': 390,"", "" u'2012-06-22': 390,"", "" u'2012-06-23': 390,"", "" u'2012-06-24': 390,"", "" u'2012-06-25': 391,"", "" u'2012-06-26': 391,"", "" u'2012-06-27': 391,"", "" u'2012-06-28': 391,"", "" u'2012-06-29': 391,"", "" u'2012-06-30': 391,"", "" u'2012-07-01': 391,"", "" u'2012-07-02': 392,"", "" u'2012-07-03': 392,"", "" u'2012-07-04': 392,"", "" u'2012-07-05': 392,"", "" u'2012-07-06': 392}, orient='index')""]","[""In[7]: pandas.DataFrame.from_dict({u'2012-06-08': 388,""]",,
32366268,"times = pd.DatetimeIndex(data.datetime_col)
grouped = df.groupby([times.hour, times.minute])","['grouped = df.groupby([times.hour, times.minute])']","['times = pd.DatetimeIndex(data.datetime_col)', 'grouped = df.groupby([times.hour, times.minute])']","['grouped = df.groupby([times.hour, times.minute])']",,
32397818,"df.groupby('id')['value'].nlargest(2)
id   
dtype: int64","[""df.groupby('id')['value'].nlargest(2)""]","[""df.groupby('id')['value'].nlargest(2)"", 'id   ', 'dtype: int64']","[""df.groupby('id')['value'].nlargest(2)""]",,
32399908,,[],[''],[],[],[]
32400969,"import pandas as pd
import io
import requests
url=""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv""
s=requests.get(url).content
c=pd.read_csv(io.StringIO(s.decode('utf-8')))","['s=requests.get(url).content', ""c=pd.read_csv(io.StringIO(s.decode('utf-8')))""]","['import pandas as pd', 'import io', 'import requests', 'url=""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv""', 's=requests.get(url).content', ""c=pd.read_csv(io.StringIO(s.decode('utf-8')))""]","['s=requests.get(url).content', ""c=pd.read_csv(io.StringIO(s.decode('utf-8')))""]",,
32401251,"c = pd.read_csv(""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv"")
print(c)","['c = pd.read_csv(""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv"")']","['c = pd.read_csv(""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv"")', 'print(c)']","['c = pd.read_csv(""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv"")']",,
32444187,"import pandas as pd
df = pd.concat(list_of_dataframes)",['df = pd.concat(list_of_dataframes)'],"['import pandas as pd', 'df = pd.concat(list_of_dataframes)']",['df = pd.concat(list_of_dataframes)'],,
32469151,"import numpy as np
df = pd.DataFrame({'listcol':[[1,2,3],[4,5,6]]})
X = pd.concat([pd.DataFrame(v, index=np.repeat(k,len(v))) 
            for k,v in df.listcol.to_dict().items()])    ","[""df = pd.DataFrame({'listcol':[[1,2,3],[4,5,6]]})"", 'X = pd.concat([pd.DataFrame(v, index=np.repeat(k,len(v))) ', '            for k,v in df.listcol.to_dict().items()])    ']","['import numpy as np', '            for k,v in df.listcol.to_dict().items()])    ']","['X = pd.concat([pd.DataFrame(v, index=np.repeat(k,len(v))) ', '            for k,v in df.listcol.to_dict().items()])    ']",,
32470490,"df = (pd.DataFrame({'name': ['A.J. Price'] * 3, 
                    'opponent': ['76ers', 'blazers', 'bobcats'], 
                    'nearest_neighbors': [['Zach LaVine', 'Jeremy Lin', 'Nate Robinson', 'Isaia']] * 3})
      .set_index(['name', 'opponent']))
df
df.reset_index(inplace=True)
rows = []
_ = df.apply(lambda row: [rows.append([row['name'], row['opponent'], nn]) 
                         for nn in row.nearest_neighbors], axis=1)
df_new = pd.DataFrame(rows, columns=df.columns).set_index(['name', 'opponent'])
df_new","[""df = (pd.DataFrame({'name': ['A.J. Price'] * 3, "", 'df.reset_index(inplace=True)', ""_ = df.apply(lambda row: [rows.append([row['name'], row['opponent'], nn]) "", ""df_new = pd.DataFrame(rows, columns=df.columns).set_index(['name', 'opponent'])""]","[""                    'opponent': ['76ers', 'blazers', 'bobcats'], "", ""                    'nearest_neighbors': [['Zach LaVine', 'Jeremy Lin', 'Nate Robinson', 'Isaia']] * 3})"", ""      .set_index(['name', 'opponent']))"", 'df', 'df.reset_index(inplace=True)', 'rows = []', ""_ = df.apply(lambda row: [rows.append([row['name'], row['opponent'], nn]) "", '                         for nn in row.nearest_neighbors], axis=1)', 'df_new']","[""df = (pd.DataFrame({'name': ['A.J. Price'] * 3, "", 'df.reset_index(inplace=True)', ""_ = df.apply(lambda row: [rows.append([row['name'], row['opponent'], nn]) "", ""df_new = pd.DataFrame(rows, columns=df.columns).set_index(['name', 'opponent'])""]",,
32489918,,[],[''],[],[],[]
32529152,"df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})
df['period'] = df[['Year', 'quarter']].apply(lambda x: ''.join(x), axis=1)","[""df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})"", ""df['period'] = df[['Year', 'quarter']].apply(lambda x: ''.join(x), axis=1)""]","[""df['period'] = df[['Year', 'quarter']].apply(lambda x: ''.join(x), axis=1)""]","[""df['period'] = df[['Year', 'quarter']].apply(lambda x: ''.join(x), axis=1)""]",,
32536193,"stocks = pd.DataFrame({ 
    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),
    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),
    'price':(np.random.randn(100).cumsum() + 10) })
stocks.head(5).to_dict()
{'date': {0: Timestamp('2011-01-01 00:00:00'),
  1: Timestamp('2011-01-01 00:00:00'),
  2: Timestamp('2011-01-01 00:00:00'),
  3: Timestamp('2011-01-01 00:00:00'),
  4: Timestamp('2011-01-02 00:00:00')},
 'price': {0: 10.284260107718254,
  1: 11.930300761831457,
  2: 10.93741046217319,
  3: 10.884574289565609,
  4: 11.78005850418319},
 'ticker': {0: 'aapl', 1: 'aapl', 2: 'aapl', 3: 'aapl', 4: 'aapl'}}
pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()
{'date': {0: Timestamp('2011-01-01 00:00:00'),
  1: Timestamp('2011-01-01 00:00:00'),
  2: Timestamp('2011-01-01 00:00:00'),
  3: Timestamp('2011-01-01 00:00:00'),
  4: Timestamp('2011-01-02 00:00:00'),
  5: Timestamp('2011-01-24 00:00:00'),
  6: Timestamp('2011-01-25 00:00:00'),
  7: Timestamp('2011-01-25 00:00:00'),
  8: Timestamp('2011-01-25 00:00:00'),
  9: Timestamp('2011-01-25 00:00:00')},
 'price': {0: 10.284260107718254,
  1: 11.930300761831457,
  2: 10.93741046217319,
  3: 10.884574289565609,
  4: 11.78005850418319,
  5: 10.017209045035006,
  6: 10.57090128181566,
  7: 11.442792747870204,
  8: 11.592953372130493,
  9: 12.864146419530938},
 'ticker': {0: 'aapl',
  1: 'aapl',
  2: 'aapl',
  3: 'aapl',
  4: 'aapl',
  5: 'msft',
  6: 'msft',
  7: 'msft',
  8: 'msft',
  9: 'msft'}}
stocks.info()
df = stocks.set_index(['date', 'ticker'])
df
...
d = df.reset_index().to_dict()
df_new = pd.DataFrame(d).set_index(['date', 'ticker'])
df_new.head()","['stocks = pd.DataFrame({ ', ""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5).to_dict()', 'pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()', 'stocks.info()', ""df = stocks.set_index(['date', 'ticker'])"", 'd = df.reset_index().to_dict()', ""df_new = pd.DataFrame(d).set_index(['date', 'ticker'])"", 'df_new.head()']","[""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5).to_dict()', ""{'date': {0: Timestamp('2011-01-01 00:00:00'),"", ""  1: Timestamp('2011-01-01 00:00:00'),"", ""  2: Timestamp('2011-01-01 00:00:00'),"", ""  3: Timestamp('2011-01-01 00:00:00'),"", ""  4: Timestamp('2011-01-02 00:00:00')},"", "" 'price': {0: 10.284260107718254,"", '  1: 11.930300761831457,', '  2: 10.93741046217319,', '  3: 10.884574289565609,', '  4: 11.78005850418319},', "" 'ticker': {0: 'aapl', 1: 'aapl', 2: 'aapl', 3: 'aapl', 4: 'aapl'}}"", 'pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()', ""{'date': {0: Timestamp('2011-01-01 00:00:00'),"", ""  1: Timestamp('2011-01-01 00:00:00'),"", ""  2: Timestamp('2011-01-01 00:00:00'),"", ""  3: Timestamp('2011-01-01 00:00:00'),"", ""  4: Timestamp('2011-01-02 00:00:00'),"", ""  5: Timestamp('2011-01-24 00:00:00'),"", ""  6: Timestamp('2011-01-25 00:00:00'),"", ""  7: Timestamp('2011-01-25 00:00:00'),"", ""  8: Timestamp('2011-01-25 00:00:00'),"", ""  9: Timestamp('2011-01-25 00:00:00')},"", "" 'price': {0: 10.284260107718254,"", '  1: 11.930300761831457,', '  2: 10.93741046217319,', '  3: 10.884574289565609,', '  4: 11.78005850418319,', '  5: 10.017209045035006,', '  6: 10.57090128181566,', '  7: 11.442792747870204,', '  8: 11.592953372130493,', '  9: 12.864146419530938},', "" 'ticker': {0: 'aapl',"", ""  1: 'aapl',"", ""  2: 'aapl',"", ""  3: 'aapl',"", ""  4: 'aapl',"", ""  5: 'msft',"", ""  6: 'msft',"", ""  7: 'msft',"", ""  8: 'msft',"", ""  9: 'msft'}}"", 'stocks.info()', ""df = stocks.set_index(['date', 'ticker'])"", 'df', '...', 'd = df.reset_index().to_dict()', 'df_new.head()']","[""    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),"", ""    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),"", ""    'price':(np.random.randn(100).cumsum() + 10) })"", 'stocks.head(5).to_dict()', 'pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()', 'stocks.info()', ""df = stocks.set_index(['date', 'ticker'])"", 'd = df.reset_index().to_dict()', ""df_new = pd.DataFrame(d).set_index(['date', 'ticker'])"", 'df_new.head()']",,
32558621,"for column in df:
    print(df[column])",[],"['for column in df:', '    print(df[column])']",[],[],[]
32583988,,[],[''],[],[],[]
32591786,"import pandas as pd
df = pd.read_excel('Book1.xlsx',sheetname='Sheet1',header=0,converters={'names':str,'ages':str})
df","[""df = pd.read_excel('Book1.xlsx',sheetname='Sheet1',header=0,converters={'names':str,'ages':str})""]","['import pandas as pd', ""df = pd.read_excel('Book1.xlsx',sheetname='Sheet1',header=0,converters={'names':str,'ages':str})"", 'df']","[""df = pd.read_excel('Book1.xlsx',sheetname='Sheet1',header=0,converters={'names':str,'ages':str})""]",,
32591799,"pandas.read_excel(my_file, converters = {my_str_column: str})","['pandas.read_excel(my_file, converters = {my_str_column: str})']","['pandas.read_excel(my_file, converters = {my_str_column: str})']","['pandas.read_excel(my_file, converters = {my_str_column: str})']",,
32606673,"import pandas
df = pandas.DataFrame(data)
df_7 = df.sample(n=7)","['df = pandas.DataFrame(data)', 'df_7 = df.sample(n=7)']","['import pandas', 'df_7 = df.sample(n=7)']",['df_7 = df.sample(n=7)'],,
32645303,"df = pd.DataFrame(df) 
df['sum'] = df.sum(axis= 1)
Range(Anchor).value = df.values
import xlwings as xw
import pandas as pd
target_df = xw.Range('A7').options(pd.DataFrame, expand='table').value ","['df = pd.DataFrame(df) ', ""df['sum'] = df.sum(axis= 1)"", 'Range(Anchor).value = df.values', ""target_df = xw.Range('A7').options(pd.DataFrame, expand='table').value ""]","[""df['sum'] = df.sum(axis= 1)"", 'Range(Anchor).value = df.values', 'import xlwings as xw', 'import pandas as pd']","[""df['sum'] = df.sum(axis= 1)"", 'Range(Anchor).value = df.values', ""target_df = xw.Range('A7').options(pd.DataFrame, expand='table').value ""]",,
32658847,"import numpy, pandas",[],"['import numpy, pandas']",[],[],[]
32662331,,[],[''],[],[],[]
32680162,"df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})","[""df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})""]",[],[],,
32700453,"days = pd.DataFrame({'date':list_of_days})
stores = pd.DataFrame({'store_id':list_of_stores})
stores['key'] = 0
days['key'] = 0
days_and_stores = days.merge(stores, how='left', on = 'key')
days_and_stores.drop('key',1, inplace=True)","[""days = pd.DataFrame({'date':list_of_days})"", ""stores = pd.DataFrame({'store_id':list_of_stores})"", ""days_and_stores = days.merge(stores, how='left', on = 'key')"", ""days_and_stores.drop('key',1, inplace=True)""]","[""stores['key'] = 0"", ""days['key'] = 0"", ""days_and_stores = days.merge(stores, how='left', on = 'key')"", ""days_and_stores.drop('key',1, inplace=True)""]","[""days_and_stores = days.merge(stores, how='left', on = 'key')"", ""days_and_stores.drop('key',1, inplace=True)""]",,
32748510,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.random.randn(100,2), columns=list('AB'))
df.hist(normed=1)
df.plot(kind='hist', normed=1, bins=20, stacked=False, alpha=.5)","[""df = pd.DataFrame(np.random.randn(100,2), columns=list('AB'))"", ""df.plot(kind='hist', normed=1, bins=20, stacked=False, alpha=.5)""]","['import pandas as pd', 'import numpy as np', 'df.hist(normed=1)', ""df.plot(kind='hist', normed=1, bins=20, stacked=False, alpha=.5)""]","[""df.plot(kind='hist', normed=1, bins=20, stacked=False, alpha=.5)""]",,
32750237,"x['cat2'] = x['cat'].astype('category')
x['cat2'].cat.codes","[""x['cat2'] = x['cat'].astype('category')"", ""x['cat2'].cat.codes""]","[""x['cat2'] = x['cat'].astype('category')"", ""x['cat2'].cat.codes""]","[""x['cat2'] = x['cat'].astype('category')"", ""x['cat2'].cat.codes""]",,
32751357,"df.groupby(['Country', 'Item_Code']).agg({'Y1961': np.sum, 'Y1962': [np.sum, np.mean]})  
df.groupby(['Code', 'Country', 'Item_Code', 'Item', 'Ele_Code', 'Unit']).agg({'Y1961': np.sum, 'Y1962': np.sum, 'Y1963': np.sum})","[""df.groupby(['Country', 'Item_Code']).agg({'Y1961': np.sum, 'Y1962': [np.sum, np.mean]})  "", ""df.groupby(['Code', 'Country', 'Item_Code', 'Item', 'Ele_Code', 'Unit']).agg({'Y1961': np.sum, 'Y1962': np.sum, 'Y1963': np.sum})""]","[""df.groupby(['Country', 'Item_Code']).agg({'Y1961': np.sum, 'Y1962': [np.sum, np.mean]})  "", ""df.groupby(['Code', 'Country', 'Item_Code', 'Item', 'Ele_Code', 'Unit']).agg({'Y1961': np.sum, 'Y1962': np.sum, 'Y1963': np.sum})""]","[""df.groupby(['Country', 'Item_Code']).agg({'Y1961': np.sum, 'Y1962': [np.sum, np.mean]})  "", ""df.groupby(['Code', 'Country', 'Item_Code', 'Item', 'Ele_Code', 'Unit']).agg({'Y1961': np.sum, 'Y1962': np.sum, 'Y1963': np.sum})""]",,
32751412,"df.groupby(['Country', 'Item_Code'])[[""Y1961"", ""Y1962"", ""Y1963""]].sum()","['df.groupby([\'Country\', \'Item_Code\'])[[""Y1961"", ""Y1962"", ""Y1963""]].sum()']","['df.groupby([\'Country\', \'Item_Code\'])[[""Y1961"", ""Y1962"", ""Y1963""]].sum()']","['df.groupby([\'Country\', \'Item_Code\'])[[""Y1961"", ""Y1962"", ""Y1963""]].sum()']",,
32752318,"df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))
df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))
df","[""df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))"", ""df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))""]",['df'],[],,
32760406,headers = df.dtypes.index,['headers = df.dtypes.index'],['headers = df.dtypes.index'],['headers = df.dtypes.index'],,
32761138,"from pyspark.sql.functions import col, rowNumber
from pyspark.sql.window import Window
w = Window.orderBy()
indexed = df.withColumn(""index"", rowNumber().over(w))
indexed.where(col(""index"").isin(set(indexes)))
indexed.where(""index in ({0})"".format("","".join(str(x) for x in indexes)))
from pyspark.sql import Row
from pyspark.sql.types import StructType, StructField, LongType
row = Row(""char"")
row_with_index = Row(""char"", ""index"")
df = sc.parallelize(row(chr(x)) for x in range(97, 112)).toDF()
df.show(5)
schema  = StructType(
    df.schema.fields[:] + [StructField(""index"", LongType(), False)])
indexed = (df.rdd 
    .zipWithIndex() 
    .map(lambda ri: row_with_index(*list(ri[0]) + [ri[1]])) 
    .toDF(schema)) 
inSet in Spark < 1.3
indexed.where(col(""index"").isin(indexes))","['indexed.where(col(""index"").isin(set(indexes)))', 'indexed.where(""index in ({0})"".format("","".join(str(x) for x in indexes)))', 'indexed = (df.rdd ', 'indexed.where(col(""index"").isin(indexes))']","['from pyspark.sql.functions import col, rowNumber', 'from pyspark.sql.window import Window', 'w = Window.orderBy()', 'indexed = df.withColumn(""index"", rowNumber().over(w))', 'indexed.where(col(""index"").isin(set(indexes)))', 'indexed.where(""index in ({0})"".format("","".join(str(x) for x in indexes)))', 'from pyspark.sql import Row', 'from pyspark.sql.types import StructType, StructField, LongType', 'row = Row(""char"")', 'row_with_index = Row(""char"", ""index"")', 'df = sc.parallelize(row(chr(x)) for x in range(97, 112)).toDF()', 'df.show(5)', 'schema  = StructType(', '    df.schema.fields[:] + [StructField(""index"", LongType(), False)])', 'indexed = (df.rdd ', '    .zipWithIndex() ', '    .map(lambda ri: row_with_index(*list(ri[0]) + [ri[1]])) ', '    .toDF(schema)) ', 'inSet in Spark < 1.3', 'indexed.where(col(""index"").isin(indexes))']","['indexed.where(col(""index"").isin(set(indexes)))', 'indexed.where(""index in ({0})"".format("","".join(str(x) for x in indexes)))', 'indexed = (df.rdd ', 'indexed.where(col(""index"").isin(indexes))']",,
32763707,"df.loc[""2011-01-07"", :datetime.time(15, 0)] = np.inf
df.loc[""2011-01-10"", datetime.time(13, 30):] = np.inf
df.loc[""2011-01-07"": ""2011-01-10"", :].idxmin(axis=1)","['df.loc[""2011-01-07"", :datetime.time(15, 0)] = np.inf', 'df.loc[""2011-01-10"", datetime.time(13, 30):] = np.inf', 'df.loc[""2011-01-07"": ""2011-01-10"", :].idxmin(axis=1)']","['df.loc[""2011-01-07"", :datetime.time(15, 0)] = np.inf', 'df.loc[""2011-01-10"", datetime.time(13, 30):] = np.inf', 'df.loc[""2011-01-07"": ""2011-01-10"", :].idxmin(axis=1)']","['df.loc[""2011-01-07"", :datetime.time(15, 0)] = np.inf', 'df.loc[""2011-01-10"", datetime.time(13, 30):] = np.inf', 'df.loc[""2011-01-07"": ""2011-01-10"", :].idxmin(axis=1)']",,
32764796,"first, last = ('2011-01-07', datetime.time(15)), ('2011-01-10', datetime.time(13, 30))
df.stack().loc[first: last].min()
first_row = df.index.get_loc(first[0])
last_row = df.index.get_loc(last[0])
if first_row == last_row:
    result = df.loc[first[0], first[1]: last[1]].min()
elif first_row < last_row:
    first_row_min = df.loc[first[0], first[1]:].min()
    last_row_min = df.loc[last[0], :last[1]].min()
    middle_min = df.iloc[first_row + 1:last_row].min().min()
    result = min(first_row_min, last_row_min, middle_min)
else: 
    raise ValueError('first row must be <= last row')","[""first, last = ('2011-01-07', datetime.time(15)), ('2011-01-10', datetime.time(13, 30))"", 'df.stack().loc[first: last].min()', 'first_row = df.index.get_loc(first[0])', 'last_row = df.index.get_loc(last[0])', '    result = df.loc[first[0], first[1]: last[1]].min()', '    first_row_min = df.loc[first[0], first[1]:].min()', '    last_row_min = df.loc[last[0], :last[1]].min()', '    middle_min = df.iloc[first_row + 1:last_row].min().min()']","[""first, last = ('2011-01-07', datetime.time(15)), ('2011-01-10', datetime.time(13, 30))"", 'df.stack().loc[first: last].min()', 'first_row = df.index.get_loc(first[0])', 'last_row = df.index.get_loc(last[0])', 'if first_row == last_row:', '    result = df.loc[first[0], first[1]: last[1]].min()', 'elif first_row < last_row:', '    first_row_min = df.loc[first[0], first[1]:].min()', '    last_row_min = df.loc[last[0], :last[1]].min()', '    middle_min = df.iloc[first_row + 1:last_row].min().min()', '    result = min(first_row_min, last_row_min, middle_min)', 'else: ', ""    raise ValueError('first row must be <= last row')""]","[""first, last = ('2011-01-07', datetime.time(15)), ('2011-01-10', datetime.time(13, 30))"", 'df.stack().loc[first: last].min()', 'first_row = df.index.get_loc(first[0])', 'last_row = df.index.get_loc(last[0])', '    result = df.loc[first[0], first[1]: last[1]].min()', '    first_row_min = df.loc[first[0], first[1]:].min()', '    last_row_min = df.loc[last[0], :last[1]].min()', '    middle_min = df.iloc[first_row + 1:last_row].min().min()']",,
32770800,"df.shift(1)
df.shift(2).iloc[:, 4:]
pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)
pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1).min(1)
pd.concat([df.iloc[:, :1].min(1),
                    df.shift(1).min(1),
                    df.shift(2).iloc[:, 4:].min(1)],
                   axis=1).min(1)","['df.shift(1)', 'df.shift(2).iloc[:, 4:]', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1).min(1)', 'pd.concat([df.iloc[:, :1].min(1),', '                    df.shift(1).min(1),', '                    df.shift(2).iloc[:, 4:].min(1)],']","['df.shift(1)', 'df.shift(2).iloc[:, 4:]', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1).min(1)', 'pd.concat([df.iloc[:, :1].min(1),', '                    df.shift(1).min(1),', '                    df.shift(2).iloc[:, 4:].min(1)],', '                   axis=1).min(1)']","['df.shift(1)', 'df.shift(2).iloc[:, 4:]', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1).min(1)', 'pd.concat([df.iloc[:, :1].min(1),', '                    df.shift(1).min(1),', '                    df.shift(2).iloc[:, 4:].min(1)],']",,
32773145,"lambdafunc = lambda x: pd.Series([x['mytime'].hour,
                                  x['mydate'].isocalendar()[1],
                                  x['mydate'].weekday()])
newcols = df.apply(lambdafunc, axis=1)
newcols.columns = ['hour', 'weekday', 'weeknum']
newdf = df.join(newcols) ","[""lambdafunc = lambda x: pd.Series([x['mytime'].hour,"", ""                                  x['mydate'].isocalendar()[1],"", ""                                  x['mydate'].weekday()])"", 'newcols = df.apply(lambdafunc, axis=1)', 'newdf = df.join(newcols) ']","[""                                  x['mydate'].isocalendar()[1],"", ""                                  x['mydate'].weekday()])"", 'newcols = df.apply(lambdafunc, axis=1)', ""newcols.columns = ['hour', 'weekday', 'weeknum']"", 'newdf = df.join(newcols) ']","[""lambdafunc = lambda x: pd.Series([x['mytime'].hour,"", ""                                  x['mydate'].isocalendar()[1],"", ""                                  x['mydate'].weekday()])"", 'newcols = df.apply(lambdafunc, axis=1)', 'newdf = df.join(newcols) ']",,
32783825,data.groupby(data.date.dt.year),['data.groupby(data.date.dt.year)'],['data.groupby(data.date.dt.year)'],['data.groupby(data.date.dt.year)'],,
32801170,"df.groupby(key_columns).size()
import pandas as pd
df = pd.DataFrame([['a', 1],
                           ['b', 2],
                           ['c', 3],
                           ['a', 4],
                           ['b', 5]], 
                          columns=['col1', 'col2'])
counts = df.groupby('col1').size(); counts
type(counts)
counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))
counts_df
type(counts_df)
df.dtypes
df
df[['col1', 'col2', 'col3', 'col4']]\
            .groupby(['col1', 'col2']).agg(['mean', 'count'])
groupby_object = df[['col1', 'col2', 'col3', 'col4']]\
            .groupby(['col1', 'col2'])
groupby_object.agg('mean')\
             .rename(columns = lambda x: x + ' mean')\
             .join(pd.DataFrame(groupby_object.size(), 
                                columns=['counts']))","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', 'import pandas as pd', ""                           ['b', 2],"", ""                           ['c', 3],"", ""                           ['a', 4],"", ""                           ['b', 5]], "", ""                          columns=['col1', 'col2'])"", ""counts = df.groupby('col1').size(); counts"", 'type(counts)', 'counts_df', 'type(counts_df)', 'df.dtypes', 'df', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""            .groupby(['col1', 'col2']).agg(['mean', 'count'])"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""            .groupby(['col1', 'col2'])"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", ""                                columns=['counts']))""]","['df.groupby(key_columns).size()', ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']"
32801924,,[],[''],[],[],[]
32802014,"import pandas as pd
df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],
                    'B': ['B0', 'B1', 'B2', 'B3'],
                    'D': ['D0', 'D1', 'D2', 'D3']},
                    index=[0, 2, 3,4])
df2 = pd.DataFrame({'A1': ['A4', 'A5', 'A6', 'A7'],
                    'C': ['C4', 'C5', 'C6', 'C7'],
                    'D2': ['D4', 'D5', 'D6', 'D7']},
                    index=[ 4, 5, 6 ,7])
df1.reset_index(drop=True, inplace=True)
df2.reset_index(drop=True, inplace=True)
df = pd.concat( [df1, df2], axis=1) ","[""df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],"", ""df2 = pd.DataFrame({'A1': ['A4', 'A5', 'A6', 'A7'],"", 'df1.reset_index(drop=True, inplace=True)', 'df2.reset_index(drop=True, inplace=True)', 'df = pd.concat( [df1, df2], axis=1) ']","['import pandas as pd', ""                    'B': ['B0', 'B1', 'B2', 'B3'],"", ""                    'D': ['D0', 'D1', 'D2', 'D3']},"", '                    index=[0, 2, 3,4])', ""                    'C': ['C4', 'C5', 'C6', 'C7'],"", ""                    'D2': ['D4', 'D5', 'D6', 'D7']},"", '                    index=[ 4, 5, 6 ,7])', 'df1.reset_index(drop=True, inplace=True)', 'df2.reset_index(drop=True, inplace=True)', 'df = pd.concat( [df1, df2], axis=1) ']","['df1.reset_index(drop=True, inplace=True)', 'df2.reset_index(drop=True, inplace=True)', 'df = pd.concat( [df1, df2], axis=1) ']",,
32850652,"df[""flips""], df[""row_name""] = zip(*df[""row""].str.split().tolist())
del df[""row""]  ","['df[""flips""], df[""row_name""] = zip(*df[""row""].str.split().tolist())']","['df[""flips""], df[""row_name""] = zip(*df[""row""].str.split().tolist())', 'del df[""row""]  ']","['df[""flips""], df[""row_name""] = zip(*df[""row""].str.split().tolist())']",,
32909107,"cols = [1,2,4,5,12]
df.drop(df.columns[cols],axis=1,inplace=True)","['df.drop(df.columns[cols],axis=1,inplace=True)']","['cols = [1,2,4,5,12]', 'df.drop(df.columns[cols],axis=1,inplace=True)']","['df.drop(df.columns[cols],axis=1,inplace=True)']",,
32944421,,[],[''],[],[],[]
32961145,"def duplicate_columns(frame):
    groups = frame.columns.to_series().groupby(frame.dtypes).groups
    dups = []
    for t, v in groups.items():
        dcols = frame[v].to_dict(orient=""list"")
        vs = dcols.values()
        ks = dcols.keys()
        lvs = len(vs)
        for i in range(lvs):
            for j in range(i+1,lvs):
                if vs[i] == vs[j]: 
                    dups.append(ks[i])
                    break
    return dups       
dups = duplicate_columns(frame)
frame = frame.drop(dups, axis=1)
from pandas.core.common import array_equivalent
def duplicate_columns(frame):
    groups = frame.columns.to_series().groupby(frame.dtypes).groups
    dups = []
    for t, v in groups.items():
        cs = frame[v].columns
        vs = frame[v]
        lcs = len(cs)
        for i in range(lcs):
            ia = vs.iloc[:,i].values
            for j in range(i+1, lcs):
                ja = vs.iloc[:,j].values
                if array_equivalent(ia, ja):
                    dups.append(cs[i])
                    break
    return dups","['    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '        dcols = frame[v].to_dict(orient=""list"")', '        vs = dcols.values()', '                    dups.append(ks[i])', 'frame = frame.drop(dups, axis=1)', '    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '            ia = vs.iloc[:,i].values', '                ja = vs.iloc[:,j].values', '                    dups.append(cs[i])']","['def duplicate_columns(frame):', '    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '    dups = []', '    for t, v in groups.items():', '        dcols = frame[v].to_dict(orient=""list"")', '        vs = dcols.values()', '        ks = dcols.keys()', '        lvs = len(vs)', '        for i in range(lvs):', '            for j in range(i+1,lvs):', '                if vs[i] == vs[j]: ', '                    dups.append(ks[i])', '                    break', '    return dups       ', 'dups = duplicate_columns(frame)', 'frame = frame.drop(dups, axis=1)', 'from pandas.core.common import array_equivalent', 'def duplicate_columns(frame):', '    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '    dups = []', '    for t, v in groups.items():', '        cs = frame[v].columns', '        vs = frame[v]', '        lcs = len(cs)', '        for i in range(lcs):', '            ia = vs.iloc[:,i].values', '            for j in range(i+1, lcs):', '                ja = vs.iloc[:,j].values', '                if array_equivalent(ia, ja):', '                    dups.append(cs[i])', '                    break', '    return dups']","['    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '        dcols = frame[v].to_dict(orient=""list"")', '        vs = dcols.values()', '                    dups.append(ks[i])', 'frame = frame.drop(dups, axis=1)', '    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '            ia = vs.iloc[:,i].values', '                ja = vs.iloc[:,j].values', '                    dups.append(cs[i])']",,
32970117,"df.memory_usage()
...
df.memory_usage(index=True).sum()
731731000","['df.memory_usage()', 'df.memory_usage(index=True).sum()']","['df.memory_usage()', '...', 'df.memory_usage(index=True).sum()', '731731000']","['df.memory_usage()', 'df.memory_usage(index=True).sum()']",,
32993553,"df = pd.read_csv(filename.tar.gz, compression='gzip', header=0, sep=',', quotechar='""')","['df = pd.read_csv(filename.tar.gz, compression=\'gzip\', header=0, sep=\',\', quotechar=\'""\')']","['df = pd.read_csv(filename.tar.gz, compression=\'gzip\', header=0, sep=\',\', quotechar=\'""\')']","['df = pd.read_csv(filename.tar.gz, compression=\'gzip\', header=0, sep=\',\', quotechar=\'""\')']",,
33000983,"import pandas as pd
import numpy as np
df['value'] = np.maximum(df['value'], 0)
df = pd.DataFrame({'value': np.arange(-1000000,1000000)})
df = pd.DataFrame({'value': np.arange(-1000000,1000000)})","[""df = pd.DataFrame({'value': np.arange(-1000000,1000000)})"", ""df = pd.DataFrame({'value': np.arange(-1000000,1000000)})""]","['import pandas as pd', 'import numpy as np', ""df['value'] = np.maximum(df['value'], 0)""]",[],,
33004253,"import pandas as pd
import numpy as np
randn = np.random.randn
df = pd.DataFrame(randn(15, 20))
df1 = pd.DataFrame(randn(10, 5))
df2 = pd.DataFrame(randn(5, 10))
funtion
def multiple_dfs(df_list, sheets, file_name, spaces):
    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   
    row = 0
    for dataframe in df_list:
        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   
        row = row + len(dataframe.index) + spaces + 1
    writer.save()
dfs = [df,df1,df2]
multiple_dfs(dfs, 'Validation', 'test1.xlsx', 1)
function
def dfs_tabs(df_list, sheet_list, file_name):
    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   
    for dataframe, sheet in zip(df_list, sheet_list):
        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   
    writer.save()
dfs = [df, df1, df2]
sheets = ['df','df1','df2']    
dfs_tabs(dfs, sheets, 'multi-test.xlsx')","['df = pd.DataFrame(randn(15, 20))', 'df1 = pd.DataFrame(randn(10, 5))', 'df2 = pd.DataFrame(randn(5, 10))', '        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   ', '        row = row + len(dataframe.index) + spaces + 1', '        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   ']","['import pandas as pd', 'import numpy as np', 'randn = np.random.randn', 'funtion', 'def multiple_dfs(df_list, sheets, file_name, spaces):', ""    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   "", '    row = 0', '    for dataframe in df_list:', '        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   ', '        row = row + len(dataframe.index) + spaces + 1', '    writer.save()', 'dfs = [df,df1,df2]', ""multiple_dfs(dfs, 'Validation', 'test1.xlsx', 1)"", 'function', 'def dfs_tabs(df_list, sheet_list, file_name):', ""    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   "", '    for dataframe, sheet in zip(df_list, sheet_list):', '        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   ', '    writer.save()', 'dfs = [df, df1, df2]', ""sheets = ['df','df1','df2']    "", ""dfs_tabs(dfs, sheets, 'multi-test.xlsx')""]","['        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   ', '        row = row + len(dataframe.index) + spaces + 1', '        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   ']",,
33011646,,[],[''],[],[],[]
33020669,,[],[''],[],[],[]
33040290,"df = pd.DataFrame({'a':list('tuhimerisabhain')})
df.a.value_counts()
df.a.value_counts()","[""df = pd.DataFrame({'a':list('tuhimerisabhain')})"", 'df.a.value_counts()', 'df.a.value_counts()']","['df.a.value_counts()', 'df.a.value_counts()']","['df.a.value_counts()', 'df.a.value_counts()']",,
33050438,"import pandas as pd
df.to_pickle('123.pkl')    
df1 = pd.read_pickle('123.pkl') ","[""df.to_pickle('123.pkl')    "", ""df1 = pd.read_pickle('123.pkl') ""]","['import pandas as pd', ""df.to_pickle('123.pkl')    "", ""df1 = pd.read_pickle('123.pkl') ""]","[""df.to_pickle('123.pkl')    "", ""df1 = pd.read_pickle('123.pkl') ""]",,
33054358,"import numpy as np
import pandas as pd
index = pd.Index(['01/01/2012','01/01/2012','01/01/2012','01/02/2012','01/02/2012'], name='Date')
df = pd.DataFrame({'ID':[100,101,102,201,202],'wt':[.5,.75,1,.5,1],'value':[60,80,100,100,80]},index=index)
df.groupby(df.index).apply(lambda x: np.average(x.wt, weights=x.value))","[""df = pd.DataFrame({'ID':[100,101,102,201,202],'wt':[.5,.75,1,.5,1],'value':[60,80,100,100,80]},index=index)"", 'df.groupby(df.index).apply(lambda x: np.average(x.wt, weights=x.value))']","['import numpy as np', 'import pandas as pd', ""index = pd.Index(['01/01/2012','01/01/2012','01/01/2012','01/02/2012','01/02/2012'], name='Date')"", 'df.groupby(df.index).apply(lambda x: np.average(x.wt, weights=x.value))']","['df.groupby(df.index).apply(lambda x: np.average(x.wt, weights=x.value))']",,
33086953,"df1.merge(df2,how='left', left_on='Column1', right_on='ColumnA')","[""df1.merge(df2,how='left', left_on='Column1', right_on='ColumnA')""]","[""df1.merge(df2,how='left', left_on='Column1', right_on='ColumnA')""]","[""df1.merge(df2,how='left', left_on='Column1', right_on='ColumnA')""]",,
33088410,"df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)","['df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)']","['df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)']","['df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)']",,
33109272,"x = pandas.Series(np.random.randn(10))
stats.skew(x)
-0.17644348972413657
x.skew()
-0.20923623968879457
stats.skew(x, bias=False)
-0.2092362396887948
stats.kurtosis(x)
0.6362620964462327
x.kurtosis()
2.0891062062174464
stats.kurtosis(x, bias=False)
2.089106206217446","['x = pandas.Series(np.random.randn(10))', 'stats.skew(x)', 'x.skew()', 'stats.skew(x, bias=False)']","['stats.skew(x)', '-0.17644348972413657', 'x.skew()', '-0.20923623968879457', 'stats.skew(x, bias=False)', '-0.2092362396887948', 'stats.kurtosis(x)', '0.6362620964462327', 'x.kurtosis()', '2.0891062062174464', 'stats.kurtosis(x, bias=False)', '2.089106206217446']","['stats.skew(x)', 'x.skew()', 'stats.skew(x, bias=False)']",,
33133356,"pandas.to_datetime('today')
Timestamp('2015-10-14 00:00:00')","[""pandas.to_datetime('today')""]","[""pandas.to_datetime('today')"", ""Timestamp('2015-10-14 00:00:00')""]","[""pandas.to_datetime('today')""]",,
33149986,,[],[''],[],[],[]
33161955,"df = pd.read_csv('somefile.csv', low_memory=False)","[""df = pd.read_csv('somefile.csv', low_memory=False)""]","[""df = pd.read_csv('somefile.csv', low_memory=False)""]","[""df = pd.read_csv('somefile.csv', low_memory=False)""]",,
33165860,"df2 = df2.reset_index(drop=True)
df2",['df2 = df2.reset_index(drop=True)'],"['df2 = df2.reset_index(drop=True)', 'df2']",['df2 = df2.reset_index(drop=True)'],,
33168054,,[],[''],[],[],[]
33178896,"sub2['income'].fillna((sub2['income'].mean()), inplace=True)","[""sub2['income'].fillna((sub2['income'].mean()), inplace=True)""]","[""sub2['income'].fillna((sub2['income'].mean()), inplace=True)""]","[""sub2['income'].fillna((sub2['income'].mean()), inplace=True)""]",,
33247007,"df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])
df
df.iloc[0]
type(_)","['df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])', 'df.iloc[0]']","['df', 'df.iloc[0]', 'type(_)']","['df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])', 'df.iloc[0]']",,
33250288,"import numpy as np
import pandas as pd
np.random.seed(1)
df = pd.DataFrame(np.random.randn(4,4)* 4 + 3)
df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))
df['grp'] = ['A', 'A', 'B', 'B']
df.groupby(['grp'])[[0,1,2,3]].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))","['df = pd.DataFrame(np.random.randn(4,4)* 4 + 3)', 'df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))', ""df.groupby(['grp'])[[0,1,2,3]].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))""]","['import numpy as np', 'import pandas as pd', 'np.random.seed(1)', 'df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))', ""df['grp'] = ['A', 'A', 'B', 'B']"", ""df.groupby(['grp'])[[0,1,2,3]].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))""]","['df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))', ""df.groupby(['grp'])[[0,1,2,3]].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))""]",,
33259038,"import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import matplotlib.ticker as ticker
dfWIM = pd.DataFrame({'AXLES': np.random.normal(8, 2, 5000).astype(int)})
ncount = len(dfWIM)
plt.figure(figsize=(12,8))
ax = sns.countplot(x=""AXLES"", data=dfWIM, order=[3,4,5,6,7,8,9,10,11,12])
plt.title('Distribution of Truck Configurations')
plt.xlabel('Number of Axles')
ax2=ax.twinx()
ax2.yaxis.tick_left()
ax.yaxis.tick_right()
ax.yaxis.set_label_position('right')
ax2.yaxis.set_label_position('left')
ax2.set_ylabel('Frequency [%]')
for p in ax.patches:
    x=p.get_bbox().get_points()[:,0]
    y=p.get_bbox().get_points()[1,1]
    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), 
            ha='center', va='bottom') 
ax.yaxis.set_major_locator(ticker.LinearLocator(11))
ax2.set_ylim(0,100)
ax.set_ylim(0,ncount)
ax2.yaxis.set_major_locator(ticker.MultipleLocator(10))
ax2.grid(None)
plt.savefig('snscounter.pdf')","[""dfWIM = pd.DataFrame({'AXLES': np.random.normal(8, 2, 5000).astype(int)})"", ""plt.title('Distribution of Truck Configurations')"", ""    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), ""]","['import pandas as pd', 'import matplotlib.pyplot as plt', 'import numpy as np', 'import seaborn as sns', 'import matplotlib.ticker as ticker', 'ncount = len(dfWIM)', 'plt.figure(figsize=(12,8))', 'ax = sns.countplot(x=""AXLES"", data=dfWIM, order=[3,4,5,6,7,8,9,10,11,12])', ""plt.title('Distribution of Truck Configurations')"", ""plt.xlabel('Number of Axles')"", 'ax2=ax.twinx()', 'ax2.yaxis.tick_left()', 'ax.yaxis.tick_right()', ""ax.yaxis.set_label_position('right')"", ""ax2.yaxis.set_label_position('left')"", ""ax2.set_ylabel('Frequency [%]')"", 'for p in ax.patches:', '    x=p.get_bbox().get_points()[:,0]', '    y=p.get_bbox().get_points()[1,1]', ""    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), "", ""            ha='center', va='bottom') "", 'ax.yaxis.set_major_locator(ticker.LinearLocator(11))', 'ax2.set_ylim(0,100)', 'ax.set_ylim(0,ncount)', 'ax2.yaxis.set_major_locator(ticker.MultipleLocator(10))', 'ax2.grid(None)', ""plt.savefig('snscounter.pdf')""]","[""dfWIM = pd.DataFrame({'AXLES': np.random.normal(8, 2, 5000).astype(int)})"", ""plt.title('Distribution of Truck Configurations')"", ""    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), ""]",,
33271634,"df.groupby([""Group"", ""Size""]).size()
df.groupby([""Group"", ""Size""]).size().reset_index(name=""Time"")","['df.groupby([""Group"", ""Size""]).size()', 'df.groupby([""Group"", ""Size""]).size().reset_index(name=""Time"")']","['df.groupby([""Group"", ""Size""]).size()', 'df.groupby([""Group"", ""Size""]).size().reset_index(name=""Time"")']","['df.groupby([""Group"", ""Size""]).size()', 'df.groupby([""Group"", ""Size""]).size().reset_index(name=""Time"")']",,
33324058,"from shapely.geometry import Polygon, Point, LinearRing
poly = Polygon([(0, 0), (2,8), (14, 10), (6,1)])
point = Point(12,4)
pol_ext = LinearRing(poly.exterior.coords)
d = pol_ext.project(point)
p = pol_ext.interpolate(d)
closest_point_coords = list(p.coords)[0]",['p = pol_ext.interpolate(d)'],"['from shapely.geometry import Polygon, Point, LinearRing', 'poly = Polygon([(0, 0), (2,8), (14, 10), (6,1)])', 'point = Point(12,4)', 'pol_ext = LinearRing(poly.exterior.coords)', 'd = pol_ext.project(point)', 'p = pol_ext.interpolate(d)', 'closest_point_coords = list(p.coords)[0]']",['p = pol_ext.interpolate(d)'],,
33346694,"df = pd.DataFrame({'a':[0,0,1,2,2,2], 'b':[1,2,3,4,np.NaN,4], 'c':np.random.randn(6)})
df
print(df.groupby(['a'])['b'].count())
print(df.groupby(['a'])['b'].size())
a
a
dtype: int64 ","[""df = pd.DataFrame({'a':[0,0,1,2,2,2], 'b':[1,2,3,4,np.NaN,4], 'c':np.random.randn(6)})"", ""print(df.groupby(['a'])['b'].count())"", ""print(df.groupby(['a'])['b'].size())""]","['df', ""print(df.groupby(['a'])['b'].count())"", ""print(df.groupby(['a'])['b'].size())"", 'a', 'a', 'dtype: int64 ']","[""print(df.groupby(['a'])['b'].count())"", ""print(df.groupby(['a'])['b'].size())""]",,
33374834,"import pandas as pd
sheet1 = xlsx.parse(0)
column = sheet1.icol(0).real
row = sheet1.irow(0).real",['sheet1 = xlsx.parse(0)'],"['import pandas as pd', 'sheet1 = xlsx.parse(0)', 'column = sheet1.icol(0).real', 'row = sheet1.irow(0).real']",['sheet1 = xlsx.parse(0)'],,
33375383,,[],[''],[],[],[]
33381151,"frame[frame.duplicated(['key1','key2'],keep=False)]","[""frame[frame.duplicated(['key1','key2'],keep=False)]""]","[""frame[frame.duplicated(['key1','key2'],keep=False)]""]","[""frame[frame.duplicated(['key1','key2'],keep=False)]""]",,
33381246,"import pandas as pd
df = pd.DataFrame(['a','b','c','d','a','b'])
df
df[df.duplicated(keep=False)]","[""df = pd.DataFrame(['a','b','c','d','a','b'])"", 'df[df.duplicated(keep=False)]']","['import pandas as pd', 'df', 'df[df.duplicated(keep=False)]']",['df[df.duplicated(keep=False)]'],,
33387356,df[~df.index.duplicated()],['df[~df.index.duplicated()]'],['df[~df.index.duplicated()]'],['df[~df.index.duplicated()]'],,
33404243,"import pandas
original = pandas.DataFrame({
    'Age':[10, 12, 13], 
    'Gender':['M','F','F']})
data = ['Nate A', 'Jessie A', 'Daniel H', 'John D']
additional = pandas.DataFrame({'Name': data})
new = pandas.concat([original, additional], axis=1) 
new = pandas.concat([original, additional], ignore_index=False, axis=1) 
print(new.head())","['original = pandas.DataFrame({', ""additional = pandas.DataFrame({'Name': data})"", 'new = pandas.concat([original, additional], axis=1) ', 'new = pandas.concat([original, additional], ignore_index=False, axis=1) ', 'print(new.head())']","['import pandas', ""    'Age':[10, 12, 13], "", ""    'Gender':['M','F','F']})"", ""data = ['Nate A', 'Jessie A', 'Daniel H', 'John D']"", 'new = pandas.concat([original, additional], axis=1) ', 'new = pandas.concat([original, additional], ignore_index=False, axis=1) ', 'print(new.head())']","['new = pandas.concat([original, additional], axis=1) ', 'new = pandas.concat([original, additional], ignore_index=False, axis=1) ', 'print(new.head())']",,
33480745,"from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay
us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())
DatetimeIndex(['2010-01-04', '2010-01-05', '2010-01-06', '2010-01-07',
               '2010-01-08', '2010-01-11', '2010-01-12', '2010-01-13',
               '2010-01-14', '2010-01-15'],
              dtype='datetime64[ns]', freq='C')",[],"['from pandas.tseries.holiday import USFederalHolidayCalendar', 'from pandas.tseries.offsets import CustomBusinessDay', 'us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())', ""DatetimeIndex(['2010-01-04', '2010-01-05', '2010-01-06', '2010-01-07',"", ""               '2010-01-08', '2010-01-11', '2010-01-12', '2010-01-13',"", ""               '2010-01-14', '2010-01-15'],"", ""              dtype='datetime64[ns]', freq='C')""]",[],[],[]
33555435,your_dataframe = your_dataframe.reindex(columns=sequence),['your_dataframe = your_dataframe.reindex(columns=sequence)'],['your_dataframe = your_dataframe.reindex(columns=sequence)'],['your_dataframe = your_dataframe.reindex(columns=sequence)'],,
33570065,,[],[''],[],[],[]
33577649,,[],[''],[],[],[]
33590284,"sns.set_style(""whitegrid"", {'axes.grid' : False})",[],"['sns.set_style(""whitegrid"", {\'axes.grid\' : False})']",[],[],[]
33687073,df['MyColumnName'] = df['MyColumnName'].astype('float64') ,"[""df['MyColumnName'] = df['MyColumnName'].astype('float64') ""]","[""df['MyColumnName'] = df['MyColumnName'].astype('float64') ""]","[""df['MyColumnName'] = df['MyColumnName'].astype('float64') ""]",,
33763855,,[],[''],[],[],[]
33768634,sample_dataframe = your_dataframe.sample(n=how_many_rows_you_want),['sample_dataframe = your_dataframe.sample(n=how_many_rows_you_want)'],['sample_dataframe = your_dataframe.sample(n=how_many_rows_you_want)'],['sample_dataframe = your_dataframe.sample(n=how_many_rows_you_want)'],,
33777664,df['quantity'] = df['quantity'].apply(lambda x: x*-1),"[""df['quantity'] = df['quantity'].apply(lambda x: x*-1)""]","[""df['quantity'] = df['quantity'].apply(lambda x: x*-1)""]","[""df['quantity'] = df['quantity'].apply(lambda x: x*-1)""]",,
33780558,"df.loc[:,'quantity'] *= -1 ","[""df.loc[:,'quantity'] *= -1 ""]","[""df.loc[:,'quantity'] *= -1 ""]","[""df.loc[:,'quantity'] *= -1 ""]",,
33782239,"from scipy import stats
import pandas as pd
import numpy as np
np.random.seed(seed=1)
df = pd.DataFrame(np.random.uniform(0,1,(10)), columns=['a'])
x = df.quantile(0.5)[0]
stats.percentileofscore(df['a'],x)","[""df = pd.DataFrame(np.random.uniform(0,1,(10)), columns=['a'])"", 'x = df.quantile(0.5)[0]']","['from scipy import stats', 'import pandas as pd', 'import numpy as np', 'np.random.seed(seed=1)', 'x = df.quantile(0.5)[0]', ""stats.percentileofscore(df['a'],x)""]",['x = df.quantile(0.5)[0]'],,
33782409,"results.val1.hist(bins = 120, log = True)",[],"['results.val1.hist(bins = 120, log = True)']",[],[],[]
33786696,"df1 = pandas.DataFrame(data = {'col1' : [1, 2, 3, 4, 5], 'col2' : [10, 11, 12, 13, 14]})
df2 = pandas.DataFrame(data = {'col1' : [1, 3, 4], 'col2' : [10, 12, 13]})
df1.loc[~df1.set_index(list(df1.columns)).index.isin(df2.set_index(list(df2.columns)).index)]","[""df1 = pandas.DataFrame(data = {'col1' : [1, 2, 3, 4, 5], 'col2' : [10, 11, 12, 13, 14]})"", ""df2 = pandas.DataFrame(data = {'col1' : [1, 3, 4], 'col2' : [10, 12, 13]})"", 'df1.loc[~df1.set_index(list(df1.columns)).index.isin(df2.set_index(list(df2.columns)).index)]']",['df1.loc[~df1.set_index(list(df1.columns)).index.isin(df2.set_index(list(df2.columns)).index)]'],['df1.loc[~df1.set_index(list(df1.columns)).index.isin(df2.set_index(list(df2.columns)).index)]'],,
33795876,"df1 = df.apply(pd.to_numeric, args=('coerce',))
df1 = df.apply(pd.to_numeric, errors='coerce')","[""df1 = df.apply(pd.to_numeric, args=('coerce',))"", ""df1 = df.apply(pd.to_numeric, errors='coerce')""]","[""df1 = df.apply(pd.to_numeric, args=('coerce',))"", ""df1 = df.apply(pd.to_numeric, errors='coerce')""]","[""df1 = df.apply(pd.to_numeric, args=('coerce',))"", ""df1 = df.apply(pd.to_numeric, errors='coerce')""]",,
33798922,"pd.set_option('max_colwidth', 800)","[""pd.set_option('max_colwidth', 800)""]","[""pd.set_option('max_colwidth', 800)""]","[""pd.set_option('max_colwidth', 800)""]",,
33814054,,[],[''],[],[],[]
33837592,"df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)","[""df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)""]",,
33872824,df.columns = [col.strip('$') for col in df.columns],"[""df.columns = [col.strip('$') for col in df.columns]""]","[""df.columns = [col.strip('$') for col in df.columns]""]","[""df.columns = [col.strip('$') for col in df.columns]""]",,
33873209,"import pandas as pd
from math import pi
from datetime import datetime as dt
from bokeh.io import output_file
from bokeh.charts import show
from bokeh.models import DatetimeTickFormatter
from bokeh.plotting import figure
df = pd.DataFrame(data=[1,2,3],
                  index=[dt(2015, 1, 1), dt(2015, 1, 2), dt(2015, 1, 3)],
                  columns=['foo'])
p = figure(plot_width=400, plot_height=400)
p.line(df.index, df['foo'])
p.xaxis.formatter=DatetimeTickFormatter(
        hours=[""%d %B %Y""],
        days=[""%d %B %Y""],
        months=[""%d %B %Y""],
        years=[""%d %B %Y""],
    )
p.xaxis.major_label_orientation = pi/4
output_file('myplot.html')
show(p)","['df = pd.DataFrame(data=[1,2,3],', ""p.line(df.index, df['foo'])""]","['import pandas as pd', 'from math import pi', 'from datetime import datetime as dt', 'from bokeh.io import output_file', 'from bokeh.charts import show', 'from bokeh.models import DatetimeTickFormatter', 'from bokeh.plotting import figure', '                  index=[dt(2015, 1, 1), dt(2015, 1, 2), dt(2015, 1, 3)],', ""                  columns=['foo'])"", 'p = figure(plot_width=400, plot_height=400)', ""p.line(df.index, df['foo'])"", 'p.xaxis.formatter=DatetimeTickFormatter(', '        hours=[""%d %B %Y""],', '        days=[""%d %B %Y""],', '        months=[""%d %B %Y""],', '        years=[""%d %B %Y""],', '    )', 'p.xaxis.major_label_orientation = pi/4', ""output_file('myplot.html')"", 'show(p)']","[""p.line(df.index, df['foo'])""]",,
33913961,"import pandas as pd
df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})","[""df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})""]",['import pandas as pd'],[],,
33952294,"import pandas as pd
from io import StringIO
data = """"""
PDB CHAIN SP_PRIMARY RES_BEG RES_END PDB_BEG PDB_END SP_BEG SP_END
5d8b N P60490 1 146 1 146 1 146
5d8b NA P80377 _ 126 1 126 1 126
5d8b O P60491 1 118 1 118 1 118
""""""
df = pd.read_csv(StringIO(data), sep=' ', keep_default_na=False, na_values=['_'])
df
df.CHAIN.apply(type)","[""df = pd.read_csv(StringIO(data), sep=' ', keep_default_na=False, na_values=['_'])"", 'df.CHAIN.apply(type)']","['import pandas as pd', 'from io import StringIO', 'data = """"""', 'PDB CHAIN SP_PRIMARY RES_BEG RES_END PDB_BEG PDB_END SP_BEG SP_END', '5d8b N P60490 1 146 1 146 1 146', '5d8b NA P80377 _ 126 1 126 1 126', '5d8b O P60491 1 118 1 118 1 118', '""""""', ""df = pd.read_csv(StringIO(data), sep=' ', keep_default_na=False, na_values=['_'])"", 'df', 'df.CHAIN.apply(type)']","[""df = pd.read_csv(StringIO(data), sep=' ', keep_default_na=False, na_values=['_'])"", 'df.CHAIN.apply(type)']",,
33957850,"df['column'] = df['column'].astype('str') 
df['column_new'] = df['column'].str.split(',') ","[""df['column'] = df['column'].astype('str') "", ""df['column_new'] = df['column'].str.split(',') ""]","[""df['column'] = df['column'].astype('str') "", ""df['column_new'] = df['column'].str.split(',') ""]","[""df['column'] = df['column'].astype('str') "", ""df['column_new'] = df['column'].str.split(',') ""]",,
33967359,dates.dt.strftime('%Y-%m-%d'),"[""dates.dt.strftime('%Y-%m-%d')""]","[""dates.dt.strftime('%Y-%m-%d')""]","[""dates.dt.strftime('%Y-%m-%d')""]",,
33986975,,[],[''],[],[],[]
33993078,"misc['product_desc'] = misc['product_desc'].replace(to_replace='\n', value='', regex=True)","[""misc['product_desc'] = misc['product_desc'].replace(to_replace='\\n', value='', regex=True)""]","[""misc['product_desc'] = misc['product_desc'].replace(to_replace='\\n', value='', regex=True)""]","[""misc['product_desc'] = misc['product_desc'].replace(to_replace='\\n', value='', regex=True)""]",,
33997632,"import seaborn.apionly as sns
titanic = sns.load_dataset('titanic')
titanic.loc[:,['sex','age','fare']]
titanic.iloc[:,[2,3,6]]
titanic.ix[:,[2,3,6]]
titanic.reindex(columns=['sex','age','fare'])","[""titanic.loc[:,['sex','age','fare']]"", 'titanic.iloc[:,[2,3,6]]', ""titanic.reindex(columns=['sex','age','fare'])""]","['import seaborn.apionly as sns', ""titanic = sns.load_dataset('titanic')"", ""titanic.loc[:,['sex','age','fare']]"", 'titanic.iloc[:,[2,3,6]]', 'titanic.ix[:,[2,3,6]]', ""titanic.reindex(columns=['sex','age','fare'])""]","[""titanic.loc[:,['sex','age','fare']]"", 'titanic.iloc[:,[2,3,6]]', ""titanic.reindex(columns=['sex','age','fare'])""]",,
34013098,"tf.initialize_all_variables().run()
init_op = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init_op)",[],"['tf.initialize_all_variables().run()', 'init_op = tf.initialize_all_variables()', 'sess = tf.Session()', 'sess.run(init_op)']",[],[],[]
34082664,"df[df.EPS.notnull()]
df[~df.EPS.isnull()]
df[~np.isnan(df.EPS)]","['df[df.EPS.notnull()]', 'df[~df.EPS.isnull()]']","['df[df.EPS.notnull()]', 'df[~df.EPS.isnull()]', 'df[~np.isnan(df.EPS)]']","['df[df.EPS.notnull()]', 'df[~df.EPS.isnull()]']",,
34092032,"Cov = pd.read_csv(""path/to/file.txt"", sep='\t', 
                  names = [""Sequence"", ""Start"", ""End"", ""Coverage""])
Frame=pd.DataFrame([Cov], columns = [""Sequence"", ""Start"", ""End"", ""Coverage""])","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', ', 'Frame=pd.DataFrame([Cov], columns = [""Sequence"", ""Start"", ""End"", ""Coverage""])']","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', ', '                  names = [""Sequence"", ""Start"", ""End"", ""Coverage""])']","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', ']",,
34094058,"Cov = pd.read_csv(""path/to/file.txt"", sep='\t', header=None)
Cov.columns = [""Sequence"", ""Start"", ""End"", ""Coverage""]","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', header=None)']","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', header=None)', 'Cov.columns = [""Sequence"", ""Start"", ""End"", ""Coverage""]']","['Cov = pd.read_csv(""path/to/file.txt"", sep=\'\\t\', header=None)']",,
34097939,,[],[''],[],[],[]
34110546,"pivoted = pandas.pivot_table(data, values='score', columns='template', index='date')
pivoted.plot()","[""pivoted = pandas.pivot_table(data, values='score', columns='template', index='date')"", 'pivoted.plot()']","[""pivoted = pandas.pivot_table(data, values='score', columns='template', index='date')"", 'pivoted.plot()']","[""pivoted = pandas.pivot_table(data, values='score', columns='template', index='date')"", 'pivoted.plot()']",,
34130874,In[24]: df['no_cumulative'] = df.groupby(['name'])['no'].apply(lambda x: x.cumsum()),"[""In[24]: df['no_cumulative'] = df.groupby(['name'])['no'].apply(lambda x: x.cumsum())""]","[""In[24]: df['no_cumulative'] = df.groupby(['name'])['no'].apply(lambda x: x.cumsum())""]","[""In[24]: df['no_cumulative'] = df.groupby(['name'])['no'].apply(lambda x: x.cumsum())""]",,
34192820,"df.columns.values[2] = ""new_name""","['df.columns.values[2] = ""new_name""']","['df.columns.values[2] = ""new_name""']","['df.columns.values[2] = ""new_name""']",,
34262133,pd.DataFrame(df.to_records()) ,['pd.DataFrame(df.to_records()) '],[],['pd.DataFrame(df.to_records()) '],,
34272155,"import pandas as pd
df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})
df.drop_duplicates(subset=['A', 'C'], keep=False)","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['import pandas as pd', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","[""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]"
34277514,df['just_date'] = df['dates'].dt.date,"[""df['just_date'] = df['dates'].dt.date""]","[""df['just_date'] = df['dates'].dt.date""]","[""df['just_date'] = df['dates'].dt.date""]",,
34282362,"CACHE = {}
STORE = 'store.h5'   
def process_row(d, key, max_len=5000, _cache=CACHE):
    """"""
    Append row d to the store 'key'.
    When the number of items in the key's cache reaches max_len,
    append the list of rows to the HDF5 store and clear the list.
    """"""
    lst = _cache.setdefault(key, [])
    if len(lst) >= max_len:
        store_and_clear(lst, key)
    lst.append(d)
def store_and_clear(lst, key):
    """"""
    Convert key's cache list to a DataFrame and append that to HDF5.
    """"""
    df = pd.DataFrame(lst)
    with pd.HDFStore(STORE) as store:
        store.append(key, df)
    lst.clear()
process_row({'time' :'2013-01-01 00:00:00', 'stock' : 'BLAH', 'high' : 4.0, 'low' : 3.0, 'open' : 2.0, 'close' : 1.0},
            key=""df"")
for k, lst in CACHE.items():  
    store_and_clear(lst, k)
with pd.HDFStore(STORE) as store:
    df = store[""df""]                    
def get_latest(key, _cache=CACHE):
    store_and_clear(_cache[key], key)
    with pd.HDFStore(STORE) as store:
        return store[key]
df = get_latest(""df"")","['    lst.append(d)', '    df = pd.DataFrame(lst)', '        store.append(key, df)', '    lst.clear()']","['CACHE = {}', ""STORE = 'store.h5'   "", 'def process_row(d, key, max_len=5000, _cache=CACHE):', '    """"""', ""    Append row d to the store 'key'."", ""    When the number of items in the key's cache reaches max_len,"", '    append the list of rows to the HDF5 store and clear the list.', '    """"""', '    lst = _cache.setdefault(key, [])', '    if len(lst) >= max_len:', '        store_and_clear(lst, key)', '    lst.append(d)', 'def store_and_clear(lst, key):', '    """"""', ""    Convert key's cache list to a DataFrame and append that to HDF5."", '    """"""', '    with pd.HDFStore(STORE) as store:', '        store.append(key, df)', '    lst.clear()', ""process_row({'time' :'2013-01-01 00:00:00', 'stock' : 'BLAH', 'high' : 4.0, 'low' : 3.0, 'open' : 2.0, 'close' : 1.0},"", '            key=""df"")', 'for k, lst in CACHE.items():  ', '    store_and_clear(lst, k)', 'with pd.HDFStore(STORE) as store:', '    df = store[""df""]                    ', 'def get_latest(key, _cache=CACHE):', '    store_and_clear(_cache[key], key)', '    with pd.HDFStore(STORE) as store:', '        return store[key]', 'df = get_latest(""df"")']","['    lst.append(d)', '        store.append(key, df)', '    lst.clear()']",,
34297689,df3 = df3[~df3.index.duplicated(keep='first')],"[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]"
34311080,"t = pd.DataFrame({'a': range(0, 10000), 'b': range(10000, 20000)})
B = []
C = []
A = time.time()
for i,r in t.iterrows():
    C.append((r['a'], r['b']))
B.append(time.time()-A)
C = []
A = time.time()
for ir in t.itertuples():
    C.append((ir[1], ir[2]))    
B.append(time.time()-A)
C = []
A = time.time()
for r in zip(t['a'], t['b']):
    C.append((r[0], r[1]))
B.append(time.time()-A)
[0.5639059543609619, 0.017839908599853516, 0.005645036697387695]","[""t = pd.DataFrame({'a': range(0, 10000), 'b': range(10000, 20000)})"", 'A = time.time()', 'for i,r in t.iterrows():', ""    C.append((r['a'], r['b']))"", 'B.append(time.time()-A)', 'A = time.time()', 'for ir in t.itertuples():', '    C.append((ir[1], ir[2]))    ', 'B.append(time.time()-A)', 'A = time.time()', '    C.append((r[0], r[1]))', 'B.append(time.time()-A)']","['B = []', 'C = []', 'A = time.time()', 'for i,r in t.iterrows():', ""    C.append((r['a'], r['b']))"", 'B.append(time.time()-A)', 'C = []', 'A = time.time()', 'for ir in t.itertuples():', '    C.append((ir[1], ir[2]))    ', 'B.append(time.time()-A)', 'C = []', 'A = time.time()', ""for r in zip(t['a'], t['b']):"", '    C.append((r[0], r[1]))', 'B.append(time.time()-A)', '[0.5639059543609619, 0.017839908599853516, 0.005645036697387695]']","['A = time.time()', 'for i,r in t.iterrows():', ""    C.append((r['a'], r['b']))"", 'B.append(time.time()-A)', 'A = time.time()', 'for ir in t.itertuples():', '    C.append((ir[1], ir[2]))    ', 'B.append(time.time()-A)', 'A = time.time()', '    C.append((r[0], r[1]))', 'B.append(time.time()-A)']",,
34333886,"df_1['key1'] = 1
df_2['key2'] = 1
df_1 = pd.merge(df_1, df_2, on=['field_x', 'field_y'], how = 'left')
df_1 = df_1[~(df_1.key2 == df_1.key1)]
df_1 = df_1.drop(['key1','key2'], axis=1)","[""df_1 = pd.merge(df_1, df_2, on=['field_x', 'field_y'], how = 'left')"", ""df_1 = df_1.drop(['key1','key2'], axis=1)""]","[""df_1['key1'] = 1"", ""df_2['key2'] = 1"", ""df_1 = pd.merge(df_1, df_2, on=['field_x', 'field_y'], how = 'left')"", 'df_1 = df_1[~(df_1.key2 == df_1.key1)]', ""df_1 = df_1.drop(['key1','key2'], axis=1)""]","[""df_1 = pd.merge(df_1, df_2, on=['field_x', 'field_y'], how = 'left')"", ""df_1 = df_1.drop(['key1','key2'], axis=1)""]",,
34365537,"import pandas as pd
import numpy as np
from tqdm import tqdm, tqdm_pandas
df = pd.DataFrame(np.random.randint(0, int(1e8), (10000, 1000)))
tqdm_pandas(tqdm())
df.groupby(0).progress_apply(lambda x: x**2)
df_users.groupby(['userID', 'requestDate']).apply(feature_rollup)
from tqdm import tqdm, tqdm_pandas
tqdm_pandas(tqdm())
df_users.groupby(['userID', 'requestDate']).progress_apply(feature_rollup)","['df = pd.DataFrame(np.random.randint(0, int(1e8), (10000, 1000)))', 'df.groupby(0).progress_apply(lambda x: x**2)', ""df_users.groupby(['userID', 'requestDate']).apply(feature_rollup)"", ""df_users.groupby(['userID', 'requestDate']).progress_apply(feature_rollup)""]","['import pandas as pd', 'import numpy as np', 'from tqdm import tqdm, tqdm_pandas', 'tqdm_pandas(tqdm())', 'df.groupby(0).progress_apply(lambda x: x**2)', ""df_users.groupby(['userID', 'requestDate']).apply(feature_rollup)"", 'from tqdm import tqdm, tqdm_pandas', 'tqdm_pandas(tqdm())', ""df_users.groupby(['userID', 'requestDate']).progress_apply(feature_rollup)""]","['df.groupby(0).progress_apply(lambda x: x**2)', ""df_users.groupby(['userID', 'requestDate']).apply(feature_rollup)"", ""df_users.groupby(['userID', 'requestDate']).progress_apply(feature_rollup)""]",,
34402423,"from IPython.display import display
display(salaries.head())
display(teams.head())","['display(salaries.head())', 'display(teams.head())']","['from IPython.display import display', 'display(salaries.head())', 'display(teams.head())']","['display(salaries.head())', 'display(teams.head())']",,
34457902,"dummies = pd.get_dummies(df['Category']).rename(columns=lambda x: 'Category_' + str(x))
df = pd.concat([df, dummies], axis=1)
df = df.drop(['Category'], inplace=True, axis=1)","[""dummies = pd.get_dummies(df['Category']).rename(columns=lambda x: 'Category_' + str(x))"", 'df = pd.concat([df, dummies], axis=1)', ""df = df.drop(['Category'], inplace=True, axis=1)""]","[""dummies = pd.get_dummies(df['Category']).rename(columns=lambda x: 'Category_' + str(x))"", 'df = pd.concat([df, dummies], axis=1)', ""df = df.drop(['Category'], inplace=True, axis=1)""]","[""dummies = pd.get_dummies(df['Category']).rename(columns=lambda x: 'Category_' + str(x))"", 'df = pd.concat([df, dummies], axis=1)', ""df = df.drop(['Category'], inplace=True, axis=1)""]",,
34466473,"df = pd.DataFrame({'$a':['a', 'b', 'c', 'd', 'a'], '$b': np.arange(5)})
df.describe(include = 'all')
df.describe(include = [np.number])
25%     1.000000
50%     2.000000
75%     3.000000
df.describe(include = ['O'])","[""df = pd.DataFrame({'$a':['a', 'b', 'c', 'd', 'a'], '$b': np.arange(5)})"", ""df.describe(include = 'all')"", 'df.describe(include = [np.number])', ""df.describe(include = ['O'])""]","[""df.describe(include = 'all')"", 'df.describe(include = [np.number])', '25%     1.000000', '50%     2.000000', '75%     3.000000', ""df.describe(include = ['O'])""]","[""df.describe(include = 'all')"", 'df.describe(include = [np.number])', ""df.describe(include = ['O'])""]",,
34530065,"df._get_numeric_data()
data
data._get_numeric_data()",[],"['df._get_numeric_data()', 'data', 'data._get_numeric_data()']",[],[],[]
34531543,DF3 = DF[(DF['a'] == 0) |  (DF['b'] == 0)],[],"[""DF3 = DF[(DF['a'] == 0) |  (DF['b'] == 0)]""]",[],[],[]
34548894,,[],[''],[],[],[]
34551914,list(data_set.itertuples(index=False)),['list(data_set.itertuples(index=False))'],['list(data_set.itertuples(index=False))'],['list(data_set.itertuples(index=False))'],,
34555201,"import pandas as pd
import html5lib
f_states=   pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states') ","[""f_states=   pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states') ""]","['import pandas as pd', 'import html5lib', ""f_states=   pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states') ""]","[""f_states=   pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states') ""]",,
34576537,"df.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')","[""df.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')""]","[""df.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')""]","[""df.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')""]",,
34592295,,[],[''],[],[],[]
34614046,"df.drop(df.index[[1,3]], inplace=True)","['df.drop(df.index[[1,3]], inplace=True)']","['df.drop(df.index[[1,3]], inplace=True)']","['df.drop(df.index[[1,3]], inplace=True)']",,
34683105,"new = old[['A', 'C', 'D']].copy()
new = old.filter(['A','B','D'], axis=1)
new = old.drop('B', axis=1)","[""new = old[['A', 'C', 'D']].copy()"", ""new = old.filter(['A','B','D'], axis=1)"", ""new = old.drop('B', axis=1)""]","[""new = old[['A', 'C', 'D']].copy()"", ""new = old.filter(['A','B','D'], axis=1)"", ""new = old.drop('B', axis=1)""]","[""new = old[['A', 'C', 'D']].copy()"", ""new = old.filter(['A','B','D'], axis=1)"", ""new = old.drop('B', axis=1)""]",,
34687479,"t = pd.date_range(start=""2013-05-18 12:00:00"", periods=2, freq='H',
                          tz= ""Europe/Brussels"")
t
t.tz_localize(None)
t.tz_convert(None)
t = pd.date_range(start=""2013-05-18 12:00:00"", periods=10000, freq='H',
                           tz=""Europe/Brussels"")","['t = pd.date_range(start=""2013-05-18 12:00:00"", periods=2, freq=\'H\',', 't.tz_localize(None)', 't.tz_convert(None)', 't = pd.date_range(start=""2013-05-18 12:00:00"", periods=10000, freq=\'H\',']","['t = pd.date_range(start=""2013-05-18 12:00:00"", periods=2, freq=\'H\',', '                          tz= ""Europe/Brussels"")', 't', 't.tz_localize(None)', 't.tz_convert(None)', 't = pd.date_range(start=""2013-05-18 12:00:00"", periods=10000, freq=\'H\',', '                           tz=""Europe/Brussels"")']","['t = pd.date_range(start=""2013-05-18 12:00:00"", periods=2, freq=\'H\',', 't.tz_localize(None)', 't.tz_convert(None)', 't = pd.date_range(start=""2013-05-18 12:00:00"", periods=10000, freq=\'H\',']",,
34756965,"df.hist(bins=20, weights=np.ones_like(df[df.columns[0]]) * 100. / len(df))",[],"['df.hist(bins=20, weights=np.ones_like(df[df.columns[0]]) * 100. / len(df))']",[],[],[]
34790248,"df = df.sort_values(by=['c1','c2'], ascending=[False,True])","[""df = df.sort_values(by=['c1','c2'], ascending=[False,True])""]","[""df = df.sort_values(by=['c1','c2'], ascending=[False,True])""]","[""df = df.sort_values(by=['c1','c2'], ascending=[False,True])""]",,
34794112,"df.replace('N/A',np.NaN)
df.loc[df['y'] == 'N/A','y'] = np.nan
df","[""df.replace('N/A',np.NaN)"", ""df.loc[df['y'] == 'N/A','y'] = np.nan""]","[""df.replace('N/A',np.NaN)"", ""df.loc[df['y'] == 'N/A','y'] = np.nan"", 'df']","[""df.replace('N/A',np.NaN)"", ""df.loc[df['y'] == 'N/A','y'] = np.nan""]",,
34812293,df.loc['Total']= df.sum(),"[""df.loc['Total']= df.sum()""]","[""df.loc['Total']= df.sum()""]","[""df.loc['Total']= df.sum()""]",,
34863702,"df['id'].map(str.strip)
...
df['id'].str.strip()
s = pd.Series(['  a', 10])
s.astype(str).map(str.strip)
s.str.strip()
dtype: object","[""df['id'].map(str.strip)"", ""df['id'].str.strip()"", ""s = pd.Series(['  a', 10])"", 's.astype(str).map(str.strip)', 's.str.strip()']","[""df['id'].map(str.strip)"", '...', ""df['id'].str.strip()"", 's.astype(str).map(str.strip)', 's.str.strip()', 'dtype: object']","[""df['id'].map(str.strip)"", ""df['id'].str.strip()"", 's.astype(str).map(str.strip)', 's.str.strip()']",,
34879805,"df.sample(frac=1)
df = df.sample(frac=1).reset_index(drop=True)","['df.sample(frac=1)', 'df = df.sample(frac=1).reset_index(drop=True)']","['df.sample(frac=1)', 'df = df.sample(frac=1).reset_index(drop=True)']","['df.sample(frac=1)', 'df = df.sample(frac=1).reset_index(drop=True)']",,
34883876,"df['UNIXTIME'] = pd.to_datetime(df['UNIXTIME'], unit='ms')
df","[""df['UNIXTIME'] = pd.to_datetime(df['UNIXTIME'], unit='ms')""]","[""df['UNIXTIME'] = pd.to_datetime(df['UNIXTIME'], unit='ms')"", 'df']","[""df['UNIXTIME'] = pd.to_datetime(df['UNIXTIME'], unit='ms')""]",,
34896797,"df[df.columns[1:-1]].apply(lambda x: x.corr(df['special_col']))
stem2   -0.500000
stem3   -0.999945
b3      -0.500000
dtype: float64","[""df[df.columns[1:-1]].apply(lambda x: x.corr(df['special_col']))""]","[""df[df.columns[1:-1]].apply(lambda x: x.corr(df['special_col']))"", 'stem2   -0.500000', 'stem3   -0.999945', 'b3      -0.500000', 'dtype: float64']","[""df[df.columns[1:-1]].apply(lambda x: x.corr(df['special_col']))""]",,
34896835,"data[data.columns[1:]].corr()['special_col'][:-1]
np.corrcoef(data[data.columns[1:]].T)[-1][:-1]","[""data[data.columns[1:]].corr()['special_col'][:-1]"", 'np.corrcoef(data[data.columns[1:]].T)[-1][:-1]']","[""data[data.columns[1:]].corr()['special_col'][:-1]"", 'np.corrcoef(data[data.columns[1:]].T)[-1][:-1]']","[""data[data.columns[1:]].corr()['special_col'][:-1]"", 'np.corrcoef(data[data.columns[1:]].T)[-1][:-1]']",,
34897294,"df.corr().iloc[:-1,-1]
df.corr().ix['special_col', :-1]","['df.corr().iloc[:-1,-1]', ""df.corr().ix['special_col', :-1]""]","['df.corr().iloc[:-1,-1]', ""df.corr().ix['special_col', :-1]""]","['df.corr().iloc[:-1,-1]', ""df.corr().ix['special_col', :-1]""]",,
34916691,"res = df.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))
print(res)","[""res = df.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))""]","[""res = df.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))"", 'print(res)']","[""res = df.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))""]",,
34962199,"a,b
1,2
2,3
3,4
4,5
df['a'] = df['a'].apply(lambda x: x + 1)","[""df['a'] = df['a'].apply(lambda x: x + 1)""]","['a,b', '1,2', '2,3', '3,4', '4,5', ""df['a'] = df['a'].apply(lambda x: x + 1)""]","[""df['a'] = df['a'].apply(lambda x: x + 1)""]",,
34962592,"df = pd.DataFrame({'a': [100, 1000], 'b': [200, 2000], 'c': [300, 3000]})
df
df.a = df.a / 2
df","[""df = pd.DataFrame({'a': [100, 1000], 'b': [200, 2000], 'c': [300, 3000]})""]","['df', 'df.a = df.a / 2', 'df']",[],,
34996876,"table = [[1 , 2], [3, 4]]
df = DataFrame(table)
df = df.transpose()
df.columns = ['Heading1', 'Heading2']",['df = df.transpose()'],"['table = [[1 , 2], [3, 4]]', 'df = DataFrame(table)', 'df = df.transpose()', ""df.columns = ['Heading1', 'Heading2']""]",['df = df.transpose()'],,
35068123,df.columns = df.columns.str.slice(1),['df.columns = df.columns.str.slice(1)'],['df.columns = df.columns.str.slice(1)'],['df.columns = df.columns.str.slice(1)'],,
35087831,"from StringIO import StringIO
dff = pd.read_csv(StringIO(raw), sep='\s+')","[""dff = pd.read_csv(StringIO(raw), sep='\\s+')""]","['from StringIO import StringIO', ""dff = pd.read_csv(StringIO(raw), sep='\\s+')""]","[""dff = pd.read_csv(StringIO(raw), sep='\\s+')""]",,
35106735,,[],[''],[],[],[]
35138807,"import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(1,7).reshape(2,3),
                  columns = list('abc'),
                  index=pd.Series([2,5], name='b'))
df
b
df.index.get_loc(5)
1","['df = pd.DataFrame(np.arange(1,7).reshape(2,3),', ""                  index=pd.Series([2,5], name='b'))"", 'df.index.get_loc(5)']","['import pandas as pd', 'import numpy as np', ""                  columns = list('abc'),"", 'df', 'b', 'df.index.get_loc(5)', '1']",['df.index.get_loc(5)'],,
35139819,"4.9,3.0,1.4,0.6
4.8,2.8,1.3,1.2",[],"['4.9,3.0,1.4,0.6', '4.8,2.8,1.3,1.2']",[],[],[]
35203149,"columns = ['b', 'c']
df1 = pd.DataFrame(df, columns=columns)","['df1 = pd.DataFrame(df, columns=columns)']","[""columns = ['b', 'c']""]",[],,
35203658,"import datetime 
df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]","['df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]']","['import datetime ', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]']","['df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]']",,
35212740,"data = pd.read_csv('file1.csv', error_bad_lines=False)
line     = []
expected = []
saw      = []     
cont     = True 
while cont == True:     
    try:
        data = pd.read_csv('file1.csv',skiprows=line)
        cont = False
    except Exception as e:    
        errortype = e.message.split('.')[0].strip()                                
        if errortype == 'Error tokenizing data':                        
           cerror      = e.message.split(':')[1].strip().replace(',','')
           nums        = [n for n in cerror.split(' ') if str.isdigit(n)]
           expected.append(int(nums[0]))
           saw.append(int(nums[2]))
           line.append(int(nums[1])-1)
           cerror      = 'Unknown'","[""data = pd.read_csv('file1.csv', error_bad_lines=False)"", ""        data = pd.read_csv('file1.csv',skiprows=line)"", ""        errortype = e.message.split('.')[0].strip()                                "", ""           cerror      = e.message.split(':')[1].strip().replace(',','')"", ""           nums        = [n for n in cerror.split(' ') if str.isdigit(n)]"", '           expected.append(int(nums[0]))', '           saw.append(int(nums[2]))', '           line.append(int(nums[1])-1)']","[""data = pd.read_csv('file1.csv', error_bad_lines=False)"", 'line     = []', 'expected = []', 'saw      = []     ', 'cont     = True ', 'while cont == True:     ', '    try:', ""        data = pd.read_csv('file1.csv',skiprows=line)"", '        cont = False', '    except Exception as e:    ', ""        errortype = e.message.split('.')[0].strip()                                "", ""        if errortype == 'Error tokenizing data':                        "", ""           cerror      = e.message.split(':')[1].strip().replace(',','')"", ""           nums        = [n for n in cerror.split(' ') if str.isdigit(n)]"", '           expected.append(int(nums[0]))', '           saw.append(int(nums[2]))', '           line.append(int(nums[1])-1)', ""           cerror      = 'Unknown'""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)"", ""        data = pd.read_csv('file1.csv',skiprows=line)"", ""        errortype = e.message.split('.')[0].strip()                                "", ""           cerror      = e.message.split(':')[1].strip().replace(',','')"", ""           nums        = [n for n in cerror.split(' ') if str.isdigit(n)]"", '           expected.append(int(nums[0]))', '           saw.append(int(nums[2]))', '           line.append(int(nums[1])-1)']",,
35219658,"df.ix[:, df.columns != col]",[],"['df.ix[:, df.columns != col]']",[],[],[]
35240942,,[],[''],[],[],[]
35245297,"import pandas
import numpy
dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32')]
values = numpy.zeros(20, dtype=dtype)
index = ['Row'+str(i) for i in range(1, len(values)+1)]
df = pandas.DataFrame(values, index=index)","['df = pandas.DataFrame(values, index=index)']","['import pandas', 'import numpy', ""dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32')]"", 'values = numpy.zeros(20, dtype=dtype)', ""index = ['Row'+str(i) for i in range(1, len(values)+1)]""]",[],,
35246041,"test = pd.read_csv('https://docs.google.com/spreadsheets/d/' + 
                   '0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc' +
                   '/export?gid=0&format=csv',
                   index_col=0,
                   parse_dates=['Quradate']
                  )
test.head(5)  ","[""test = pd.read_csv('https://docs.google.com/spreadsheets/d/' + "", 'test.head(5)  ']","[""test = pd.read_csv('https://docs.google.com/spreadsheets/d/' + "", ""                   '0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc' +"", ""                   '/export?gid=0&format=csv',"", '                   index_col=0,', ""                   parse_dates=['Quradate']"", '                  )', 'test.head(5)  ']","[""test = pd.read_csv('https://docs.google.com/spreadsheets/d/' + "", 'test.head(5)  ']",,
35282530,"n = 10
df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))
df
df[(df.a < df.b) & (df.b < df.c)]
df.query('(a < b) & (b < c)')
exclude = ('red', 'orange')
df.query('color not in @exclude')","[""df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))"", ""df.query('(a < b) & (b < c)')"", ""df.query('color not in @exclude')""]","['n = 10', 'df', 'df[(df.a < df.b) & (df.b < df.c)]', ""df.query('(a < b) & (b < c)')"", ""exclude = ('red', 'orange')"", ""df.query('color not in @exclude')""]","[""df.query('(a < b) & (b < c)')"", ""df.query('color not in @exclude')""]",,
35318270,"mean_ratings = data.pivot_table('rating', rows='title', cols='gender', aggfunc='mean')
mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')","[""mean_ratings = data.pivot_table('rating', rows='title', cols='gender', aggfunc='mean')"", ""mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')""]","[""mean_ratings = data.pivot_table('rating', rows='title', cols='gender', aggfunc='mean')"", ""mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')""]","[""mean_ratings = data.pivot_table('rating', rows='title', cols='gender', aggfunc='mean')"", ""mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')""]",,
35368792,"df.index = df.index.map(unicode) 
df.index = df.index.map(str)","['df.index = df.index.map(unicode) ', 'df.index = df.index.map(str)']","['df.index = df.index.map(unicode) ', 'df.index = df.index.map(str)']","['df.index = df.index.map(unicode) ', 'df.index = df.index.map(str)']",,
35385805,"df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df], 
        axis=1, inplace=True)","[""df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df], ""]","[""df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df], "", '        axis=1, inplace=True)']","[""df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df], ""]",,
35387028,,[],[''],[],[],[]
35387129,"df['e'] = e.values
df1 = df1.assign(e=e.values)
df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
df.assign(mean_a=df.a.mean(), mean_b=df.b.mean())
np.random.seed(0)
df1 = pd.DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])
mask = df1.applymap(lambda x: x <-0.7)
df1 = df1[-mask.any(axis=1)]
sLength = len(df1['a'])
e = pd.Series(np.random.randn(sLength))
df1
e
0   -1.048553
1   -1.420018
2   -1.706270
4   -0.509652
dtype: float64
df1 = df1.assign(e=e.values)
df1","[""df['e'] = e.values"", 'df1 = df1.assign(e=e.values)', ""df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})"", 'df.assign(mean_a=df.a.mean(), mean_b=df.b.mean())', ""df1 = pd.DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])"", 'mask = df1.applymap(lambda x: x <-0.7)', 'df1 = df1[-mask.any(axis=1)]', 'e = pd.Series(np.random.randn(sLength))', 'df1 = df1.assign(e=e.values)']","[""df['e'] = e.values"", 'df1 = df1.assign(e=e.values)', 'df.assign(mean_a=df.a.mean(), mean_b=df.b.mean())', 'np.random.seed(0)', 'mask = df1.applymap(lambda x: x <-0.7)', 'df1 = df1[-mask.any(axis=1)]', ""sLength = len(df1['a'])"", 'df1', 'e', '0   -1.048553', '1   -1.420018', '2   -1.706270', '4   -0.509652', 'dtype: float64', 'df1 = df1.assign(e=e.values)', 'df1']","[""df['e'] = e.values"", 'df1 = df1.assign(e=e.values)', 'df.assign(mean_a=df.a.mean(), mean_b=df.b.mean())', 'mask = df1.applymap(lambda x: x <-0.7)', 'df1 = df1[-mask.any(axis=1)]', 'df1 = df1.assign(e=e.values)']",,
35415751,"df.groupby(['year', 'month', 'item'])['value'].sum().unstack('item')
df.pivot_table(values='value', index=['year', 'month'], columns='item')","[""df.groupby(['year', 'month', 'item'])['value'].sum().unstack('item')"", ""df.pivot_table(values='value', index=['year', 'month'], columns='item')""]","[""df.groupby(['year', 'month', 'item'])['value'].sum().unstack('item')"", ""df.pivot_table(values='value', index=['year', 'month'], columns='item')""]","[""df.groupby(['year', 'month', 'item'])['value'].sum().unstack('item')"", ""df.pivot_table(values='value', index=['year', 'month'], columns='item')""]",,
35416021,"df.set_index(['year', 'month', 'item']).unstack(level=-1)","[""df.set_index(['year', 'month', 'item']).unstack(level=-1)""]","[""df.set_index(['year', 'month', 'item']).unstack(level=-1)""]","[""df.set_index(['year', 'month', 'item']).unstack(level=-1)""]",,
35446404,"import pandas as pd
import numpy as np
from matplotlib.ticker import FuncFormatter
df = pd.DataFrame(np.random.randn(100,5))
ax = df.plot()
ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) ","['df = pd.DataFrame(np.random.randn(100,5))', 'ax = df.plot()', ""ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) ""]","['import pandas as pd', 'import numpy as np', 'from matplotlib.ticker import FuncFormatter', 'ax = df.plot()', ""ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) ""]","['ax = df.plot()', ""ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) ""]",,
35453836,"ax = data.plot(...)
ax.grid(False)
ax.right_ax(False)",['ax = data.plot(...)'],"['ax = data.plot(...)', 'ax.grid(False)', 'ax.right_ax(False)']",['ax = data.plot(...)'],,
35476539,,[],[''],[],[],[]
35509134,"import pandas as pd
list=[['a','b']]
list.append(['e','f'])
df=pd.DataFrame(list,columns=['col1','col2'])","[""list.append(['e','f'])"", ""df=pd.DataFrame(list,columns=['col1','col2'])""]","['import pandas as pd', ""list=[['a','b']]"", ""list.append(['e','f'])""]","[""list.append(['e','f'])""]",,
35523946,"Count_Row=df.shape[0] 
Count_Col=df.shape[1] ","['Count_Row=df.shape[0] ', 'Count_Col=df.shape[1] ']","['Count_Row=df.shape[0] ', 'Count_Col=df.shape[1] ']","['Count_Row=df.shape[0] ', 'Count_Col=df.shape[1] ']",,
35531218,"train=df.sample(frac=0.8,random_state=200)
test=df.drop(train.index)","['train=df.sample(frac=0.8,random_state=200)', 'test=df.drop(train.index)']","['train=df.sample(frac=0.8,random_state=200)', 'test=df.drop(train.index)']","['train=df.sample(frac=0.8,random_state=200)', 'test=df.drop(train.index)']",,
35583219,"f = pandas.DataFrame(data = {'Animal':['cow','horse'], 'Color':['blue', 'red']})
f
f.append({'Animal':'mouse', 'Color':'black'}, ignore_index=True)","[""f = pandas.DataFrame(data = {'Animal':['cow','horse'], 'Color':['blue', 'red']})"", ""f.append({'Animal':'mouse', 'Color':'black'}, ignore_index=True)""]","['f', ""f.append({'Animal':'mouse', 'Color':'black'}, ignore_index=True)""]","[""f.append({'Animal':'mouse', 'Color':'black'}, ignore_index=True)""]",,
35616082,a.to_frame().join(b.to_frame()),['a.to_frame().join(b.to_frame())'],['a.to_frame().join(b.to_frame())'],['a.to_frame().join(b.to_frame())'],,
35619846,"class SubclassedDataFrame(DataFrame):
    _metadata = ['added_property']
    added_property = 1  
    @property
    def _constructor(self):
        return SubclassedDataFrame",[],"['class SubclassedDataFrame(DataFrame):', ""    _metadata = ['added_property']"", '    added_property = 1  ', '    @property', '    def _constructor(self):', '        return SubclassedDataFrame']",[],[],[]
35715029,"import matplotlib.pyplot as plt
import pandas as pd
from pandas.tools.plotting import table
ax = plt.subplot(111, frame_on=False) 
ax.xaxis.set_visible(False)  
ax.yaxis.set_visible(False)  
table(ax, df)  
plt.savefig('mytable.png')
dtype: float64
df = df.reset_index() 
df
df.ix[df.duplicated('first') , 'first'] = ''
df
new_cols = df.columns.values
new_cols[:2] = '',''  
df.columns = new_cols 
table(ax, df, rowLabels=['']*df.shape[0], loc='center')","['df = df.reset_index() ', ""df.ix[df.duplicated('first') , 'first'] = ''"", 'new_cols = df.columns.values', ""table(ax, df, rowLabels=['']*df.shape[0], loc='center')""]","['import matplotlib.pyplot as plt', 'import pandas as pd', 'from pandas.tools.plotting import table', 'ax = plt.subplot(111, frame_on=False) ', 'ax.xaxis.set_visible(False)  ', 'ax.yaxis.set_visible(False)  ', 'table(ax, df)  ', ""plt.savefig('mytable.png')"", 'dtype: float64', 'df = df.reset_index() ', 'df', ""df.ix[df.duplicated('first') , 'first'] = ''"", 'df', 'new_cols = df.columns.values', ""new_cols[:2] = '',''  "", 'df.columns = new_cols ', ""table(ax, df, rowLabels=['']*df.shape[0], loc='center')""]","['df = df.reset_index() ', ""df.ix[df.duplicated('first') , 'first'] = ''"", 'new_cols = df.columns.values', ""table(ax, df, rowLabels=['']*df.shape[0], loc='center')""]",,
35768306,"df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)","[""df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)""]",,
35783766,"s.loc[(~np.isfinite(s)) & s.notnull()] = np.nan
df = pd.DataFrame(np.ones((3, 3)), columns=list('ABC'))
for i in range(3): 
    df.iat[i, i] = np.inf
df
df.sum()
dtype: float64
df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()
dtype: float64","['s.loc[(~np.isfinite(s)) & s.notnull()] = np.nan', ""df = pd.DataFrame(np.ones((3, 3)), columns=list('ABC'))"", '    df.iat[i, i] = np.inf', 'df.sum()', 'df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()']","['s.loc[(~np.isfinite(s)) & s.notnull()] = np.nan', 'for i in range(3): ', '    df.iat[i, i] = np.inf', 'df', 'df.sum()', 'dtype: float64', 'df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()', 'dtype: float64']","['s.loc[(~np.isfinite(s)) & s.notnull()] = np.nan', '    df.iat[i, i] = np.inf', 'df.sum()', 'df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()']",,
35784666,df.sample(frac=1),['df.sample(frac=1)'],['df.sample(frac=1)'],['df.sample(frac=1)'],,
35850749,import pandas as pd,[],['import pandas as pd'],[],[],[]
35902487,"ax.axvline(pd.to_datetime('2015-11-01'), color='r', linestyle='--', lw=2)
xposition = [pd.to_datetime('2010-01-01'), pd.to_datetime('2015-12-31')]
for xc in xposition:
    ax.axvline(x=xc, color='k', linestyle='-')","[""ax.axvline(pd.to_datetime('2015-11-01'), color='r', linestyle='--', lw=2)"", ""xposition = [pd.to_datetime('2010-01-01'), pd.to_datetime('2015-12-31')]""]","[""ax.axvline(pd.to_datetime('2015-11-01'), color='r', linestyle='--', lw=2)"", ""xposition = [pd.to_datetime('2010-01-01'), pd.to_datetime('2015-12-31')]"", 'for xc in xposition:', ""    ax.axvline(x=xc, color='k', linestyle='-')""]","[""ax.axvline(pd.to_datetime('2015-11-01'), color='r', linestyle='--', lw=2)"", ""xposition = [pd.to_datetime('2010-01-01'), pd.to_datetime('2015-12-31')]""]",,
35970794,"df = pd.DataFrame.from_records([{ 'A':a,'B':b }])
df = pd.DataFrame.from_records([{ 'A':a,'B':b }], index='A')","[""df = pd.DataFrame.from_records([{ 'A':a,'B':b }])"", ""df = pd.DataFrame.from_records([{ 'A':a,'B':b }], index='A')""]",[],"[""df = pd.DataFrame.from_records([{ 'A':a,'B':b }])"", ""df = pd.DataFrame.from_records([{ 'A':a,'B':b }], index='A')""]",,
36001191,"np.isnan(np.array([np.nan, 0], dtype=np.float64))
np.isnan(np.array([np.nan, 0], dtype=object))
pd.isnull(np.array([np.nan, 0], dtype=float))
pd.isnull(np.array([np.nan, 0], dtype=object))
Out[98]: array([ True, False], dtype=bool)","['pd.isnull(np.array([np.nan, 0], dtype=float))', 'pd.isnull(np.array([np.nan, 0], dtype=object))']","['np.isnan(np.array([np.nan, 0], dtype=np.float64))', 'np.isnan(np.array([np.nan, 0], dtype=object))', 'pd.isnull(np.array([np.nan, 0], dtype=float))', 'pd.isnull(np.array([np.nan, 0], dtype=object))', 'Out[98]: array([ True, False], dtype=bool)']","['pd.isnull(np.array([np.nan, 0], dtype=float))', 'pd.isnull(np.array([np.nan, 0], dtype=object))']",,
36012306,"import pandas as pd
pd.__version__
'0.14.1'",[],"['import pandas as pd', 'pd.__version__', ""'0.14.1'""]",[],[],[]
36013757,"foo              
foo              
foo              ",[],"['foo              ', 'foo              ', 'foo              ']",[],[],[]
36014326,"foo              
foo
None",[],"['foo              ', 'foo', 'None']",[],[],[]
36041831,"import pandas as pd
df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': ['q1', 'q2']})
df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)
import pandas as pd
df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': [1, 2]})
df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}q{}'.format(x[0],x[1]), axis=1)
dtype: object","[""df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': ['q1', 'q2']})"", ""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)"", ""df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': [1, 2]})"", ""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}q{}'.format(x[0],x[1]), axis=1)""]","['import pandas as pd', ""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)"", 'import pandas as pd', ""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}q{}'.format(x[0],x[1]), axis=1)"", 'dtype: object']","[""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)"", ""df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}q{}'.format(x[0],x[1]), axis=1)""]",,
36059898,"df['Age_group'] = np.where(df.Age<18, 'under 18',
                           np.where(df.Age<40,'under 40', '>40'))","[""df['Age_group'] = np.where(df.Age<18, 'under 18',"", ""                           np.where(df.Age<40,'under 40', '>40'))""]","[""df['Age_group'] = np.where(df.Age<18, 'under 18',"", ""                           np.where(df.Age<40,'under 40', '>40'))""]","[""df['Age_group'] = np.where(df.Age<18, 'under 18',"", ""                           np.where(df.Age<40,'under 40', '>40'))""]",,
36073837,df.groupby('id').nth(1) ,"[""df.groupby('id').nth(1) ""]","[""df.groupby('id').nth(1) ""]","[""df.groupby('id').nth(1) ""]",,
36074520,"In[34]: df.sort_values(['job','count'],ascending=False).groupby('job').head(3)","[""In[34]: df.sort_values(['job','count'],ascending=False).groupby('job').head(3)""]","[""In[34]: df.sort_values(['job','count'],ascending=False).groupby('job').head(3)""]","[""In[34]: df.sort_values(['job','count'],ascending=False).groupby('job').head(3)""]",,
36082588,"df = pd.DataFrame(columns=['Year', 'Month ', 'Value'])
print(df.columns.tolist())
df.columns = df.columns.str.strip()
df.columns.tolist()
['Year', 'Month ', 'Value']
['Year', 'Month', 'Value']","[""df = pd.DataFrame(columns=['Year', 'Month ', 'Value'])"", 'print(df.columns.tolist())', 'df.columns = df.columns.str.strip()', 'df.columns.tolist()']","['print(df.columns.tolist())', 'df.columns = df.columns.str.strip()', 'df.columns.tolist()', ""['Year', 'Month ', 'Value']"", ""['Year', 'Month', 'Value']""]","['print(df.columns.tolist())', 'df.columns = df.columns.str.strip()', 'df.columns.tolist()']",,
36091388,"import random
n_samples = 10
samples = []
for i, line in enumerate(f):
    if i < n_samples:
        samples.append(line)
    elif random.random() < n_samples * 1. / (i+1):
            samples[random.randint(0, n_samples-1)] = line",['        samples.append(line)'],"['import random', 'n_samples = 10', 'samples = []', 'for i, line in enumerate(f):', '    if i < n_samples:', '        samples.append(line)', '    elif random.random() < n_samples * 1. / (i+1):', '            samples[random.randint(0, n_samples-1)] = line']",['        samples.append(line)'],,
36149967,"df.columns = ['a', 'b', 'c', 'd', 'e']
df.columns.values[2] = 'c'    ","[""df.columns.values[2] = 'c'    ""]","[""df.columns = ['a', 'b', 'c', 'd', 'e']"", ""df.columns.values[2] = 'c'    ""]","[""df.columns.values[2] = 'c'    ""]",,
36184396,,[],[''],[],[],[]
36188131,,[],[''],[],[],[]
36226137,"df
pd.isnull(df).sum() > 0
df.isnull().any()
df.columns[df.isnull().any()].tolist()
df.loc[:, df.isnull().any()]","['pd.isnull(df).sum() > 0', 'df.isnull().any()', 'df.columns[df.isnull().any()].tolist()', 'df.loc[:, df.isnull().any()]']","['df', 'pd.isnull(df).sum() > 0', 'df.isnull().any()', 'df.columns[df.isnull().any()].tolist()', 'df.loc[:, df.isnull().any()]']","['pd.isnull(df).sum() > 0', 'df.isnull().any()', 'df.columns[df.isnull().any()].tolist()', 'df.loc[:, df.isnull().any()]']",,
36236885,"w.female.replace(to_replace=dict(female=1, male=0), inplace=True)","['w.female.replace(to_replace=dict(female=1, male=0), inplace=True)']","['w.female.replace(to_replace=dict(female=1, male=0), inplace=True)']","['w.female.replace(to_replace=dict(female=1, male=0), inplace=True)']",,
36257640,"pd.read_sql(session.query(Complaint).filter(Complaint.id == 2).statement,session.bind) ","['pd.read_sql(session.query(Complaint).filter(Complaint.id == 2).statement,session.bind) ']","['pd.read_sql(session.query(Complaint).filter(Complaint.id == 2).statement,session.bind) ']","['pd.read_sql(session.query(Complaint).filter(Complaint.id == 2).statement,session.bind) ']",,
36319915,"import matplotlib.ticker as mtick
ax = df['myvar'].plot(kind='bar')
ax.yaxis.set_major_formatter(mtick.PercentFormatter())","[""ax = df['myvar'].plot(kind='bar')""]","['import matplotlib.ticker as mtick', ""ax = df['myvar'].plot(kind='bar')"", 'ax.yaxis.set_major_formatter(mtick.PercentFormatter())']","[""ax = df['myvar'].plot(kind='bar')""]",,
36372667,,[],[''],[],[],[]
36373866,"pd.set_option('display.large_repr', 'truncate')
pd.set_option('display.max_columns', 0)","[""pd.set_option('display.large_repr', 'truncate')"", ""pd.set_option('display.max_columns', 0)""]","[""pd.set_option('display.large_repr', 'truncate')"", ""pd.set_option('display.max_columns', 0)""]","[""pd.set_option('display.large_repr', 'truncate')"", ""pd.set_option('display.max_columns', 0)""]",,
36416258,"path = r'C:\DRO\DCL_rawdata_files'                     
all_files = glob.glob(os.path.join(path, ""*.csv""))     
df_from_each_file = (pd.read_csv(f) for f in all_files)
concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)","['all_files = glob.glob(os.path.join(path, ""*.csv""))     ', 'df_from_each_file = (pd.read_csv(f) for f in all_files)', 'concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)']","[""path = r'C:\\DRO\\DCL_rawdata_files'                     "", 'all_files = glob.glob(os.path.join(path, ""*.csv""))     ', 'df_from_each_file = (pd.read_csv(f) for f in all_files)', 'concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)']","['all_files = glob.glob(os.path.join(path, ""*.csv""))     ', 'df_from_each_file = (pd.read_csv(f) for f in all_files)', 'concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)']",,
36434248,df.apply(pd.value_counts),['df.apply(pd.value_counts)'],['df.apply(pd.value_counts)'],['df.apply(pd.value_counts)'],,
36475297,"import pandas as pd
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
dfTest = pd.DataFrame({'A':[14.00,90.20,90.95,96.27,91.21],
                           'B':[103.02,107.26,110.35,114.23,114.68],
                           'C':['big','small','big','small','small']})
dfTest[['A', 'B']] = scaler.fit_transform(dfTest[['A', 'B']])
dfTest","[""dfTest = pd.DataFrame({'A':[14.00,90.20,90.95,96.27,91.21],""]","['import pandas as pd', 'from sklearn.preprocessing import MinMaxScaler', 'scaler = MinMaxScaler()', ""                           'B':[103.02,107.26,110.35,114.23,114.68],"", ""                           'C':['big','small','big','small','small']})"", ""dfTest[['A', 'B']] = scaler.fit_transform(dfTest[['A', 'B']])"", 'dfTest']",[],,
36513262,"Cols = list(df.columns)
for i,item in enumerate(df.columns):
    if item in df.columns[:i]: Cols[i] = ""toDROP""
df.columns = Cols
df = df.drop(""toDROP"",1)","['df = df.drop(""toDROP"",1)']","['Cols = list(df.columns)', 'for i,item in enumerate(df.columns):', '    if item in df.columns[:i]: Cols[i] = ""toDROP""', 'df.columns = Cols', 'df = df.drop(""toDROP"",1)']","['df = df.drop(""toDROP"",1)']",,
36519122,"df = pd.DataFrame(np.random.randn(5,3), columns=list('abc'))
pd.read_csv(io.StringIO(df.to_csv()))
pd.read_csv(io.StringIO(df.to_csv(index=False)))
pd.read_csv(io.StringIO(df.to_csv()), index_col=0)","[""df = pd.DataFrame(np.random.randn(5,3), columns=list('abc'))"", 'pd.read_csv(io.StringIO(df.to_csv()))', 'pd.read_csv(io.StringIO(df.to_csv(index=False)))', 'pd.read_csv(io.StringIO(df.to_csv()), index_col=0)']","['pd.read_csv(io.StringIO(df.to_csv()))', 'pd.read_csv(io.StringIO(df.to_csv(index=False)))', 'pd.read_csv(io.StringIO(df.to_csv()), index_col=0)']","['pd.read_csv(io.StringIO(df.to_csv()))', 'pd.read_csv(io.StringIO(df.to_csv(index=False)))', 'pd.read_csv(io.StringIO(df.to_csv()), index_col=0)']",,
36539513,"import numpy as np
import pandas as pd
from collections import OrderedDict
foo = np.array( [ 1, 2, 3 ] )
bar = np.array( [ 4, 5, 6 ] )
pd.DataFrame( OrderedDict( { 'foo': pd.Series(foo), 'bar': pd.Series(bar) } ) )
import numpy as np
import pandas as pd
from collections import OrderedDict
a = np.array( [ 1, 2, 3 ] )
b = np.array( [ 4, 5, 6 ] )
c = np.array( [ 7, 8, 9 ] )
pd.DataFrame( OrderedDict( { 'a': pd.Series(a), 'b': pd.Series(b), 'c': pd.Series(c) } ) )
pd.DataFrame( OrderedDict( (('a', pd.Series(a)), ('b', pd.Series(b)), ('c', pd.Series(c))) ) )","[""pd.DataFrame( OrderedDict( { 'foo': pd.Series(foo), 'bar': pd.Series(bar) } ) )"", ""pd.DataFrame( OrderedDict( { 'a': pd.Series(a), 'b': pd.Series(b), 'c': pd.Series(c) } ) )"", ""pd.DataFrame( OrderedDict( (('a', pd.Series(a)), ('b', pd.Series(b)), ('c', pd.Series(c))) ) )""]","['import numpy as np', 'import pandas as pd', 'from collections import OrderedDict', 'foo = np.array( [ 1, 2, 3 ] )', 'bar = np.array( [ 4, 5, 6 ] )', 'import numpy as np', 'import pandas as pd', 'from collections import OrderedDict', 'a = np.array( [ 1, 2, 3 ] )', 'b = np.array( [ 4, 5, 6 ] )', 'c = np.array( [ 7, 8, 9 ] )']",[],,
36572039,"df.read_csv(filename ,  index = False)  ","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']"
36590692,"import pandas
df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')
df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=2)","[""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')"", ""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=2)""]","['import pandas', ""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')"", ""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=2)""]","[""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')"", ""df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=2)""]",,
36682678,"df
df = df.xs('a', axis=1, drop_level=True)
df","[""df = df.xs('a', axis=1, drop_level=True)""]","['df', ""df = df.xs('a', axis=1, drop_level=True)"", 'df']","[""df = df.xs('a', axis=1, drop_level=True)""]",,
36685531,"df
df.loc[df['B'] == 3, 'A']
df.loc[df['B'] == 3, 'A'].iloc[0]
Out[4]: 'p3'","[""df.loc[df['B'] == 3, 'A']"", ""df.loc[df['B'] == 3, 'A'].iloc[0]""]","['df', ""df.loc[df['B'] == 3, 'A']"", ""df.loc[df['B'] == 3, 'A'].iloc[0]"", ""Out[4]: 'p3'""]","[""df.loc[df['B'] == 3, 'A']"", ""df.loc[df['B'] == 3, 'A'].iloc[0]""]",,
36694513,"pd.core.format.header_style = None
import pandas as pd
data = pd.DataFrame({'test_data': [1,2,3,4,5]})
writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')
pd.core.format.header_style = None
data.to_excel(writer, sheet_name='test', index=False)
workbook  = writer.book
worksheet = writer.sheets['test']
font_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10})
header_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10, 'bold': True})
worksheet.set_column('A:A', None, font_fmt)
worksheet.set_row(0, None, header_fmt)
writer.save()
pd.core.format.header_style = None
pd.formats.format.header_style = None","['pd.core.format.header_style = None', ""data = pd.DataFrame({'test_data': [1,2,3,4,5]})"", 'pd.core.format.header_style = None', ""data.to_excel(writer, sheet_name='test', index=False)"", 'pd.core.format.header_style = None', 'pd.formats.format.header_style = None']","['pd.core.format.header_style = None', 'import pandas as pd', ""writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')"", 'pd.core.format.header_style = None', ""data.to_excel(writer, sheet_name='test', index=False)"", 'workbook  = writer.book', ""worksheet = writer.sheets['test']"", ""font_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10})"", ""header_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10, 'bold': True})"", ""worksheet.set_column('A:A', None, font_fmt)"", 'worksheet.set_row(0, None, header_fmt)', 'writer.save()', 'pd.core.format.header_style = None', 'pd.formats.format.header_style = None']","['pd.core.format.header_style = None', 'pd.core.format.header_style = None', ""data.to_excel(writer, sheet_name='test', index=False)"", 'pd.core.format.header_style = None', 'pd.formats.format.header_style = None']",,
36704460,"df['RN'] = df.sort_values(['data1','data2'], ascending=[True,False]) \
             .groupby(['key1']) \
             .cumcount() + 1
print(df)","[""df['RN'] = df.sort_values(['data1','data2'], ascending=[True,False]) \\""]","[""df['RN'] = df.sort_values(['data1','data2'], ascending=[True,False]) \\"", ""             .groupby(['key1']) \\"", '             .cumcount() + 1', 'print(df)']","[""df['RN'] = df.sort_values(['data1','data2'], ascending=[True,False]) \\""]",,
36709634,,[],[''],[],[],[]
36710126,,[],[''],[],[],[]
36725677,"import blaze as bz
import pandas as pd
df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':[2,4,6,8,10]})","[""df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':[2,4,6,8,10]})""]","['import blaze as bz', 'import pandas as pd']",[],,
36816769,"out.apply(pd.Series)
out.columns=['Kstats','Pvalue']
out.index.name=None","['out.apply(pd.Series)', 'out.index.name=None']","[""out.columns=['Kstats','Pvalue']"", 'out.index.name=None']","['out.apply(pd.Series)', 'out.index.name=None']",,
36893675,"merged = df1.merge(df2, indicator=True, how='outer')
merged[merged['_merge'] == 'right_only']","[""merged = df1.merge(df2, indicator=True, how='outer')""]","[""merged = df1.merge(df2, indicator=True, how='outer')"", ""merged[merged['_merge'] == 'right_only']""]","[""merged = df1.merge(df2, indicator=True, how='outer')""]",,
36911306,"df['period'] = df['Year'].astype(str) + df['quarter']
df['period'] = df[['Year','quarter']].astype(str).sum(axis=1)
df
df = pd.concat([df] * 10**5)
df.shape","[""df['period'] = df['Year'].astype(str) + df['quarter']"", ""df['period'] = df[['Year','quarter']].astype(str).sum(axis=1)"", 'df = pd.concat([df] * 10**5)', 'df.shape']","[""df['period'] = df['Year'].astype(str) + df['quarter']"", ""df['period'] = df[['Year','quarter']].astype(str).sum(axis=1)"", 'df', 'df = pd.concat([df] * 10**5)', 'df.shape']","[""df['period'] = df['Year'].astype(str) + df['quarter']"", ""df['period'] = df[['Year','quarter']].astype(str).sum(axis=1)"", 'df = pd.concat([df] * 10**5)', 'df.shape']",,
36922103,"result = result[(result['var']>0.25) | (result['var']<-0.25)]
import pandas as pd
x = pd.Series([1])
bool(x)
x or x
x and x",['x = pd.Series([1])'],"[""result = result[(result['var']>0.25) | (result['var']<-0.25)]"", 'import pandas as pd', 'bool(x)', 'x or x', 'x and x']",[],,
36922486,"np.random.seed(0)
df = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))
df
df.loc[(df.C > 0.25) | (df.C < -0.25)]
df.C > 0.25
(df.C > 0.25).any() or (df.C < -0.25).any()
True
(df.C > 0.25).all() or (df.C < -0.25).all()
False
df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]","[""df = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))"", 'df.loc[(df.C > 0.25) | (df.C < -0.25)]', '(df.C > 0.25).any() or (df.C < -0.25).any()', '(df.C > 0.25).all() or (df.C < -0.25).all()']","['np.random.seed(0)', 'df', 'df.loc[(df.C > 0.25) | (df.C < -0.25)]', 'df.C > 0.25', '(df.C > 0.25).any() or (df.C < -0.25).any()', 'True', '(df.C > 0.25).all() or (df.C < -0.25).all()', 'False', 'df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]']","['df.loc[(df.C > 0.25) | (df.C < -0.25)]', '(df.C > 0.25).any() or (df.C < -0.25).any()', '(df.C > 0.25).all() or (df.C < -0.25).all()']",,
36951842,grouped_df = df.groupby('A'),"[""grouped_df = df.groupby('A')""]","[""grouped_df = df.groupby('A')""]","[""grouped_df = df.groupby('A')""]",,
36955053,"df.loc[:, 'C':'E']
import pandas as pd
import numpy as np
np.random.seed(5)
df = pd.DataFrame(np.random.randint(100, size=(100, 6)), 
                  columns=list('ABCDEF'), 
                  index=['R{}'.format(i) for i in range(100)])
df.head()
df.loc[:, 'C':'E']
...
df.loc['R6':'R10', 'C':'E']
df.loc[:, df.columns.isin(list('BCD'))]
...","[""df.loc[:, 'C':'E']"", 'df = pd.DataFrame(np.random.randint(100, size=(100, 6)), ', ""                  index=['R{}'.format(i) for i in range(100)])"", 'df.head()', ""df.loc[:, 'C':'E']"", ""df.loc['R6':'R10', 'C':'E']"", ""df.loc[:, df.columns.isin(list('BCD'))]""]","[""df.loc[:, 'C':'E']"", 'import pandas as pd', 'import numpy as np', 'np.random.seed(5)', ""                  columns=list('ABCDEF'), "", ""                  index=['R{}'.format(i) for i in range(100)])"", 'df.head()', ""df.loc[:, 'C':'E']"", '...', ""df.loc['R6':'R10', 'C':'E']"", ""df.loc[:, df.columns.isin(list('BCD'))]"", '...']","[""df.loc[:, 'C':'E']"", ""                  index=['R{}'.format(i) for i in range(100)])"", 'df.head()', ""df.loc[:, 'C':'E']"", ""df.loc['R6':'R10', 'C':'E']"", ""df.loc[:, df.columns.isin(list('BCD'))]""]",,
36957431,"w.female.replace(['male', 'female'], [1, 0], inplace=True)","[""w.female.replace(['male', 'female'], [1, 0], inplace=True)""]","[""w.female.replace(['male', 'female'], [1, 0], inplace=True)""]","[""w.female.replace(['male', 'female'], [1, 0], inplace=True)""]",,
36958937,"df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')","[""df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')""]","[""df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')""]","[""df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')""]",,
37000877,,[],[''],[],[],[]
37012035,"storage
df.shape
df.info()
dtypes: datetime64[ns](6)
df.head()","['df.shape', 'df.info()', 'df.head()']","['storage', 'df.shape', 'df.info()', 'dtypes: datetime64[ns](6)', 'df.head()']","['df.shape', 'df.info()', 'df.head()']",,
37043071,,[],[''],[],[],[]
37069701,"yourdf.drop(['columnheading1', 'columnheading2'], axis=1, inplace=True)","[""yourdf.drop(['columnheading1', 'columnheading2'], axis=1, inplace=True)""]","[""yourdf.drop(['columnheading1', 'columnheading2'], axis=1, inplace=True)""]","[""yourdf.drop(['columnheading1', 'columnheading2'], axis=1, inplace=True)""]",,
37097791,"In[17]: df
In[18]: df.drop('one')
In[19]: df.drop(df.index[[0]])","[""In[18]: df.drop('one')"", 'In[19]: df.drop(df.index[[0]])']","['In[17]: df', ""In[18]: df.drop('one')"", 'In[19]: df.drop(df.index[[0]])']","[""In[18]: df.drop('one')"", 'In[19]: df.drop(df.index[[0]])']",,
37103131,"import pandas as pd
df = pd.DataFrame({'year': [2015, 2016],
                   'month': [2, 3],
                    'day': [4, 5],
                    'hour': [2, 3],
                    'minute': [10, 30],
                    'second': [21,25]})
dtype: datetime64[ns]
dtype: datetime64[ns]
dtype: datetime64[ns]
dtype: datetime64[ns]
dtype: datetime64[ns]","[""df = pd.DataFrame({'year': [2015, 2016],""]","['import pandas as pd', ""                   'month': [2, 3],"", ""                    'day': [4, 5],"", ""                    'hour': [2, 3],"", ""                    'minute': [10, 30],"", ""                    'second': [21,25]})"", 'dtype: datetime64[ns]', 'dtype: datetime64[ns]', 'dtype: datetime64[ns]', 'dtype: datetime64[ns]', 'dtype: datetime64[ns]']",[],,
37199623,"import pandas as pd
from sklearn import preprocessing
data = {'score': [234,24,14,27,-74,46,73,-18,59,160]}
df = pd.DataFrame(data)
df
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
df_normalized = pd.DataFrame(np_scaled)
df_normalized","['df = pd.DataFrame(data)', 'df_normalized = pd.DataFrame(np_scaled)']","['import pandas as pd', 'from sklearn import preprocessing', ""data = {'score': [234,24,14,27,-74,46,73,-18,59,160]}"", 'df', 'min_max_scaler = preprocessing.MinMaxScaler()', 'np_scaled = min_max_scaler.fit_transform(df)', 'df_normalized']",[],,
37226672,"pd.Timestamp.min
pd.Timestamp.max
Out[55]: Timestamp('2262-04-11 23:47:16.854775807')","['pd.Timestamp.min', 'pd.Timestamp.max']","['pd.Timestamp.min', 'pd.Timestamp.max', ""Out[55]: Timestamp('2262-04-11 23:47:16.854775807')""]","['pd.Timestamp.min', 'pd.Timestamp.max']",,
37282998,"df = DataFrame({'a': [-1, 100, -2]})
df
df.clip(lower=0)",['df.clip(lower=0)'],"[""df = DataFrame({'a': [-1, 100, -2]})"", 'df', 'df.clip(lower=0)']",['df.clip(lower=0)'],,
37293283,"from sklearn.preprocessing import LabelEncoder
def dummyEncode(df):
        columnsToEncode = list(df.select_dtypes(include=['category','object']))
        le = LabelEncoder()
        for feature in columnsToEncode:
            try:
                df[feature] = le.fit_transform(df[feature])
            except:
                print('Error encoding '+feature)
        return df","[""        columnsToEncode = list(df.select_dtypes(include=['category','object']))""]","['from sklearn.preprocessing import LabelEncoder', 'def dummyEncode(df):', ""        columnsToEncode = list(df.select_dtypes(include=['category','object']))"", '        le = LabelEncoder()', '        for feature in columnsToEncode:', '            try:', '                df[feature] = le.fit_transform(df[feature])', '            except:', ""                print('Error encoding '+feature)"", '        return df']","[""        columnsToEncode = list(df.select_dtypes(include=['category','object']))""]",,
37327506,pd.Series(test).where(lambda x : x!=1).dropna(),['pd.Series(test).where(lambda x : x!=1).dropna()'],[],['pd.Series(test).where(lambda x : x!=1).dropna()'],,
37347783,"pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.describe_option('display')","[""pd.set_option('display.max_columns', None)"", ""pd.set_option('display.max_rows', None)"", ""pd.describe_option('display')""]","[""pd.set_option('display.max_columns', None)"", ""pd.set_option('display.max_rows', None)"", ""pd.describe_option('display')""]","[""pd.set_option('display.max_columns', None)"", ""pd.set_option('display.max_rows', None)"", ""pd.describe_option('display')""]",,
37384347,"np_df = df.as_matrix()
np_df[i] ",['np_df = df.as_matrix()'],"['np_df = df.as_matrix()', 'np_df[i] ']",['np_df = df.as_matrix()'],,
37426982,"import pandas as pd
cats = ['a', 'b', 'c']
df = pd.DataFrame({'cat': ['a', 'b', 'a']})
dummies = pd.get_dummies(df, prefix='', prefix_sep='')
dummies = dummies.T.reindex(cats).T.fillna(0)","[""df = pd.DataFrame({'cat': ['a', 'b', 'a']})"", ""dummies = pd.get_dummies(df, prefix='', prefix_sep='')"", 'dummies = dummies.T.reindex(cats).T.fillna(0)']","['import pandas as pd', ""cats = ['a', 'b', 'c']"", ""dummies = pd.get_dummies(df, prefix='', prefix_sep='')"", 'dummies = dummies.T.reindex(cats).T.fillna(0)']","[""dummies = pd.get_dummies(df, prefix='', prefix_sep='')"", 'dummies = dummies.T.reindex(cats).T.fillna(0)']",,
37441204,"df2 = df[df.columns.difference(['B', 'D'])]","[""df2 = df[df.columns.difference(['B', 'D'])]""]","[""df2 = df[df.columns.difference(['B', 'D'])]""]","[""df2 = df[df.columns.difference(['B', 'D'])]""]",,
37442692,"df.isnull().T.any().T.sum()
nan_rows = df[df.isnull().T.any().T]","['df.isnull().T.any().T.sum()', 'nan_rows = df[df.isnull().T.any().T]']","['df.isnull().T.any().T.sum()', 'nan_rows = df[df.isnull().T.any().T]']","['df.isnull().T.any().T.sum()', 'nan_rows = df[df.isnull().T.any().T]']",,
37447530,,[],[''],[],[],[]
37451867,"import pandas as pd
cat=pd.Series(list('aba'),index=range(1,4))
cat=cat.astype('category',categories=list('abc'))
cat
pd.get_dummies(cat)","[""cat=pd.Series(list('aba'),index=range(1,4))"", ""cat=cat.astype('category',categories=list('abc'))"", 'pd.get_dummies(cat)']","['import pandas as pd', ""cat=cat.astype('category',categories=list('abc'))"", 'cat', 'pd.get_dummies(cat)']","[""cat=cat.astype('category',categories=list('abc'))"", 'pd.get_dummies(cat)']",,
37453925,"headers = ['col1', 'col2', 'col3', 'col4']
dtypes = {'col1': 'str', 'col2': 'str', 'col3': 'str', 'col4': 'float'}
parse_dates = ['col1', 'col2']
pd.read_csv(file, sep='\t', header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)
date_parser = pd.datetools.to_datetime
date_parser = pd.datetools.to_datetime()","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)"", 'date_parser = pd.datetools.to_datetime', 'date_parser = pd.datetools.to_datetime()']","[""headers = ['col1', 'col2', 'col3', 'col4']"", ""dtypes = {'col1': 'str', 'col2': 'str', 'col3': 'str', 'col4': 'float'}"", ""parse_dates = ['col1', 'col2']"", ""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)"", 'date_parser = pd.datetools.to_datetime', 'date_parser = pd.datetools.to_datetime()']","[""pd.read_csv(file, sep='\\t', header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)"", 'date_parser = pd.datetools.to_datetime', 'date_parser = pd.datetools.to_datetime()']",,
37562101,,[],[''],[],[],[]
37592047,"import pandas as pd
import numpy as np
df = pd.DataFrame({'ItemQty': {0: 3, 1: 25}, 
                   'Seatblocks': {0: '2:218:10:4,6', 1: '1:13:36:1,12 1:13:37:1,13'}, 
                   'ItemExt': {0: 60, 1: 300}, 
                   'CustomerName': {0: 'McCartney, Paul', 1: 'Lennon, John'}, 
                   'CustNum': {0: 32363, 1: 31316}, 
                   'Item': {0: 'F04', 1: 'F01'}}, 
                    columns=['CustNum','CustomerName','ItemQty','Item','Seatblocks','ItemExt'])
print (df)
print (df.drop('Seatblocks', axis=1)
             .join
             (
             df.Seatblocks
             .str
             .split(expand=True)
             .stack()
             .reset_index(drop=True, level=1)
             .rename('Seatblocks')           
             ))
df = pd.DataFrame(['a b c']*100000, columns=['col'])
df = pd.DataFrame(['a b c']*10, columns=['col'])
df.loc[0] = np.nan
print (df.head())
print (df.col.str.split(expand=True))","[""df = pd.DataFrame({'ItemQty': {0: 3, 1: 25}, "", ""print (df.drop('Seatblocks', axis=1)"", '             df.Seatblocks', ""df = pd.DataFrame(['a b c']*100000, columns=['col'])"", ""df = pd.DataFrame(['a b c']*10, columns=['col'])"", 'df.loc[0] = np.nan', 'print (df.head())', 'print (df.col.str.split(expand=True))']","['import pandas as pd', 'import numpy as np', ""                   'Seatblocks': {0: '2:218:10:4,6', 1: '1:13:36:1,12 1:13:37:1,13'}, "", ""                   'ItemExt': {0: 60, 1: 300}, "", ""                   'CustomerName': {0: 'McCartney, Paul', 1: 'Lennon, John'}, "", ""                   'CustNum': {0: 32363, 1: 31316}, "", ""                   'Item': {0: 'F04', 1: 'F01'}}, "", ""                    columns=['CustNum','CustomerName','ItemQty','Item','Seatblocks','ItemExt'])"", 'print (df)', ""print (df.drop('Seatblocks', axis=1)"", '             .join', '             (', '             df.Seatblocks', '             .str', '             .split(expand=True)', '             .stack()', '             .reset_index(drop=True, level=1)', ""             .rename('Seatblocks')           "", '             ))', 'df.loc[0] = np.nan', 'print (df.head())', 'print (df.col.str.split(expand=True))']","[""print (df.drop('Seatblocks', axis=1)"", '             df.Seatblocks', 'df.loc[0] = np.nan', 'print (df.head())', 'print (df.col.str.split(expand=True))']",,
37602937,"df.groupby(['Name','Type','ID'], as_index=False).count()","[""df.groupby(['Name','Type','ID'], as_index=False).count()""]","[""df.groupby(['Name','Type','ID'], as_index=False).count()""]","[""df.groupby(['Name','Type','ID'], as_index=False).count()""]",,
37644056,"df.xs('A', level='Col', axis=1)
df.loc[:, (slice(None), 'A')]","[""df.xs('A', level='Col', axis=1)"", ""df.loc[:, (slice(None), 'A')]""]","[""df.xs('A', level='Col', axis=1)"", ""df.loc[:, (slice(None), 'A')]""]","[""df.xs('A', level='Col', axis=1)"", ""df.loc[:, (slice(None), 'A')]""]",,
37647160,,[],[''],[],[],[]
37654890,,[],[''],[],[],[]
37655063,,[],[''],[],[],[]
37717675,"df
df.drop('b', axis=1)","[""df.drop('b', axis=1)""]","['df', ""df.drop('b', axis=1)""]","[""df.drop('b', axis=1)""]",,
37749078,"import pandas as pd
cols = pd.MultiIndex.from_arrays([['basic_amt']*4,
                                     ['NSW','QLD','VIC','All']], 
                                     names = [None, 'Faculty'])
idx = pd.Index(['All', 'Full Time', 'Part Time'])
df = pd.DataFrame([(1,1,2,4),
                   (0,1,0,1),
                   (1,0,2,3)], index = idx, columns=cols)
print (df)
df.columns = df.columns.droplevel(0)
df = df.rename_axis(None, axis=1)
print (df)
print (df.columns)
Index(['NSW', 'QLD', 'VIC', 'All'], dtype='object')
df.columns = ['_'.join(col) for col in df.columns]
print (df)
print (df.columns)
Index(['basic_amt_NSW', 'basic_amt_QLD', 'basic_amt_VIC', 'basic_amt_All'], dtype='object')","[""cols = pd.MultiIndex.from_arrays([['basic_amt']*4,"", 'df = pd.DataFrame([(1,1,2,4),', 'df.columns = df.columns.droplevel(0)', 'df = df.rename_axis(None, axis=1)', ""df.columns = ['_'.join(col) for col in df.columns]""]","['import pandas as pd', ""cols = pd.MultiIndex.from_arrays([['basic_amt']*4,"", ""                                     ['NSW','QLD','VIC','All']], "", ""                                     names = [None, 'Faculty'])"", ""idx = pd.Index(['All', 'Full Time', 'Part Time'])"", '                   (0,1,0,1),', '                   (1,0,2,3)], index = idx, columns=cols)', 'print (df)', 'df.columns = df.columns.droplevel(0)', 'df = df.rename_axis(None, axis=1)', 'print (df)', 'print (df.columns)', ""Index(['NSW', 'QLD', 'VIC', 'All'], dtype='object')"", ""df.columns = ['_'.join(col) for col in df.columns]"", 'print (df)', 'print (df.columns)', ""Index(['basic_amt_NSW', 'basic_amt_QLD', 'basic_amt_VIC', 'basic_amt_All'], dtype='object')""]","[""cols = pd.MultiIndex.from_arrays([['basic_amt']*4,"", 'df.columns = df.columns.droplevel(0)', 'df = df.rename_axis(None, axis=1)', ""df.columns = ['_'.join(col) for col in df.columns]""]",,
37757763,"import pandas as pd
import tia.bbg.datamgr as dm
mgr = dm.BbgDataManager()
sids = mgr['MSFT US EQUITY', 'IBM US EQUITY', 'CSCO US EQUITY']
df = sids.get_historical('PX_LAST', '1/1/2014', '11/12/2014')",[],"['import pandas as pd', 'import tia.bbg.datamgr as dm', 'mgr = dm.BbgDataManager()', ""sids = mgr['MSFT US EQUITY', 'IBM US EQUITY', 'CSCO US EQUITY']"", ""df = sids.get_historical('PX_LAST', '1/1/2014', '11/12/2014')""]",[],[],[]
37793940,"a = pd.Series(range(100) + ([0]*20))
def jitter(a_series, noise_reduction=1000000):
    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))
a_deciles = pd.qcut(a + jitter(a), 10, labels=False)
a_deciles = pd.qcut(a, 10, labels=False)","['a = pd.Series(range(100) + ([0]*20))', '    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))', 'a_deciles = pd.qcut(a + jitter(a), 10, labels=False)', 'a_deciles = pd.qcut(a, 10, labels=False)']","['def jitter(a_series, noise_reduction=1000000):', '    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))', 'a_deciles = pd.qcut(a + jitter(a), 10, labels=False)', 'a_deciles = pd.qcut(a, 10, labels=False)']","['    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))', 'a_deciles = pd.qcut(a + jitter(a), 10, labels=False)', 'a_deciles = pd.qcut(a, 10, labels=False)']",,
37806819,"from pandas_datareader import data
aapl = data.DataReader('AAPL', 'google', '1980-01-01')
aapl.head()
aapl.tail()
aapl.to_csv('d:/temp/aapl_data.csv')
1980-12-12,28.75,28.875,28.75,28.75,117258400,0.431358
1980-12-15,27.375001,27.375001,27.25,27.25,43971200,0.408852
1980-12-16,25.375,25.375,25.25,25.25,26432000,0.378845
1980-12-17,25.875,25.999999,25.875,25.875,21610400,0.38822199999999996
1980-12-18,26.625,26.75,26.625,26.625,18362400,0.399475
...","['aapl.head()', 'aapl.tail()', ""aapl.to_csv('d:/temp/aapl_data.csv')""]","['from pandas_datareader import data', ""aapl = data.DataReader('AAPL', 'google', '1980-01-01')"", 'aapl.head()', 'aapl.tail()', ""aapl.to_csv('d:/temp/aapl_data.csv')"", '1980-12-12,28.75,28.875,28.75,28.75,117258400,0.431358', '1980-12-15,27.375001,27.375001,27.25,27.25,43971200,0.408852', '1980-12-16,25.375,25.375,25.25,25.25,26432000,0.378845', '1980-12-17,25.875,25.999999,25.875,25.875,21610400,0.38822199999999996', '1980-12-18,26.625,26.75,26.625,26.625,18362400,0.399475', '...']","['aapl.head()', 'aapl.tail()', ""aapl.to_csv('d:/temp/aapl_data.csv')""]",,
37851232,import pandas as pd,[],['import pandas as pd'],[],[],[]
37891437,"left.join(right, on=key_or_keys)
pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)","['left.join(right, on=key_or_keys)', ""pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)""]","['left.join(right, on=key_or_keys)', ""pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)""]","['left.join(right, on=key_or_keys)', ""pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)""]",,
37992805,"import pandas as pd
import numpy as np
s = pd.Series(np.arange(4)**2, index=np.arange(4))
s
id(s.index), id(s.values)
s[2] = 14  
id(s.index), id(s.values)
s[4] = 16
s
id(s.index), id(s.values)
new_items = {item: item**2 for item in range(5, 7)}
s2 = pd.Series(new_items)
s2  
s = s.append(s2); s
dtype: int64","['s = pd.Series(np.arange(4)**2, index=np.arange(4))', 'id(s.index), id(s.values)', 'id(s.index), id(s.values)', 'id(s.index), id(s.values)', 's2 = pd.Series(new_items)', 's = s.append(s2); s']","['import pandas as pd', 'import numpy as np', 's', 'id(s.index), id(s.values)', 's[2] = 14  ', 'id(s.index), id(s.values)', 's[4] = 16', 's', 'id(s.index), id(s.values)', 'new_items = {item: item**2 for item in range(5, 7)}', 's2  ', 's = s.append(s2); s', 'dtype: int64']","['id(s.index), id(s.values)', 'id(s.index), id(s.values)', 'id(s.index), id(s.values)', 's = s.append(s2); s']",,
38025280,"df.index
df.columns",['df.index'],"['df.index', 'df.columns']",['df.index'],,
38034085,"dfNew = df.merge(df2, left_index=True, right_index=True,
                 how='outer', suffixes=('', '_y'))","['dfNew = df.merge(df2, left_index=True, right_index=True,']","['dfNew = df.merge(df2, left_index=True, right_index=True,', ""                 how='outer', suffixes=('', '_y'))""]","['dfNew = df.merge(df2, left_index=True, right_index=True,']",,
38055014,[int(i.days) for i in (df.B - df.A)],['[int(i.days) for i in (df.B - df.A)]'],['[int(i.days) for i in (df.B - df.A)]'],['[int(i.days) for i in (df.B - df.A)]'],,
38105540,"import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
iris = load_iris()
data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],
                     columns= iris['feature_names'] + ['target'])","[""data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],""]","['import numpy as np', 'import pandas as pd', 'from sklearn.datasets import load_iris', 'iris = load_iris()', ""                     columns= iris['feature_names'] + ['target'])""]",[],,
38134049,"df[['a', 'b']] = df[['a','b']].fillna(value=0)","[""df[['a', 'b']] = df[['a','b']].fillna(value=0)""]","[""df[['a', 'b']] = df[['a','b']].fillna(value=0)""]","[""df[['a', 'b']] = df[['a','b']].fillna(value=0)""]",,
38156594,"import pandas as pd
import numpy as np    
x = np.empty((10,), dtype=[('x', np.uint8), ('y', np.float64)])
df = pd.DataFrame(x)","[""x = np.empty((10,), dtype=[('x', np.uint8), ('y', np.float64)])"", 'df = pd.DataFrame(x)']","['import pandas as pd', 'import numpy as np    ', ""x = np.empty((10,), dtype=[('x', np.uint8), ('y', np.float64)])""]","[""x = np.empty((10,), dtype=[('x', np.uint8), ('y', np.float64)])""]",,
38185759,"df = pd.DataFrame({'A': [1, 2, 3], 'B': [1.0, 2.0, 3.0], 
                   'C': [1j, 2j, 3j], 'D': ['a', 'b', 'c']})
df
df.dtypes
dtype: object
np.issubdtype(df['A'].dtype, np.number)
Out: True
np.issubdtype(df['B'].dtype, np.number)
Out: True
np.issubdtype(df['C'].dtype, np.number)
Out: True
np.issubdtype(df['D'].dtype, np.number)
Out: False
is_number = np.vectorize(lambda x: np.issubdtype(x, np.number))
is_number(df.dtypes)
Out: array([ True,  True,  True, False], dtype=bool)
df.select_dtypes(include=[np.number])","[""df = pd.DataFrame({'A': [1, 2, 3], 'B': [1.0, 2.0, 3.0], "", 'df.dtypes', ""np.issubdtype(df['A'].dtype, np.number)"", ""np.issubdtype(df['B'].dtype, np.number)"", ""np.issubdtype(df['C'].dtype, np.number)"", ""np.issubdtype(df['D'].dtype, np.number)"", 'is_number(df.dtypes)', 'df.select_dtypes(include=[np.number])']","[""                   'C': [1j, 2j, 3j], 'D': ['a', 'b', 'c']})"", 'df', 'df.dtypes', 'dtype: object', ""np.issubdtype(df['A'].dtype, np.number)"", 'Out: True', ""np.issubdtype(df['B'].dtype, np.number)"", 'Out: True', ""np.issubdtype(df['C'].dtype, np.number)"", 'Out: True', ""np.issubdtype(df['D'].dtype, np.number)"", 'Out: False', 'is_number = np.vectorize(lambda x: np.issubdtype(x, np.number))', 'is_number(df.dtypes)', 'Out: array([ True,  True,  True, False], dtype=bool)', 'df.select_dtypes(include=[np.number])']","['df.dtypes', ""np.issubdtype(df['A'].dtype, np.number)"", ""np.issubdtype(df['B'].dtype, np.number)"", ""np.issubdtype(df['C'].dtype, np.number)"", ""np.issubdtype(df['D'].dtype, np.number)"", 'is_number(df.dtypes)', 'df.select_dtypes(include=[np.number])']",,
38231651,"df = pd.DataFrame({'a':[1,2,3], 'b':[{'c':1}, {'d':3}, {'c':5, 'd':6}]})
df
df['b'].apply(pd.Series)
pd.concat([df.drop(['b'], axis=1), df['b'].apply(pd.Series)], axis=1)
pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)","[""df = pd.DataFrame({'a':[1,2,3], 'b':[{'c':1}, {'d':3}, {'c':5, 'd':6}]})"", ""df['b'].apply(pd.Series)"", ""pd.concat([df.drop(['b'], axis=1), df['b'].apply(pd.Series)], axis=1)"", ""pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)""]",['df'],"[""df['b'].apply(pd.Series)"", ""pd.concat([df.drop(['b'], axis=1), df['b'].apply(pd.Series)], axis=1)"", ""pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)""]",,
38251063,"import numpy as np
import pandas as pd
def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):
    np.random.seed(seed)
    perm = np.random.permutation(df.index)
    m = len(df)
    train_end = int(train_percent * m)
    validate_end = int(validate_percent * m) + train_end
    train = df.ix[perm[:train_end]]
    validate = df.ix[perm[train_end:validate_end]]
    test = df.ix[perm[validate_end:]]
    return train, validate, test
np.random.seed([3,1415])
df = pd.DataFrame(np.random.rand(10, 5), columns=list('ABCDE'))
df
train, validate, test = train_validate_test_split(df)
train
validate
test","['    perm = np.random.permutation(df.index)', ""df = pd.DataFrame(np.random.rand(10, 5), columns=list('ABCDE'))""]","['import numpy as np', 'import pandas as pd', 'def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):', '    np.random.seed(seed)', '    perm = np.random.permutation(df.index)', '    m = len(df)', '    train_end = int(train_percent * m)', '    validate_end = int(validate_percent * m) + train_end', '    train = df.ix[perm[:train_end]]', '    validate = df.ix[perm[train_end:validate_end]]', '    test = df.ix[perm[validate_end:]]', '    return train, validate, test', 'np.random.seed([3,1415])', 'df', 'train, validate, test = train_validate_test_split(df)', 'train', 'validate', 'test']",['    perm = np.random.permutation(df.index)'],,
38251213,"train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])
train
validate
test
a = np.arange(1, 21)
a
np.split(a, [int(.8 * len(a)), int(.9 * len(a))])
[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]),
 array([17, 18]),
 array([19, 20])]","['train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])', 'np.split(a, [int(.8 * len(a)), int(.9 * len(a))])']","['train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])', 'train', 'validate', 'test', 'a = np.arange(1, 21)', 'a', 'np.split(a, [int(.8 * len(a)), int(.9 * len(a))])', '[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]),', ' array([17, 18]),', ' array([19, 20])]']","['train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])', 'np.split(a, [int(.8 * len(a)), int(.9 * len(a))])']",,
38258390,"memloc = pd.DataFrame({'df1': list(map(id, df1['letter'])),
                       'df2': list(map(id, df2['letter'])), })
diffs = memloc.diff(); diffs.head(30)
diffs['df1'].value_counts()
len(diffs['df1'].value_counts())
diffs['df2'].value_counts().head()
len(diffs['df2'].value_counts())","[""memloc = pd.DataFrame({'df1': list(map(id, df1['letter'])),"", 'diffs = memloc.diff(); diffs.head(30)', ""diffs['df1'].value_counts()"", ""len(diffs['df1'].value_counts())"", ""diffs['df2'].value_counts().head()"", ""len(diffs['df2'].value_counts())""]","[""                       'df2': list(map(id, df2['letter'])), })"", 'diffs = memloc.diff(); diffs.head(30)', ""diffs['df1'].value_counts()"", ""len(diffs['df1'].value_counts())"", ""diffs['df2'].value_counts().head()"", ""len(diffs['df2'].value_counts())""]","['diffs = memloc.diff(); diffs.head(30)', ""diffs['df1'].value_counts()"", ""len(diffs['df1'].value_counts())"", ""diffs['df2'].value_counts().head()"", ""len(diffs['df2'].value_counts())""]",,
38278787,"import pandas as pd
s = pd.Series(['1.0', '2', -3])
pd.to_numeric(s)
s = pd.Series(['apple', '1.0', '2', -3])
pd.to_numeric(s, errors='ignore')
pd.to_numeric(s, errors='coerce')","[""s = pd.Series(['1.0', '2', -3])"", 'pd.to_numeric(s)', ""s = pd.Series(['apple', '1.0', '2', -3])"", ""pd.to_numeric(s, errors='ignore')"", ""pd.to_numeric(s, errors='coerce')""]","['import pandas as pd', 'pd.to_numeric(s)', ""pd.to_numeric(s, errors='ignore')"", ""pd.to_numeric(s, errors='coerce')""]","['pd.to_numeric(s)', ""pd.to_numeric(s, errors='ignore')"", ""pd.to_numeric(s, errors='coerce')""]",,
38341066,df = df[(df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10')],[],"[""df = df[(df['date'] > '2000-6-1') & (df['date'] <= '2000-6-10')]""]",[],[],[]
38348167,"import pandas as pd 
BaseData = pd.DataFrame({ 'Customer' : ['Acme','Mega','Acme','Acme','Mega','Acme'],
                          'Territory'  : ['West','East','South','West','East','South'],
                          'Product'  : ['Econ','Luxe','Econ','Std','Std','Econ']})
BaseData
columns = ['Customer','Num Unique Products', 'List Unique Products']
rows_list=[]
for name, group in BaseData.groupby('Customer'):
    RecordtoAdd={} 
    RecordtoAdd.update({'Customer' : name}) 
    RecordtoAdd.update({'Num Unique Products' : len(pd.unique(group['Product']))})      
    RecordtoAdd.update({'List Unique Products' : pd.unique(group['Product'])})                   
    rows_list.append(RecordtoAdd)
AnalysedData = pd.DataFrame(rows_list)
print('Base Data : \n',BaseData,'\n\n Analysed Data : \n',AnalysedData)","[""BaseData = pd.DataFrame({ 'Customer' : ['Acme','Mega','Acme','Acme','Mega','Acme'],"", ""for name, group in BaseData.groupby('Customer'):"", ""    RecordtoAdd.update({'Customer' : name}) "", ""    RecordtoAdd.update({'Num Unique Products' : len(pd.unique(group['Product']))})      "", ""    RecordtoAdd.update({'List Unique Products' : pd.unique(group['Product'])})                   "", '    rows_list.append(RecordtoAdd)', 'AnalysedData = pd.DataFrame(rows_list)']","['import pandas as pd ', ""                          'Territory'  : ['West','East','South','West','East','South'],"", ""                          'Product'  : ['Econ','Luxe','Econ','Std','Std','Econ']})"", 'BaseData', ""columns = ['Customer','Num Unique Products', 'List Unique Products']"", 'rows_list=[]', ""for name, group in BaseData.groupby('Customer'):"", '    RecordtoAdd={} ', ""    RecordtoAdd.update({'Customer' : name}) "", ""    RecordtoAdd.update({'Num Unique Products' : len(pd.unique(group['Product']))})      "", ""    RecordtoAdd.update({'List Unique Products' : pd.unique(group['Product'])})                   "", '    rows_list.append(RecordtoAdd)', ""print('Base Data : \\n',BaseData,'\\n\\n Analysed Data : \\n',AnalysedData)""]","[""for name, group in BaseData.groupby('Customer'):"", ""    RecordtoAdd.update({'Customer' : name}) "", ""    RecordtoAdd.update({'Num Unique Products' : len(pd.unique(group['Product']))})      "", ""    RecordtoAdd.update({'List Unique Products' : pd.unique(group['Product'])})                   "", '    rows_list.append(RecordtoAdd)']",,
38421614,"import pandas as pd
import numpy as np
def diff_pd(df1, df2):
    """"""Identify differences between two pandas DataFrames""""""
    assert (df1.columns == df2.columns).all(), \
        ""DataFrame column names are different""
    if df1.equals(df2):
        return None
    else:
        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())
        ne_stacked = diff_mask.stack()
        changed = ne_stacked[ne_stacked]
        changed.index.names = ['id', 'col']
        difference_locations = np.where(diff_mask)
        changed_from = df1.values[difference_locations]
        changed_to = df2.values[difference_locations]
        return pd.DataFrame({'from': changed_from, 'to': changed_to},
                            index=changed.index)
import sys
if sys.version_info[0] < 3:
    from StringIO import StringIO
else:
    from io import StringIO
DF1 = StringIO(""""""id   Name   score                    isEnrolled           Comment
111  Jack   2.17                     True                 ""He was late to class""
112  Nick   1.11                     False                ""Graduated""
113  Zoe    NaN                     True                  "" ""
"""""")
DF2 = StringIO(""""""id   Name   score                    isEnrolled           Comment
111  Jack   2.17                     True                 ""He was late to class""
112  Nick   1.21                     False                ""Graduated""
113  Zoe    NaN                     False                ""On vacation"" """""")
df1 = pd.read_table(DF1, sep='\s+', index_col='id')
df2 = pd.read_table(DF2, sep='\s+', index_col='id')
diff_pd(df1, df2)","['    assert (df1.columns == df2.columns).all(), \\', '    if df1.equals(df2):', '        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())', '        ne_stacked = diff_mask.stack()', ""        changed.index.names = ['id', 'col']"", '        difference_locations = np.where(diff_mask)', '        changed_from = df1.values[difference_locations]', '        changed_to = df2.values[difference_locations]', ""        return pd.DataFrame({'from': changed_from, 'to': changed_to},"", '                            index=changed.index)', ""df1 = pd.read_table(DF1, sep='\\s+', index_col='id')"", ""df2 = pd.read_table(DF2, sep='\\s+', index_col='id')""]","['import pandas as pd', 'import numpy as np', 'def diff_pd(df1, df2):', '    """"""Identify differences between two pandas DataFrames""""""', '    assert (df1.columns == df2.columns).all(), \\', '        ""DataFrame column names are different""', '    if df1.equals(df2):', '        return None', '    else:', '        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())', '        ne_stacked = diff_mask.stack()', '        changed = ne_stacked[ne_stacked]', ""        changed.index.names = ['id', 'col']"", '        difference_locations = np.where(diff_mask)', '        changed_from = df1.values[difference_locations]', '        changed_to = df2.values[difference_locations]', '                            index=changed.index)', 'import sys', 'if sys.version_info[0] < 3:', '    from StringIO import StringIO', 'else:', '    from io import StringIO', 'DF1 = StringIO(""""""id   Name   score                    isEnrolled           Comment', '111  Jack   2.17                     True                 ""He was late to class""', '112  Nick   1.11                     False                ""Graduated""', '113  Zoe    NaN                     True                  "" ""', '"""""")', 'DF2 = StringIO(""""""id   Name   score                    isEnrolled           Comment', '111  Jack   2.17                     True                 ""He was late to class""', '112  Nick   1.21                     False                ""Graduated""', '113  Zoe    NaN                     False                ""On vacation"" """""")', ""df1 = pd.read_table(DF1, sep='\\s+', index_col='id')"", ""df2 = pd.read_table(DF2, sep='\\s+', index_col='id')"", 'diff_pd(df1, df2)']","['    assert (df1.columns == df2.columns).all(), \\', '    if df1.equals(df2):', '        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())', '        ne_stacked = diff_mask.stack()', ""        changed.index.names = ['id', 'col']"", '        difference_locations = np.where(diff_mask)', '        changed_from = df1.values[difference_locations]', '        changed_to = df2.values[difference_locations]', '                            index=changed.index)', ""df1 = pd.read_table(DF1, sep='\\s+', index_col='id')"", ""df2 = pd.read_table(DF2, sep='\\s+', index_col='id')""]",,
38440332,"import numpy as np
def balanced_subsample(y, size=None):
    subsample = []
    if size is None:
        n_smp = y.value_counts().min()
    else:
        n_smp = int(size / len(y.value_counts().index))
    for label in y.value_counts().index:
        samples = y[y == label].index.values
        index_range = range(samples.shape[0])
        indexes = np.random.choice(index_range, size=n_smp, replace=False)
        subsample += samples[indexes].tolist()
    return subsample","['        n_smp = y.value_counts().min()', '        n_smp = int(size / len(y.value_counts().index))', '    for label in y.value_counts().index:', '        samples = y[y == label].index.values', '        index_range = range(samples.shape[0])', '        subsample += samples[indexes].tolist()']","['import numpy as np', 'def balanced_subsample(y, size=None):', '    subsample = []', '    if size is None:', '        n_smp = y.value_counts().min()', '    else:', '        n_smp = int(size / len(y.value_counts().index))', '    for label in y.value_counts().index:', '        samples = y[y == label].index.values', '        index_range = range(samples.shape[0])', '        indexes = np.random.choice(index_range, size=n_smp, replace=False)', '        subsample += samples[indexes].tolist()', '    return subsample']","['        n_smp = y.value_counts().min()', '        n_smp = int(size / len(y.value_counts().index))', '    for label in y.value_counts().index:', '        samples = y[y == label].index.values', '        index_range = range(samples.shape[0])', '        subsample += samples[indexes].tolist()']",,
38466059,,[],[''],[],[],[]
38467449,,[],[''],[],[],[]
38470963,"cls.sum = _make_stat_function(
            'sum', name, name2, axis_descr,
            'Return the sum of the values for the requested axis',
            nanops.nansum)
def _make_stat_function(name, name1, name2, axis_descr, desc, f):
    @Substitution(outname=name, desc=desc, name1=name1, name2=name2,
                  axis_descr=axis_descr)
    @Appender(_num_doc)
    def stat_func(self, axis=None, skipna=None, level=None, numeric_only=None,
                  **kwargs):
        _validate_kwargs(name, kwargs, 'out', 'dtype')
        if skipna is None:
            skipna = True
        if axis is None:
            axis = self._stat_axis_number
        if level is not None:
            return self._agg_by_level(name, axis=axis, level=level,
                                      skipna=skipna)
        return self._reduce(f, name, axis=axis, skipna=skipna,
                            numeric_only=numeric_only)
def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None,
            filter_type=None, **kwds):
    axis = self._get_axis_number(axis)
    def f(x):
        return op(x, axis=axis, skipna=skipna, **kwds)
    labels = self._get_agg_axis(axis)
    if axis == 1 and self._is_mixed_type and self._is_datelike_mixed_type:
        numeric_only = True
    if numeric_only is None:
        try:
            values = self.values
            result = f(values)
        except Exception as e:
            if filter_type is None and axis == 0:
                try:
                    result = self.apply(f, reduce=False)
                    if result.ndim == self.ndim:
                        result = result.iloc[0]
                    return result
                except:
                    pass
            if filter_type is None or filter_type == 'numeric':
                data = self._get_numeric_data()
            elif filter_type == 'bool':
                data = self._get_bool_data()
            else:  
                e = NotImplementedError(""Handling exception with filter_""
                                        ""type %s not implemented."" %
                                        filter_type)
                raise_with_traceback(e)
            result = f(data.values)
            labels = data._get_agg_axis(axis)
    else:
        if numeric_only:
            if filter_type is None or filter_type == 'numeric':
                data = self._get_numeric_data()
            elif filter_type == 'bool':
                data = self._get_bool_data()
            else:  
                msg = (""Generating numeric_only data with filter_type %s""
                       ""not supported."" % filter_type)
                raise NotImplementedError(msg)
            values = data.values
            labels = data._get_agg_axis(axis)
        else:
            values = self.values
        result = f(values)
    if hasattr(result, 'dtype') and is_object_dtype(result.dtype):
        try:
            if filter_type is None or filter_type == 'numeric':
                result = result.astype(np.float64)
            elif filter_type == 'bool' and notnull(result).all():
                result = result.astype(np.bool_)
        except (ValueError, TypeError):
            if axis == 0:
                result = com._coerce_to_dtypes(result, self.dtypes)
    return Series(result, index=labels)","['cls.sum = _make_stat_function(', '            values = self.values', '                    result = self.apply(f, reduce=False)', '                    if result.ndim == self.ndim:', '                        result = result.iloc[0]', '            result = f(data.values)', '            values = data.values', '            values = self.values', ""    if hasattr(result, 'dtype') and is_object_dtype(result.dtype):"", '                result = result.astype(np.float64)', ""            elif filter_type == 'bool' and notnull(result).all():"", '                result = result.astype(np.bool_)', '                result = com._coerce_to_dtypes(result, self.dtypes)']","['cls.sum = _make_stat_function(', ""            'sum', name, name2, axis_descr,"", ""            'Return the sum of the values for the requested axis',"", '            nanops.nansum)', 'def _make_stat_function(name, name1, name2, axis_descr, desc, f):', '    @Substitution(outname=name, desc=desc, name1=name1, name2=name2,', '                  axis_descr=axis_descr)', '    @Appender(_num_doc)', '    def stat_func(self, axis=None, skipna=None, level=None, numeric_only=None,', '                  **kwargs):', ""        _validate_kwargs(name, kwargs, 'out', 'dtype')"", '        if skipna is None:', '            skipna = True', '        if axis is None:', '            axis = self._stat_axis_number', '        if level is not None:', '            return self._agg_by_level(name, axis=axis, level=level,', '                                      skipna=skipna)', '        return self._reduce(f, name, axis=axis, skipna=skipna,', '                            numeric_only=numeric_only)', 'def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None,', '            filter_type=None, **kwds):', '    axis = self._get_axis_number(axis)', '    def f(x):', '        return op(x, axis=axis, skipna=skipna, **kwds)', '    labels = self._get_agg_axis(axis)', '    if axis == 1 and self._is_mixed_type and self._is_datelike_mixed_type:', '        numeric_only = True', '    if numeric_only is None:', '        try:', '            values = self.values', '            result = f(values)', '        except Exception as e:', '            if filter_type is None and axis == 0:', '                try:', '                    result = self.apply(f, reduce=False)', '                    if result.ndim == self.ndim:', '                        result = result.iloc[0]', '                    return result', '                except:', '                    pass', ""            if filter_type is None or filter_type == 'numeric':"", '                data = self._get_numeric_data()', ""            elif filter_type == 'bool':"", '                data = self._get_bool_data()', '            else:  ', '                e = NotImplementedError(""Handling exception with filter_""', '                                        ""type %s not implemented."" %', '                                        filter_type)', '                raise_with_traceback(e)', '            result = f(data.values)', '            labels = data._get_agg_axis(axis)', '    else:', '        if numeric_only:', ""            if filter_type is None or filter_type == 'numeric':"", '                data = self._get_numeric_data()', ""            elif filter_type == 'bool':"", '                data = self._get_bool_data()', '            else:  ', '                msg = (""Generating numeric_only data with filter_type %s""', '                       ""not supported."" % filter_type)', '                raise NotImplementedError(msg)', '            values = data.values', '            labels = data._get_agg_axis(axis)', '        else:', '            values = self.values', '        result = f(values)', ""    if hasattr(result, 'dtype') and is_object_dtype(result.dtype):"", '        try:', ""            if filter_type is None or filter_type == 'numeric':"", '                result = result.astype(np.float64)', ""            elif filter_type == 'bool' and notnull(result).all():"", '                result = result.astype(np.bool_)', '        except (ValueError, TypeError):', '            if axis == 0:', '                result = com._coerce_to_dtypes(result, self.dtypes)', '    return Series(result, index=labels)']","['cls.sum = _make_stat_function(', '            values = self.values', '                    result = self.apply(f, reduce=False)', '                    if result.ndim == self.ndim:', '                        result = result.iloc[0]', '            result = f(data.values)', '            values = data.values', '            values = self.values', ""    if hasattr(result, 'dtype') and is_object_dtype(result.dtype):"", '                result = result.astype(np.float64)', ""            elif filter_type == 'bool' and notnull(result).all():"", '                result = result.astype(np.bool_)', '                result = com._coerce_to_dtypes(result, self.dtypes)']",,
38490727,"se = pd.Series(mylist)
df['new_col'] = se.values","['se = pd.Series(mylist)', ""df['new_col'] = se.values""]","[""df['new_col'] = se.values""]","[""df['new_col'] = se.values""]",,
38503561,"import pandas as pd
df = pd.DataFrame([['A','C','A','B','C','A','B','B','A','A'], ['ONE','TWO','ONE','ONE','ONE','TWO','ONE','TWO','ONE','THREE']]).T
df.columns = [['Alphabet','Words']]
print(df)   
df['COUNTER'] =1       
group_data = df.groupby(['Alphabet','Words'])['COUNTER'].sum() 
print(group_data)","[""df = pd.DataFrame([['A','C','A','B','C','A','B','B','A','A'], ['ONE','TWO','ONE','ONE','ONE','TWO','ONE','TWO','ONE','THREE']]).T"", ""group_data = df.groupby(['Alphabet','Words'])['COUNTER'].sum() ""]","['import pandas as pd', ""df.columns = [['Alphabet','Words']]"", 'print(df)   ', ""df['COUNTER'] =1       "", ""group_data = df.groupby(['Alphabet','Words'])['COUNTER'].sum() "", 'print(group_data)']","[""df = pd.DataFrame([['A','C','A','B','C','A','B','B','A','A'], ['ONE','TWO','ONE','ONE','ONE','TWO','ONE','TWO','ONE','THREE']]).T"", ""group_data = df.groupby(['Alphabet','Words'])['COUNTER'].sum() ""]",,
38510820,,[],[''],[],[],[]
38544742,,[],[''],[],[],[]
38579700,"(df['A'] + df['B']).where((df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])
np.where(m, A, B)
A.where(m, B)
pd.DataFrame.where(cond=(df['A'] < 0) | (df['B'] > 0), self=df['A'] + df['B'], other=df['A'] / df['B'])
pd.DataFrame.where(df['A'] + df['B'], (df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])","[""(df['A'] + df['B']).where((df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])"", 'np.where(m, A, B)', 'A.where(m, B)', ""pd.DataFrame.where(cond=(df['A'] < 0) | (df['B'] > 0), self=df['A'] + df['B'], other=df['A'] / df['B'])"", ""pd.DataFrame.where(df['A'] + df['B'], (df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])""]","[""(df['A'] + df['B']).where((df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])"", 'np.where(m, A, B)', 'A.where(m, B)']","[""(df['A'] + df['B']).where((df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])"", 'np.where(m, A, B)', 'A.where(m, B)', ""pd.DataFrame.where(cond=(df['A'] < 0) | (df['B'] > 0), self=df['A'] + df['B'], other=df['A'] / df['B'])"", ""pd.DataFrame.where(df['A'] + df['B'], (df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])""]",,
38580576,"pipeline = make_pipeline(
     CountVectorizer(), 
     FunctionTransformer(lambda x: x.todense(), accept_sparse=True), 
     RandomForestClassifier()
)",[],"['pipeline = make_pipeline(', '     CountVectorizer(), ', '     FunctionTransformer(lambda x: x.todense(), accept_sparse=True), ', '     RandomForestClassifier()', ')']",[],[],[]
38650886,,[],[''],[],[],[]
38709267,"df.plot(kind='bar', stacked=True, colormap='Paired')","[""df.plot(kind='bar', stacked=True, colormap='Paired')""]","[""df.plot(kind='bar', stacked=True, colormap='Paired')""]","[""df.plot(kind='bar', stacked=True, colormap='Paired')""]",,
38713212,"df.T.apply(tuple).apply(list)
pd.Series(df.T.to_dict('list'))
a    [1, 2, 3, 4]
b    [5, 6, 7, 8]
dtype: object
from string import ascii_letters
letters = list(ascii_letters)
df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),
                  pd.MultiIndex.from_product([letters, letters]),
                  letters)","['df.T.apply(tuple).apply(list)', ""pd.Series(df.T.to_dict('list'))"", 'df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),', '                  pd.MultiIndex.from_product([letters, letters]),']","['df.T.apply(tuple).apply(list)', 'a    [1, 2, 3, 4]', 'b    [5, 6, 7, 8]', 'dtype: object', 'from string import ascii_letters', 'letters = list(ascii_letters)', '                  pd.MultiIndex.from_product([letters, letters]),', '                  letters)']","['df.T.apply(tuple).apply(list)', ""pd.Series(df.T.to_dict('list'))"", '                  pd.MultiIndex.from_product([letters, letters]),']",,
38713387,"print (pd.Series(df.values.tolist(), index=df.index))
a    [1, 2, 3, 4]
b    [5, 6, 7, 8]
dtype: object
from string import ascii_letters
letters = list(ascii_letters)
df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),
                  pd.MultiIndex.from_product([letters, letters]),
                  letters)","['print (pd.Series(df.values.tolist(), index=df.index))', 'df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),', '                  pd.MultiIndex.from_product([letters, letters]),']","['a    [1, 2, 3, 4]', 'b    [5, 6, 7, 8]', 'dtype: object', 'from string import ascii_letters', 'letters = list(ascii_letters)', '                  pd.MultiIndex.from_product([letters, letters]),', '                  letters)']","['print (pd.Series(df.values.tolist(), index=df.index))', '                  pd.MultiIndex.from_product([letters, letters]),']",,
38750433,"for k, v in dtype.items():
    df[k] = df[k].astype(v)",['    df[k] = df[k].astype(v)'],"['for k, v in dtype.items():', '    df[k] = df[k].astype(v)']",['    df[k] = df[k].astype(v)'],,
38757990,"df = pd.read_csv('output_list.txt', sep="" "", header=None, names=[""a"", ""b"", ""c""])","['df = pd.read_csv(\'output_list.txt\', sep="" "", header=None, names=[""a"", ""b"", ""c""])']","['df = pd.read_csv(\'output_list.txt\', sep="" "", header=None, names=[""a"", ""b"", ""c""])']","['df = pd.read_csv(\'output_list.txt\', sep="" "", header=None, names=[""a"", ""b"", ""c""])']",,
38776854,"import pandas as pd
import re
df = pd.DataFrame({'$a':[1,2], '$b': [3,4],'$c':[5,6], '$d': [7,8], '$e': [9,10]})
delimiters = '$'
matchPattern = '|'.join(map(re.escape, delimiters))
df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]
df
df","[""df = pd.DataFrame({'$a':[1,2], '$b': [3,4],'$c':[5,6], '$d': [7,8], '$e': [9,10]})"", ""matchPattern = '|'.join(map(re.escape, delimiters))"", 'df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]']","['import pandas as pd', 'import re', ""delimiters = '$'"", ""matchPattern = '|'.join(map(re.escape, delimiters))"", 'df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]', 'df', 'df']","[""matchPattern = '|'.join(map(re.escape, delimiters))"", 'df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]']",,
38801975,"import pandas as pd
import numpy as np
from IPython.display import display, HTML
CSS = """"""
.output {
    flex-direction: row;
}
""""""
HTML('<style>{}</style>'.format(CSS))
CSS = """"""
div.cell:nth-child(5) .output {
    flex-direction: row;
}
""""""","[""HTML('<style>{}</style>'.format(CSS))""]","['import pandas as pd', 'import numpy as np', 'from IPython.display import display, HTML', 'CSS = """"""', '.output {', '    flex-direction: row;', '}', '""""""', ""HTML('<style>{}</style>'.format(CSS))"", 'CSS = """"""', 'div.cell:nth-child(5) .output {', '    flex-direction: row;', '}', '""""""']","[""HTML('<style>{}</style>'.format(CSS))""]",,
38886211,"df = pd.DataFrame({True:[1,2,3],False:[3,4,5]}); df
df[[True]]
df2 = pd.DataFrame({'A':[1,2,3],'B':[3,4,5]}); df2
df2[['B']]
df.loc[[True]]
df2.loc[[True,False,True], 'B']
df2.loc[1:2]
df2[1:2]","['df = pd.DataFrame({True:[1,2,3],False:[3,4,5]}); df', ""df2 = pd.DataFrame({'A':[1,2,3],'B':[3,4,5]}); df2"", 'df.loc[[True]]', ""df2.loc[[True,False,True], 'B']"", 'df2.loc[1:2]']","['df[[True]]', ""df2[['B']]"", 'df.loc[[True]]', ""df2.loc[[True,False,True], 'B']"", 'df2.loc[1:2]', 'df2[1:2]']","['df.loc[[True]]', ""df2.loc[[True,False,True], 'B']"", 'df2.loc[1:2]']",,
38889524,"df = pd.DataFrame({'closing_price': np.random.randint(95, 105, 10)})
df
df.query('99 <= closing_price <= 101')
qry = ""(closing_price.mean() - 2*closing_price.std())"" +\
df.query(qry)","[""df = pd.DataFrame({'closing_price': np.random.randint(95, 105, 10)})"", ""df.query('99 <= closing_price <= 101')"", 'df.query(qry)']","['df', ""df.query('99 <= closing_price <= 101')"", 'qry = ""(closing_price.mean() - 2*closing_price.std())"" +\\', 'df.query(qry)']","[""df.query('99 <= closing_price <= 101')"", 'df.query(qry)']",,
38900352,,[],[''],[],[],[]
38902835,"import pandas as pd
df = pd.DataFrame({'A':range(5), 'B':range(5)})
print('df: {0}'.format(df))
import sklearn.utils
df = sklearn.utils.shuffle(df)
print('\n\ndf: {0}'.format(df))
df = df.reset_index(drop=True)","[""df = pd.DataFrame({'A':range(5), 'B':range(5)})"", ""print('df: {0}'.format(df))"", ""print('\\n\\ndf: {0}'.format(df))"", 'df = df.reset_index(drop=True)']","['import pandas as pd', ""print('df: {0}'.format(df))"", 'import sklearn.utils', 'df = sklearn.utils.shuffle(df)', ""print('\\n\\ndf: {0}'.format(df))"", 'df = df.reset_index(drop=True)']","[""print('df: {0}'.format(df))"", ""print('\\n\\ndf: {0}'.format(df))"", 'df = df.reset_index(drop=True)']",,
38931854,"df.columns = df.columns.str.lower()
df
df.columns = df.columns.str.lower()
df","['df.columns = df.columns.str.lower()', 'df.columns = df.columns.str.lower()']","['df.columns = df.columns.str.lower()', 'df', 'df.columns = df.columns.str.lower()', 'df']","['df.columns = df.columns.str.lower()', 'df.columns = df.columns.str.lower()']",,
38935669,"df.groupby('col1').agg({'col2': 'max', 'col3': 'min'})
col1            
df.groupby('col1', as_index=False).agg({'col2': 'max', 'col3': 'min'})
df.groupby('col1').agg({'col2': 'max', 'col3': 'min'}).reset_index()
agg_df = df.groupby('col1').agg({'col2': ['max', 'min', 'std'], 
                                 'col3': ['size', 'std', 'mean', 'max']})
col1                                           
agg_df['col2']  
col1                    
agg_df[('col2', 'max')]  
col1
agg_df.xs('max', axis=1, level=1)  
col1            
df.groupby('col1')['col2'].agg({'max_col2': 'max'})
col1          
df.groupby('col1')['col2'].agg(['max']).rename(columns={'max': 'col2_max'})
col1          
agg_df.columns = ['_'.join(col) for col in agg_df.columns]
col1                                                                        
df.assign(new_col=df.eval('col2 * col3')).groupby('col1').agg('max') 
col1                     
df.assign(new_col=df.eval('col2 * col3')).groupby('col1')['new_col'].agg('max')
col1
1   -1
df.groupby('col1').apply(lambda x: (x.col2 * x.col3).max())
col1
1   -1
dtype: int64","[""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'})"", ""df.groupby('col1', as_index=False).agg({'col2': 'max', 'col3': 'min'})"", ""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'}).reset_index()"", ""agg_df = df.groupby('col1').agg({'col2': ['max', 'min', 'std'], "", ""agg_df.xs('max', axis=1, level=1)  "", ""df.groupby('col1')['col2'].agg({'max_col2': 'max'})"", ""df.groupby('col1')['col2'].agg(['max']).rename(columns={'max': 'col2_max'})"", ""agg_df.columns = ['_'.join(col) for col in agg_df.columns]"", ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1').agg('max') "", ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1')['new_col'].agg('max')"", ""df.groupby('col1').apply(lambda x: (x.col2 * x.col3).max())""]","[""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'})"", 'col1            ', ""df.groupby('col1', as_index=False).agg({'col2': 'max', 'col3': 'min'})"", ""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'}).reset_index()"", ""agg_df = df.groupby('col1').agg({'col2': ['max', 'min', 'std'], "", ""                                 'col3': ['size', 'std', 'mean', 'max']})"", 'col1                                           ', ""agg_df['col2']  "", 'col1                    ', ""agg_df[('col2', 'max')]  "", 'col1', ""agg_df.xs('max', axis=1, level=1)  "", 'col1            ', ""df.groupby('col1')['col2'].agg({'max_col2': 'max'})"", 'col1          ', ""df.groupby('col1')['col2'].agg(['max']).rename(columns={'max': 'col2_max'})"", 'col1          ', ""agg_df.columns = ['_'.join(col) for col in agg_df.columns]"", 'col1                                                                        ', ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1').agg('max') "", 'col1                     ', ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1')['new_col'].agg('max')"", 'col1', '1   -1', ""df.groupby('col1').apply(lambda x: (x.col2 * x.col3).max())"", 'col1', '1   -1', 'dtype: int64']","[""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'})"", ""df.groupby('col1', as_index=False).agg({'col2': 'max', 'col3': 'min'})"", ""df.groupby('col1').agg({'col2': 'max', 'col3': 'min'}).reset_index()"", ""agg_df = df.groupby('col1').agg({'col2': ['max', 'min', 'std'], "", ""agg_df.xs('max', axis=1, level=1)  "", ""df.groupby('col1')['col2'].agg({'max_col2': 'max'})"", ""df.groupby('col1')['col2'].agg(['max']).rename(columns={'max': 'col2_max'})"", ""agg_df.columns = ['_'.join(col) for col in agg_df.columns]"", ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1').agg('max') "", ""df.assign(new_col=df.eval('col2 * col3')).groupby('col1')['new_col'].agg('max')"", ""df.groupby('col1').apply(lambda x: (x.col2 * x.col3).max())""]",,
38951835,"pandas.read_csv(filename, sep='\t', lineterminator='\r')
import codecs
doc = codecs.open('document','rU','UTF-16') 
df = pandas.read_csv(doc, sep='\t')","[""pandas.read_csv(filename, sep='\\t', lineterminator='\\r')"", ""df = pandas.read_csv(doc, sep='\\t')""]","[""pandas.read_csv(filename, sep='\\t', lineterminator='\\r')"", 'import codecs', ""doc = codecs.open('document','rU','UTF-16') "", ""df = pandas.read_csv(doc, sep='\\t')""]","[""pandas.read_csv(filename, sep='\\t', lineterminator='\\r')"", ""df = pandas.read_csv(doc, sep='\\t')""]",,
39104306,"from sklearn.metrics.pairwise import cosine_similarity
from scipy import sparse
A =  np.array([[0, 1, 0, 0, 1], [0, 0, 1, 1, 1],[1, 1, 0, 1, 0]])
A_sparse = sparse.csr_matrix(A)
similarities = cosine_similarity(A_sparse)
print('pairwise dense output:\n {}\n'.format(similarities))
similarities_sparse = cosine_similarity(A_sparse,dense_output=False)
print('pairwise sparse output:\n {}\n'.format(similarities_sparse))
A_sparse.transpose()","[""print('pairwise dense output:\\n {}\\n'.format(similarities))"", ""print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"", 'A_sparse.transpose()']","['from sklearn.metrics.pairwise import cosine_similarity', 'from scipy import sparse', 'A =  np.array([[0, 1, 0, 0, 1], [0, 0, 1, 1, 1],[1, 1, 0, 1, 0]])', 'A_sparse = sparse.csr_matrix(A)', 'similarities = cosine_similarity(A_sparse)', ""print('pairwise dense output:\\n {}\\n'.format(similarities))"", 'similarities_sparse = cosine_similarity(A_sparse,dense_output=False)', ""print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"", 'A_sparse.transpose()']","[""print('pairwise dense output:\\n {}\\n'.format(similarities))"", ""print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"", 'A_sparse.transpose()']",,
39116381,"import matplotlib.pyplot as plt
import numpy as np
for i in range(3):
    plt.plot(np.arange(10) + i)
plt.gca().set_prop_cycle(None)
for i in range(3):
    plt.plot(np.arange(10, 0, -1) + i)
plt.show()","['    plt.plot(np.arange(10) + i)', '    plt.plot(np.arange(10, 0, -1) + i)']","['import matplotlib.pyplot as plt', 'import numpy as np', 'for i in range(3):', '    plt.plot(np.arange(10) + i)', 'plt.gca().set_prop_cycle(None)', 'for i in range(3):', '    plt.plot(np.arange(10, 0, -1) + i)', 'plt.show()']","['    plt.plot(np.arange(10) + i)', '    plt.plot(np.arange(10, 0, -1) + i)']",,
39132900,"df.groupby(['id', 'group', 'term']).size().unstack(fill_value=0)
df = pd.DataFrame(dict(id=np.random.choice(100, 1000000),
                       group=np.random.choice(20, 1000000),
                       term=np.random.choice(10, 1000000)))","[""df.groupby(['id', 'group', 'term']).size().unstack(fill_value=0)"", 'df = pd.DataFrame(dict(id=np.random.choice(100, 1000000),']","[""df.groupby(['id', 'group', 'term']).size().unstack(fill_value=0)"", '                       group=np.random.choice(20, 1000000),', '                       term=np.random.choice(10, 1000000)))']","[""df.groupby(['id', 'group', 'term']).size().unstack(fill_value=0)""]",,
39162006,"df = pd.DataFrame(np.random.randint(0,5,(6, 2)), columns=['col1','col2'])
df['ind1'] = list('AAABCC')
df['ind2'] = range(6)
df.set_index(['ind1','ind2'], inplace=True)
df
df.groupby([df.index.get_level_values(0),'col1']).count()","[""df = pd.DataFrame(np.random.randint(0,5,(6, 2)), columns=['col1','col2'])"", ""df.set_index(['ind1','ind2'], inplace=True)"", ""df.groupby([df.index.get_level_values(0),'col1']).count()""]","[""df['ind1'] = list('AAABCC')"", ""df['ind2'] = range(6)"", ""df.set_index(['ind1','ind2'], inplace=True)"", 'df', ""df.groupby([df.index.get_level_values(0),'col1']).count()""]","[""df.set_index(['ind1','ind2'], inplace=True)"", ""df.groupby([df.index.get_level_values(0),'col1']).count()""]",,
39186403,"grouped = df.groupby('Location').resample('H')['Event'].count()
grouped.unstack(level=0).fillna(0)","[""grouped = df.groupby('Location').resample('H')['Event'].count()"", 'grouped.unstack(level=0).fillna(0)']","[""grouped = df.groupby('Location').resample('H')['Event'].count()"", 'grouped.unstack(level=0).fillna(0)']","[""grouped = df.groupby('Location').resample('H')['Event'].count()"", 'grouped.unstack(level=0).fillna(0)']",,
39192113,df[df.columns.difference(['b'])],"[""df[df.columns.difference(['b'])]""]","[""df[df.columns.difference(['b'])]""]","[""df[df.columns.difference(['b'])]""]",,
39206377,,[],[''],[],[],[]
39237712,"df = df.reindex_axis(['mean',0,1,2,3,4], axis=1)
df = df.reindex_axis(sorted(df.columns), axis=1)
df = df.reindex_axis(['opened'] + list([a for a in df.columns if a != 'opened']), axis=1)","[""df = df.reindex_axis(['mean',0,1,2,3,4], axis=1)"", 'df = df.reindex_axis(sorted(df.columns), axis=1)', ""df = df.reindex_axis(['opened'] + list([a for a in df.columns if a != 'opened']), axis=1)""]","[""df = df.reindex_axis(['mean',0,1,2,3,4], axis=1)"", 'df = df.reindex_axis(sorted(df.columns), axis=1)', ""df = df.reindex_axis(['opened'] + list([a for a in df.columns if a != 'opened']), axis=1)""]","[""df = df.reindex_axis(['mean',0,1,2,3,4], axis=1)"", 'df = df.reindex_axis(sorted(df.columns), axis=1)', ""df = df.reindex_axis(['opened'] + list([a for a in df.columns if a != 'opened']), axis=1)""]",,
39246607,"f.sort_values(by=[""c1"",""c2""], ascending=[False, True])","['f.sort_values(by=[""c1"",""c2""], ascending=[False, True])']","['f.sort_values(by=[""c1"",""c2""], ascending=[False, True])']","['f.sort_values(by=[""c1"",""c2""], ascending=[False, True])']",,
39247824,"grouped = s.groupby(s)
grouped = s.groupby(lambda x: s[x])","['grouped = s.groupby(s)', 'grouped = s.groupby(lambda x: s[x])']","['grouped = s.groupby(s)', 'grouped = s.groupby(lambda x: s[x])']","['grouped = s.groupby(s)', 'grouped = s.groupby(lambda x: s[x])']",,
39251401,"import seaborn as sns
import pandas as pd
import numpy as np
np.random.seed(1974)
df = pd.DataFrame(
    np.random.normal(10, 1, 30).reshape(10, 3),
    index=pd.date_range('2010-01-01', freq='M', periods=10),
    columns=('one', 'two', 'three'))
df['key1'] = (4, 4, 4, 6, 6, 6, 8, 8, 8, 8)
sns.pairplot(x_vars=[""one""], y_vars=[""two""], data=df, hue=""key1"", size=5)
sns.pairplot(vars=[""one"",""two"",""three""], data=df, hue=""key1"", size=5)","['df = pd.DataFrame(', ""    index=pd.date_range('2010-01-01', freq='M', periods=10),""]","['import seaborn as sns', 'import pandas as pd', 'import numpy as np', 'np.random.seed(1974)', '    np.random.normal(10, 1, 30).reshape(10, 3),', ""    index=pd.date_range('2010-01-01', freq='M', periods=10),"", ""    columns=('one', 'two', 'three'))"", ""df['key1'] = (4, 4, 4, 6, 6, 6, 8, 8, 8, 8)"", 'sns.pairplot(x_vars=[""one""], y_vars=[""two""], data=df, hue=""key1"", size=5)', 'sns.pairplot(vars=[""one"",""two"",""three""], data=df, hue=""key1"", size=5)']","[""    index=pd.date_range('2010-01-01', freq='M', periods=10),""]",,
39259437,"df['col_3'] = df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)","[""df['col_3'] = df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)""]","[""df['col_3'] = df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)""]","[""df['col_3'] = df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)""]",,
39276195,"numpy.percentile(df.a,95) 
df.a.quantile(.95)  
df[df.a < np.percentile(df.a,95)]",['df.a.quantile(.95)  '],"['numpy.percentile(df.a,95) ', 'df.a.quantile(.95)  ', 'df[df.a < np.percentile(df.a,95)]']",['df.a.quantile(.95)  '],,
39287161,,[],[''],[],[],[]
39310387,"In[114]: index = pd.DatetimeIndex([pd.Timestamp('2012-01-01 02:03:04.000'), pd.Timestamp('2012-01-01 02:03:04.002'), pd.Timestamp('20130712 02:03:04.500'), pd.Timestamp('2012-01-01 02:03:04.501')])
In[115]: index.values
array(['2012-01-01T02:03:04.000000000', '2012-01-01T02:03:04.002000000',
       '2013-07-12T02:03:04.500000000', '2012-01-01T02:03:04.501000000'], dtype='datetime64[ns]')
In[116]: index.round('S')
DatetimeIndex(['2012-01-01 02:03:04', '2012-01-01 02:03:04',
               '2013-07-12 02:03:04', '2012-01-01 02:03:05'],
              dtype='datetime64[ns]', freq=None)","[""In[114]: index = pd.DatetimeIndex([pd.Timestamp('2012-01-01 02:03:04.000'), pd.Timestamp('2012-01-01 02:03:04.002'), pd.Timestamp('20130712 02:03:04.500'), pd.Timestamp('2012-01-01 02:03:04.501')])"", 'In[115]: index.values', ""In[116]: index.round('S')""]","[""In[114]: index = pd.DatetimeIndex([pd.Timestamp('2012-01-01 02:03:04.000'), pd.Timestamp('2012-01-01 02:03:04.002'), pd.Timestamp('20130712 02:03:04.500'), pd.Timestamp('2012-01-01 02:03:04.501')])"", 'In[115]: index.values', ""array(['2012-01-01T02:03:04.000000000', '2012-01-01T02:03:04.002000000',"", ""       '2013-07-12T02:03:04.500000000', '2012-01-01T02:03:04.501000000'], dtype='datetime64[ns]')"", ""In[116]: index.round('S')"", ""DatetimeIndex(['2012-01-01 02:03:04', '2012-01-01 02:03:04',"", ""               '2013-07-12 02:03:04', '2012-01-01 02:03:05'],"", ""              dtype='datetime64[ns]', freq=None)""]","[""In[114]: index = pd.DatetimeIndex([pd.Timestamp('2012-01-01 02:03:04.000'), pd.Timestamp('2012-01-01 02:03:04.002'), pd.Timestamp('20130712 02:03:04.500'), pd.Timestamp('2012-01-01 02:03:04.501')])"", 'In[115]: index.values', ""In[116]: index.round('S')""]",,
39347475,"import pandas as pd
df = []
df.append(dict(date='2016-04-01', sleep=11.2, calories=2740))
df.append(dict(date='2016-04-02', sleep=7.3, calories=3600))
df.append(dict(date='2016-04-03', sleep=8.3, calories=3500))
df = pd.DataFrame(df)","[""df.append(dict(date='2016-04-01', sleep=11.2, calories=2740))"", ""df.append(dict(date='2016-04-02', sleep=7.3, calories=3600))"", ""df.append(dict(date='2016-04-03', sleep=8.3, calories=3500))"", 'df = pd.DataFrame(df)']","['import pandas as pd', 'df = []', ""df.append(dict(date='2016-04-01', sleep=11.2, calories=2740))"", ""df.append(dict(date='2016-04-02', sleep=7.3, calories=3600))"", ""df.append(dict(date='2016-04-03', sleep=8.3, calories=3500))""]","[""df.append(dict(date='2016-04-01', sleep=11.2, calories=2740))"", ""df.append(dict(date='2016-04-02', sleep=7.3, calories=3600))"", ""df.append(dict(date='2016-04-03', sleep=8.3, calories=3500))""]",,
39358752,"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import six
df = pd.DataFrame()
df['date'] = ['2016-04-01', '2016-04-02', '2016-04-03']
df['calories'] = [2200, 2100, 1500]
df['sleep hours'] = [2200, 2100, 1500]
df['gym'] = [True, False, False]
def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,
                     bbox=[0, 0, 1, 1], header_columns=0,
                     ax=None, **kwargs):
    if ax is None:
        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])
        fig, ax = plt.subplots(figsize=size)
        ax.axis('off')
    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)
    mpl_table.auto_set_font_size(False)
    mpl_table.set_fontsize(font_size)
    for k, cell in six.iteritems(mpl_table._cells):
        cell.set_edgecolor(edge_color)
        if k[0] == 0 or k[1] < header_columns:
            cell.set_text_props(weight='bold', color='w')
            cell.set_facecolor(header_color)
        else:
            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])
    return ax
render_mpl_table(df, header_columns=0, col_width=2.0)","['df = pd.DataFrame()', '        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])', '    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)', '    for k, cell in six.iteritems(mpl_table._cells):']","['import pandas as pd', 'import numpy as np', 'import matplotlib.pyplot as plt', 'import six', ""df['date'] = ['2016-04-01', '2016-04-02', '2016-04-03']"", ""df['calories'] = [2200, 2100, 1500]"", ""df['sleep hours'] = [2200, 2100, 1500]"", ""df['gym'] = [True, False, False]"", 'def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,', '                     bbox=[0, 0, 1, 1], header_columns=0,', '                     ax=None, **kwargs):', '    if ax is None:', '        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])', '        fig, ax = plt.subplots(figsize=size)', ""        ax.axis('off')"", '    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)', '    mpl_table.auto_set_font_size(False)', '    mpl_table.set_fontsize(font_size)', '    for k, cell in six.iteritems(mpl_table._cells):', '        cell.set_edgecolor(edge_color)', '        if k[0] == 0 or k[1] < header_columns:', ""            cell.set_text_props(weight='bold', color='w')"", '            cell.set_facecolor(header_color)', '        else:', '            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])', '    return ax', 'render_mpl_table(df, header_columns=0, col_width=2.0)']","['        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])', '    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)', '    for k, cell in six.iteritems(mpl_table._cells):']",,
39358924,"df['A'], df['B'] = df['AB'].str.split(' ', 1).str
df['AB'].str.split(' ', 1, expand=True)
import pandas as pd
df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})
df
df['AB_split'] = df['AB'].str.split('-')
df
upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})
upper_lower_df
upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()
upper_lower_df
df['AB'].str[0]
df['AB'].str[1]
df['AB'].str.split('-', 1).str[0]
df['AB'].str.split('-', 1).str[1]
df['A'], df['B'] = df['AB'].str.split('-', 1).str
df
df['AB'].str.split('-', 1, expand=True)
df = df[['AB']]
df
df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", 'import pandas as pd', 'df', ""df['AB_split'] = df['AB'].str.split('-')"", 'df', 'upper_lower_df', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', 'upper_lower_df', ""df['AB'].str[0]"", ""df['AB'].str[1]"", ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", 'df', ""df['AB'].str.split('-', 1, expand=True)"", ""df = df[['AB']]"", 'df', ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]"
39363715,"df_ = pd.cut(df[['A', 'B']].stack(), 5, labels=list(range(5))).unstack()
df_.columns = df_.columns.to_series() + 'bkt'
pd.concat([df, df_], axis=1)
df = pd.DataFrame(dict(A=(np.random.randn(10000) * 100 + 20).astype(int),
                       B=(np.random.randn(10000) * 100 - 20).astype(int)))
import seaborn as sns
df.index = df.index.to_series().astype(str).radd('city')
df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()
df_.columns = df_.columns.to_series() + 'bkt'
sns.jointplot(x=df_.Abkt, y=df_.Bbkt, kind=""scatter"", color=""k"")
mean, cov = [0, 1], [(1, .5), (.5, 1)]
data = np.random.multivariate_normal(mean, cov, 100000)
df = pd.DataFrame(data, columns=[""A"", ""B""])
df.index = df.index.to_series().astype(str).radd('city')
df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()
df_.columns = df_.columns.to_series() + 'bkt'
sns.jointplot(x=df_.Abkt, y=df_.Bbkt, kind=""scatter"", color=""k"")
from bokeh.io import show, output_notebook, output_file
from bokeh.plotting import figure
from bokeh.layouts import row, column
from bokeh.models import ColumnDataSource, Select, CustomJS
output_notebook()
flips = np.random.choice((1, -1), (5, 5))
flips = np.tril(flips, -1) + np.triu(flips, 1) + np.eye(flips.shape[0])
half = np.ones((5, 5)) / 2
cov = (half + np.diag(np.diag(half))) * flips
mean = np.zeros(5)
data = np.random.multivariate_normal(mean, cov, 10000)
df = pd.DataFrame(data, columns=list('ABCDE'))
df.index = df.index.to_series().astype(str).radd('city')
b = 20
df_ = pd.cut(df.stack(), b, labels=list(range(b))).unstack()
df_[['x', 'y']] = df_.loc[:, ['A', 'B']]
source = ColumnDataSource(data=df_)
tools = 'box_select,pan,box_zoom,wheel_zoom,reset,resize,save'
p = figure(plot_width=600, plot_height=300)
p.circle('x', 'y', source=source, fill_color='olive', line_color='black', alpha=.5)
def gcb(like, n):
    code = """"""
    var data = source.get('data');
    var f = cb_obj.get('value');
    data['{0}{1}'] = data[f];
    source.trigger('change');
    """"""
    return CustomJS(args=dict(source=source), code=code.format(like, n))
xcb = CustomJS(
    args=dict(source=source),
    code=""""""
    var data = source.get('data');
    var colm = cb_obj.get('value');
    data['x'] = data[colm];
    source.trigger('change');
    """"""
)
ycb = CustomJS(
    args=dict(source=source),
    code=""""""
    var data = source.get('data');
    var colm = cb_obj.get('value');
    data['y'] = data[colm];
    source.trigger('change');
    """"""
)
options = list('ABCDE')
x_select = Select(options=options, callback=xcb, value='A')
y_select = Select(options=options, callback=ycb, value='B')
show(column(p, row(x_select, y_select)))","[""df_ = pd.cut(df[['A', 'B']].stack(), 5, labels=list(range(5))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'pd.concat([df, df_], axis=1)', 'df = pd.DataFrame(dict(A=(np.random.randn(10000) * 100 + 20).astype(int),', '                       B=(np.random.randn(10000) * 100 - 20).astype(int)))', ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'df = pd.DataFrame(data, columns=[""A"", ""B""])', ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'flips = np.tril(flips, -1) + np.triu(flips, 1) + np.eye(flips.shape[0])', ""df = pd.DataFrame(data, columns=list('ABCDE'))"", ""df.index = df.index.to_series().astype(str).radd('city')"", 'df_ = pd.cut(df.stack(), b, labels=list(range(b))).unstack()', ""df_[['x', 'y']] = df_.loc[:, ['A', 'B']]"", '    return CustomJS(args=dict(source=source), code=code.format(like, n))']","[""df_ = pd.cut(df[['A', 'B']].stack(), 5, labels=list(range(5))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'pd.concat([df, df_], axis=1)', '                       B=(np.random.randn(10000) * 100 - 20).astype(int)))', 'import seaborn as sns', ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'sns.jointplot(x=df_.Abkt, y=df_.Bbkt, kind=""scatter"", color=""k"")', 'mean, cov = [0, 1], [(1, .5), (.5, 1)]', 'data = np.random.multivariate_normal(mean, cov, 100000)', ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'sns.jointplot(x=df_.Abkt, y=df_.Bbkt, kind=""scatter"", color=""k"")', 'from bokeh.io import show, output_notebook, output_file', 'from bokeh.plotting import figure', 'from bokeh.layouts import row, column', 'from bokeh.models import ColumnDataSource, Select, CustomJS', 'output_notebook()', 'flips = np.random.choice((1, -1), (5, 5))', 'flips = np.tril(flips, -1) + np.triu(flips, 1) + np.eye(flips.shape[0])', 'half = np.ones((5, 5)) / 2', 'cov = (half + np.diag(np.diag(half))) * flips', 'mean = np.zeros(5)', 'data = np.random.multivariate_normal(mean, cov, 10000)', ""df.index = df.index.to_series().astype(str).radd('city')"", 'b = 20', 'df_ = pd.cut(df.stack(), b, labels=list(range(b))).unstack()', ""df_[['x', 'y']] = df_.loc[:, ['A', 'B']]"", 'source = ColumnDataSource(data=df_)', ""tools = 'box_select,pan,box_zoom,wheel_zoom,reset,resize,save'"", 'p = figure(plot_width=600, plot_height=300)', ""p.circle('x', 'y', source=source, fill_color='olive', line_color='black', alpha=.5)"", 'def gcb(like, n):', '    code = """"""', ""    var data = source.get('data');"", ""    var f = cb_obj.get('value');"", ""    data['{0}{1}'] = data[f];"", ""    source.trigger('change');"", '    """"""', '    return CustomJS(args=dict(source=source), code=code.format(like, n))', 'xcb = CustomJS(', '    args=dict(source=source),', '    code=""""""', ""    var data = source.get('data');"", ""    var colm = cb_obj.get('value');"", ""    data['x'] = data[colm];"", ""    source.trigger('change');"", '    """"""', ')', 'ycb = CustomJS(', '    args=dict(source=source),', '    code=""""""', ""    var data = source.get('data');"", ""    var colm = cb_obj.get('value');"", ""    data['y'] = data[colm];"", ""    source.trigger('change');"", '    """"""', ')', ""options = list('ABCDE')"", ""x_select = Select(options=options, callback=xcb, value='A')"", ""y_select = Select(options=options, callback=ycb, value='B')"", 'show(column(p, row(x_select, y_select)))']","[""df_ = pd.cut(df[['A', 'B']].stack(), 5, labels=list(range(5))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'pd.concat([df, df_], axis=1)', 'df = pd.DataFrame(dict(A=(np.random.randn(10000) * 100 + 20).astype(int),', '                       B=(np.random.randn(10000) * 100 - 20).astype(int)))', ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", ""df.index = df.index.to_series().astype(str).radd('city')"", ""df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()"", ""df_.columns = df_.columns.to_series() + 'bkt'"", 'flips = np.tril(flips, -1) + np.triu(flips, 1) + np.eye(flips.shape[0])', ""df.index = df.index.to_series().astype(str).radd('city')"", 'df_ = pd.cut(df.stack(), b, labels=list(range(b))).unstack()', ""df_[['x', 'y']] = df_.loc[:, ['A', 'B']]"", '    return CustomJS(args=dict(source=source), code=code.format(like, n))']",,
39366792,"dat1 = pd.concat([dat1, dat2], axis=1)","['dat1 = pd.concat([dat1, dat2], axis=1)']","['dat1 = pd.concat([dat1, dat2], axis=1)']","['dat1 = pd.concat([dat1, dat2], axis=1)']",,
39370553,,[],[''],[],[],[]
39371897,"if set(['A','C']).issubset(df.columns):
   df['sum'] = df['A'] + df['C']                ",[],"[""if set(['A','C']).issubset(df.columns):"", ""   df['sum'] = df['A'] + df['C']                ""]",[],[],[]
39377643,"import os, psutil, numpy as np",[],"['import os, psutil, numpy as np']",[],[],[]
39405540,"mydf = mydf.reindex( mydf.columns.tolist() + ['newcol1','newcol2'])  
mydf = mydf.reindex( mydf.columns.values + ['newcol1','newcol2'])  ","[""mydf = mydf.reindex( mydf.columns.tolist() + ['newcol1','newcol2'])  "", ""mydf = mydf.reindex( mydf.columns.values + ['newcol1','newcol2'])  ""]","[""mydf = mydf.reindex( mydf.columns.tolist() + ['newcol1','newcol2'])  "", ""mydf = mydf.reindex( mydf.columns.values + ['newcol1','newcol2'])  ""]","[""mydf = mydf.reindex( mydf.columns.tolist() + ['newcol1','newcol2'])  "", ""mydf = mydf.reindex( mydf.columns.values + ['newcol1','newcol2'])  ""]",,
39474812,"df.apply(lambda r : pd.datetime.combine(r['date_column_name'],r['time_column_name']),1)","[""df.apply(lambda r : pd.datetime.combine(r['date_column_name'],r['time_column_name']),1)""]","[""df.apply(lambda r : pd.datetime.combine(r['date_column_name'],r['time_column_name']),1)""]","[""df.apply(lambda r : pd.datetime.combine(r['date_column_name'],r['time_column_name']),1)""]",,
39478896,"import pandas
df = pandas.read_csv('somefile.txt')
df = df.fillna(0)","[""df = pandas.read_csv('somefile.txt')"", 'df = df.fillna(0)']","['import pandas', ""df = pandas.read_csv('somefile.txt')"", 'df = df.fillna(0)']","[""df = pandas.read_csv('somefile.txt')"", 'df = df.fillna(0)']",,
39482402,"swarm_plot = sns.swarmplot(...)
fig = swarm_plot.get_figure()
fig.savefig(...) 
fig = myGridPlotObject.fig",[],"['swarm_plot = sns.swarmplot(...)', 'fig = swarm_plot.get_figure()', 'fig.savefig(...) ', 'fig = myGridPlotObject.fig']",[],[],[]
39563662,"pd.read_json(jsonfile, lines=True)","['pd.read_json(jsonfile, lines=True)']","['pd.read_json(jsonfile, lines=True)']","['pd.read_json(jsonfile, lines=True)']",,
39621872,"df=pd.DataFrame({'A':np.random.rand(2)-1,'B':np.random.rand(2)},index=['val1','val2'] )
ax = df.plot(kind='bar', color=['r','b']) 
x_offset = -0.03
y_offset = 0.02
for p in ax.patches:
    b = p.get_bbox()
    val = ""{:+.2f}"".format(b.y1 + b.y0)        
    ax.annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 + y_offset))","[""df=pd.DataFrame({'A':np.random.rand(2)-1,'B':np.random.rand(2)},index=['val1','val2'] )"", ""ax = df.plot(kind='bar', color=['r','b']) "", '    val = ""{:+.2f}"".format(b.y1 + b.y0)        ']","[""ax = df.plot(kind='bar', color=['r','b']) "", 'x_offset = -0.03', 'y_offset = 0.02', 'for p in ax.patches:', '    b = p.get_bbox()', '    val = ""{:+.2f}"".format(b.y1 + b.y0)        ', '    ax.annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 + y_offset))']","[""ax = df.plot(kind='bar', color=['r','b']) "", '    val = ""{:+.2f}"".format(b.y1 + b.y0)        ']",,
39628860,"df2 = df
func1(df2)
func2(df)
df2 = df.copy()
func1(df2)
func2(df)",['df2 = df.copy()'],"['df2 = df', 'func1(df2)', 'func2(df)', 'df2 = df.copy()', 'func1(df2)', 'func2(df)']",['df2 = df.copy()'],,
39634150,"df_row_merged = pd.concat([df_a, df_b], ignore_index=True)
df_col_merged =pd.concat([df_a, df_b], axis=1)","['df_row_merged = pd.concat([df_a, df_b], ignore_index=True)', 'df_col_merged =pd.concat([df_a, df_b], axis=1)']","['df_row_merged = pd.concat([df_a, df_b], ignore_index=True)', 'df_col_merged =pd.concat([df_a, df_b], axis=1)']","['df_row_merged = pd.concat([df_a, df_b], ignore_index=True)', 'df_col_merged =pd.concat([df_a, df_b], axis=1)']",,
39657077,"df.columns = ['log(gdp)' if x=='gdp' else x for x in df.columns]
df.columns = ['log(gdp)' if x=='gdp' else 'cap_mod' if x=='cap' else x for x in df.columns]
col_dict = {'gdp': 'log(gdp)', 'cap': 'cap_mod'}   
df.columns = [col_dict.get(x, x) for x in df.columns]
df.rename(columns={'gdp':'log(gdp)'}, inplace=True)
df.columns = ['log(gdp)' if x=='gdp' else x for x in df.columns]","['df.columns = [col_dict.get(x, x) for x in df.columns]', ""df.rename(columns={'gdp':'log(gdp)'}, inplace=True)""]","[""df.columns = ['log(gdp)' if x=='gdp' else x for x in df.columns]"", ""df.columns = ['log(gdp)' if x=='gdp' else 'cap_mod' if x=='cap' else x for x in df.columns]"", ""col_dict = {'gdp': 'log(gdp)', 'cap': 'cap_mod'}   "", 'df.columns = [col_dict.get(x, x) for x in df.columns]', ""df.rename(columns={'gdp':'log(gdp)'}, inplace=True)"", ""df.columns = ['log(gdp)' if x=='gdp' else x for x in df.columns]""]","['df.columns = [col_dict.get(x, x) for x in df.columns]', ""df.rename(columns={'gdp':'log(gdp)'}, inplace=True)""]",,
39673666,"from sklearn.utils import shuffle
df = shuffle(df)",[],"['from sklearn.utils import shuffle', 'df = shuffle(df)']",[],[],[]
39762850,,[],[''],[],[],[]
39770407,"df.columns = ['column_one', 'column_two']
df.columns.names = ['name of the list of columns']
df.index.names = ['name of the index']
df.columns = [['one', 'one'], ['one', 'two']]","[""df.index.names = ['name of the index']""]","[""df.columns = ['column_one', 'column_two']"", ""df.columns.names = ['name of the list of columns']"", ""df.index.names = ['name of the index']"", ""df.columns = [['one', 'one'], ['one', 'two']]""]","[""df.index.names = ['name of the index']""]",,
39820329,"df = df[df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)]","[""df = df[df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)]""]","[""df = df[df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)]""]","[""df = df[df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)]""]",,
39830464,"data = 'col1,col2,col3\na,b,1\na,b,2\nc,d,3'
df = pd.read_csv(StringIO(data), dtype='category')
print (df)
print (df.dtypes)
dtype: object","[""df = pd.read_csv(StringIO(data), dtype='category')"", 'print (df.dtypes)']","[""data = 'col1,col2,col3\\na,b,1\\na,b,2\\nc,d,3'"", ""df = pd.read_csv(StringIO(data), dtype='category')"", 'print (df)', 'print (df.dtypes)', 'dtype: object']","[""df = pd.read_csv(StringIO(data), dtype='category')"", 'print (df.dtypes)']",,
39837358,"mydict = dict(zip(df.id, df.value))","['mydict = dict(zip(df.id, df.value))']","['mydict = dict(zip(df.id, df.value))']","['mydict = dict(zip(df.id, df.value))']",,
39891994,df['column']=df['column'].fillna(value),"[""df['column']=df['column'].fillna(value)""]","[""df['column']=df['column'].fillna(value)""]","[""df['column']=df['column'].fillna(value)""]",,
39923958,print(df.to_string()),['print(df.to_string())'],['print(df.to_string())'],['print(df.to_string())'],,
39946744,"def tidy_split(df, column, sep='|', keep=False):
    """"""
    Split the values of a column and expand so the new DataFrame has one split
    value per row. Filters rows where the column is missing.
    Params
    ------
    df : pandas.DataFrame
        dataframe with the column to split and expand
    column : str
        the column to split and expand
    sep : str
        the string used to split the column's values
    keep : bool
        whether to retain the presplit value as it's own row
    Returns
    -------
    pandas.DataFrame
        Returns a dataframe with the same columns as `df`.
    """"""
    indexes = list()
    new_values = list()
    df = df.dropna(subset=[column])
    for i, presplit in enumerate(df[column].astype(str)):
        values = presplit.split(sep)
        if keep and len(values) > 1:
            indexes.append(i)
            new_values.append(presplit)
        for value in values:
            indexes.append(i)
            new_values.append(value)
    new_df = df.iloc[indexes, :].copy()
    new_df[column] = new_values
    return new_df
tidy_split(a, 'var1', sep=',')","['    df = df.dropna(subset=[column])', '    for i, presplit in enumerate(df[column].astype(str)):', '        values = presplit.split(sep)', '            indexes.append(i)', '            new_values.append(presplit)', '            indexes.append(i)', '            new_values.append(value)', '    new_df = df.iloc[indexes, :].copy()']","[""def tidy_split(df, column, sep='|', keep=False):"", '    """"""', '    Split the values of a column and expand so the new DataFrame has one split', '    value per row. Filters rows where the column is missing.', '    Params', '    ------', '    df : pandas.DataFrame', '        dataframe with the column to split and expand', '    column : str', '        the column to split and expand', '    sep : str', ""        the string used to split the column's values"", '    keep : bool', ""        whether to retain the presplit value as it's own row"", '    Returns', '    -------', '    pandas.DataFrame', '        Returns a dataframe with the same columns as `df`.', '    """"""', '    indexes = list()', '    new_values = list()', '    df = df.dropna(subset=[column])', '    for i, presplit in enumerate(df[column].astype(str)):', '        values = presplit.split(sep)', '        if keep and len(values) > 1:', '            indexes.append(i)', '            new_values.append(presplit)', '        for value in values:', '            indexes.append(i)', '            new_values.append(value)', '    new_df = df.iloc[indexes, :].copy()', '    new_df[column] = new_values', '    return new_df', ""tidy_split(a, 'var1', sep=',')""]","['    df = df.dropna(subset=[column])', '    for i, presplit in enumerate(df[column].astype(str)):', '        values = presplit.split(sep)', '            indexes.append(i)', '            new_values.append(presplit)', '            indexes.append(i)', '            new_values.append(value)', '    new_df = df.iloc[indexes, :].copy()']",,
40005797,"import pandas as pd
import numpy as np
df = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv"")
df.head()
df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)
df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])
df['cumulative_input_vectors'] = df.single_input_vector.cumsum()
df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)
from keras.preprocessing.sequence import pad_sequences
max_sequence_length = df.cumulative_input_vectors.apply(len).max()
padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()
df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)
X_train_init = np.asarray(df.padded_input_vectors)
X_train = np.hstack(X_train_init).reshape(len(df),max_sequence_length,len(input_cols))
y_train = np.hstack(np.asarray(df.output_vector)).reshape(len(df),len(output_cols))
print(X_train_init.shape)
(11,)
print(X_train.shape)
(11, 11, 6)
print(X_train == X_train_init)
False
input_length = X_train.shape[1]
input_dim = X_train.shape[2]
output_dim = len(y_train[0])
from keras.models import Model, Sequential
from keras.layers import LSTM, Dense
model = Sequential()
model.add(LSTM(4, input_dim = input_dim, input_length = input_length))
model.add(Dense(output_dim, activation='relu'))
model.compile(loss='mean_squared_error',
              optimizer='sgd',
              metrics=['accuracy'])
history = model.fit(X_train, y_train,
              batch_size=7, nb_epoch=3,
              verbose = 1)","['df = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv"")', 'df.head()', ""df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)"", ""df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])"", ""df['cumulative_input_vectors'] = df.single_input_vector.cumsum()"", ""df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)"", 'max_sequence_length = df.cumulative_input_vectors.apply(len).max()', 'padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()', ""df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)"", 'print(X_train_init.shape)', 'print(X_train.shape)', 'input_length = X_train.shape[1]', 'input_dim = X_train.shape[2]', 'model.add(LSTM(4, input_dim = input_dim, input_length = input_length))', ""model.add(Dense(output_dim, activation='relu'))""]","['import pandas as pd', 'import numpy as np', 'df = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv"")', 'df.head()', ""df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)"", ""df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])"", ""df['cumulative_input_vectors'] = df.single_input_vector.cumsum()"", ""df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)"", 'from keras.preprocessing.sequence import pad_sequences', 'max_sequence_length = df.cumulative_input_vectors.apply(len).max()', 'padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()', 'X_train_init = np.asarray(df.padded_input_vectors)', 'X_train = np.hstack(X_train_init).reshape(len(df),max_sequence_length,len(input_cols))', 'y_train = np.hstack(np.asarray(df.output_vector)).reshape(len(df),len(output_cols))', 'print(X_train_init.shape)', '(11,)', 'print(X_train.shape)', '(11, 11, 6)', 'print(X_train == X_train_init)', 'False', 'input_length = X_train.shape[1]', 'input_dim = X_train.shape[2]', 'output_dim = len(y_train[0])', 'from keras.models import Model, Sequential', 'from keras.layers import LSTM, Dense', 'model = Sequential()', 'model.add(LSTM(4, input_dim = input_dim, input_length = input_length))', ""model.add(Dense(output_dim, activation='relu'))"", ""model.compile(loss='mean_squared_error',"", ""              optimizer='sgd',"", ""              metrics=['accuracy'])"", 'history = model.fit(X_train, y_train,', '              batch_size=7, nb_epoch=3,', '              verbose = 1)']","['df = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv"")', 'df.head()', ""df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)"", ""df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])"", ""df['cumulative_input_vectors'] = df.single_input_vector.cumsum()"", ""df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)"", 'max_sequence_length = df.cumulative_input_vectors.apply(len).max()', 'padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()', ""df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)"", 'print(X_train_init.shape)', 'print(X_train.shape)', 'input_length = X_train.shape[1]', 'input_dim = X_train.shape[2]', 'model.add(LSTM(4, input_dim = input_dim, input_length = input_length))', ""model.add(Dense(output_dim, activation='relu'))""]",,
40008322,"df.loc[:, df.columns.to_series().str.contains('a').tolist()]","[""df.loc[:, df.columns.to_series().str.contains('a').tolist()]""]","[""df.loc[:, df.columns.to_series().str.contains('a').tolist()]""]","[""df.loc[:, df.columns.to_series().str.contains('a').tolist()]""]",,
40110335,"df= df[df[""score""] > 50]",[],"['df= df[df[""score""] > 50]']",[],[],[]
40145561,"df.iloc[:,-1]","['df.iloc[:,-1]']","['df.iloc[:,-1]']","['df.iloc[:,-1]']",,
40208359,"df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])
df.T.squeeze()","['df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])', 'df.T.squeeze()']",['df.T.squeeze()'],"['df = pd.DataFrame([list(range(5))], columns=[""a{}"".format(i) for i in range(5)])', 'df.T.squeeze()']",,
40209737,"df.rolling(5,min_periods=5).sum().dropna().resample('3D').first()","[""df.rolling(5,min_periods=5).sum().dropna().resample('3D').first()""]","[""df.rolling(5,min_periods=5).sum().dropna().resample('3D').first()""]","[""df.rolling(5,min_periods=5).sum().dropna().resample('3D').first()""]",,
40214434,"quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]
df = pd.DataFrame({""a"": [1,2,3,4], ""b"": [1,1,2,2]})
dfcopy = df.ix[:,[""a""]]
dfcopy.a.ix[0] = 2
df.ix[0, ""a""] = 3
quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) 
quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)
quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]
columns = ['STK', 'TPrice', 'TPCLOSE', 'TOpen', 'THigh', 'TLow', 'TVol', 'TAmt', 'TDate', 'TTime']
df = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])
df.columns = columns","['df = pd.DataFrame({""a"": [1,2,3,4], ""b"": [1,1,2,2]})', ""quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) "", ""quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)"", ""df = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])""]","['quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]', 'dfcopy = df.ix[:,[""a""]]', 'dfcopy.a.ix[0] = 2', 'df.ix[0, ""a""] = 3', ""quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) "", ""quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)"", 'quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]', ""columns = ['STK', 'TPrice', 'TPCLOSE', 'TOpen', 'THigh', 'TLow', 'TVol', 'TAmt', 'TDate', 'TTime']"", ""df = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])"", 'df.columns = columns']","[""quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) "", ""quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)"", ""df = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])""]",,
40225796,"df.columns = pd.MultiIndex.from_product([df.columns, ['C']])
print(df)","[""df.columns = pd.MultiIndex.from_product([df.columns, ['C']])""]","[""df.columns = pd.MultiIndex.from_product([df.columns, ['C']])"", 'print(df)']","[""df.columns = pd.MultiIndex.from_product([df.columns, ['C']])""]",,
40228738,"import seaborn as sns
corr = dataframe.corr()
sns.heatmap(corr, 
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values)","['corr = dataframe.corr()', '            xticklabels=corr.columns.values,', '            yticklabels=corr.columns.values)']","['import seaborn as sns', 'corr = dataframe.corr()', 'sns.heatmap(corr, ', '            xticklabels=corr.columns.values,', '            yticklabels=corr.columns.values)']","['corr = dataframe.corr()', '            xticklabels=corr.columns.values,', '            yticklabels=corr.columns.values)']",,
40429755,"s = pd.Series(list('abc'))
s
s.isin(['a'])
s[s.isin(['a'])].empty
s[s.isin(['z'])].empty
Out[5]: True
df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})
df.isin({'A': [1, 3], 'B': [4, 7, 12]})","[""s = pd.Series(list('abc'))"", ""s.isin(['a'])"", ""s[s.isin(['a'])].empty"", ""s[s.isin(['z'])].empty"", ""df.isin({'A': [1, 3], 'B': [4, 7, 12]})""]","['s', ""s.isin(['a'])"", ""s[s.isin(['a'])].empty"", ""s[s.isin(['z'])].empty"", 'Out[5]: True', ""df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})"", ""df.isin({'A': [1, 3], 'B': [4, 7, 12]})""]","[""s.isin(['a'])"", ""s[s.isin(['a'])].empty"", ""s[s.isin(['z'])].empty"", ""df.isin({'A': [1, 3], 'B': [4, 7, 12]})""]",,
40435354,"df = df.loc[:,~df.columns.duplicated()]","['df = df.loc[:,~df.columns.duplicated()]']","['df = df.loc[:,~df.columns.duplicated()]']","['df = df.loc[:,~df.columns.duplicated()]']",,
40442778,"df = df[df['closing_price'].between(99, 101, inclusive=True)]","[""df = df[df['closing_price'].between(99, 101, inclusive=True)]""]","[""df = df[df['closing_price'].between(99, 101, inclusive=True)]""]","[""df = df[df['closing_price'].between(99, 101, inclusive=True)]""]",,
40449726,"def explode(df, lst_cols, fill_value=''):
    if lst_cols and not isinstance(lst_cols, list):
        lst_cols = [lst_cols]
    idx_cols = df.columns.difference(lst_cols)
    lens = df[lst_cols[0]].str.len()
    if (lens > 0).all():
        return pd.DataFrame({
            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())
            for col in idx_cols
        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \
          .loc[:, df.columns]
    else:
        return pd.DataFrame({
            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())
            for col in idx_cols
        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \
          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \
          .loc[:, df.columns]
df
explode(df, ['num','text'], fill_value='')
df
explode(df.assign(var1=df.var1.str.split(',')), 'var1')
df.assign(var1=df.var1.str.split(','))
df
lst_col = 'var1' 
x = df.assign(**{lst_col:df[lst_col].str.split(',')})
x","['    idx_cols = df.columns.difference(lst_cols)', '    lens = df[lst_cols[0]].str.len()', '    if (lens > 0).all():', '        return pd.DataFrame({', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '        return pd.DataFrame({', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\', ""explode(df.assign(var1=df.var1.str.split(',')), 'var1')"", ""df.assign(var1=df.var1.str.split(','))"", ""x = df.assign(**{lst_col:df[lst_col].str.split(',')})""]","[""def explode(df, lst_cols, fill_value=''):"", '    if lst_cols and not isinstance(lst_cols, list):', '        lst_cols = [lst_cols]', '    idx_cols = df.columns.difference(lst_cols)', '    lens = df[lst_cols[0]].str.len()', '    if (lens > 0).all():', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '          .loc[:, df.columns]', '    else:', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\', '          .loc[:, df.columns]', 'df', ""explode(df, ['num','text'], fill_value='')"", 'df', ""explode(df.assign(var1=df.var1.str.split(',')), 'var1')"", ""df.assign(var1=df.var1.str.split(','))"", 'df', ""lst_col = 'var1' "", ""x = df.assign(**{lst_col:df[lst_col].str.split(',')})"", 'x']","['    idx_cols = df.columns.difference(lst_cols)', '    lens = df[lst_cols[0]].str.len()', '    if (lens > 0).all():', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\', '          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\', ""explode(df.assign(var1=df.var1.str.split(',')), 'var1')"", ""df.assign(var1=df.var1.str.split(','))"", ""x = df.assign(**{lst_col:df[lst_col].str.split(',')})""]",,
40501868,,[],[''],[],[],[]
40535454,"dfs = {'gadgets': df_gadgets, 'widgets': df_widgets}
writer = pd.ExcelWriter(filename, engine='xlsxwriter')
for sheetname, df in dfs.items():  
    df.to_excel(writer, sheet_name=sheetname)  
    worksheet = writer.sheets[sheetname]  
    for idx, col in enumerate(df):  
        series = df[col]
        max_len = max((
            series.astype(str).map(len).max(),  
            len(str(series.name))  
            )) + 1  
        worksheet.set_column(idx, idx, max_len)  
writer.save()","['    df.to_excel(writer, sheet_name=sheetname)  ', '            series.astype(str).map(len).max(),  ']","[""dfs = {'gadgets': df_gadgets, 'widgets': df_widgets}"", ""writer = pd.ExcelWriter(filename, engine='xlsxwriter')"", 'for sheetname, df in dfs.items():  ', '    df.to_excel(writer, sheet_name=sheetname)  ', '    worksheet = writer.sheets[sheetname]  ', '    for idx, col in enumerate(df):  ', '        series = df[col]', '        max_len = max((', '            series.astype(str).map(len).max(),  ', '            len(str(series.name))  ', '            )) + 1  ', '        worksheet.set_column(idx, idx, max_len)  ', 'writer.save()']","['    df.to_excel(writer, sheet_name=sheetname)  ', '            series.astype(str).map(len).max(),  ']",,
40593226,"pd.crosstab(df.A,df.B, normalize='index')
A           ","[""pd.crosstab(df.A,df.B, normalize='index')""]","[""pd.crosstab(df.A,df.B, normalize='index')"", 'A           ']","[""pd.crosstab(df.A,df.B, normalize='index')""]",,
40629420,"df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])","[""df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])""]","[""df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])""]","[""df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])""]",,
40679977,,[],[''],[],[],[]
40746465,"engine = create_engine('postgresql+psycopg2://user:pswd@mydb')
df.to_sql('temp_table', engine, if_exists='replace')
sql = ""UPDATE final_table AS f"" + \
      "" SET col1 = t.col1"" + \
      "" FROM temp_table AS t"" + \
      "" WHERE f.id = t.id""
with engine.begin() as conn:     
    conn.execute(sql)","[""df.to_sql('temp_table', engine, if_exists='replace')""]","[""engine = create_engine('postgresql+psycopg2://user:pswd@mydb')"", ""df.to_sql('temp_table', engine, if_exists='replace')"", 'sql = ""UPDATE final_table AS f"" + \\', '      "" SET col1 = t.col1"" + \\', '      "" FROM temp_table AS t"" + \\', '      "" WHERE f.id = t.id""', 'with engine.begin() as conn:     ', '    conn.execute(sql)']","[""df.to_sql('temp_table', engine, if_exists='replace')""]",,
40762674,"df.merge(s.to_frame(), left_index=True, right_index=True)","['df.merge(s.to_frame(), left_index=True, right_index=True)']","['df.merge(s.to_frame(), left_index=True, right_index=True)']","['df.merge(s.to_frame(), left_index=True, right_index=True)']",,
40770463,"GB=DF.groupby([(DF.index.year),(DF.index.month)]).sum()
print(GB)
GB.plot('abc','xyz',kind='scatter')","['GB=DF.groupby([(DF.index.year),(DF.index.month)]).sum()', ""GB.plot('abc','xyz',kind='scatter')""]","['GB=DF.groupby([(DF.index.year),(DF.index.month)]).sum()', 'print(GB)', ""GB.plot('abc','xyz',kind='scatter')""]","['GB=DF.groupby([(DF.index.year),(DF.index.month)]).sum()', ""GB.plot('abc','xyz',kind='scatter')""]",,
40817489,"df                                                                    
df.query('3.3 <= A <= 6.6') 
df.query('3.3 < A < 6.6') 
df.query('2.0 <= A <= 4.0')                                        
df.query('111 <= B <= 500')                                        
df.query('0 < A < 4 and 150 < B < 400')                            ","[""df.query('3.3 <= A <= 6.6') "", ""df.query('3.3 < A < 6.6') "", ""df.query('2.0 <= A <= 4.0')                                        "", ""df.query('111 <= B <= 500')                                        "", ""df.query('0 < A < 4 and 150 < B < 400')                            ""]","['df                                                                    ', ""df.query('3.3 <= A <= 6.6') "", ""df.query('3.3 < A < 6.6') "", ""df.query('2.0 <= A <= 4.0')                                        "", ""df.query('111 <= B <= 500')                                        "", ""df.query('0 < A < 4 and 150 < B < 400')                            ""]","[""df.query('3.3 <= A <= 6.6') "", ""df.query('3.3 < A < 6.6') "", ""df.query('2.0 <= A <= 4.0')                                        "", ""df.query('111 <= B <= 500')                                        "", ""df.query('0 < A < 4 and 150 < B < 400')                            ""]",,
40818627,"DataFrame.replace(
        to_replace=None,
        value=None,
        inplace=False,
        limit=None,
        regex=False, 
        method='pad',
        axis=None)
df['BrandName'].replace(
    to_replace=['ABC', 'AB'],
    value='A',
    inplace=True
)","['DataFrame.replace(', ""df['BrandName'].replace(""]","['DataFrame.replace(', '        to_replace=None,', '        value=None,', '        inplace=False,', '        limit=None,', '        regex=False, ', ""        method='pad',"", '        axis=None)', ""df['BrandName'].replace("", ""    to_replace=['ABC', 'AB'],"", ""    value='A',"", '    inplace=True', ')']","['DataFrame.replace(', ""df['BrandName'].replace(""]",,
40834052,df_filtered = df.query('a == 4 & b != 2'),"[""df_filtered = df.query('a == 4 & b != 2')""]","[""df_filtered = df.query('a == 4 & b != 2')""]","[""df_filtered = df.query('a == 4 & b != 2')""]",,
40872584,"grpd = df.groupby(['A','B']).size().to_frame('size')","[""grpd = df.groupby(['A','B']).size().to_frame('size')""]","[""grpd = df.groupby(['A','B']).size().to_frame('size')""]","[""grpd = df.groupby(['A','B']).size().to_frame('size')""]",,
40943143,"email
dtype: int64
df = df.to_frame().reset_index()
df = df.rename(columns= {0: 'list'})
df.index.name = 'index'","['df = df.to_frame().reset_index()', ""df = df.rename(columns= {0: 'list'})"", ""df.index.name = 'index'""]","['email', 'dtype: int64', 'df = df.to_frame().reset_index()', ""df = df.rename(columns= {0: 'list'})"", ""df.index.name = 'index'""]","['df = df.to_frame().reset_index()', ""df = df.rename(columns= {0: 'list'})"", ""df.index.name = 'index'""]",,
40962126,"df = pd.DataFrame({'A' : list('wwwwxxxx'), 
                   'B':list('yyzzyyzz'), 
                   'C':np.random.rand(8), 
                   'D':np.random.rand(8)})
df.groupby(['A', 'B']).agg({'C':['mean', 'median'], 'D':'max'})
df.groupby(['A', 'B']).agg({'C':{'C_mean': 'mean', 'C_median': 'median'}, 
                            'D':{'D_max': 'max'}})","[""df = pd.DataFrame({'A' : list('wwwwxxxx'), "", ""df.groupby(['A', 'B']).agg({'C':['mean', 'median'], 'D':'max'})"", ""df.groupby(['A', 'B']).agg({'C':{'C_mean': 'mean', 'C_median': 'median'}, ""]","[""                   'B':list('yyzzyyzz'), "", ""                   'C':np.random.rand(8), "", ""                   'D':np.random.rand(8)})"", ""df.groupby(['A', 'B']).agg({'C':['mean', 'median'], 'D':'max'})"", ""df.groupby(['A', 'B']).agg({'C':{'C_mean': 'mean', 'C_median': 'median'}, "", ""                            'D':{'D_max': 'max'}})""]","[""df.groupby(['A', 'B']).agg({'C':['mean', 'median'], 'D':'max'})"", ""df.groupby(['A', 'B']).agg({'C':{'C_mean': 'mean', 'C_median': 'median'}, ""]",,
41022840,,[],[''],[],[],[]
41150420,,[],[''],[],[],[]
41173392,,[],[''],[],[],[]
41191127,"mask = np.isnan(arr)
idx = np.where(~mask,np.arange(mask.shape[1]),0)
np.maximum.accumulate(idx,axis=1, out=idx)
out = arr[np.arange(idx.shape[0])[:,None], idx]
arr[mask] = arr[np.nonzero(mask)[0], idx[mask]]
arr
out
array([[ 5.,  5.,  5.,  7.,  2.,  6.,  5.],
       [ 3.,  3.,  1.,  8.,  8.,  5.,  5.],
       [ 4.,  9.,  6.,  6.,  6.,  6.,  7.]])","['idx = np.where(~mask,np.arange(mask.shape[1]),0)', 'out = arr[np.arange(idx.shape[0])[:,None], idx]']","['mask = np.isnan(arr)', 'idx = np.where(~mask,np.arange(mask.shape[1]),0)', 'np.maximum.accumulate(idx,axis=1, out=idx)', 'out = arr[np.arange(idx.shape[0])[:,None], idx]', 'arr[mask] = arr[np.nonzero(mask)[0], idx[mask]]', 'arr', 'out', 'array([[ 5.,  5.,  5.,  7.,  2.,  6.,  5.],', '       [ 3.,  3.,  1.,  8.,  8.,  5.,  5.],', '       [ 4.,  9.,  6.,  6.,  6.,  6.,  7.]])']","['idx = np.where(~mask,np.arange(mask.shape[1]),0)', 'out = arr[np.arange(idx.shape[0])[:,None], idx]']",,
41191278,"df.groupby('id')['x'].rolling(2).mean()
df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)
df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)
df['x'] = df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)","[""df.groupby('id')['x'].rolling(2).mean()"", ""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)"", ""df['x'] = df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)""]","[""df.groupby('id')['x'].rolling(2).mean()"", ""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)"", ""df['x'] = df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)""]","[""df.groupby('id')['x'].rolling(2).mean()"", ""df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)"", ""df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)"", ""df['x'] = df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)""]",,
41210491,"step = 50
bin_range = np.arange(-200, 1000+step, step)
out, bins  = pd.cut(s, bins=bin_range, include_lowest=True, right=False, retbins=True)
out.value_counts(sort=False).plot.bar()
out.value_counts().head()
dtype: int64
out.cat.categories = bins[:-1]
out.value_counts(sort=False).plot.bar()","['out, bins  = pd.cut(s, bins=bin_range, include_lowest=True, right=False, retbins=True)', 'out.value_counts(sort=False).plot.bar()', 'out.value_counts().head()', 'out.cat.categories = bins[:-1]', 'out.value_counts(sort=False).plot.bar()']","['step = 50', 'bin_range = np.arange(-200, 1000+step, step)', 'out, bins  = pd.cut(s, bins=bin_range, include_lowest=True, right=False, retbins=True)', 'out.value_counts(sort=False).plot.bar()', 'out.value_counts().head()', 'dtype: int64', 'out.cat.categories = bins[:-1]', 'out.value_counts(sort=False).plot.bar()']","['out, bins  = pd.cut(s, bins=bin_range, include_lowest=True, right=False, retbins=True)', 'out.value_counts(sort=False).plot.bar()', 'out.value_counts().head()', 'out.cat.categories = bins[:-1]', 'out.value_counts(sort=False).plot.bar()']",,
41218519,,[],[''],[],[],[]
41226605,"import pandas as pd
data = pd.read_json('/path/to/file.json', lines=True)","[""data = pd.read_json('/path/to/file.json', lines=True)""]","['import pandas as pd', ""data = pd.read_json('/path/to/file.json', lines=True)""]","[""data = pd.read_json('/path/to/file.json', lines=True)""]",,
41228272,"df['deltaT'] = df.index.to_series().diff().dt.seconds.div(60, fill_value=0)
ser_diff = df.index.to_series().diff()
ser_diff
ser_diff.dt.seconds.div(60, fill_value=0)
ser_diff.dt.total_seconds().div(60, fill_value=0)
time","[""df['deltaT'] = df.index.to_series().diff().dt.seconds.div(60, fill_value=0)"", 'ser_diff = df.index.to_series().diff()', 'ser_diff.dt.seconds.div(60, fill_value=0)', 'ser_diff.dt.total_seconds().div(60, fill_value=0)']","[""df['deltaT'] = df.index.to_series().diff().dt.seconds.div(60, fill_value=0)"", 'ser_diff = df.index.to_series().diff()', 'ser_diff', 'ser_diff.dt.seconds.div(60, fill_value=0)', 'ser_diff.dt.total_seconds().div(60, fill_value=0)', 'time']","[""df['deltaT'] = df.index.to_series().diff().dt.seconds.div(60, fill_value=0)"", 'ser_diff = df.index.to_series().diff()', 'ser_diff.dt.seconds.div(60, fill_value=0)', 'ser_diff.dt.total_seconds().div(60, fill_value=0)']",,
41228807,"s = pd.Series(pd.timedelta_range(start='1 days', end='12 days', freq='3000T'))
s
s.dt.days
s.dt.components
s.dt.components.hours","[""s = pd.Series(pd.timedelta_range(start='1 days', end='12 days', freq='3000T'))"", 's.dt.days', 's.dt.components', 's.dt.components.hours']","['s', 's.dt.days', 's.dt.components', 's.dt.components.hours']","[""s = pd.Series(pd.timedelta_range(start='1 days', end='12 days', freq='3000T'))"", 's.dt.days', 's.dt.components', 's.dt.components.hours']",,
41452422,"sns_plot.figure.savefig(""output.png"")",[],"['sns_plot.figure.savefig(""output.png"")']",[],[],[]
41464194,"a - delta_left
def delta_cluster(a, dleft, dright):
    rng = np.arange(len(a))
    edge_left = a.searchsorted(a - dleft)
    starts = edge_left == rng
    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])
    ends = edge_right == rng
    return (starts & ends).cumsum()
print(delta_cluster(a, 1, 1))
print(delta_cluster(a, 2, 1))
def delta_cluster(a, dleft, dright):
    s = a.argsort()
    size = s.size
    if size > 1000:
        y = np.empty(s.size, dtype=np.int64)
        y[s] = np.arange(s.size)
    else:
        y = s.argsort()
    a = a[s]
    rng = np.arange(len(a))
    edge_left = a.searchsorted(a - dleft)
    starts = edge_left == rng
    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])
    ends = edge_right == rng
    return (starts & ends).cumsum()[y]
b = np.random.permutation(a)
print(b)
print(delta_cluster(a, 2, 1))
print(delta_cluster(b, 2, 1))
print(delta_cluster(b, 2, 1)[b.argsort()])","['    edge_left = a.searchsorted(a - dleft)', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    return (starts & ends).cumsum()', '    s = a.argsort()', '    size = s.size', '        y = np.empty(s.size, dtype=np.int64)', '        y[s] = np.arange(s.size)', '        y = s.argsort()', '    edge_left = a.searchsorted(a - dleft)', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    return (starts & ends).cumsum()[y]', 'print(delta_cluster(b, 2, 1)[b.argsort()])']","['a - delta_left', 'def delta_cluster(a, dleft, dright):', '    rng = np.arange(len(a))', '    edge_left = a.searchsorted(a - dleft)', '    starts = edge_left == rng', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    ends = edge_right == rng', '    return (starts & ends).cumsum()', 'print(delta_cluster(a, 1, 1))', 'print(delta_cluster(a, 2, 1))', 'def delta_cluster(a, dleft, dright):', '    s = a.argsort()', '    size = s.size', '    if size > 1000:', '        y = np.empty(s.size, dtype=np.int64)', '        y[s] = np.arange(s.size)', '    else:', '        y = s.argsort()', '    a = a[s]', '    rng = np.arange(len(a))', '    edge_left = a.searchsorted(a - dleft)', '    starts = edge_left == rng', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    ends = edge_right == rng', '    return (starts & ends).cumsum()[y]', 'b = np.random.permutation(a)', 'print(b)', 'print(delta_cluster(a, 2, 1))', 'print(delta_cluster(b, 2, 1))', 'print(delta_cluster(b, 2, 1)[b.argsort()])']","['    edge_left = a.searchsorted(a - dleft)', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    return (starts & ends).cumsum()', '    s = a.argsort()', '    size = s.size', '        y = np.empty(s.size, dtype=np.int64)', '        y[s] = np.arange(s.size)', '        y = s.argsort()', '    edge_left = a.searchsorted(a - dleft)', ""    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])"", '    return (starts & ends).cumsum()[y]', 'print(delta_cluster(b, 2, 1)[b.argsort()])']",,
41517319,"from sklearn import linear_model
reg = linear_model.LinearRegression()
reg.fit(df[['B', 'C']], df['A'])
reg.coef_
array([  4.01182386e-01,   3.51587361e-04])",[],"['from sklearn import linear_model', 'reg = linear_model.LinearRegression()', ""reg.fit(df[['B', 'C']], df['A'])"", 'reg.coef_', 'array([  4.01182386e-01,   3.51587361e-04])']",[],[],[]
41529411,"newDF = pd.DataFrame() 
newDF = newDF.append(oldDF, ignore_index = True) ","['newDF = pd.DataFrame() ', 'newDF = newDF.append(oldDF, ignore_index = True) ']","['newDF = newDF.append(oldDF, ignore_index = True) ']","['newDF = newDF.append(oldDF, ignore_index = True) ']",,
41532180,"normalized_df=(df-df.mean())/df.std()
normalized_df=(df-df.min())/(df.max()-df.min())","['normalized_df=(df-df.mean())/df.std()', 'normalized_df=(df-df.min())/(df.max()-df.min())']","['normalized_df=(df-df.mean())/df.std()', 'normalized_df=(df-df.min())/(df.max()-df.min())']","['normalized_df=(df-df.mean())/df.std()', 'normalized_df=(df-df.min())/(df.max()-df.min())']",,
41554866,"import pandas as pd
sum(pd.isnull(df1['col1']))","[""sum(pd.isnull(df1['col1']))""]","['import pandas as pd', ""sum(pd.isnull(df1['col1']))""]","[""sum(pd.isnull(df1['col1']))""]",,
41607207,"tf.global_variables_initializer()
with tf.Session() as sess:
     sess.run(tf.global_variables_initializer())",[],"['tf.global_variables_initializer()', 'with tf.Session() as sess:', '     sess.run(tf.global_variables_initializer())']",[],[],[]
41629653,"df = pd.DataFrame(np.random.randn(3, 2), columns=['A','B'])
df
df.loc[13] = df.loc[1]
df","[""df = pd.DataFrame(np.random.randn(3, 2), columns=['A','B'])"", 'df.loc[13] = df.loc[1]']","['df', 'df.loc[13] = df.loc[1]', 'df']",['df.loc[13] = df.loc[1]'],,
41678874,"df['col1'].map(di)
df['col1'].update( df['col1'].map(di) )   
di = {1: ""A"", 2: ""B"", 3: ""C"", 4: ""D"", 5: ""E"", 6: ""F"", 7: ""G"", 8: ""H"" }
df = pd.DataFrame({ 'col1': np.random.choice( range(1,9), 100000 ) })","[""df['col1'].map(di)"", ""df['col1'].update( df['col1'].map(di) )   "", ""df = pd.DataFrame({ 'col1': np.random.choice( range(1,9), 100000 ) })""]","[""df['col1'].map(di)"", ""df['col1'].update( df['col1'].map(di) )   "", 'di = {1: ""A"", 2: ""B"", 3: ""C"", 4: ""D"", 5: ""E"", 6: ""F"", 7: ""G"", 8: ""H"" }']","[""df['col1'].map(di)"", ""df['col1'].update( df['col1'].map(di) )   ""]",,
41786821,"df[df.duplicated(['ID'], keep=False)]","[""df[df.duplicated(['ID'], keep=False)]""]","[""df[df.duplicated(['ID'], keep=False)]""]","[""df[df.duplicated(['ID'], keep=False)]""]",,
41802199,"import numpy as np   
import pandas as pd
df = pd.DataFrame(np.random.random((30, 3)))
df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')
in_range_df = df[df[""date""].isin(pd.date_range(""2017-01-15"", ""2017-01-20""))]
print(in_range_df)  ","['df = pd.DataFrame(np.random.random((30, 3)))', ""df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')"", 'in_range_df = df[df[""date""].isin(pd.date_range(""2017-01-15"", ""2017-01-20""))]']","['import numpy as np   ', 'import pandas as pd', ""df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')"", 'in_range_df = df[df[""date""].isin(pd.date_range(""2017-01-15"", ""2017-01-20""))]', 'print(in_range_df)  ']","[""df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')"", 'in_range_df = df[df[""date""].isin(pd.date_range(""2017-01-15"", ""2017-01-20""))]']",,
41816244,"df.select_dtypes(include=['float64']).apply(your_function)
df.select_dtypes(exclude=['string','object']).apply(your_other_function)","[""df.select_dtypes(include=['float64']).apply(your_function)"", ""df.select_dtypes(exclude=['string','object']).apply(your_other_function)""]","[""df.select_dtypes(include=['float64']).apply(your_function)"", ""df.select_dtypes(exclude=['string','object']).apply(your_other_function)""]","[""df.select_dtypes(include=['float64']).apply(your_function)"", ""df.select_dtypes(exclude=['string','object']).apply(your_other_function)""]",,
41845355,"df[(df['date']>datetime.date(2016,1,1)) & (df['date']<datetime.date(2016,3,1))]  
import datetime
datetime.datetime.strptime","[""df[(df['date']>datetime.date(2016,1,1)) & (df['date']<datetime.date(2016,3,1))]  "", 'datetime.datetime.strptime']","[""df[(df['date']>datetime.date(2016,1,1)) & (df['date']<datetime.date(2016,3,1))]  "", 'import datetime', 'datetime.datetime.strptime']","[""df[(df['date']>datetime.date(2016,1,1)) & (df['date']<datetime.date(2016,3,1))]  "", 'datetime.datetime.strptime']",,
41876593,"import pandas as pd
data = {'spike-2': [1,2,3], 'hey spke': [4,5,6]}
df = pd.DataFrame(data)
print(df.filter(like='spike').columns)
print(df.filter(regex='spike|spke').columns)","['df = pd.DataFrame(data)', ""print(df.filter(like='spike').columns)"", ""print(df.filter(regex='spike|spke').columns)""]","['import pandas as pd', ""data = {'spike-2': [1,2,3], 'hey spke': [4,5,6]}"", ""print(df.filter(like='spike').columns)"", ""print(df.filter(regex='spike|spke').columns)""]","[""print(df.filter(like='spike').columns)"", ""print(df.filter(regex='spike|spke').columns)""]",,
41880513,"import pandas as pd
url=""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv""
c=pd.read_csv(url)",['c=pd.read_csv(url)'],"['import pandas as pd', 'url=""https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv""', 'c=pd.read_csv(url)']",['c=pd.read_csv(url)'],,
41890871,"def coskew(df, bias=False):
    v = df.values
    s1 = sigma = v.std(0, keepdims=True)
    means = v.mean(0, keepdims=True)
    v1 = v - means
    s2 = sigma ** 2
    v2 = v1 ** 2
    m = v.shape[0]
    skew = pd.DataFrame(v2.T.dot(v1) / s2.T.dot(s1) / m, df.columns, df.columns)
    if not bias:
        skew *= ((m - 1) * m) ** .5 / (m - 2)
    return skew
coskew(df)
df.skew()
a   -0.36938
dtype: float64
def cokurt(df, bias=False, fisher=True, variant='middle'):
    v = df.values
    s1 = sigma = v.std(0, keepdims=True)
    means = v.mean(0, keepdims=True)
    v1 = v - means
    s2 = sigma ** 2
    s3 = sigma ** 3
    v2 = v1 ** 2
    v3 = v1 ** 3
    m = v.shape[0]
    if variant in ['left', 'right']:
        kurt = pd.DataFrame(v3.T.dot(v1) / s3.T.dot(s1) / m, df.columns, df.columns)
        if variant == 'right':
            kurt = kurt.T
    elif variant == 'middle':
        kurt = pd.DataFrame(v2.T.dot(v2) / s2.T.dot(s2) / m, df.columns, df.columns)
    if not bias:
        kurt = kurt * (m ** 2 - 1) / (m - 2) / (m - 3) - 3 * (m - 1) ** 2 / (m - 2) / (m - 3)
    if not fisher:
        kurt += 3
    return kurt
cokurt(df, variant='middle', bias=False, fisher=False)
cokurt(df, variant='left', bias=False, fisher=False)
df.kurtosis() + 3
dtype: float64","['    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    m = v.shape[0]', '    skew = pd.DataFrame(v2.T.dot(v1) / s2.T.dot(s1) / m, df.columns, df.columns)', 'df.skew()', '    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    m = v.shape[0]', '        kurt = pd.DataFrame(v3.T.dot(v1) / s3.T.dot(s1) / m, df.columns, df.columns)', '            kurt = kurt.T', '        kurt = pd.DataFrame(v2.T.dot(v2) / s2.T.dot(s2) / m, df.columns, df.columns)']","['def coskew(df, bias=False):', '    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    v1 = v - means', '    s2 = sigma ** 2', '    v2 = v1 ** 2', '    m = v.shape[0]', '    if not bias:', '        skew *= ((m - 1) * m) ** .5 / (m - 2)', '    return skew', 'coskew(df)', 'df.skew()', 'a   -0.36938', 'dtype: float64', ""def cokurt(df, bias=False, fisher=True, variant='middle'):"", '    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    v1 = v - means', '    s2 = sigma ** 2', '    s3 = sigma ** 3', '    v2 = v1 ** 2', '    v3 = v1 ** 3', '    m = v.shape[0]', ""    if variant in ['left', 'right']:"", ""        if variant == 'right':"", '            kurt = kurt.T', ""    elif variant == 'middle':"", '    if not bias:', '        kurt = kurt * (m ** 2 - 1) / (m - 2) / (m - 3) - 3 * (m - 1) ** 2 / (m - 2) / (m - 3)', '    if not fisher:', '        kurt += 3', '    return kurt', ""cokurt(df, variant='middle', bias=False, fisher=False)"", ""cokurt(df, variant='left', bias=False, fisher=False)"", 'df.kurtosis() + 3', 'dtype: float64']","['    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    m = v.shape[0]', '    skew = pd.DataFrame(v2.T.dot(v1) / s2.T.dot(s1) / m, df.columns, df.columns)', 'df.skew()', '    v = df.values', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    m = v.shape[0]', '        kurt = pd.DataFrame(v3.T.dot(v1) / s3.T.dot(s1) / m, df.columns, df.columns)', '            kurt = kurt.T', '        kurt = pd.DataFrame(v2.T.dot(v2) / s2.T.dot(s2) / m, df.columns, df.columns)']",,
41929910,"df = df.groupby(['from','to']).datetime
print (df)
df = df.join(df.groupby(['from','to'])
               .datetime
               .apply(lambda x: x.sort_values().diff().dt.seconds // 60)
               .fillna(0)
               .reset_index(level=[0,1], drop=True)
               .rename('timediff in minutes'))
print (df)","[""df = df.groupby(['from','to']).datetime"", ""df = df.join(df.groupby(['from','to'])"", '               .apply(lambda x: x.sort_values().diff().dt.seconds // 60)']","[""df = df.groupby(['from','to']).datetime"", 'print (df)', ""df = df.join(df.groupby(['from','to'])"", '               .datetime', '               .apply(lambda x: x.sort_values().diff().dt.seconds // 60)', '               .fillna(0)', '               .reset_index(level=[0,1], drop=True)', ""               .rename('timediff in minutes'))"", 'print (df)']","[""df = df.groupby(['from','to']).datetime"", ""df = df.join(df.groupby(['from','to'])"", '               .apply(lambda x: x.sort_values().diff().dt.seconds // 60)']",,
41929939,"result = df.sort_values(['from','to','datetime'])\
           .groupby(['from','to'])['datetime']\
           .diff().dt.seconds.fillna(0)","[""result = df.sort_values(['from','to','datetime'])\\""]","[""result = df.sort_values(['from','to','datetime'])\\"", ""           .groupby(['from','to'])['datetime']\\"", '           .diff().dt.seconds.fillna(0)']","[""result = df.sort_values(['from','to','datetime'])\\""]",,
41929958,"df.assign(
    timediff=df.sort_values(
        'datetime', ascending=False
    ).groupby(['from', 'to']).datetime.diff(-1).dt.seconds.div(60).fillna(0))","['df.assign(', '    timediff=df.sort_values(']","['df.assign(', '    timediff=df.sort_values(', ""        'datetime', ascending=False"", ""    ).groupby(['from', 'to']).datetime.diff(-1).dt.seconds.div(60).fillna(0))""]","['df.assign(', '    timediff=df.sort_values(']",,
42094658,"import pandas as pd
pd.concat([df], keys=['Foo'], names=['Firstlevel'])","[""pd.concat([df], keys=['Foo'], names=['Firstlevel'])""]","['import pandas as pd', ""pd.concat([df], keys=['Foo'], names=['Firstlevel'])""]","[""pd.concat([df], keys=['Foo'], names=['Firstlevel'])""]",,
42133330,,[],[''],[],[],[]
42180357,"data_file = pd.read_excel('path_to_file.xls', sheetname=""sheet_name"")","['data_file = pd.read_excel(\'path_to_file.xls\', sheetname=""sheet_name"")']","['data_file = pd.read_excel(\'path_to_file.xls\', sheetname=""sheet_name"")']","['data_file = pd.read_excel(\'path_to_file.xls\', sheetname=""sheet_name"")']",,
42247228,td.dt.days,['td.dt.days'],['td.dt.days'],['td.dt.days'],,
42293737,"pd.set_option('display.max_columns', None)  ","[""pd.set_option('display.max_columns', None)  ""]","[""pd.set_option('display.max_columns', None)  ""]","[""pd.set_option('display.max_columns', None)  ""]",,
42305299,"import numpy as np
class PercentileOfScore(object):
    def __init__(self, aList):
        self.a = np.array( aList )
        self.a.sort()
        self.n = float(len(self.a))
        self.pct = self.__rank_searchsorted_list
    def __rank_searchsorted_list(self, score_list):
        adx = np.searchsorted(self.a, score_list, side='right')
        pct = []
        for idx in adx:
            pct.append( (float(idx) / self.n) * 100.0 )
        return pct
PctOS = None
def percentile_7(df_flat):
    global PctOS
    result = {}
    for k in df_flat.pair_dict.keys():
        result[k] = PctOS.pct( df_flat.pair_dict[k] )
    return result
from PercentileData import DF_flat
def main():
    df_flat = DF_flat()
    global PctOS
    PctOS = PercentileOfScore(df_flat.a_list)
    result = percentile_7(df_flat)","[""        adx = np.searchsorted(self.a, score_list, side='right')"", '            pct.append( (float(idx) / self.n) * 100.0 )']","['import numpy as np', 'class PercentileOfScore(object):', '    def __init__(self, aList):', '        self.a = np.array( aList )', '        self.a.sort()', '        self.n = float(len(self.a))', '        self.pct = self.__rank_searchsorted_list', '    def __rank_searchsorted_list(self, score_list):', ""        adx = np.searchsorted(self.a, score_list, side='right')"", '        pct = []', '        for idx in adx:', '            pct.append( (float(idx) / self.n) * 100.0 )', '        return pct', 'PctOS = None', 'def percentile_7(df_flat):', '    global PctOS', '    result = {}', '    for k in df_flat.pair_dict.keys():', '        result[k] = PctOS.pct( df_flat.pair_dict[k] )', '    return result', 'from PercentileData import DF_flat', 'def main():', '    df_flat = DF_flat()', '    global PctOS', '    PctOS = PercentileOfScore(df_flat.a_list)', '    result = percentile_7(df_flat)']","[""        adx = np.searchsorted(self.a, score_list, side='right')"", '            pct.append( (float(idx) / self.n) * 100.0 )']",,
42335527,,[],[''],[],[],[]
42392805,"from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = ""all""
df1
df2",[],"['from IPython.core.interactiveshell import InteractiveShell', 'InteractiveShell.ast_node_interactivity = ""all""', 'df1', 'df2']",[],[],[]
42401977,"import pandas as pd
from multiprocessing import Pool
def reader(filename):
    return pd.read_excel(filename)
def main():
    pool = Pool(4) 
    file_list = [file1.xlsx, file2.xlsx, file3.xlsx, ...]
    df_list = pool.map(reader, file_list) 
    df = pd.concat(df_list) 
if __name__ == '__main__':
    main()","['    return pd.read_excel(filename)', '    df_list = pool.map(reader, file_list) ', '    df = pd.concat(df_list) ']","['import pandas as pd', 'from multiprocessing import Pool', 'def reader(filename):', '    return pd.read_excel(filename)', 'def main():', '    pool = Pool(4) ', '    file_list = [file1.xlsx, file2.xlsx, file3.xlsx, ...]', '    df_list = pool.map(reader, file_list) ', '    df = pd.concat(df_list) ', ""if __name__ == '__main__':"", '    main()']","['    return pd.read_excel(filename)', '    df_list = pool.map(reader, file_list) ', '    df = pd.concat(df_list) ']",,
42426751,"print(
    df
    .head(10)
    .to_string(
        formatters={""total_bill"": ""${:,.2f}"".format, 
                    ""tip"": ""${:,.2f}"".format,
                    ""date"": lambda x: ""{:%m/%d/%Y}"".format(pd.to_datetime(x, unit=""D""))
        }
    )
)","['    df', '        formatters={""total_bill"": ""${:,.2f}"".format, ', '                    ""tip"": ""${:,.2f}"".format,', '                    ""date"": lambda x: ""{:%m/%d/%Y}"".format(pd.to_datetime(x, unit=""D""))']","['print(', '    df', '    .head(10)', '    .to_string(', '        formatters={""total_bill"": ""${:,.2f}"".format, ', '                    ""tip"": ""${:,.2f}"".format,', '                    ""date"": lambda x: ""{:%m/%d/%Y}"".format(pd.to_datetime(x, unit=""D""))', '        }', '    )', ')']","['    df', '        formatters={""total_bill"": ""${:,.2f}"".format, ', '                    ""tip"": ""${:,.2f}"".format,', '                    ""date"": lambda x: ""{:%m/%d/%Y}"".format(pd.to_datetime(x, unit=""D""))']",,
42476224,"from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = ""all""",[],"['from IPython.core.interactiveshell import InteractiveShell', 'InteractiveShell.ast_node_interactivity = ""all""']",[],[],[]
42516230,"np.random.seed(1)
df = pd.DataFrame(np.random.randint(4, size=(5,1)))
print (df)
print ((df[0] == 0).idxmax())
2
df.loc[(df[0] == 0).idxmax(), 0] = 100
print (df)
df.loc[(df[0] == 3).idxmax(), 0] = 200
print (df)
np.random.seed(1)
df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])
print (df)
df = df.reset_index()
df.loc[(df[0] == 3).idxmax(), 0] = 200
df = df.set_index('index')
df.index.name = None
print (df)
np.random.seed(1)
df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])
print (df)
df.index = [np.arange(len(df.index)), df.index]
print (df)
df.loc[(df[0] == 3).idxmax(), 0] = 200
df = df.reset_index(level=0, drop=True)
print (df)
np.random.seed(1)
df = pd.DataFrame([4,0,4,7,4], index=[1,2,2,3,4])
print (df)
mask = (df[0] == 0).cumsum().cumsum()
print (mask)
df.loc[mask == 1, 0] = 200
print (df)","['df = pd.DataFrame(np.random.randint(4, size=(5,1)))', 'print ((df[0] == 0).idxmax())', 'df.loc[(df[0] == 0).idxmax(), 0] = 100', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])', 'df = df.reset_index()', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', ""df = df.set_index('index')"", 'df.index.name = None', 'df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])', 'df.index = [np.arange(len(df.index)), df.index]', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = df.reset_index(level=0, drop=True)', 'df = pd.DataFrame([4,0,4,7,4], index=[1,2,2,3,4])', 'mask = (df[0] == 0).cumsum().cumsum()', 'df.loc[mask == 1, 0] = 200']","['np.random.seed(1)', 'print (df)', 'print ((df[0] == 0).idxmax())', '2', 'df.loc[(df[0] == 0).idxmax(), 0] = 100', 'print (df)', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'print (df)', 'np.random.seed(1)', 'print (df)', 'df = df.reset_index()', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', ""df = df.set_index('index')"", 'df.index.name = None', 'print (df)', 'np.random.seed(1)', 'print (df)', 'df.index = [np.arange(len(df.index)), df.index]', 'print (df)', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = df.reset_index(level=0, drop=True)', 'print (df)', 'np.random.seed(1)', 'print (df)', 'mask = (df[0] == 0).cumsum().cumsum()', 'print (mask)', 'df.loc[mask == 1, 0] = 200', 'print (df)']","['print ((df[0] == 0).idxmax())', 'df.loc[(df[0] == 0).idxmax(), 0] = 100', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = df.reset_index()', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', ""df = df.set_index('index')"", 'df.index.name = None', 'df.index = [np.arange(len(df.index)), df.index]', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = df.reset_index(level=0, drop=True)', 'mask = (df[0] == 0).cumsum().cumsum()', 'df.loc[mask == 1, 0] = 200']",,
42545576,"a = np.ones((3,5,7))
b = np.zeros((5,7))
for i in range(5):
    for j in range(7):
        b[i,j] += a[:,i,j].sum()
array([[ 3.,  3.,  3.,  3.,  3.,  3.,  3.],
       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],
       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],
       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],
       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.]])","['        b[i,j] += a[:,i,j].sum()']","['a = np.ones((3,5,7))', 'b = np.zeros((5,7))', 'for i in range(5):', '    for j in range(7):', '        b[i,j] += a[:,i,j].sum()', 'array([[ 3.,  3.,  3.,  3.,  3.,  3.,  3.],', '       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],', '       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],', '       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.],', '       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.]])']","['        b[i,j] += a[:,i,j].sum()']",,
42550516,"import numpy as np
df = pd.DataFrame( {'a':np.random.randint(0,60,600), 'b':[1,2,5,5,4,6]*100})
def f(df):
         keys,values=df.sort_values('a').values.T
         ukeys,index=np.unique(keys,True)
         arrays=np.split(values,index[1:])
         df2=pd.DataFrame({'a':ukeys,'b':[list(a) for a in arrays]})
         return df2","[""df = pd.DataFrame( {'a':np.random.randint(0,60,600), 'b':[1,2,5,5,4,6]*100})"", ""         keys,values=df.sort_values('a').values.T"", '         ukeys,index=np.unique(keys,True)', '         arrays=np.split(values,index[1:])', ""         df2=pd.DataFrame({'a':ukeys,'b':[list(a) for a in arrays]})""]","['import numpy as np', 'def f(df):', ""         keys,values=df.sort_values('a').values.T"", '         ukeys,index=np.unique(keys,True)', '         arrays=np.split(values,index[1:])', '         return df2']","[""         keys,values=df.sort_values('a').values.T"", '         ukeys,index=np.unique(keys,True)', '         arrays=np.split(values,index[1:])']",,
42652112,"import sys
if sys.version_info[0] < 3:
    from StringIO import StringIO
else:
    from io import StringIO
import pandas as pd
DF1 = StringIO(""""""Date       Fruit  Num  Color 
2013-11-24 Banana 22.1 Yellow
2013-11-24 Orange  8.6 Orange
2013-11-24 Apple   7.6 Green
2013-11-24 Celery 10.2 Green
"""""")
DF2 = StringIO(""""""Date       Fruit  Num  Color 
2013-11-24 Banana 22.1 Yellow
2013-11-24 Orange  8.6 Orange
2013-11-24 Apple   7.6 Green
2013-11-24 Celery 10.2 Green
2013-11-25 Apple  22.1 Red
2013-11-25 Orange  8.6 Orange"""""")
df1 = pd.read_table(DF1, sep='\s+')
df2 = pd.read_table(DF2, sep='\s+')
dfs_dictionary = {'DF1':df1,'DF2':df2}
df=pd.concat(dfs_dictionary)
df.drop_duplicates(keep=False)","[""df1 = pd.read_table(DF1, sep='\\s+')"", ""df2 = pd.read_table(DF2, sep='\\s+')"", 'df=pd.concat(dfs_dictionary)', 'df.drop_duplicates(keep=False)']","['import sys', 'if sys.version_info[0] < 3:', '    from StringIO import StringIO', 'else:', '    from io import StringIO', 'import pandas as pd', 'DF1 = StringIO(""""""Date       Fruit  Num  Color ', '2013-11-24 Banana 22.1 Yellow', '2013-11-24 Orange  8.6 Orange', '2013-11-24 Apple   7.6 Green', '2013-11-24 Celery 10.2 Green', '"""""")', 'DF2 = StringIO(""""""Date       Fruit  Num  Color ', '2013-11-24 Banana 22.1 Yellow', '2013-11-24 Orange  8.6 Orange', '2013-11-24 Apple   7.6 Green', '2013-11-24 Celery 10.2 Green', '2013-11-25 Apple  22.1 Red', '2013-11-25 Orange  8.6 Orange"""""")', ""df1 = pd.read_table(DF1, sep='\\s+')"", ""df2 = pd.read_table(DF2, sep='\\s+')"", ""dfs_dictionary = {'DF1':df1,'DF2':df2}"", 'df=pd.concat(dfs_dictionary)', 'df.drop_duplicates(keep=False)']","[""df1 = pd.read_table(DF1, sep='\\s+')"", ""df2 = pd.read_table(DF2, sep='\\s+')"", 'df=pd.concat(dfs_dictionary)', 'df.drop_duplicates(keep=False)']",,
42796283,"import pandas as pd
import sqlite3
presidents = pd.DataFrame({""name"": [""Bush"", ""Obama"", ""Trump""],
                           ""president_id"":[43, 44, 45]})
terms = pd.DataFrame({'start_date': pd.date_range('2001-01-20', periods=5, freq='48M'),
                      'end_date': pd.date_range('2005-01-21', periods=5, freq='48M'),
                      'president_id': [43, 43, 44, 44, 45]})
war_declarations = pd.DataFrame({""date"": [datetime(2001, 9, 14), datetime(2003, 3, 3)],
                                 ""name"": [""War in Afghanistan"", ""Iraq War""]})
conn = sqlite3.connect(':memory:')
terms.to_sql('terms', conn, index=False)
presidents.to_sql('presidents', conn, index=False)
war_declarations.to_sql('wars', conn, index=False)
df = pd.read_sql_query(qry, conn)","['presidents = pd.DataFrame({""name"": [""Bush"", ""Obama"", ""Trump""],', ""terms = pd.DataFrame({'start_date': pd.date_range('2001-01-20', periods=5, freq='48M'),"", ""                      'end_date': pd.date_range('2005-01-21', periods=5, freq='48M'),"", 'war_declarations = pd.DataFrame({""date"": [datetime(2001, 9, 14), datetime(2003, 3, 3)],', ""terms.to_sql('terms', conn, index=False)"", ""presidents.to_sql('presidents', conn, index=False)"", ""war_declarations.to_sql('wars', conn, index=False)"", 'df = pd.read_sql_query(qry, conn)']","['import pandas as pd', 'import sqlite3', '                           ""president_id"":[43, 44, 45]})', ""                      'end_date': pd.date_range('2005-01-21', periods=5, freq='48M'),"", ""                      'president_id': [43, 43, 44, 44, 45]})"", '                                 ""name"": [""War in Afghanistan"", ""Iraq War""]})', ""conn = sqlite3.connect(':memory:')"", ""terms.to_sql('terms', conn, index=False)"", ""presidents.to_sql('presidents', conn, index=False)"", ""war_declarations.to_sql('wars', conn, index=False)"", 'df = pd.read_sql_query(qry, conn)']","[""terms = pd.DataFrame({'start_date': pd.date_range('2001-01-20', periods=5, freq='48M'),"", ""                      'end_date': pd.date_range('2005-01-21', periods=5, freq='48M'),"", ""terms.to_sql('terms', conn, index=False)"", ""presidents.to_sql('presidents', conn, index=False)"", ""war_declarations.to_sql('wars', conn, index=False)"", 'df = pd.read_sql_query(qry, conn)']",,
42837693,"df = pd.Dataframe(columns=[""firstname"", ""lastname""])
df = df.append({
     ""firstname"": ""John"",
     ""lastname"":  ""Johny""
      }, ignore_index=True)",['df = df.append({'],"['df = pd.Dataframe(columns=[""firstname"", ""lastname""])', 'df = df.append({', '     ""firstname"": ""John"",', '     ""lastname"":  ""Johny""', '      }, ignore_index=True)']",['df = df.append({'],,
42874900,"import numpy as np
nb_classes = 6
data = [[2, 3, 4, 0]]
def indices_to_one_hot(data, nb_classes):
    """"""Convert an iterable of indices to one-hot encoded labels.""""""
    targets = np.array(data).reshape(-1)
    return np.eye(nb_classes)[targets]
array([[[ 0.,  0.,  1.,  0.,  0.,  0.],
        [ 0.,  0.,  0.,  1.,  0.,  0.],
        [ 0.,  0.,  0.,  0.,  1.,  0.],
        [ 1.,  0.,  0.,  0.,  0.,  0.]]])",[],"['import numpy as np', 'nb_classes = 6', 'data = [[2, 3, 4, 0]]', 'def indices_to_one_hot(data, nb_classes):', '    """"""Convert an iterable of indices to one-hot encoded labels.""""""', '    targets = np.array(data).reshape(-1)', '    return np.eye(nb_classes)[targets]', 'array([[[ 0.,  0.,  1.,  0.,  0.,  0.],', '        [ 0.,  0.,  0.,  1.,  0.,  0.],', '        [ 0.,  0.,  0.,  0.,  1.,  0.],', '        [ 1.,  0.,  0.,  0.,  0.,  0.]]])']",[],[],[]
42879831,"import numpy as np
def one_hot_encode(x, n_classes):
    """"""
    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.
    : x: List of sample Labels
    : return: Numpy array of one-hot encoded labels
     """"""
    return np.eye(n_classes)[x]
def main():
    list = [0,1,2,3,4,3,2,1,0]
    n_classes = 5
    one_hot_list = one_hot_encode(list, n_classes)
    print(one_hot_list)
if __name__ == ""__main__"":
    main()",[],"['import numpy as np', 'def one_hot_encode(x, n_classes):', '    """"""', '    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.', '    : x: List of sample Labels', '    : return: Numpy array of one-hot encoded labels', '     """"""', '    return np.eye(n_classes)[x]', 'def main():', '    list = [0,1,2,3,4,3,2,1,0]', '    n_classes = 5', '    one_hot_list = one_hot_encode(list, n_classes)', '    print(one_hot_list)', 'if __name__ == ""__main__"":', '    main()']",[],[],[]
42932524,"x, x_test, y, y_test = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8)
x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.25,train_size =0.75)",[],"['x, x_test, y, y_test = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8)', 'x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.25,train_size =0.75)']",[],[],[]
42965916,"sns.palplot(sns.color_palette(""Set2"", 8))
color_labels = df['color'].unique()
rgb_values = sns.color_palette(""Set2"", 8)
color_map = dict(zip(color_labels, rgb_values))
plt.scatter(df['carat'], df['price'], c=df['color'].map(color_map))","[""color_labels = df['color'].unique()"", ""plt.scatter(df['carat'], df['price'], c=df['color'].map(color_map))""]","['sns.palplot(sns.color_palette(""Set2"", 8))', ""color_labels = df['color'].unique()"", 'rgb_values = sns.color_palette(""Set2"", 8)', 'color_map = dict(zip(color_labels, rgb_values))', ""plt.scatter(df['carat'], df['price'], c=df['color'].map(color_map))""]","[""color_labels = df['color'].unique()"", ""plt.scatter(df['carat'], df['price'], c=df['color'].map(color_map))""]",,
42977946,"pd.scatter_matrix(dataframe, alpha = 0.3, figsize = (14,8), diagonal = 'kde');
sns.pairplot(dataframe)
import seaborn as sns
f, ax = pl.subplots(figsize=(10, 8))
corr = dataframe.corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),
            square=True, ax=ax)",['corr = dataframe.corr()'],"[""pd.scatter_matrix(dataframe, alpha = 0.3, figsize = (14,8), diagonal = 'kde');"", 'sns.pairplot(dataframe)', 'import seaborn as sns', 'f, ax = pl.subplots(figsize=(10, 8))', 'corr = dataframe.corr()', 'sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),', '            square=True, ax=ax)']",['corr = dataframe.corr()'],,
42978156,,[],[''],[],[],[]
43093390,"q = df[""col""].quantile(0.99)
df[df[""col""] < q]","['q = df[""col""].quantile(0.99)']","['q = df[""col""].quantile(0.99)', 'df[df[""col""] < q]']","['q = df[""col""].quantile(0.99)']",,
43180437,"df['protected'] = ['no', 'no', 'no', 'yes']
df.index = [3,2,1,0]
df['protected'] = ['no', 'no', 'no', 'yes']
df['protected'] = pd.Series(['no', 'no', 'no', 'yes'])
df['protected'] = pd.Series(['no', 'no', 'no', 'yes']).values
df['protected'] = list(pd.Series(['no', 'no', 'no', 'yes']))
df['protected'] = pd.Series(['no', 'no', 'no', 'yes'], index=df.index)
protected_series = pd.Series(['no', 'no', 'no', 'yes'])
protected_series.index = df.index
df['protected'] = protected_series
df.reset_index(drop=True)
protected_series.reset_index(drop=True)
df['protected'] = protected_series
df.assign(protected=pd.Series(['no', 'no', 'no', 'yes']))","['df.index = [3,2,1,0]', ""df['protected'] = pd.Series(['no', 'no', 'no', 'yes'])"", ""df['protected'] = pd.Series(['no', 'no', 'no', 'yes']).values"", ""df['protected'] = list(pd.Series(['no', 'no', 'no', 'yes']))"", ""df['protected'] = pd.Series(['no', 'no', 'no', 'yes'], index=df.index)"", ""protected_series = pd.Series(['no', 'no', 'no', 'yes'])"", 'protected_series.index = df.index', 'df.reset_index(drop=True)', 'protected_series.reset_index(drop=True)', ""df.assign(protected=pd.Series(['no', 'no', 'no', 'yes']))""]","[""df['protected'] = ['no', 'no', 'no', 'yes']"", 'df.index = [3,2,1,0]', ""df['protected'] = ['no', 'no', 'no', 'yes']"", 'protected_series.index = df.index', ""df['protected'] = protected_series"", 'df.reset_index(drop=True)', 'protected_series.reset_index(drop=True)', ""df['protected'] = protected_series""]","['df.index = [3,2,1,0]', ""df['protected'] = pd.Series(['no', 'no', 'no', 'yes']).values"", ""df['protected'] = pd.Series(['no', 'no', 'no', 'yes'], index=df.index)"", 'protected_series.index = df.index', 'df.reset_index(drop=True)', 'protected_series.reset_index(drop=True)', ""df.assign(protected=pd.Series(['no', 'no', 'no', 'yes']))""]",,
43190411,import pandas as pd ,[],['import pandas as pd '],[],[],[]
43289220,"import pandas as pd
wheel_number = 5
car_name = 'jeep'
minutes_spent = 4.5
data_columns = ['wheel_number', 'car_name', 'minutes_spent']
data_df = pd.DataFrame(columns = data_columns)
df_temp = pd.DataFrame([[wheel_number, car_name, minutes_spent]],columns = data_columns)
data_df = data_df.append(df_temp, ignore_index=True) 
data_df.dtypes
data_df.dtypes","['data_df = pd.DataFrame(columns = data_columns)', 'df_temp = pd.DataFrame([[wheel_number, car_name, minutes_spent]],columns = data_columns)', 'data_df = data_df.append(df_temp, ignore_index=True) ', 'data_df.dtypes', 'data_df.dtypes']","['import pandas as pd', 'wheel_number = 5', ""car_name = 'jeep'"", 'minutes_spent = 4.5', ""data_columns = ['wheel_number', 'car_name', 'minutes_spent']"", 'data_df = data_df.append(df_temp, ignore_index=True) ', 'data_df.dtypes', 'data_df.dtypes']","['data_df = data_df.append(df_temp, ignore_index=True) ', 'data_df.dtypes', 'data_df.dtypes']",,
43421391,"indexes_to_keep = set(range(df.shape[0])) - set(indexes_to_drop)
df_sliced = df.take(list(indexes_to_keep))","['indexes_to_keep = set(range(df.shape[0])) - set(indexes_to_drop)', 'df_sliced = df.take(list(indexes_to_keep))']","['indexes_to_keep = set(range(df.shape[0])) - set(indexes_to_drop)', 'df_sliced = df.take(list(indexes_to_keep))']","['indexes_to_keep = set(range(df.shape[0])) - set(indexes_to_drop)', 'df_sliced = df.take(list(indexes_to_keep))']",,
43547088,"df = pd.DataFrame(np.random.rand(6, 4),
                 index=['one', 'two', 'three', 'four', 'five', 'six'],
                 columns=pd.Index(['A', 'B', 'C', 'D'],
                 name='Genus')).round(2)
ax = df.plot(kind='bar',figsize=(10,4), rot = 0)
ax.minorticks_on()
rects_locs = map(lambda x: x.get_x() +x.get_width()/2., ax.patches)
ax.set_xticks(rects_locs, minor = True)
new_ticks = reduce(lambda x, y: x + y, map(lambda x: [x] * df.shape[0], df.columns.tolist()))
from matplotlib import ticker
ax.xaxis.set_minor_formatter(ticker.FixedFormatter(new_ticks))  
ax.tick_params(axis='x', which='major', pad=15)
ax.tick_params(axis='x',which='both', top='off')
ax.tick_params(axis='y',which='both', left='off', right = 'off')","['df = pd.DataFrame(np.random.rand(6, 4),', ""                 columns=pd.Index(['A', 'B', 'C', 'D'],"", ""ax = df.plot(kind='bar',figsize=(10,4), rot = 0)"", 'new_ticks = reduce(lambda x, y: x + y, map(lambda x: [x] * df.shape[0], df.columns.tolist()))']","[""                 index=['one', 'two', 'three', 'four', 'five', 'six'],"", ""                 columns=pd.Index(['A', 'B', 'C', 'D'],"", ""                 name='Genus')).round(2)"", ""ax = df.plot(kind='bar',figsize=(10,4), rot = 0)"", 'ax.minorticks_on()', 'rects_locs = map(lambda x: x.get_x() +x.get_width()/2., ax.patches)', 'ax.set_xticks(rects_locs, minor = True)', 'new_ticks = reduce(lambda x, y: x + y, map(lambda x: [x] * df.shape[0], df.columns.tolist()))', 'from matplotlib import ticker', 'ax.xaxis.set_minor_formatter(ticker.FixedFormatter(new_ticks))  ', ""ax.tick_params(axis='x', which='major', pad=15)"", ""ax.tick_params(axis='x',which='both', top='off')"", ""ax.tick_params(axis='y',which='both', left='off', right = 'off')""]","[""                 columns=pd.Index(['A', 'B', 'C', 'D'],"", ""ax = df.plot(kind='bar',figsize=(10,4), rot = 0)"", 'new_ticks = reduce(lambda x, y: x + y, map(lambda x: [x] * df.shape[0], df.columns.tolist()))']",,
43547282,"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
df = pd.DataFrame(np.random.rand(6, 4),
                 index=['one', 'two', 'three', 'four', 'five', 'six'],
                 columns=pd.Index(['A', 'B', 'C', 'D'], 
                 name='Genus')).round(2)
df.plot(kind='bar',figsize=(10,4))
ax = plt.gca()
pos = []
for bar in ax.patches:
    pos.append(bar.get_x()+bar.get_width()/2.)
ax.set_xticks(pos,minor=True)
lab = []
for i in range(len(pos)):
    l = df.columns.values[i//len(df.index.values)]
    lab.append(l)
ax.set_xticklabels(lab,minor=True)
ax.tick_params(axis='x', which='major', pad=15, size=0)
plt.setp(ax.get_xticklabels(), rotation=0)
plt.show()","['df = pd.DataFrame(np.random.rand(6, 4),', ""                 columns=pd.Index(['A', 'B', 'C', 'D'], "", ""df.plot(kind='bar',figsize=(10,4))"", '    pos.append(bar.get_x()+bar.get_width()/2.)', '    l = df.columns.values[i//len(df.index.values)]', '    lab.append(l)']","['import matplotlib.pyplot as plt', 'import numpy as np', 'import pandas as pd', ""                 index=['one', 'two', 'three', 'four', 'five', 'six'],"", ""                 columns=pd.Index(['A', 'B', 'C', 'D'], "", ""                 name='Genus')).round(2)"", ""df.plot(kind='bar',figsize=(10,4))"", 'ax = plt.gca()', 'pos = []', 'for bar in ax.patches:', '    pos.append(bar.get_x()+bar.get_width()/2.)', 'ax.set_xticks(pos,minor=True)', 'lab = []', 'for i in range(len(pos)):', '    l = df.columns.values[i//len(df.index.values)]', '    lab.append(l)', 'ax.set_xticklabels(lab,minor=True)', ""ax.tick_params(axis='x', which='major', pad=15, size=0)"", 'plt.setp(ax.get_xticklabels(), rotation=0)', 'plt.show()']","[""                 columns=pd.Index(['A', 'B', 'C', 'D'], "", ""df.plot(kind='bar',figsize=(10,4))"", '    pos.append(bar.get_x()+bar.get_width()/2.)', '    l = df.columns.values[i//len(df.index.values)]', '    lab.append(l)']",,
43553043,"from sklearn.datasets import load_iris
import pandas as pd
data = load_iris()
df = pd.DataFrame(data.data, columns=data.feature_names)
df.head()","['df = pd.DataFrame(data.data, columns=data.feature_names)', 'df.head()']","['from sklearn.datasets import load_iris', 'import pandas as pd', 'data = load_iris()', 'df.head()']",['df.head()'],,
43559496,"x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])
print(x)
q += 2
print(x)  
x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])
print(x)
q = x.loc[:, 'a'].copy()
q += 2
print(x)  ","[""x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])"", ""x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])"", ""q = x.loc[:, 'a'].copy()""]","['print(x)', 'q += 2', 'print(x)  ', 'print(x)', ""q = x.loc[:, 'a'].copy()"", 'q += 2', 'print(x)  ']","[""q = x.loc[:, 'a'].copy()""]",,
43577783,"a = np.array([2,1,2,3,4,5,4,6,5,7,8,9,8,10,11])
b = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])
a_cummax = np.maximum.accumulate(a)    
a_new, idx = np.unique(a_cummax, return_index=True)
a_new
array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
b[idx]
array([ 1,  4,  5,  6,  8, 10, 11, 12, 14, 15])","['a_new, idx = np.unique(a_cummax, return_index=True)']","['a = np.array([2,1,2,3,4,5,4,6,5,7,8,9,8,10,11])', 'b = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])', 'a_cummax = np.maximum.accumulate(a)    ', 'a_new, idx = np.unique(a_cummax, return_index=True)', 'a_new', 'array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])', 'b[idx]', 'array([ 1,  4,  5,  6,  8, 10, 11, 12, 14, 15])']","['a_new, idx = np.unique(a_cummax, return_index=True)']",,
43578010,"a = [2,1,2,3,4,5,4,6,5,7,8,9,8,10,11]
b = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
a_new, b_new = [], []
last = float('-inf')",[],"['a = [2,1,2,3,4,5,4,6,5,7,8,9,8,10,11]', 'b = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]', 'a_new, b_new = [], []', ""last = float('-inf')""]",[],[],[]
43578378,"a = [2,1,2,3,4,5,4,6,5,7,8,9,8,10,11]
arr = np.array(a)
aux = np.maximum.accumulate(arr)
flag = np.concatenate(([True], aux[1:] != aux[:-1])) 
idx = np.nonzero(flag)
idx
arr[idx]
np.array(b)[idx]
np.unique(aux, return_index=True)[1]","['np.unique(aux, return_index=True)[1]']","['a = [2,1,2,3,4,5,4,6,5,7,8,9,8,10,11]', 'arr = np.array(a)', 'aux = np.maximum.accumulate(arr)', 'flag = np.concatenate(([True], aux[1:] != aux[:-1])) ', 'idx = np.nonzero(flag)', 'idx', 'arr[idx]', 'np.array(b)[idx]', 'np.unique(aux, return_index=True)[1]']","['np.unique(aux, return_index=True)[1]']",,
43578600,"import numba
def psi(A):
    a_cummax = np.maximum.accumulate(A)
    a_new, idx = np.unique(a_cummax, return_index=True)
    return idx
def foo(arr):
    aux=np.maximum.accumulate(arr)
    flag = np.concatenate(([True], aux[1:] != aux[:-1]))
    return np.nonzero(flag)[0]
@numba.jit
def f(A):
    m = A[0]
    a_new, idx = [m], [0]
    for i, a in enumerate(A[1:], 1):
        if a > m:
            m = a
            a_new.append(a)
            idx.append(i)
    return idx","['    a_new, idx = np.unique(a_cummax, return_index=True)', '            a_new.append(a)', '            idx.append(i)']","['import numba', 'def psi(A):', '    a_cummax = np.maximum.accumulate(A)', '    a_new, idx = np.unique(a_cummax, return_index=True)', '    return idx', 'def foo(arr):', '    aux=np.maximum.accumulate(arr)', '    flag = np.concatenate(([True], aux[1:] != aux[:-1]))', '    return np.nonzero(flag)[0]', '@numba.jit', 'def f(A):', '    m = A[0]', '    a_new, idx = [m], [0]', '    for i, a in enumerate(A[1:], 1):', '        if a > m:', '            m = a', '            a_new.append(a)', '            idx.append(i)', '    return idx']","['    a_new, idx = np.unique(a_cummax, return_index=True)', '            a_new.append(a)', '            idx.append(i)']",,
43665978,"@profile
def foo():
    df = pd.DataFrame(np.random.randn(2 * 10 ** 7))
    d1 = df[:]
    d1 = d1.copy()
if __name__ == '__main__':
    foo()
Filename: demo.py
Line 
Line ","['    df = pd.DataFrame(np.random.randn(2 * 10 ** 7))', '    d1 = d1.copy()']","['@profile', 'def foo():', '    d1 = df[:]', '    d1 = d1.copy()', ""if __name__ == '__main__':"", '    foo()', 'Filename: demo.py', 'Line ', 'Line ']",['    d1 = d1.copy()'],,
43821531,"arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],
          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]
index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])
df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],
                   'B': np.arange(8)}, index=index)
print (df)
print (df.groupby(['second', 'A']).sum())","[""index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])"", ""df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],"", ""print (df.groupby(['second', 'A']).sum())""]","[""arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],"", ""          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]"", ""index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])"", ""                   'B': np.arange(8)}, index=index)"", 'print (df)', ""print (df.groupby(['second', 'A']).sum())""]","[""index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])"", ""print (df.groupby(['second', 'A']).sum())""]",,
43896119,"import datetime as dt
df['month_year'] = df.date_column.dt.to_period('M')","[""df['month_year'] = df.date_column.dt.to_period('M')""]","['import datetime as dt', ""df['month_year'] = df.date_column.dt.to_period('M')""]","[""df['month_year'] = df.date_column.dt.to_period('M')""]",,
43897124,"df = pd.DataFrame({'A': [1, 1, 1, 2, 2],
                   'B': range(5),
                   'C': range(5)})
df.groupby('A').B.agg({'foo': 'count'})
df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})
df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})
df.groupby('A').agg({'B': 'sum', 'C': 'min'}).rename(columns={'B': 'foo', 'C': 'bar'})
(df.groupby('A')
    .agg({'B': 'sum', 'C': 'min'})
    .rename(columns={'B': 'foo', 'C': 'bar'})
)
df.groupby('A').agg({'B': {'min': lambda x: x.min(), 'max': lambda x: x.max()}})
A        
df.groupby('A').agg({'B': [np.min, np.max]})
A          
df.groupby('A').agg({'B': [lambda x: x.min(), lambda x: x.max]})
def my_min(x):
       B       
A              ","[""df = pd.DataFrame({'A': [1, 1, 1, 2, 2],"", ""df.groupby('A').B.agg({'foo': 'count'})"", ""df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})"", ""df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})"", ""df.groupby('A').agg({'B': 'sum', 'C': 'min'}).rename(columns={'B': 'foo', 'C': 'bar'})"", ""(df.groupby('A')"", ""df.groupby('A').agg({'B': {'min': lambda x: x.min(), 'max': lambda x: x.max()}})"", ""df.groupby('A').agg({'B': [np.min, np.max]})"", ""df.groupby('A').agg({'B': [lambda x: x.min(), lambda x: x.max]})""]","[""                   'B': range(5),"", ""                   'C': range(5)})"", ""df.groupby('A').B.agg({'foo': 'count'})"", ""df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})"", ""df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})"", ""df.groupby('A').agg({'B': 'sum', 'C': 'min'}).rename(columns={'B': 'foo', 'C': 'bar'})"", ""(df.groupby('A')"", ""    .agg({'B': 'sum', 'C': 'min'})"", ""    .rename(columns={'B': 'foo', 'C': 'bar'})"", ')', ""df.groupby('A').agg({'B': {'min': lambda x: x.min(), 'max': lambda x: x.max()}})"", 'A        ', ""df.groupby('A').agg({'B': [np.min, np.max]})"", 'A          ', ""df.groupby('A').agg({'B': [lambda x: x.min(), lambda x: x.max]})"", 'def my_min(x):', '       B       ', 'A              ']","[""df.groupby('A').B.agg({'foo': 'count'})"", ""df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})"", ""df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})"", ""df.groupby('A').agg({'B': 'sum', 'C': 'min'}).rename(columns={'B': 'foo', 'C': 'bar'})"", ""(df.groupby('A')"", ""df.groupby('A').agg({'B': {'min': lambda x: x.min(), 'max': lambda x: x.max()}})"", ""df.groupby('A').agg({'B': [np.min, np.max]})"", ""df.groupby('A').agg({'B': [lambda x: x.min(), lambda x: x.max]})""]",,
43968774,"df.loc[df.index[2], 'ColName'] = 3
df.loc[df.index[1:3], 'ColName'] = 3
df.iloc[2, df.columns.get_loc('ColName')] = 3
df.iloc[2, 4] = 3
df.iloc[:3, 2:4] = 3
df.at[df.index[2], 'ColName'] = 3
df.at['C', 'ColName'] = 3
IBM.iat[2, IBM.columns.get_loc('PNL')] = 3
df.set_value(df.index[2], 'ColName', 3)
df.set_value(2, df.columns.get_loc('ColName'), 3, takable=True)","[""df.loc[df.index[2], 'ColName'] = 3"", ""df.loc[df.index[1:3], 'ColName'] = 3"", ""df.iloc[2, df.columns.get_loc('ColName')] = 3"", 'df.iloc[2, 4] = 3', 'df.iloc[:3, 2:4] = 3', ""df.at[df.index[2], 'ColName'] = 3"", ""df.at['C', 'ColName'] = 3"", ""IBM.iat[2, IBM.columns.get_loc('PNL')] = 3"", ""df.set_value(df.index[2], 'ColName', 3)"", ""df.set_value(2, df.columns.get_loc('ColName'), 3, takable=True)""]","[""df.loc[df.index[2], 'ColName'] = 3"", ""df.loc[df.index[1:3], 'ColName'] = 3"", ""df.iloc[2, df.columns.get_loc('ColName')] = 3"", 'df.iloc[2, 4] = 3', 'df.iloc[:3, 2:4] = 3', ""df.at[df.index[2], 'ColName'] = 3"", ""df.at['C', 'ColName'] = 3"", ""IBM.iat[2, IBM.columns.get_loc('PNL')] = 3"", ""df.set_value(df.index[2], 'ColName', 3)"", ""df.set_value(2, df.columns.get_loc('ColName'), 3, takable=True)""]","[""df.loc[df.index[2], 'ColName'] = 3"", ""df.loc[df.index[1:3], 'ColName'] = 3"", ""df.iloc[2, df.columns.get_loc('ColName')] = 3"", 'df.iloc[2, 4] = 3', 'df.iloc[:3, 2:4] = 3', ""df.at[df.index[2], 'ColName'] = 3"", ""df.at['C', 'ColName'] = 3"", ""IBM.iat[2, IBM.columns.get_loc('PNL')] = 3"", ""df.set_value(df.index[2], 'ColName', 3)"", ""df.set_value(2, df.columns.get_loc('ColName'), 3, takable=True)""]",,
44123892,,[],[''],[],[],[]
44208076,"d = {}
[0, 1, 2, 3, 4, 1, 2]
from itertools import count
c = count()
[0, 1, 2, 3, 4, 1, 2, 5]
[0, 1, 2, 3, 4, 1, 2, 5]",[],"['d = {}', '[0, 1, 2, 3, 4, 1, 2]', 'from itertools import count', 'c = count()', '[0, 1, 2, 3, 4, 1, 2, 5]', '[0, 1, 2, 3, 4, 1, 2, 5]']",[],[],[]
44208229,pd.Series(tups).factorize()[0],['pd.Series(tups).factorize()[0]'],[],['pd.Series(tups).factorize()[0]'],,
44311454,"mask = df.my_channel > 20000
column_name = 'my_channel'
df.loc[mask, column_name] = 0","['df.loc[mask, column_name] = 0']","['mask = df.my_channel > 20000', ""column_name = 'my_channel'"", 'df.loc[mask, column_name] = 0']","['df.loc[mask, column_name] = 0']",,
44724677,"df1.to_csv('file.csv', index=False)
df2.to_csv('file.csv', mode='a', columns=False, index=False)
df3.to_csv('file.csv', mode='a', columns=False, index=False)
del df1, df2, df3
df = pd.read_csv('file.csv')
df1.to_csv('file.csv', index=False)
df2.to_csv('file1.csv', index=False)
df3.to_csv('file2.csv', index=False)
del df1, df2, df3
def concat(file1, file2):
    with open(file2, 'r') as filename2:
        data = file2.read()
    with open(file1, 'a') as filename1:
        file.write(data)
concat('file.csv', 'file1.csv')
concat('file.csv', 'file2.csv')
concat('file.csv', 'file3.csv')
df = pd.read_csv('file.csv')","[""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file.csv', mode='a', columns=False, index=False)"", ""df3.to_csv('file.csv', mode='a', columns=False, index=False)"", ""df = pd.read_csv('file.csv')"", ""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file1.csv', index=False)"", ""df3.to_csv('file2.csv', index=False)"", ""df = pd.read_csv('file.csv')""]","[""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file.csv', mode='a', columns=False, index=False)"", ""df3.to_csv('file.csv', mode='a', columns=False, index=False)"", 'del df1, df2, df3', ""df = pd.read_csv('file.csv')"", ""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file1.csv', index=False)"", ""df3.to_csv('file2.csv', index=False)"", 'del df1, df2, df3', 'def concat(file1, file2):', ""    with open(file2, 'r') as filename2:"", '        data = file2.read()', ""    with open(file1, 'a') as filename1:"", '        file.write(data)', ""concat('file.csv', 'file1.csv')"", ""concat('file.csv', 'file2.csv')"", ""concat('file.csv', 'file3.csv')"", ""df = pd.read_csv('file.csv')""]","[""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file.csv', mode='a', columns=False, index=False)"", ""df3.to_csv('file.csv', mode='a', columns=False, index=False)"", ""df = pd.read_csv('file.csv')"", ""df1.to_csv('file.csv', index=False)"", ""df2.to_csv('file1.csv', index=False)"", ""df3.to_csv('file2.csv', index=False)"", ""df = pd.read_csv('file.csv')""]",,
44736467,"df.loc[:, 'foo':'sat']
df.loc[:, 'foo':'cat':2]
df.loc[:, :'bar']
df.loc[:, 'quz'::3]
df.loc[:, 'sat':'bar']
df.loc[:, 'sat':'bar':-1]
df.loc[:, slice('quz',None, 2)]
df.loc[:, ['foo','bar','dat']]
df.loc['w':'y', 'foo':'ant':3]
w
x
y","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]"", 'w', 'x', 'y']","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]"
44800142,"df1.to_csv(filename)
df2.to_csv(filename, mode='a', columns=False)
df3.to_csv(filename, mode='a', columns=False)
del df1, df2, df3
df_concat = pd.read_csv(filename)","['df1.to_csv(filename)', ""df2.to_csv(filename, mode='a', columns=False)"", ""df3.to_csv(filename, mode='a', columns=False)"", 'df_concat = pd.read_csv(filename)']","['df1.to_csv(filename)', ""df2.to_csv(filename, mode='a', columns=False)"", ""df3.to_csv(filename, mode='a', columns=False)"", 'del df1, df2, df3', 'df_concat = pd.read_csv(filename)']","['df1.to_csv(filename)', ""df2.to_csv(filename, mode='a', columns=False)"", ""df3.to_csv(filename, mode='a', columns=False)"", 'df_concat = pd.read_csv(filename)']",,
44913631,"import pandas as pd 
import numpy as np 
df = pd.DataFrame({""A"":[0,1,0], ""B"":[2,0,5]}, columns=list('AB'))
df.loc[df.A == 0, 'B'] = np.nan
df","['df = pd.DataFrame({""A"":[0,1,0], ""B"":[2,0,5]}, columns=list(\'AB\'))', ""df.loc[df.A == 0, 'B'] = np.nan""]","['import pandas as pd ', 'import numpy as np ', ""df.loc[df.A == 0, 'B'] = np.nan"", 'df']","[""df.loc[df.A == 0, 'B'] = np.nan""]",,
44948390,"file = ""./data.csv""
chunks = pd.read_csv(file, sep=""/"", header=0, dtype=str, chunksize = 100000)
for it, chunk in enumerate(chunks):
    chunk.to_csv('chunk_{}.csv'.format(it), sep=""/"") ","['chunks = pd.read_csv(file, sep=""/"", header=0, dtype=str, chunksize = 100000)', '    chunk.to_csv(\'chunk_{}.csv\'.format(it), sep=""/"") ']","['file = ""./data.csv""', 'chunks = pd.read_csv(file, sep=""/"", header=0, dtype=str, chunksize = 100000)', 'for it, chunk in enumerate(chunks):', '    chunk.to_csv(\'chunk_{}.csv\'.format(it), sep=""/"") ']","['chunks = pd.read_csv(file, sep=""/"", header=0, dtype=str, chunksize = 100000)', '    chunk.to_csv(\'chunk_{}.csv\'.format(it), sep=""/"") ']",,
44998387,"from itertools import combinations
[x for x in combinations(df.columns, 2) if (df[x[0]] == df[x[-1]]).all()]
cols = df.columns
dftv = df.T.values
cross = pd.DataFrame((dftv == dftv[:, None]).all(-1), cols, cols)
cross
s = cross.where(np.tri(*cross.shape, k=-1)).unstack()
s[s == 1].index.tolist()
Out[129]: [('A', 'C'), ('B', 'D')]","['[x for x in combinations(df.columns, 2) if (df[x[0]] == df[x[-1]]).all()]', 'dftv = df.T.values', 'cross = pd.DataFrame((dftv == dftv[:, None]).all(-1), cols, cols)', 's = cross.where(np.tri(*cross.shape, k=-1)).unstack()', 's[s == 1].index.tolist()']","['from itertools import combinations', '[x for x in combinations(df.columns, 2) if (df[x[0]] == df[x[-1]]).all()]', 'cols = df.columns', 'dftv = df.T.values', 'cross', 's = cross.where(np.tri(*cross.shape, k=-1)).unstack()', 's[s == 1].index.tolist()', ""Out[129]: [('A', 'C'), ('B', 'D')]""]","['[x for x in combinations(df.columns, 2) if (df[x[0]] == df[x[-1]]).all()]', 'dftv = df.T.values', 'cross = pd.DataFrame((dftv == dftv[:, None]).all(-1), cols, cols)', 's = cross.where(np.tri(*cross.shape, k=-1)).unstack()', 's[s == 1].index.tolist()']",,
44999009,"def group_duplicate_cols(df):
    a = df.values
    sidx = np.lexsort(a)
    b = a[:,sidx]
    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))
    idx = np.flatnonzero(m[1:] != m[:-1])
    C = df.columns[sidx].tolist()
    return [C[i:j] for i,j in zip(idx[::2],idx[1::2]+1)]
df
group_duplicate_cols(df)
df.F = df.A
group_duplicate_cols(df)
df2
group_duplicate_rows(df2)
def view1D(a): 
    a = np.ascontiguousarray(a)
    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))
    return a.view(void_dt).ravel()
def group_duplicate_cols_v2(df):
    a = df.values
    sidx = view1D(a.T).argsort()
    b = a[:,sidx]
    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))
    idx = np.flatnonzero(m[1:] != m[:-1])
    C = df.columns[sidx].tolist()
    return [C[i:j] for i,j in zip(idx[::2],idx[1::2]+1)]","['    a = df.values', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()', '    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))', '    a = df.values', '    sidx = view1D(a.T).argsort()', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()']","['def group_duplicate_cols(df):', '    a = df.values', '    sidx = np.lexsort(a)', '    b = a[:,sidx]', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    idx = np.flatnonzero(m[1:] != m[:-1])', '    C = df.columns[sidx].tolist()', '    return [C[i:j] for i,j in zip(idx[::2],idx[1::2]+1)]', 'df', 'group_duplicate_cols(df)', 'df.F = df.A', 'group_duplicate_cols(df)', 'df2', 'group_duplicate_rows(df2)', 'def view1D(a): ', '    a = np.ascontiguousarray(a)', '    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))', '    return a.view(void_dt).ravel()', 'def group_duplicate_cols_v2(df):', '    a = df.values', '    sidx = view1D(a.T).argsort()', '    b = a[:,sidx]', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    idx = np.flatnonzero(m[1:] != m[:-1])', '    C = df.columns[sidx].tolist()', '    return [C[i:j] for i,j in zip(idx[::2],idx[1::2]+1)]']","['    a = df.values', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()', '    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))', '    a = df.values', '    sidx = view1D(a.T).argsort()', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()']",,
45013739,"import numpy as np
from multiprocessing import Pool
def processor(df):
    df.sort_values('id', inplace=True)
    return df
size = 8
df_split = np.array_split(df, size)
cores = 8
pool = Pool(cores)
for n, frame in enumerate(pool.imap(processor, df_split), start=1):
    frame.to_csv('{}'.format(n))
pool.close()
pool.join()","[""    df.sort_values('id', inplace=True)"", ""    frame.to_csv('{}'.format(n))"", 'pool.join()']","['import numpy as np', 'from multiprocessing import Pool', 'def processor(df):', ""    df.sort_values('id', inplace=True)"", '    return df', 'size = 8', 'df_split = np.array_split(df, size)', 'cores = 8', 'pool = Pool(cores)', 'for n, frame in enumerate(pool.imap(processor, df_split), start=1):', ""    frame.to_csv('{}'.format(n))"", 'pool.close()', 'pool.join()']","[""    df.sort_values('id', inplace=True)"", ""    frame.to_csv('{}'.format(n))"", 'pool.join()']",,
45193340,"n = 3
df.apply(lambda x: pd.Series(x.nsmallest(n).index))",['df.apply(lambda x: pd.Series(x.nsmallest(n).index))'],['n = 3'],['df.apply(lambda x: pd.Series(x.nsmallest(n).index))'],,
45193636,"a = np.argsort(-df.values, axis=0)[-3:]
print (a)
b = pd.DataFrame(df.index[a][::-1], columns=df.columns)
print (b)","['a = np.argsort(-df.values, axis=0)[-3:]', 'b = pd.DataFrame(df.index[a][::-1], columns=df.columns)']","['a = np.argsort(-df.values, axis=0)[-3:]', 'print (a)', 'print (b)']","['a = np.argsort(-df.values, axis=0)[-3:]', 'b = pd.DataFrame(df.index[a][::-1], columns=df.columns)']",,
45333133,"from toolz import interleave
pd.concat([d1, d2], axis=1)[list(interleave([d1, d2]))]","['pd.concat([d1, d2], axis=1)[list(interleave([d1, d2]))]']","['from toolz import interleave', 'pd.concat([d1, d2], axis=1)[list(interleave([d1, d2]))]']","['pd.concat([d1, d2], axis=1)[list(interleave([d1, d2]))]']",,
45333267,"def numpy_interweave(d1, d2):
    c1 = list(d1.columns)
    c2 = list(d2.columns)
    N = (len(c1)+len(c2))
    cols = [None]*N
    cols[::2] = c1
    cols[1::2] = c2
    out_dtype = np.result_type(d1.values.dtype, d2.values.dtype)
    out = np.empty((d1.shape[0],N),dtype=out_dtype)
    out[:,::2] = d1.values
    out[:,1::2] = d2.values
    df_out = pd.DataFrame(out, columns=cols, index=d1.index)
    return df_out
d1
d2
numpy_interweave(d1, d2)","['    out_dtype = np.result_type(d1.values.dtype, d2.values.dtype)', '    out = np.empty((d1.shape[0],N),dtype=out_dtype)', '    out[:,::2] = d1.values', '    out[:,1::2] = d2.values', '    df_out = pd.DataFrame(out, columns=cols, index=d1.index)']","['def numpy_interweave(d1, d2):', '    c1 = list(d1.columns)', '    c2 = list(d2.columns)', '    N = (len(c1)+len(c2))', '    cols = [None]*N', '    cols[::2] = c1', '    cols[1::2] = c2', '    out_dtype = np.result_type(d1.values.dtype, d2.values.dtype)', '    out = np.empty((d1.shape[0],N),dtype=out_dtype)', '    out[:,::2] = d1.values', '    out[:,1::2] = d2.values', '    return df_out', 'd1', 'd2', 'numpy_interweave(d1, d2)']","['    out_dtype = np.result_type(d1.values.dtype, d2.values.dtype)', '    out = np.empty((d1.shape[0],N),dtype=out_dtype)', '    out[:,::2] = d1.values', '    out[:,1::2] = d2.values', '    df_out = pd.DataFrame(out, columns=cols, index=d1.index)']",,
45357725,"df = df.drop('your_column', axis=1)
df = df.drop(['col_1','col_2','col_3'], axis=1)","[""df = df.drop('your_column', axis=1)"", ""df = df.drop(['col_1','col_2','col_3'], axis=1)""]","[""df = df.drop('your_column', axis=1)"", ""df = df.drop(['col_1','col_2','col_3'], axis=1)""]","[""df = df.drop('your_column', axis=1)"", ""df = df.drop(['col_1','col_2','col_3'], axis=1)""]",,
45494714,"df = pd.DataFrame(np.random.randint(10, size=(10, 3)))
df[np.array(lst).astype(bool)]","['df = pd.DataFrame(np.random.randint(10, size=(10, 3)))', 'df[np.array(lst).astype(bool)]']",['df[np.array(lst).astype(bool)]'],['df[np.array(lst).astype(bool)]'],,
45494718,"df[np.array([0,1,0,0,1,1,0,0,0,1],dtype=bool)]
df2 = df[np.array([0,1,0,0,1,1,0,0,0,1],dtype=bool)]",[],"['df[np.array([0,1,0,0,1,1,0,0,0,1],dtype=bool)]', 'df2 = df[np.array([0,1,0,0,1,1,0,0,0,1],dtype=bool)]']",[],[],[]
45494808,"df = pd.DataFrame(np.random.randint(10, size=(10, 3)))
df[list(map(bool, lst))]
results.div(results.min(1), 0).round(2).pipe(lambda d: d.assign(Best=d.idxmin(1)))
N                                        
fig, (a1, a2) = plt.subplots(2, 1, figsize=(6, 6))
results.plot(loglog=True, lw=3, ax=a1)
results.div(results.min(1), 0).round(2).plot.bar(logy=True, ax=a2)
fig.tight_layout()
ayh = lambda d, l: d[np.array(l).astype(bool)]
wvo = lambda d, l: d[np.array(l, dtype=bool)]
pir = lambda d, l: d[list(map(bool, l))]
wen = lambda d, l: d.loc[[i for i, x in enumerate(l) if x == 1], :]
def mxu(d, l):
    a = np.array(l)
    return d.query('@a != 0')
results = pd.DataFrame(
    index=pd.Index([1, 3, 10, 30, 100, 300,
                    1000, 3000, 10000, 30000, 100000], name='N'),
    columns='ayh wvo pir mxu wen'.split(),
    dtype=float
)
for i in results.index:
    d = pd.concat([df] * i, ignore_index=True)
    l = lst * i
    for j in results.columns:
        stmt = '{}(d, l)'.format(j)
        setp = 'from __main__ import d, l, {}'.format(j)
        results.set_value(i, j, timeit(stmt, setp, number=10))","['df = pd.DataFrame(np.random.randint(10, size=(10, 3)))', 'results.div(results.min(1), 0).round(2).pipe(lambda d: d.assign(Best=d.idxmin(1)))', 'results.plot(loglog=True, lw=3, ax=a1)', 'results.div(results.min(1), 0).round(2).plot.bar(logy=True, ax=a2)', 'ayh = lambda d, l: d[np.array(l).astype(bool)]', 'wen = lambda d, l: d.loc[[i for i, x in enumerate(l) if x == 1], :]', ""    return d.query('@a != 0')"", 'results = pd.DataFrame(', ""    columns='ayh wvo pir mxu wen'.split(),"", 'for i in results.index:', '    d = pd.concat([df] * i, ignore_index=True)', ""        stmt = '{}(d, l)'.format(j)"", ""        setp = 'from __main__ import d, l, {}'.format(j)"", '        results.set_value(i, j, timeit(stmt, setp, number=10))']","['df[list(map(bool, lst))]', 'results.div(results.min(1), 0).round(2).pipe(lambda d: d.assign(Best=d.idxmin(1)))', 'N                                        ', 'fig, (a1, a2) = plt.subplots(2, 1, figsize=(6, 6))', 'results.plot(loglog=True, lw=3, ax=a1)', 'results.div(results.min(1), 0).round(2).plot.bar(logy=True, ax=a2)', 'fig.tight_layout()', 'ayh = lambda d, l: d[np.array(l).astype(bool)]', 'wvo = lambda d, l: d[np.array(l, dtype=bool)]', 'pir = lambda d, l: d[list(map(bool, l))]', 'wen = lambda d, l: d.loc[[i for i, x in enumerate(l) if x == 1], :]', 'def mxu(d, l):', '    a = np.array(l)', ""    return d.query('@a != 0')"", '    index=pd.Index([1, 3, 10, 30, 100, 300,', ""                    1000, 3000, 10000, 30000, 100000], name='N'),"", ""    columns='ayh wvo pir mxu wen'.split(),"", '    dtype=float', ')', 'for i in results.index:', '    d = pd.concat([df] * i, ignore_index=True)', '    l = lst * i', '    for j in results.columns:', ""        stmt = '{}(d, l)'.format(j)"", ""        setp = 'from __main__ import d, l, {}'.format(j)"", '        results.set_value(i, j, timeit(stmt, setp, number=10))']","['results.div(results.min(1), 0).round(2).pipe(lambda d: d.assign(Best=d.idxmin(1)))', 'results.plot(loglog=True, lw=3, ax=a1)', 'results.div(results.min(1), 0).round(2).plot.bar(logy=True, ax=a2)', 'ayh = lambda d, l: d[np.array(l).astype(bool)]', 'wen = lambda d, l: d.loc[[i for i, x in enumerate(l) if x == 1], :]', ""    return d.query('@a != 0')"", ""    columns='ayh wvo pir mxu wen'.split(),"", 'for i in results.index:', '    d = pd.concat([df] * i, ignore_index=True)', ""        stmt = '{}(d, l)'.format(j)"", ""        setp = 'from __main__ import d, l, {}'.format(j)"", '        results.set_value(i, j, timeit(stmt, setp, number=10))']",,
45494910,"a = np.array(lst)
df.query(""index * @a > 0"")
df.query(""@a != 0"")","['df.query(""index * @a > 0"")', 'df.query(""@a != 0"")']","['a = np.array(lst)', 'df.query(""index * @a > 0"")', 'df.query(""@a != 0"")']","['df.query(""index * @a > 0"")', 'df.query(""@a != 0"")']",,
45568211,"from pandas.api.types import is_string_dtype
from pandas.api.types import is_numeric_dtype
is_string_dtype(df['A'])
True
is_numeric_dtype(df['B'])
True
for y in agg.columns:
    if (is_string_dtype(agg[y])):
        treat_str(agg[y])
    elif (is_numeric_dtype(agg[y])):
        treat_numeric(agg[y])",[],"['from pandas.api.types import is_string_dtype', 'from pandas.api.types import is_numeric_dtype', ""is_string_dtype(df['A'])"", 'True', ""is_numeric_dtype(df['B'])"", 'True', 'for y in agg.columns:', '    if (is_string_dtype(agg[y])):', '        treat_str(agg[y])', '    elif (is_numeric_dtype(agg[y])):', '        treat_numeric(agg[y])']",[],[],[]
45741989,"def read_clipboard_mi(index_names_row=None, **kwargs):
    encoding = kwargs.pop('encoding', 'utf-8')
    if encoding is not None and encoding.lower().replace('-', '') != 'utf8':
        raise NotImplementedError(
            'reading from clipboard only supports utf-8 encoding')
    from pandas import compat, read_fwf
    from pandas.io.clipboard import clipboard_get
    from pandas.io.common import StringIO
    data = clipboard_get()
    if compat.PY3:
        try:
            text = compat.bytes_to_str(
                text, encoding=(kwargs.get('encoding') or
                                get_option('display.encoding'))
            )
        except:
            pass
    index_names = None
    if index_names_row:
        if isinstance(index_names_row, int):
            index_names = data.splitlines()[index_names_row].split()
            skiprows = [index_names_row]
            kwargs.update({'skiprows': skiprows})
        else:
            raise Exception('[index_names_row] must be of [int] data type')
    df = read_fwf(StringIO(data), **kwargs)
    unnamed_cols = df.columns[df.columns.str.contains(r'Unnamed:')].tolist()
    if index_names:
        idx_cols = df.columns[range(len(index_names))].tolist()
    elif unnamed_cols:
        idx_cols = df.columns[range(len(unnamed_cols))].tolist()
        index_names = [None] * len(idx_cols)
    df[idx_cols] = df[idx_cols].ffill()
    df = df.set_index(idx_cols).rename_axis(index_names)
    return df
read_clipboard_mi()
read_clipboard_mi(index_names_row=1)","[""    encoding = kwargs.pop('encoding', 'utf-8')"", ""    if encoding is not None and encoding.lower().replace('-', '') != 'utf8':"", ""                text, encoding=(kwargs.get('encoding') or"", '            index_names = data.splitlines()[index_names_row].split()', ""            kwargs.update({'skiprows': skiprows})"", ""    unnamed_cols = df.columns[df.columns.str.contains(r'Unnamed:')].tolist()"", '        idx_cols = df.columns[range(len(index_names))].tolist()', '        idx_cols = df.columns[range(len(unnamed_cols))].tolist()', '    df[idx_cols] = df[idx_cols].ffill()', '    df = df.set_index(idx_cols).rename_axis(index_names)']","['def read_clipboard_mi(index_names_row=None, **kwargs):', ""    encoding = kwargs.pop('encoding', 'utf-8')"", ""    if encoding is not None and encoding.lower().replace('-', '') != 'utf8':"", '        raise NotImplementedError(', ""            'reading from clipboard only supports utf-8 encoding')"", '    from pandas import compat, read_fwf', '    from pandas.io.clipboard import clipboard_get', '    from pandas.io.common import StringIO', '    data = clipboard_get()', '    if compat.PY3:', '        try:', '            text = compat.bytes_to_str(', ""                text, encoding=(kwargs.get('encoding') or"", ""                                get_option('display.encoding'))"", '            )', '        except:', '            pass', '    index_names = None', '    if index_names_row:', '        if isinstance(index_names_row, int):', '            index_names = data.splitlines()[index_names_row].split()', '            skiprows = [index_names_row]', ""            kwargs.update({'skiprows': skiprows})"", '        else:', ""            raise Exception('[index_names_row] must be of [int] data type')"", '    df = read_fwf(StringIO(data), **kwargs)', ""    unnamed_cols = df.columns[df.columns.str.contains(r'Unnamed:')].tolist()"", '    if index_names:', '        idx_cols = df.columns[range(len(index_names))].tolist()', '    elif unnamed_cols:', '        idx_cols = df.columns[range(len(unnamed_cols))].tolist()', '        index_names = [None] * len(idx_cols)', '    df[idx_cols] = df[idx_cols].ffill()', '    df = df.set_index(idx_cols).rename_axis(index_names)', '    return df', 'read_clipboard_mi()', 'read_clipboard_mi(index_names_row=1)']","[""    encoding = kwargs.pop('encoding', 'utf-8')"", ""    if encoding is not None and encoding.lower().replace('-', '') != 'utf8':"", ""                text, encoding=(kwargs.get('encoding') or"", '            index_names = data.splitlines()[index_names_row].split()', ""            kwargs.update({'skiprows': skiprows})"", ""    unnamed_cols = df.columns[df.columns.str.contains(r'Unnamed:')].tolist()"", '        idx_cols = df.columns[range(len(index_names))].tolist()', '        idx_cols = df.columns[range(len(unnamed_cols))].tolist()', '    df[idx_cols] = df[idx_cols].ffill()', '    df = df.set_index(idx_cols).rename_axis(index_names)']",,
45871837,"cum_r = (1 + r).cumprod()
result = cum_r * v0
for date in r.index[r.index.is_quarter_end]:
     result[date:] -= cum_r[date:] * (dist / cum_r.loc[date])
cum_r = (1 + r).cumprod()
t = (r.index.is_quarter_end / cum_r).cumsum()
result = cum_r * (v0 - dist * t)","['cum_r = (1 + r).cumprod()', 'for date in r.index[r.index.is_quarter_end]:', '     result[date:] -= cum_r[date:] * (dist / cum_r.loc[date])', 'cum_r = (1 + r).cumprod()', 't = (r.index.is_quarter_end / cum_r).cumsum()']","['cum_r = (1 + r).cumprod()', 'result = cum_r * v0', 'for date in r.index[r.index.is_quarter_end]:', '     result[date:] -= cum_r[date:] * (dist / cum_r.loc[date])', 'cum_r = (1 + r).cumprod()', 't = (r.index.is_quarter_end / cum_r).cumsum()', 'result = cum_r * (v0 - dist * t)']","['cum_r = (1 + r).cumprod()', 'for date in r.index[r.index.is_quarter_end]:', '     result[date:] -= cum_r[date:] * (dist / cum_r.loc[date])', 'cum_r = (1 + r).cumprod()', 't = (r.index.is_quarter_end / cum_r).cumsum()']",,
