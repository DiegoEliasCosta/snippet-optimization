{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get AnswerId and Question Text combo from dataset to build the context\n",
    "def buildAnswerIdQuestionTextDict(dataset_df):\n",
    "    dataset_answerId_QText_Dict = dict()\n",
    "    try:\n",
    "        for idx, row in dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                dataset_answerId_QText_Dict[answerId] = row['QuestionText']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return dataset_answerId_QText_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get AnswerId and Question Text combo from dataset to build the context\n",
    "def buildAnswerIdSolutionsDict(dataset_df):\n",
    "    dataset_answerId_Solution_Dict = dict()\n",
    "    try:\n",
    "        for idx, row in dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                if answerId in dataset_answerId_Solution_Dict.keys():\n",
    "                    solution = dataset_answerId_Solution_Dict[answerId]\n",
    "                    dataset_answerId_Solution_Dict[answerId] = solution + \" \" +row['Solution']\n",
    "                else:\n",
    "                    dataset_answerId_Solution_Dict[answerId] = row['Solution']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return dataset_answerId_Solution_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tagged dataset\n",
    "tagged_datset = pd.read_csv('../data/stack-overflow/Dataset - Pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['QuestionId', 'QuestionText', 'ObjectiveQuestion', 'AnswerId',\n",
       "       'SolutionId', 'Solution', 'Remark'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_datset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_answerId_QText_Dict = buildAnswerIdQuestionTextDict(tagged_datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_answerId_Solution_Dict = buildAnswerIdSolutionsDict(tagged_datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17071908: \"df.loc[df['column_name'] == some_value] df.loc[df['column_name'].isin(some_values)] df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)] df.loc[df['column_name'] != some_value] df.loc[~df['column_name'].isin(some_values)] df.loc[df['A'] == 'foo'] df.loc[df['B'].isin(['one','three'])] df = df.set_index(['B'])\\ndf.loc['one'] df.loc[df.index.isin(['one','two'])]\",\n",
       " 12065904: \"rpt[rpt['STK_ID'].isin(stk_list)]\",\n",
       " 19960116: 'pd.isin() something.isin(somewhere) ~something.isin(somewhere) df.countries.isin(countries) df[df.countries.isin(countries)] df[~df.countries.isin(countries)]',\n",
       " 11346337: \"df.columns = ['a', 'b']\",\n",
       " 11354850: \"df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}) df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\",\n",
       " 20221655: 'book = load_workbook(\\'Masterfile.xlsx\\')\\nwriter = pandas.ExcelWriter(\\'Masterfile.xlsx\\', engine=\\'openpyxl\\') \\nwriter.book = book\\nwriter.sheets = dict((ws.title, ws) for ws in book.worksheets)\\n\\ndata_filtered.to_excel(writer, \"Main\", cols=[\\'Diff1\\', \\'Diff2\\'])\\n\\nwriter.save()',\n",
       " 12681217: \"pd.concat([Series(row['var2'], row['var1'].split(','))\",\n",
       " 41386927: 'df = pd.read_csv(\\'filename.txt\\', sep=\";\", names=[\\'Region Name\\']) df.insert(0, \\'State\\', df[\\'Region Name\\'].str.extract(\\'(.*)\\\\[edit\\\\]\\', expand=False).ffill())\\r\\ndf[\\'Region Name\\'] = df[\\'Region Name\\'].str.replace(r\\' \\\\(.+$\\', \\'\\') df = df[~df[\\'Region Name\\'].str.contains(\\'\\\\[edit\\\\]\\')].reset_index(drop=True) df = pd.read_csv(\\'filename.txt\\', sep=\";\", names=[\\'Region Name\\'])\\r\\ndf.insert(0, \\'State\\', df[\\'Region Name\\'].str.extract(\\'(.*)\\\\[edit\\\\]\\', expand=False).ffill())\\r\\ndf = df[~df[\\'Region Name\\'].str.contains(\\'\\\\[edit\\\\]\\')].reset_index(drop=True)',\n",
       " 24888331: 'df.loc[i] = [randint(-1,1) for n in range(3)]',\n",
       " 25962187: 'for chunk in pd.read_csv(filename, chunksize=chunksize):\\r\\n    process(chunk)',\n",
       " 13270110: \"merge(df1, df2,on='key')[['col1', 'col2', 'col3']]\",\n",
       " 28648923: \"pd.to_numeric(s) pd.to_numeric(s, errors='coerce') pd.to_numeric(s, errors='ignore') df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric) df.apply(pd.to_numeric, errors='ignore') df = df.infer_objects()\",\n",
       " 16476974: \"for index, row in df.iterrows():\\r\\n    print row['c1'], row['c2'] for index, row in df.iterrows():\\r\\n     print row['c1'], row['c2']\",\n",
       " 11617194: 'for index, row in df.iterrows(): itertuples()',\n",
       " 18173074: 'df = df[df.line_race != 0]',\n",
       " 13842286: \"df.set_value('C', 'x', 10) df.xs('C')['x']=10 df['x']['C'] = 10 df.at['C', 'x'] = 10 df.set_value('C', 'x', 10) df['x']['C'] = 10 df.at['C', 'x'] = 10\",\n",
       " 17729985: \"d.sales[d.sales==24] = 100 d.loc[d.sales == 12, 'sales'] = 99 d.sales = d.sales.replace(23, 24)\",\n",
       " 14745484: \"df = pd.DataFrame(df.row.str.split(' ',1).tolist(),\\n                                   columns = ['flips','row'])\",\n",
       " 39358924: \"df['A'], df['B'] = df['AB'].str.split(' ', 1).str df['AB'].str.split(' ', 1, expand=True) df['AB_split'] = df['AB'].str.split('-') df['AB'].str.split('-', 1).str[0] df['AB'].str.split('-', 1).str[1] df['A'], df['B'] = df['AB'].str.split('-', 1).str df['AB'].str.split('-', 1, expand=True) df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))\",\n",
       " 28902170: \"common = df1.merge(df2,on=['col1','col2'])\\ndf1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))] df1[~df1.isin(df2)].dropna() df1[~df1.isin(df2)].dropna()\",\n",
       " 14900065: \"df4 = df3.drop_duplicates(subset='rownum', keep='last') df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')\",\n",
       " 34297689: \"df3 = df3[~df3.index.duplicated(keep='first')] df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') df3.groupby(df3.index).first() df3[~df3.index.duplicated(keep='first')]\",\n",
       " 15705958: \"df.groupby(['Mt'], sort=False)['count'].max() idx = df.groupby(['Mt'])['count'].transform(max) == df['count'] df['count_max'] = df.groupby(['Mt'])['count'].transform(max)\",\n",
       " 10374456: 'g1.add_suffix(\\'_Count\\').reset_index() DataFrame({\\'count\\' : df1.groupby( [ \"Name\", \"City\"] ).size()}).reset_index()',\n",
       " 30691921: \"with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\",\n",
       " 22391554: \"df.groupby('a').count() df['a'].value_counts() df['freq'] = df.groupby('a')['a'].transform('count')\",\n",
       " 16923367: \"df.to_csv(file_name, sep='\\\\t') df.to_csv(file_name, sep='\\\\t', encoding='utf-8')\",\n",
       " 11531402: 'df[df[\\'A\\'].str.contains(\"hello\")]',\n",
       " 21232849: 'frame = pd.DataFrame()\\nlist_ = []\\nfor file_ in allFiles:\\n    df = pd.read_csv(file_,index_col=None, header=0)\\n    list_.append(df)\\nframe = pd.concat(list_)',\n",
       " 19378497: 'dataframe[\"period\"] = dataframe[\"Year\"].map(str) + dataframe[\"quarter\"]',\n",
       " 16354730: \"df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)\",\n",
       " 14508355: \"df.columns = df.columns.get_level_values(0) df.columns = [' '.join(col).strip() for col in df.columns.values] [' '.join(col).strip() for col in df.columns.values]\",\n",
       " 17531025: \"with open('my_csv.csv', 'a') as f:\\n    df.to_csv(f, header=False) with open('foo.csv', 'a') as f:\\n             (df + 6).to_csv(f, header=False)\",\n",
       " 15772263: 'pd.rolling_mean(df.resample(\"1D\", fill_method=\"ffill\"), window=3, min_periods=1) df.resample(\"1d\").sum().fillna(0).rolling(window=3, min_periods=1).mean()',\n",
       " 21463854: 'data[\\'amount\\'] = data[\"amount\"].fillna(data.groupby(\"num\")[\"amount\"].transform(\"mean\")) data[\"amount\"] = data[\\'amount\\'].fillna(mean_avg) data[\\'amount\\'] = data[\\'amount\\'].fillna(mean_avg)*2',\n",
       " 13337376: 'df.apply(f, axis=1)',\n",
       " 30512931: \"dfs = [df0, df1, df2, dfN]\\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs\",\n",
       " 39923012: \"df.groupby(['Fruit','Name']).sum()\",\n",
       " 24147363: 'train, test = train_test_split(df, test_size=0.2)',\n",
       " 13682381: \"data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))\",\n",
       " 18129082: \"data = pd.read_csv('file1.csv', error_bad_lines=False)\",\n",
       " 15252012: 'my_cols = [\"A\", \"B\", \"C\", \"D\", \"E\"]\\npd.read_csv(\"ragged.csv\", names=my_cols, engine=\\'python\\')\\n',\n",
       " 18431417: \"df.fillna(-1).groupby('b').sum()\",\n",
       " 15026839: 'pd.read_csv(\"whitespace.csv\", header=None, delimiter=r\"\\\\s+\") pd.read_csv(\"whitespace.csv\", header=None, delim_whitespace=True)',\n",
       " 26301947: \"pd.set_option('display.max_colwidth', -1)\",\n",
       " 34272155: \"df.drop_duplicates(subset=['A', 'C'], keep=False)\",\n",
       " 11287278: \"df1 = df[['a','b']] df1 = df.iloc[:,0:2] df1 = df.iloc[0,0:2].copy()\",\n",
       " 18837389: \"pd.DataFrame(d.items()) pd.DataFrame(d.items(), columns=['Date', 'DateValue']) s = pd.Series(d, name='DateValue')\\ns.index.name = 'Date'\\ns.reset_index()\",\n",
       " 37043071: 'df=df.values',\n",
       " 24793359: 'numpyMatrix = df.as_matrix()',\n",
       " 17095620: 'ne = (df1 != df2).any(1) ne_stacked = (df1 != df2).stack()',\n",
       " 21266043: \"json_normalize(data['results'])\",\n",
       " 18695700: \"df.set_index('id').to_dict() df.set_index('id')['value'].to_dict()\",\n",
       " 19324591: 's = s.reindex(idx, fill_value=0)',\n",
       " 46526249: \"df_2.index = pd.IntervalIndex.from_arrays(df_2['start'],df_2['end'],closed='both')\\ndf_1['event'] = df_1['timestamp'].apply(lambda x : df_2.iloc[df_2.index.get_loc(x)]['event'])\",\n",
       " 37787724: \"df.sort_values('2')\",\n",
       " 17841294: 'df.groupby(\\'A\\')[\\'C\\'].apply(lambda x: \"{%s}\" % \\', \\'.join(x))',\n",
       " 11138275: \"import pandas as pd\\r\\nimport cx_Oracle\\r\\n\\r\\nora_conn = cx_Oracle.connect('your_connection_string')\\r\\ndf_ora = pd.read_sql('select * from user_objects', con=ora_conn)    \\r\\nprint 'loaded dataframe from Oracle. # Records: ', len(df_ora)\\r\\nora_conn.close() import MySQLdb\\r\\nmysql_cn= MySQLdb.connect(host='myhost', \\r\\n                port=3306,user='myusername', passwd='mypassword', \\r\\n                db='information_schema')\\r\\ndf_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    \\r\\nprint 'loaded dataframe from MySQL. records:', len(df_mysql)\\r\\nmysql_cn.close()\",\n",
       " 32558621: 'for column in df:\\r\\n        print(df[column])',\n",
       " 17950531: \"df['A'].apply(str) df.applymap(str)\",\n",
       " 19237920: \"k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']] k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')\",\n",
       " 14946246: \"grp = df.groupby('A')\\ngrp[['B']].transform(sum).sort('B')\\nsort1 = df.ix[grp[['B']].transform(sum).sort('B').index]\\nf = lambda x: x.sort('C', ascending=False)\\nsort2 = sort1.groupby('A', sort=False).apply(f)\\nsort2.reset_index(0, drop=True)\",\n",
       " 36572039: 'df.to_csv(filename ,  index = False) df.read_csv(filename ,  index = False)  ',\n",
       " 12555510: \"df1['e'] = Series(np.random.randn(sLength), index=df1.index) df1['e'] = p.Series(np.random.randn(sLength), index=df1.index) df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)\",\n",
       " 19483025: 'list(my_dataframe.columns.values) list(my_dataframe)',\n",
       " 15943975: 'df.shape df[0].count() len(df.index)',\n",
       " 13786327: 'df_ = pd.DataFrame(index=index, columns=columns)\\ndf_ = df_.fillna(0) # with 0s rather than NaNs',\n",
       " 13413845: \"df = df[np.isfinite(df['EPS'])]\",\n",
       " 13434501: \"df.dropna() df.dropna(how='all') df.dropna(thresh=2) df.dropna(subset=[1])\",\n",
       " 16104482: 'df.iloc[[2]] df.loc[[2]]',\n",
       " 14661768: 'df.drop(df.index[[1,3]])',\n",
       " 13148611: 'cols = df.columns.tolist()\\r\\ncols = cols[-1:] + cols[:-1]\\r\\ndf = df[cols]',\n",
       " 11872393: \"df[(df.A == 1) & (df.D == 6)] def mask(df, key, value):\\r\\n   return df[df[key] == value]\\r\\npandas.DataFrame.mask = mask\\r\\ndf.mask('A', 1)\\r\\ndf.mask('A', 1).mask('D', 6)\",\n",
       " 12098586: \"df[df['A'].isin([3, 6])]\",\n",
       " 13295801: 'df.fillna(0) df[1].fillna(0, inplace=True)',\n",
       " 13704307: \"dt64 = np.datetime64(dt) datetime.utcfromtimestamp(ts) np.datetime64(datetime.utcnow()).astype(datetime) numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime) numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime) datetime.utcfromtimestamp(dt64.astype(int) * ns) datetime.utcfromtimestamp(dt64.astype(int))\",\n",
       " 16729808: \"sub_df.iloc[0] sub_df.iloc[0]['A']\",\n",
       " 17242374: 'df.index.values',\n",
       " 44736467: \"df.loc[:, 'foo':'sat'] df.loc[:, 'foo':'cat':2] df.loc[:, :'bar'] df.loc[:, 'quz'::3] df.loc[:, 'sat':'bar'] df.loc[:, 'sat':'bar':-1] df.loc[:, slice('quz',None, 2)] df.loc[:, ['foo','bar','dat']] df.loc['w':'y', 'foo':'ant':3]\",\n",
       " 21800319: \"df.index[df['BoolCol'] == True].tolist() df.index[df['BoolCol']].tolist() df.index[df['BoolCol']].tolist() idx = df.index[df['BoolCol']] df.loc[df['BoolCol']] df.iloc[np.flatnonzero(df['BoolCol'])]\",\n",
       " 19385591: \"df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])\",\n",
       " 32801170: \"df.groupby(['col1','col2']).size() df.groupby(['col1', 'col2']).size().reset_index(name='counts') df.groupby(['col1', 'col2']).size() df.groupby(['col1', 'col2']).size().reset_index(name='counts')\",\n",
       " 29530601: 'df.isnull().values.any() df.isnull().any().any() df.isnull().values.sum() df.isnull().sum().sum() df.isnull().values.any()',\n",
       " 22475141: 'g = df.columns.to_series().groupby(df.dtypes).groups',\n",
       " 20763459: 'pd.DataFrame(data=data[1:,1:],    # values\\n              index=data[1:,0],    # 1st column as index\\n              columns=data[0,1:])  # 1st row as the column names',\n",
       " 22341390: 'dfList = df[\\'one\\'].tolist() my_list = df[\"cluster\"].tolist()',\n",
       " 20868446: \"df=df.rename(columns = {'two':'new_name'})\",\n",
       " 17063653: 'xl = pd.ExcelFile(\"dummydata.xlsx\")\\ndf = xl.parse(\"Sheet1\") parsed = pd.io.parsers.ExcelFile.parse(xl, \"Sheet1\")',\n",
       " 18023468: 'df.index.name',\n",
       " 10458386: \"data2 = data.set_index('a')\",\n",
       " 11362056: 'print paramdata.values',\n",
       " 20461206: \"df['index1'] = df.index df.reset_index(level=0, inplace=True) df.reset_index(level=['tick', 'obs'])\",\n",
       " 23749057: \"df['a'].values.tolist() df['a'].tolist() df['a'].drop_duplicates().values.tolist() list(set(df['a']))\",\n",
       " 20491748: 'df = df.reset_index(drop=True)',\n",
       " 15411596: \"table.groupby('YEARMONTH').CLIENTCODE.nunique()\",\n",
       " 17682726: \"df.loc[df['c']>0.5,['a','d']].values\",\n",
       " 17682662: \"df[df.c > 0.5][['b', 'e']].values\",\n",
       " 16597375: 'df.append(data) df = df.append(data)',\n",
       " 11711637: \"pd.set_option('display.height', 1000) pd.set_option('display.max_rows', 500) pd.set_option('display.max_columns', 500) pd.set_option('display.width', 1000)\",\n",
       " 19961557: 'df = pd.DataFrame(data)\\ndf.pivot(index=0, columns=1, values=2) df.pivot(index=0, columns=1, values=3)',\n",
       " 25254087: \"df_test.iloc[0] df_test['Btime'].iloc[0]\",\n",
       " 18062521: 'pd.concat([s1, s2], axis=1) pd.concat([s1, s2], axis=1).reset_index()',\n",
       " 16735476: 'df.convert_objects(convert_numeric=True)',\n",
       " 25748826: \"df['e'] = df.sum(axis=1) col_list= list(df)\\ncol_list.remove('d')\\ndf['e'] = df[col_list].sum(axis=1)\",\n",
       " 24284680: 'df.loc[-1] = [2, 3, 4]  # adding a row\\ndf.index = df.index + 1  # shifting index\\ndf = df.sort_index()  # sorting by index',\n",
       " 17134750: 'df[\\'col\\'] = pd.to_datetime(df[\\'col\\']) pd.to_datetime(pd.Series([\\'05/23/2005\\'])) pd.to_datetime(pd.Series([\\'05/23/2005\\']), format=\"%m/%d/%Y\")',\n",
       " 12525836: 'df_norm = (df - df.mean()) / (df.max() - df.min())',\n",
       " 21291622: 'df[list(\"ABCD\")] = df[list(\"ABCD\")].astype(int) df[list(\"ABCD\")] = df[list(\"ABCD\")].fillna(0.0).astype(int)',\n",
       " 23307361: \"w['female'] = w['female'].map({'female': 1, 'male': 0})\",\n",
       " 26266451: 's.isnull().sum() df.isnull().sum()',\n",
       " 18942558: \"df['Col3'] = (df['Col2'] <= 1).astype(int) df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55) df['Col3'] = 0\\ncondition = df['Col2'] > 1\\ndf.loc[condition, 'Col3'] = 42\\ndf.loc[~condition, 'Col3'] = 55\",\n",
       " 19112890: 'df = DataFrame(table, columns=headers)',\n",
       " 17141755: \"df.sort_values(['a', 'b'], ascending=[True, False]) df.sort(['a', 'b'], ascending=[True, False]) df1.sort(['a', 'b'], ascending=[True, False]) df1 = df1.sort(['a', 'b'], ascending=[True, False]) df1.sort(['a', 'b'], ascending=[True, False], inplace=True)\",\n",
       " 14760930: 'df1.tail(10)',\n",
       " 27791362: 'df = pd.read_csv(StringIO(csv),\\n        header=0,\\n        index_col=[\"date\", \"loc\"], \\n        usecols=[\"date\", \"loc\", \"x\"],\\n        parse_dates=[\"date\"])',\n",
       " 22006514: \"total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)\",\n",
       " 17813222: \"df.plot(x='col_name_1', y='col_name_2', style='o') df.plot(style=['o','rx'])\",\n",
       " 11067072: 'df.reindex_axis(sorted(df.columns), axis=1)',\n",
       " 10202789: \"df['A'].argmax() df['B'].argmax() df['C'].argmax() dfrm['A'].idxmax() dfrm.ix[dfrm['A'].idxmax()]\",\n",
       " 22276757: \"image_name_data['id'] = image_name_data['id'].astype(int).astype('str') image_name_data['id'] = image_name_data['id'].map('{:.0f}'.format)\",\n",
       " 19851521: \"df.index.names = ['Date'] df1 = df.set_index('A') df1.rename(index={1: 'a'}) df1.rename(columns={'B': 'BB'}) df1.index.names = ['index']\",\n",
       " 14734627: 'gb.get_group(\\'foo\\') gb[[\"A\", \"B\"]].get_group(\"foo\") gb[\"C\"].get_group(\"foo\")',\n",
       " 29319200: \"df.drop(df.columns[[1, 2]], axis=1, inplace=True) df1 = df1.drop(['B', 'C'], axis=1) df1 = df[['a','d']]\",\n",
       " 17098736: \"df.to_pickle(file_name) store = HDFStore('store.h5')\",\n",
       " 13851602: \"df[df['column name'].map(len) < 2]\",\n",
       " 27360130: 'df = df.drop(some labels) df = df.drop(df[<some boolean condition>].index) df = df.drop(df[df.score < 50].index) df.drop(df[df.score < 50].index, inplace=True) df = df.drop(df[(df.score < 50) & (df.score > 20)].index)',\n",
       " 25376997: \"df.loc[len(df)]=['8/19/2014','Jun','Fly','98765']\",\n",
       " 15362700: 's = df.ix[:,0]',\n",
       " 20084895: 'Series(df.values.ravel()).unique() Series(df.values.ravel()).unique() np.unique(df.values.ravel())',\n",
       " 18327852: 'myseries[myseries == 7].index[0]',\n",
       " 17619032: \"df.sort(['c1','c2'], ascending=[False,True]) df.sort(['c1','c2'], ascending=[True,True]) df.sort(['c1','c2'], ascending=[False,True]) df.sort_values(['c1','c2'], ascending=[False,True])\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_answerId_Solution_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_solutions = pd.read_csv('actual_results_file/pandas-solutioncode-h1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'AcceptedAnswerId', 'AnswerCount', 'Body',\n",
       "       'ClosedDate', 'CommentCount', 'CommunityOwnedDate', 'CreationDate',\n",
       "       'FavoriteCount', 'Id', 'LastActivityDate', 'LastEditDate',\n",
       "       'LastEditorDisplayName', 'LastEditorUserId', 'OwnerDisplayName',\n",
       "       'OwnerUserId', 'ParentId', 'PostTypeId', 'Score', 'Tags', 'Title',\n",
       "       'ViewCount', 'Code', 'PreprocessedCode', 'PreprocessedCode2',\n",
       "       'PreprocessedCode2_1', 'PreprocessedCode3', 'BodyText', 'BodyTextRake',\n",
       "       'TitleRake', 'Solution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_solutions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_solutions = pd.read_csv('actual_results_file/pandas-solutioncode-h2.csv')\n",
    "h1h2_solutions = pd.read_csv('actual_results_file/pandas-solutioncode-h1h2.csv')\n",
    "m1tfidf_solutions = pd.read_csv('actual_results_file/pandas-solutioncode-m1.csv')\n",
    "m1doc2vec_solutions = pd.read_csv('actual_results_file/pandas-solutioncode-m1-doc2vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'AcceptedAnswerId', 'AnswerCount', 'Body',\n",
       "       'ClosedDate', 'CommentCount', 'CommunityOwnedDate', 'CreationDate',\n",
       "       'FavoriteCount', 'Id', 'LastActivityDate', 'LastEditDate',\n",
       "       'LastEditorDisplayName', 'LastEditorUserId', 'OwnerDisplayName',\n",
       "       'OwnerUserId', 'ParentId', 'PostTypeId', 'Score', 'Tags', 'Title',\n",
       "       'ViewCount', 'Code', 'PreprocessedCode', 'PreprocessedCode2',\n",
       "       'PreprocessedCode2_1', 'PreprocessedCode3', 'BodyText', 'BodyTextRake',\n",
       "       'TitleRake', 'Solution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2_solutions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_solutions_filter = h1_solutions[h1_solutions['PostTypeId']!=1]\n",
    "h2_solutions_filter = h2_solutions[h1_solutions['PostTypeId']!=1]\n",
    "h1h2_solutions_filter = h1h2_solutions[h1_solutions['PostTypeId']!=1]\n",
    "m1tfidf_solutions_filter = m1tfidf_solutions[h1_solutions['PostTypeId']!=1]\n",
    "m1doc2vec_solutions_filter = m1doc2vec_solutions[h1_solutions['PostTypeId']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = pd.DataFrame(columns=['AnswerId', 'Title', 'preprocessed_code', 'actual_solutions', 'h1', 'h2', 'h1h2', 'm1tfidf', 'm1doc2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions['AnswerId'] = h1_solutions_filter['Id']\n",
    "solutions['preprocessed_code'] = h1_solutions_filter['PreprocessedCode3']\n",
    "solutions['h1'] = h1_solutions_filter['Solution']\n",
    "solutions['h2'] = h2_solutions_filter['Solution']\n",
    "solutions['h1h2'] = h1h2_solutions_filter['Solution']\n",
    "solutions['m1tfidf'] = m1tfidf_solutions_filter['Solution']\n",
    "solutions['m1doc2vec'] = m1doc2vec_solutions_filter['Solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for index, row in solutions.iterrows():\n",
    "    try:\n",
    "        title = dataset_answerId_QText_Dict[row['AnswerId']]\n",
    "        solution = dataset_answerId_Solution_Dict[row['AnswerId']]\n",
    "        solutions.set_value(index, 'Title', title)\n",
    "        solutions.set_value(index, 'actual_solutions', solution)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>Title</th>\n",
       "      <th>preprocessed_code</th>\n",
       "      <th>actual_solutions</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h1h2</th>\n",
       "      <th>m1tfidf</th>\n",
       "      <th>m1doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>10202789</td>\n",
       "      <td>Pandas DataFrame - Find row where values for c...</td>\n",
       "      <td>import pandas\\nimport numpy as np\\ndf = pandas...</td>\n",
       "      <td>df['A'].argmax() df['B'].argmax() df['C'].argm...</td>\n",
       "      <td>[\"df = pandas.DataFrame(np.random.randn(5,3),c...</td>\n",
       "      <td>['import pandas', 'import numpy as np', 'df', ...</td>\n",
       "      <td>[\"df['A'].argmax()\", \"df['B'].argmax()\", \"df['...</td>\n",
       "      <td>[\"df = pandas.DataFrame(np.random.randn(5,3),c...</td>\n",
       "      <td>[\"df = pandas.DataFrame(np.random.randn(5,3),c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>10374456</td>\n",
       "      <td>Converting a Pandas GroupBy object to DataFrame</td>\n",
       "      <td>type(g1)\\ng1.index\\ng1.add_suffix('_Count').re...</td>\n",
       "      <td>g1.add_suffix('_Count').reset_index() DataFram...</td>\n",
       "      <td>['g1.index', \"g1.add_suffix('_Count').reset_in...</td>\n",
       "      <td>['type(g1)', 'g1.index', \"g1.add_suffix('_Coun...</td>\n",
       "      <td>['g1.index', \"g1.add_suffix('_Count').reset_in...</td>\n",
       "      <td>['g1.index', \"g1.add_suffix('_Count').reset_in...</td>\n",
       "      <td>['g1.index', \"g1.add_suffix('_Count').reset_in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>10458386</td>\n",
       "      <td>Redefining the Index in a Pandas DataFrame object</td>\n",
       "      <td>In : col = ['a','b','c']\\nIn : data = DataFram...</td>\n",
       "      <td>data2 = data.set_index('a')</td>\n",
       "      <td>[\"In : data2 = data.set_index('a')\"]</td>\n",
       "      <td>[\"In : col = ['a','b','c']\", 'In : data = Data...</td>\n",
       "      <td>[\"In : data2 = data.set_index('a')\"]</td>\n",
       "      <td>[\"In : data2 = data.set_index('a')\"]</td>\n",
       "      <td>[\"In : data2 = data.set_index('a')\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>11067072</td>\n",
       "      <td>Python Pandas - Re-ordering columns in a dataf...</td>\n",
       "      <td>df.reindex_axis(sorted(df.columns), axis=1)</td>\n",
       "      <td>df.reindex_axis(sorted(df.columns), axis=1)</td>\n",
       "      <td>['df.reindex_axis(sorted(df.columns), axis=1)']</td>\n",
       "      <td>['df.reindex_axis(sorted(df.columns), axis=1)']</td>\n",
       "      <td>['df.reindex_axis(sorted(df.columns), axis=1)']</td>\n",
       "      <td>['df.reindex_axis(sorted(df.columns), axis=1)']</td>\n",
       "      <td>['df.reindex_axis(sorted(df.columns), axis=1)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>11138275</td>\n",
       "      <td>python-pandas and databases like mysql</td>\n",
       "      <td>import pandas as pd\\nimport cx_Oracle\\nora_con...</td>\n",
       "      <td>import pandas as pd\\r\\nimport cx_Oracle\\r\\n\\r\\...</td>\n",
       "      <td>[\"df_ora = pd.read_sql('select * from user_obj...</td>\n",
       "      <td>['import pandas as pd', 'import cx_Oracle', \"o...</td>\n",
       "      <td>[\"df_ora = pd.read_sql('select * from user_obj...</td>\n",
       "      <td>[\"df_ora = pd.read_sql('select * from user_obj...</td>\n",
       "      <td>[\"df_ora = pd.read_sql('select * from user_obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>34297689</td>\n",
       "      <td>Remove rows with duplicate indices (Pandas Dat...</td>\n",
       "      <td>df3 = df3[~df3.index.duplicated(keep='first')]</td>\n",
       "      <td>df3 = df3[~df3.index.duplicated(keep='first')]...</td>\n",
       "      <td>[\"df3 = df3[~df3.index.duplicated(keep='first'...</td>\n",
       "      <td>[\"df3 = df3[~df3.index.duplicated(keep='first'...</td>\n",
       "      <td>[\"df3 = df3[~df3.index.duplicated(keep='first'...</td>\n",
       "      <td>[\"df3 = df3[~df3.index.duplicated(keep='first'...</td>\n",
       "      <td>[\"df3 = df3[~df3.index.duplicated(keep='first'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>36572039</td>\n",
       "      <td>Removing index column in pandas</td>\n",
       "      <td>df.read_csv(filename ,  index = False)</td>\n",
       "      <td>df.to_csv(filename ,  index = False) df.read_c...</td>\n",
       "      <td>['df.read_csv(filename ,  index = False)  ']</td>\n",
       "      <td>['df.read_csv(filename ,  index = False)  ']</td>\n",
       "      <td>['df.read_csv(filename ,  index = False)  ']</td>\n",
       "      <td>['df.read_csv(filename ,  index = False)  ']</td>\n",
       "      <td>['df.read_csv(filename ,  index = False)  ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>37043071</td>\n",
       "      <td>Convert pandas dataframe to numpy array, prese...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>df=df.values</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>39358924</td>\n",
       "      <td>How to split a column into two columns?</td>\n",
       "      <td>df['A'], df['B'] = df['AB'].str.split(' ', 1)....</td>\n",
       "      <td>df['A'], df['B'] = df['AB'].str.split(' ', 1)....</td>\n",
       "      <td>[\"df['A'], df['B'] = df['AB'].str.split(' ', 1...</td>\n",
       "      <td>[\"df['A'], df['B'] = df['AB'].str.split(' ', 1...</td>\n",
       "      <td>[\"df['A'], df['B'] = df['AB'].str.split(' ', 1...</td>\n",
       "      <td>[\"df['A'], df['B'] = df['AB'].str.split(' ', 1...</td>\n",
       "      <td>[\"df['A'], df['B'] = df['AB'].str.split(' ', 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>44736467</td>\n",
       "      <td>How to take column-slices of dataframe in pandas</td>\n",
       "      <td>df.loc[:, 'foo':'sat']\\ndf.loc[:, 'foo':'cat':...</td>\n",
       "      <td>df.loc[:, 'foo':'sat'] df.loc[:, 'foo':'cat':2...</td>\n",
       "      <td>[\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...</td>\n",
       "      <td>[\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...</td>\n",
       "      <td>[\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...</td>\n",
       "      <td>[\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...</td>\n",
       "      <td>[\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AnswerId                                              Title  \\\n",
       "1209  10202789  Pandas DataFrame - Find row where values for c...   \n",
       "1211  10374456    Converting a Pandas GroupBy object to DataFrame   \n",
       "1213  10458386  Redefining the Index in a Pandas DataFrame object   \n",
       "1232  11067072  Python Pandas - Re-ordering columns in a dataf...   \n",
       "1238  11138275             python-pandas and databases like mysql   \n",
       "...        ...                                                ...   \n",
       "2859  34297689  Remove rows with duplicate indices (Pandas Dat...   \n",
       "2951  36572039                    Removing index column in pandas   \n",
       "2971  37043071  Convert pandas dataframe to numpy array, prese...   \n",
       "3060  39358924            How to split a column into two columns?   \n",
       "3186  44736467   How to take column-slices of dataframe in pandas   \n",
       "\n",
       "                                      preprocessed_code  \\\n",
       "1209  import pandas\\nimport numpy as np\\ndf = pandas...   \n",
       "1211  type(g1)\\ng1.index\\ng1.add_suffix('_Count').re...   \n",
       "1213  In : col = ['a','b','c']\\nIn : data = DataFram...   \n",
       "1232        df.reindex_axis(sorted(df.columns), axis=1)   \n",
       "1238  import pandas as pd\\nimport cx_Oracle\\nora_con...   \n",
       "...                                                 ...   \n",
       "2859     df3 = df3[~df3.index.duplicated(keep='first')]   \n",
       "2951           df.read_csv(filename ,  index = False)     \n",
       "2971                                                NaN   \n",
       "3060  df['A'], df['B'] = df['AB'].str.split(' ', 1)....   \n",
       "3186  df.loc[:, 'foo':'sat']\\ndf.loc[:, 'foo':'cat':...   \n",
       "\n",
       "                                       actual_solutions  \\\n",
       "1209  df['A'].argmax() df['B'].argmax() df['C'].argm...   \n",
       "1211  g1.add_suffix('_Count').reset_index() DataFram...   \n",
       "1213                        data2 = data.set_index('a')   \n",
       "1232        df.reindex_axis(sorted(df.columns), axis=1)   \n",
       "1238  import pandas as pd\\r\\nimport cx_Oracle\\r\\n\\r\\...   \n",
       "...                                                 ...   \n",
       "2859  df3 = df3[~df3.index.duplicated(keep='first')]...   \n",
       "2951  df.to_csv(filename ,  index = False) df.read_c...   \n",
       "2971                                       df=df.values   \n",
       "3060  df['A'], df['B'] = df['AB'].str.split(' ', 1)....   \n",
       "3186  df.loc[:, 'foo':'sat'] df.loc[:, 'foo':'cat':2...   \n",
       "\n",
       "                                                     h1  \\\n",
       "1209  [\"df = pandas.DataFrame(np.random.randn(5,3),c...   \n",
       "1211  ['g1.index', \"g1.add_suffix('_Count').reset_in...   \n",
       "1213               [\"In : data2 = data.set_index('a')\"]   \n",
       "1232    ['df.reindex_axis(sorted(df.columns), axis=1)']   \n",
       "1238  [\"df_ora = pd.read_sql('select * from user_obj...   \n",
       "...                                                 ...   \n",
       "2859  [\"df3 = df3[~df3.index.duplicated(keep='first'...   \n",
       "2951       ['df.read_csv(filename ,  index = False)  ']   \n",
       "2971                                                 []   \n",
       "3060  [\"df['A'], df['B'] = df['AB'].str.split(' ', 1...   \n",
       "3186  [\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...   \n",
       "\n",
       "                                                     h2  \\\n",
       "1209  ['import pandas', 'import numpy as np', 'df', ...   \n",
       "1211  ['type(g1)', 'g1.index', \"g1.add_suffix('_Coun...   \n",
       "1213  [\"In : col = ['a','b','c']\", 'In : data = Data...   \n",
       "1232    ['df.reindex_axis(sorted(df.columns), axis=1)']   \n",
       "1238  ['import pandas as pd', 'import cx_Oracle', \"o...   \n",
       "...                                                 ...   \n",
       "2859  [\"df3 = df3[~df3.index.duplicated(keep='first'...   \n",
       "2951       ['df.read_csv(filename ,  index = False)  ']   \n",
       "2971                                               ['']   \n",
       "3060  [\"df['A'], df['B'] = df['AB'].str.split(' ', 1...   \n",
       "3186  [\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...   \n",
       "\n",
       "                                                   h1h2  \\\n",
       "1209  [\"df['A'].argmax()\", \"df['B'].argmax()\", \"df['...   \n",
       "1211  ['g1.index', \"g1.add_suffix('_Count').reset_in...   \n",
       "1213               [\"In : data2 = data.set_index('a')\"]   \n",
       "1232    ['df.reindex_axis(sorted(df.columns), axis=1)']   \n",
       "1238  [\"df_ora = pd.read_sql('select * from user_obj...   \n",
       "...                                                 ...   \n",
       "2859  [\"df3 = df3[~df3.index.duplicated(keep='first'...   \n",
       "2951       ['df.read_csv(filename ,  index = False)  ']   \n",
       "2971                                                 []   \n",
       "3060  [\"df['A'], df['B'] = df['AB'].str.split(' ', 1...   \n",
       "3186  [\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...   \n",
       "\n",
       "                                                m1tfidf  \\\n",
       "1209  [\"df = pandas.DataFrame(np.random.randn(5,3),c...   \n",
       "1211  ['g1.index', \"g1.add_suffix('_Count').reset_in...   \n",
       "1213               [\"In : data2 = data.set_index('a')\"]   \n",
       "1232    ['df.reindex_axis(sorted(df.columns), axis=1)']   \n",
       "1238  [\"df_ora = pd.read_sql('select * from user_obj...   \n",
       "...                                                 ...   \n",
       "2859  [\"df3 = df3[~df3.index.duplicated(keep='first'...   \n",
       "2951       ['df.read_csv(filename ,  index = False)  ']   \n",
       "2971                                                 []   \n",
       "3060  [\"df['A'], df['B'] = df['AB'].str.split(' ', 1...   \n",
       "3186  [\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...   \n",
       "\n",
       "                                              m1doc2vec  \n",
       "1209  [\"df = pandas.DataFrame(np.random.randn(5,3),c...  \n",
       "1211  ['g1.index', \"g1.add_suffix('_Count').reset_in...  \n",
       "1213               [\"In : data2 = data.set_index('a')\"]  \n",
       "1232    ['df.reindex_axis(sorted(df.columns), axis=1)']  \n",
       "1238  [\"df_ora = pd.read_sql('select * from user_obj...  \n",
       "...                                                 ...  \n",
       "2859  [\"df3 = df3[~df3.index.duplicated(keep='first'...  \n",
       "2951       ['df.read_csv(filename ,  index = False)  ']  \n",
       "2971                                                 []  \n",
       "3060  [\"df['A'], df['B'] = df['AB'].str.split(' ', 1...  \n",
       "3186  [\"df.loc[:, 'foo':'sat']\", \"df.loc[:, 'foo':'c...  \n",
       "\n",
       "[127 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions_filter = solutions[~pd.isna(solutions['Title'])]\n",
    "solutions_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_filter.to_csv('Combined_Solution_Code_Identified.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
