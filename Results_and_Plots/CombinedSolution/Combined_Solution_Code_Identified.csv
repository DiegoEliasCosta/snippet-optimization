AnswerId,Title,preprocessed_code,actual_solutions,h1,h2,h1h2,m1tfidf,m1doc2vec
10202789,Pandas DataFrame - Find row where values for column is maximal,"import pandasimport numpy as npdf = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])dfdf['A'].argmax()3df['B'].argmax()4df['C'].argmax()1dfrmdfrm['A'].idxmax()dfrm.ix[dfrm['A'].idxmax()]",df['A'].argmax() df['B'].argmax() df['C'].argmax() dfrm['A'].idxmax() dfrm.ix[dfrm['A'].idxmax()],"[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","['import pandas', 'import numpy as np', 'df', ""df['A'].argmax()"", '3', ""df['B'].argmax()"", '4', ""df['C'].argmax()"", '1', 'dfrm', ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]","[""df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])"", ""df['A'].argmax()"", ""df['B'].argmax()"", ""df['C'].argmax()"", ""dfrm['A'].idxmax()"", ""dfrm.ix[dfrm['A'].idxmax()]""]"
10374456,Converting a Pandas GroupBy object to DataFrame,"type(g1)g1.indexg1.add_suffix('_Count').reset_index()DataFrame({'count' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()","g1.add_suffix('_Count').reset_index() DataFrame({'count' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['type(g1)', 'g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']","['g1.index', ""g1.add_suffix('_Count').reset_index()"", 'DataFrame({\'count\' : df1.groupby( [ ""Name"", ""City""] ).size()}).reset_index()']"
10458386,Redefining the Index in a Pandas DataFrame object,"In : col = ['a','b','c']In : data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)In : dataIn : data2 = data.set_index('a')In : data2a",data2 = data.set_index('a'),"[""In : data2 = data.set_index('a')""]","[""In : col = ['a','b','c']"", 'In : data = DataFrame([[1,2,3],[10,11,12],[20,21,22]],columns=col)', 'In : data', ""In : data2 = data.set_index('a')"", 'In : data2', 'a']","[""In : data2 = data.set_index('a')""]","[""In : data2 = data.set_index('a')""]","[""In : data2 = data.set_index('a')""]"
11067072,Python Pandas - Re-ordering columns in a dataframe based on column name,"df.reindex_axis(sorted(df.columns), axis=1)","df.reindex_axis(sorted(df.columns), axis=1)","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']","['df.reindex_axis(sorted(df.columns), axis=1)']"
11138275,python-pandas and databases like mysql,"import pandas as pdimport cx_Oracleora_conn = cx_Oracle.connect('your_connection_string')df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    ora_conn.close()import MySQLdbmysql_cn= MySQLdb.connect(host='myhost',                 port=3306,user='myusername', passwd='mypassword',                 db='information_schema')df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    mysql_cn.close()","import pandas as pdimport cx_Oracleora_conn = cx_Oracle.connect('your_connection_string')df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    print 'loaded dataframe from Oracle. # Records: ', len(df_ora)ora_conn.close() import MySQLdbmysql_cn= MySQLdb.connect(host='myhost',                 port=3306,user='myusername', passwd='mypassword',                 db='information_schema')df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    print 'loaded dataframe from MySQL. records:', len(df_mysql)mysql_cn.close()","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","['import pandas as pd', 'import cx_Oracle', ""ora_conn = cx_Oracle.connect('your_connection_string')"", ""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", 'ora_conn.close()', 'import MySQLdb', ""mysql_cn= MySQLdb.connect(host='myhost', "", ""                port=3306,user='myusername', passwd='mypassword', "", ""                db='information_schema')"", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    "", 'mysql_cn.close()']","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]","[""df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    "", ""df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    ""]"
11287278,Selecting columns in a pandas dataframe,"df1 = df[['a','b']]df1 = df.ix[:,0:2] df1 = df.ix[0,0:2].copy() ","df1 = df[['a','b']] df1 = df.iloc[:,0:2] df1 = df.iloc[0,0:2].copy()","['df1 = df.ix[0,0:2].copy() ']","[""df1 = df[['a','b']]"", 'df1 = df.ix[:,0:2] ', 'df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']","['df1 = df.ix[0,0:2].copy() ']"
11346337,Renaming columns in pandas,"df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})df.columns = ['a', 'b']df","df.columns = ['a', 'b']","[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]","[""df.columns = ['a', 'b']"", 'df']",[],"[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]","[""df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})""]"
11354850,Renaming columns in pandas,"df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})ORdf.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)","df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}) df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", 'OR', ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]","[""df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})"", ""df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)""]"
11362056,Output data from all columns in a dataframe in pandas,"paramdata.columnsparamdata.index",print paramdata.values,['paramdata.index'],"['paramdata.columns', 'paramdata.index']",['paramdata.index'],['paramdata.index'],['paramdata.index']
11531402,pandas + dataframe - select by partial string match,"df[df['A'].str.contains(""hello"")]","df[df['A'].str.contains(""hello"")]","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']","['df[df[\'A\'].str.contains(""hello"")]']"
11617194,What is the most efficient way to loop through dataframes with pandas?,,"for index, row in df.iterrows(): itertuples()",[],[''],[],[],[]
11711637,"Python pandas, how to widen output display to see more columns?","import pandas as pdpd.set_option('display.height', 1000)pd.set_option('display.max_rows', 500)pd.set_option('display.max_columns', 500)pd.set_option('display.width', 1000)ParametersReturnsNoneRaisesfloat or Nonebooleanbooleanstr/unicodebooleancallableintintintintintint or Noneintint or Noneboolbooleanbooleanintintintbooleanboolean","pd.set_option('display.height', 1000) pd.set_option('display.max_rows', 500) pd.set_option('display.max_columns', 500) pd.set_option('display.width', 1000)","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","['import pandas as pd', ""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)"", 'Parameters', 'Returns', 'None', 'Raises', 'float or None', 'boolean', 'boolean', 'str/unicode', 'boolean', 'callable', 'int', 'int', 'int', 'int', 'int', 'int or None', 'int', 'int or None', 'bool', 'boolean', 'boolean', 'int', 'int', 'int', 'boolean', 'boolean']","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]","[""pd.set_option('display.height', 1000)"", ""pd.set_option('display.max_rows', 500)"", ""pd.set_option('display.max_columns', 500)"", ""pd.set_option('display.width', 1000)""]"
11872393,pandas: filter rows of DataFrame with operator chaining,"dfdf[(df.A == 1) & (df.D == 6)]","df[(df.A == 1) & (df.D == 6)] def mask(df, key, value):   return df[df[key] == value]pandas.DataFrame.mask = maskdf.mask('A', 1)df.mask('A', 1).mask('D', 6)",[],"['df', 'df[(df.A == 1) & (df.D == 6)]']",[],[],[]
12065904,Filter dataframe rows if value in column is in a set list of values,,rpt[rpt['STK_ID'].isin(stk_list)],[],[''],[],[],[]
12098586,use a list of values to select rows from a pandas dataframe,"df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})dfdf[df['A'].isin([3, 6])]","df[df['A'].isin([3, 6])]","[""df[df['A'].isin([3, 6])]""]","[""df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})"", 'df', ""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]","[""df[df['A'].isin([3, 6])]""]"
12525836,Normalize data in pandas,"dfdf_norm = (df - df.mean()) / (df.max() - df.min())df_normdf_norm.mean()df_norm.max() - df_norm.min()",df_norm = (df - df.mean()) / (df.max() - df.min()),"['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df', 'df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']","['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']"
12555510,Adding new column to existing DataFrame in Python pandas,"df1['e'] = Series(np.random.randn(sLength), index=df1.index)sLength = len(df1['a'])df1df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)df1p.version.short_version'0.16.1'df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)df1df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)","df1['e'] = Series(np.random.randn(sLength), index=df1.index) df1['e'] = p.Series(np.random.randn(sLength), index=df1.index) df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""sLength = len(df1['a'])"", 'df1', 'df1', 'p.version.short_version', ""'0.16.1'"", 'df1']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']","[""df1['e'] = Series(np.random.randn(sLength), index=df1.index)"", ""df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)"", ""df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)"", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']"
12681217,Split (explode) pandas dataframe string entry to separate rows,"pd.concat([Series(row['var2'], row['var1'].split(','))                                  for _, row in a.iterrows()]).reset_index()","pd.concat([Series(row['var2'], row['var1'].split(','))","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']","[""pd.concat([Series(row['var2'], row['var1'].split(','))              "", '                    for _, row in a.iterrows()]).reset_index()']"
13148611,How to change the order of DataFrame columns?,"dfcols = df.columns.tolist()colscols = cols[-1:] + cols[:-1]colsdf = df[cols]  df","cols = df.columns.tolist()cols = cols[-1:] + cols[:-1]df = df[cols]",['cols = df.columns.tolist()'],"['df', 'cols = df.columns.tolist()', 'cols', 'cols = cols[-1:] + cols[:-1]', 'cols', 'df = df[cols]  ', 'df']",['cols = df.columns.tolist()'],[],['cols = df.columns.tolist()']
13270110,cartesian product in pandas,"from pandas import DataFrame, mergedf1 = DataFrame({'key':[1,1], 'col1':[1,2],'col2':[3,4]})df2 = DataFrame({'key':[1,1], 'col3':[5,6]})merge(df1, df2,on='key')[['col1', 'col2', 'col3']]","merge(df1, df2,on='key')[['col1', 'col2', 'col3']]",[],"['from pandas import DataFrame, merge', ""df1 = DataFrame({'key':[1,1], 'col1':[1,2],'col2':[3,4]})"", ""df2 = DataFrame({'key':[1,1], 'col3':[5,6]})"", ""merge(df1, df2,on='key')[['col1', 'col2', 'col3']]""]",[],[],[]
13295801,How can I replace all the NaN values with Zero's in a column of a pandas dataframe,"dfdf.fillna(0)df[1].fillna(0, inplace=True)df","df.fillna(0) df[1].fillna(0, inplace=True)","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df', 'df.fillna(0)', 'df[1].fillna(0, inplace=True)', 'df']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']","['df.fillna(0)', 'df[1].fillna(0, inplace=True)']"
13337376,How to apply a function to two columns of Pandas dataframe,df,"df.apply(f, axis=1)",[],['df'],[],[],[]
13413845,How to drop rows of Pandas DataFrame whose value in certain columns is NaN,df = df[np.isfinite(df['EPS'])],df = df[np.isfinite(df['EPS'])],[],"[""df = df[np.isfinite(df['EPS'])]""]",[],[],[]
13434501,How to drop rows of Pandas DataFrame whose value in certain columns is NaN,"df = pd.DataFrame(np.random.randn(10,3))df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;dfdf.dropna()     df.dropna(how='all')     df.dropna(thresh=2)   df.dropna(subset=[1])   ",df.dropna() df.dropna(how='all') df.dropna(thresh=2) df.dropna(subset=[1]),"['df = pd.DataFrame(np.random.randn(10,3))', 'df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df = pd.DataFrame(np.random.randn(10,3))', 'df.iloc[::2,0] = np.nan; df.iloc[::4,1] = np.nan; df.iloc[::3,2] = np.nan;', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']","['df = pd.DataFrame(np.random.randn(10,3))', 'df.dropna()     ', ""df.dropna(how='all')     "", 'df.dropna(thresh=2)   ', 'df.dropna(subset=[1])   ']"
13682381,Pandas DataFrame: remove unwanted parts from strings in a column,data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC')),data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC')),"[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]","[""data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))""]"
13704307,"Converting between datetime, Timestamp and datetime64","from datetime import datetimeimport numpy as npdt = datetime.utcnow()dtdatetime.datetime(2012, 12, 4, 19, 51, 25, 362455)dt64 = np.datetime64(dt)ts = (dt64 - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')ts1354650685.3624549datetime.utcfromtimestamp(ts)datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)np.__version__'1.8.0.dev-7b75899'np.datetime64(datetime.utcnow()).astype(datetime)datetime.datetime(2012, 12, 4, 13, 34, 52, 827542)from datetime import datetimeimport numpy numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)datetime.datetime(2002, 6, 28, 0, 0)numpy.__version__'1.6.2' from datetime import datetimeimport numpynumpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)numpy.__version__'1.8.0.dev-7b75899'dt64.dtypedtype('<M8[ns]')ns = 1e-9 datetime.utcfromtimestamp(dt64.astype(int) * ns)datetime.datetime(2002, 6, 28, 0, 0)dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100', 's')dt64.dtypedtype('<M8[s]')datetime.utcfromtimestamp(dt64.astype(int))datetime.datetime(2002, 6, 28, 0, 0)",dt64 = np.datetime64(dt) datetime.utcfromtimestamp(ts) np.datetime64(datetime.utcnow()).astype(datetime) numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime) numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime) datetime.utcfromtimestamp(dt64.astype(int) * ns) datetime.utcfromtimestamp(dt64.astype(int)),"['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']","['from datetime import datetime', 'import numpy as np', 'dt = datetime.utcnow()', 'dt', 'datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)', 'dt64 = np.datetime64(dt)', ""ts = (dt64 - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')"", 'ts', '1354650685.3624549', 'datetime.utcfromtimestamp(ts)', 'datetime.datetime(2012, 12, 4, 19, 51, 25, 362455)', 'np.__version__', ""'1.8.0.dev-7b75899'"", 'np.datetime64(datetime.utcnow()).astype(datetime)', 'datetime.datetime(2012, 12, 4, 13, 34, 52, 827542)', 'from datetime import datetime', 'import numpy ', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'datetime.datetime(2002, 6, 28, 0, 0)', 'numpy.__version__', ""'1.6.2' "", 'from datetime import datetime', 'import numpy', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'numpy.__version__', ""'1.8.0.dev-7b75899'"", 'dt64.dtype', ""dtype('<M8[ns]')"", 'ns = 1e-9 ', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'datetime.datetime(2002, 6, 28, 0, 0)', ""dt64 = numpy.datetime64('2002-06-28T01:00:00.000000000+0100', 's')"", 'dt64.dtype', ""dtype('<M8[s]')"", 'datetime.utcfromtimestamp(dt64.astype(int))', 'datetime.datetime(2002, 6, 28, 0, 0)']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'datetime.utcfromtimestamp(dt64.astype(int))']","['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", ""numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)"", 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', 'dt64.dtype', 'datetime.utcfromtimestamp(dt64.astype(int))']"
13786327,"Creating an empty Pandas DataFrame, then filling it?","import datetimeimport pandas as pdimport numpy as nptodays_date = datetime.datetime.now().date()index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')columns = ['A','B', 'C']df_ = pd.DataFrame(index=index, columns=columns)df_ = df_.fillna(0) data = np.array([np.arange(10)]*3).Tdf = pd.DataFrame(data, index=index, columns=columns)df","df_ = pd.DataFrame(index=index, columns=columns)df_ = df_.fillna(0) # with 0s rather than NaNs","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']","['import datetime', 'import pandas as pd', 'import numpy as np', 'todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", ""columns = ['A','B', 'C']"", 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']","['todays_date = datetime.datetime.now().date()', ""index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')"", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) ', 'data = np.array([np.arange(10)]*3).T', 'df = pd.DataFrame(data, index=index, columns=columns)']"
13842286,Set value for particular cell in pandas DataFrame using index,"df.xs('C')['x']=10df['x']['C'] = 10df.xs('C', copy = False)['x']=10","df.set_value('C', 'x', 10) df.xs('C')['x']=10 df['x']['C'] = 10 df.at['C', 'x'] = 10 df.set_value('C', 'x', 10) df['x']['C'] = 10 df.at['C', 'x'] = 10","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df['x']['C'] = 10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]","[""df.xs('C')['x']=10"", ""df.xs('C', copy = False)['x']=10""]"
13851602,How to delete rows from a pandas DataFrame based on a conditional expression,df[df['column name'].map(len) < 2],df[df['column name'].map(len) < 2],"[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]","[""df[df['column name'].map(len) < 2]""]"
14508355,Python Pandas - How to flatten a hierarchical index in columns,"df.columns = df.columns.get_level_values(0)df.columns = [' '.join(col).strip() for col in df.columns.values][' '.join(col).strip() for col in df.columns.values]['USAF', 'WBAN', 'day', 'month', 's_CD sum', 's_CL sum', 's_CNT sum', 's_PC sum', 'tempf amax', 'tempf amin', 'year']",df.columns = df.columns.get_level_values(0) df.columns = [' '.join(col).strip() for col in df.columns.values] [' '.join(col).strip() for col in df.columns.values],"['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]"", ""['USAF',"", "" 'WBAN',"", "" 'day',"", "" 'month',"", "" 's_CD sum',"", "" 's_CL sum',"", "" 's_CNT sum',"", "" 's_PC sum',"", "" 'tempf amax',"", "" 'tempf amin',"", "" 'year']""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]","['df.columns = df.columns.get_level_values(0)', ""df.columns = [' '.join(col).strip() for col in df.columns.values]"", ""[' '.join(col).strip() for col in df.columns.values]""]"
14661768,How to drop a list of rows from Pandas dataframe?,"dfdf.drop(df.index[[1,3]])","df.drop(df.index[[1,3]])","['df.drop(df.index[[1,3]])']","['df', 'df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']","['df.drop(df.index[[1,3]])']"
14734627,How to access pandas groupby dataframe by key,"gb.get_group('foo')gb[[""A"", ""B""]].get_group(""foo"")gb[""C""].get_group(""foo"")","gb.get_group('foo') gb[[""A"", ""B""]].get_group(""foo"") gb[""C""].get_group(""foo"")","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']","[""gb.get_group('foo')"", 'gb[[""A"", ""B""]].get_group(""foo"")', 'gb[""C""].get_group(""foo"")']"
14745484,How to split a column into two columns?,"import pandas as pddfdf = pd.DataFrame(df.row.str.split(' ',1).tolist(),                                   columns = ['flips','row'])df","df = pd.DataFrame(df.row.str.split(' ',1).tolist(),                                   columns = ['flips','row'])","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","['import pandas as pd', 'df', ""                                   columns = ['flips','row'])"", 'df']","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]","[""df = pd.DataFrame(df.row.str.split(' ',1).tolist(),""]"
14760930,How to get the last n row of pandas dataframe?,,df1.tail(10),[],[''],[],[],[]
14900065,Remove rows with duplicate indices (Pandas DataFrame and TimeSeries),"df4 = df3.drop_duplicates(subset='rownum', keep='last')df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')df3 = df3.sort()","df4 = df3.drop_duplicates(subset='rownum', keep='last') df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')"", 'df3 = df3.sort()']","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]","[""df4 = df3.drop_duplicates(subset='rownum', keep='last')"", ""df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')""]"
14946246,Pandas sort by group aggregate and column,"grp = df.groupby('A')grp[['B']].transform(sum).sort('B')sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]sort1f = lambda x: x.sort('C', ascending=False)sort2 = sort1.groupby('A', sort=False).apply(f)sort2sort2.reset_index(0, drop=True)","grp = df.groupby('A')grp[['B']].transform(sum).sort('B')sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]f = lambda x: x.sort('C', ascending=False)sort2 = sort1.groupby('A', sort=False).apply(f)sort2.reset_index(0, drop=True)","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", 'sort1', ""f = lambda x: x.sort('C', ascending=False)"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2', 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)"", 'sort2.reset_index(0, drop=True)']","[""grp = df.groupby('A')"", ""grp[['B']].transform(sum).sort('B')"", ""sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]"", ""sort2 = sort1.groupby('A', sort=False).apply(f)""]"
15026839,How to make separator in read_csv more flexible wrt whitespace?,import pandas as pd,"pd.read_csv(""whitespace.csv"", header=None, delimiter=r""\s+"") pd.read_csv(""whitespace.csv"", header=None, delim_whitespace=True)",[],['import pandas as pd'],[],[],[]
15252012,Handling Variable Number of Columns with Pandas while reading CSV file,"1,2,31,2,3,41,2,3,4,51,21,2,3,4my_cols = [""A"", ""B"", ""C"", ""D"", ""E""]pd.read_csv(""ragged.csv"", names=my_cols, engine='python')","my_cols = [""A"", ""B"", ""C"", ""D"", ""E""]pd.read_csv(""ragged.csv"", names=my_cols, engine='python')","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['1,2,3', '1,2,3,4', '1,2,3,4,5', '1,2', '1,2,3,4', 'my_cols = [""A"", ""B"", ""C"", ""D"", ""E""]', 'pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']","['pd.read_csv(""ragged.csv"", names=my_cols, engine=\'python\')']"
15362700,How to get the first column of a pandas DataFrame as a Series?,"import pandas as pddf = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})dfs = df.ix[:,0]type(s)","s = df.ix[:,0]","[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]","['import pandas as pd', 'df', 's = df.ix[:,0]', 'type(s)']",[],"[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]","[""df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})""]"
15411596,Pandas count(distinct) equivalent,"table.groupby('YEARMONTH').CLIENTCODE.nunique()tabletable.groupby('YEARMONTH').CLIENTCODE.nunique()YEARMONTH",table.groupby('YEARMONTH').CLIENTCODE.nunique(),"[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", 'table', ""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", 'YEARMONTH']","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]","[""table.groupby('YEARMONTH').CLIENTCODE.nunique()"", ""table.groupby('YEARMONTH').CLIENTCODE.nunique()""]"
15705958,Python : Getting the Row which has the max value in groups using groupby,"dfdf.groupby(['Mt'], sort=False)['count'].max()idx = df.groupby(['Mt'])['count'].transform(max) == df['count']df[idx]df['count_max'] = df.groupby(['Mt'])['count'].transform(max)df","df.groupby(['Mt'], sort=False)['count'].max() idx = df.groupby(['Mt'])['count'].transform(max) == df['count'] df['count_max'] = df.groupby(['Mt'])['count'].transform(max)","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","['df', ""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", 'df[idx]', ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)"", 'df']","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]","[""df.groupby(['Mt'], sort=False)['count'].max()"", ""idx = df.groupby(['Mt'])['count'].transform(max) == df['count']"", ""df['count_max'] = df.groupby(['Mt'])['count'].transform(max)""]"
15772263,Pandas: rolling mean by time interval,"pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)enddatedf.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()","pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1) df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'enddate', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']","['pd.rolling_mean(df.resample(""1D"", fill_method=""ffill""), window=3, min_periods=1)', 'df.resample(""1d"").sum().fillna(0).rolling(window=3, min_periods=1).mean()']"
15943975,How do I get the row count of a Pandas dataframe?,"import numpy as npimport pandas as pddf = pd.DataFrame(np.arange(9).reshape(3,3))dfdf.shapelen(df.index)",df.shape df[0].count() len(df.index),"['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']","['import numpy as np', 'import pandas as pd', 'df', 'df.shape', 'len(df.index)']","['df.shape', 'len(df.index)']","['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']","['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'df.shape', 'len(df.index)']"
16104482,Selecting a row of pandas series/dataframe by integer index,"df = DataFrame(randn(5,2),index=range(0,10,2),columns=list('AB'))dfdf.iloc[[2]]df.loc[[2]]",df.iloc[[2]] df.loc[[2]],"['df.iloc[[2]]', 'df.loc[[2]]']","[""df = DataFrame(randn(5,2),index=range(0,10,2),columns=list('AB'))"", 'df', 'df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']","['df.iloc[[2]]', 'df.loc[[2]]']"
16354730,Pandas: How to use apply function to multiple columns,"df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)df","df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)"", 'df']","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]","[""df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)""]"
16476974,iterating row by row through a pandas dataframe,,"for index, row in df.iterrows():    print row['c1'], row['c2'] for index, row in df.iterrows():     print row['c1'], row['c2']",[],[''],[],[],[]
16597375,Appending to an empty data frame in Pandas?,"df = pd.DataFrame()data = pd.DataFrame({""A"": range(3)})df.append(data)dfColumns: []Index: []df = df.append(data)df",df.append(data) df = df.append(data),"['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']","['df.append(data)', 'df', 'Columns: []', 'Index: []', 'df = df.append(data)', 'df']","['df.append(data)', 'df = df.append(data)']","['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']","['df = pd.DataFrame()', 'data = pd.DataFrame({""A"": range(3)})', 'df.append(data)', 'df = df.append(data)']"
16729808,How to get a value from a cell of a data frame?,"sub_dfsub_df.iloc[0]sub_df.iloc[0]['A']Out[5]: -0.13365288513107493",sub_df.iloc[0] sub_df.iloc[0]['A'],"['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]","['sub_df', 'sub_df.iloc[0]', ""sub_df.iloc[0]['A']"", 'Out[5]: -0.13365288513107493']","['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]",[],"['sub_df.iloc[0]', ""sub_df.iloc[0]['A']""]"
16735476,Converting strings to floats in a DataFrame,"df = DataFrame(dict(A = Series(['1.0','1']), B = Series(['1.0','foo'])))dfdf.dtypesdf.convert_objects(convert_numeric=True)df.convert_objects(convert_numeric=True).dtypesdtype: object",df.convert_objects(convert_numeric=True),"['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","[""df = DataFrame(dict(A = Series(['1.0','1']), B = Series(['1.0','foo'])))"", 'df', 'df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes', 'dtype: object']","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","['df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']","['df.dtypes', 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']"
16923367,Pandas writing dataframe to CSV file,"df.to_csv(file_name, sep='\t')df.to_csv(file_name, sep='\t', encoding='utf-8')","df.to_csv(file_name, sep='\t') df.to_csv(file_name, sep='\t', encoding='utf-8')","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]","[""df.to_csv(file_name, sep='\\t')"", ""df.to_csv(file_name, sep='\\t', encoding='utf-8')""]"
17063653,Reading an Excel file in python using pandas,"xl = pd.ExcelFile(""dummydata.xlsx"")xl.sheet_names[u'Sheet1', u'Sheet2', u'Sheet3']df = xl.parse(""Sheet1"")df.head()parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")parsed.columnsIndex([u'Tid', u'dummy1', u'dummy2', u'dummy3', u'dummy4', u'dummy5', u'dummy6', u'dummy7', u'dummy8', u'dummy9'], dtype=object)","xl = pd.ExcelFile(""dummydata.xlsx"")df = xl.parse(""Sheet1"") parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['xl = pd.ExcelFile(""dummydata.xlsx"")', 'xl.sheet_names', ""[u'Sheet1', u'Sheet2', u'Sheet3']"", 'df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")', 'parsed.columns', ""Index([u'Tid', u'dummy1', u'dummy2', u'dummy3', u'dummy4', u'dummy5', u'dummy6', u'dummy7', u'dummy8', u'dummy9'], dtype=object)""]","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']","['df = xl.parse(""Sheet1"")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, ""Sheet1"")']"
17071908,Select rows from a DataFrame based on values in a column in pandas,"df.loc[df['column_name'] == some_value]df.loc[df['column_name'].isin(some_values)]df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]df.loc[df['column_name'] != some_value]df.loc[~df['column_name'].isin(some_values)]import pandas as pdimport numpy as npdf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                   'B': 'one one two three two two one three'.split(),                   'C': np.arange(8), 'D': np.arange(8) * 2})print(df)print(df.loc[df['A'] == 'foo'])print(df.loc[df['B'].isin(['one','three'])])df = df.set_index(['B'])print(df.loc['one'])B              df.loc[df.index.isin(['one','two'])]B              ","df.loc[df['column_name'] == some_value] df.loc[df['column_name'].isin(some_values)] df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)] df.loc[df['column_name'] != some_value] df.loc[~df['column_name'].isin(some_values)] df.loc[df['A'] == 'foo'] df.loc[df['B'].isin(['one','three'])] df = df.set_index(['B'])df.loc['one'] df.loc[df.index.isin(['one','two'])]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", 'import pandas as pd', 'import numpy as np', ""                   'B': 'one one two three two two one three'.split(),"", ""                   'C': np.arange(8), 'D': np.arange(8) * 2})"", 'print(df)', ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", 'B              ', ""df.loc[df.index.isin(['one','two'])]"", 'B              ']","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]","[""df.loc[df['column_name'] == some_value]"", ""df.loc[df['column_name'].isin(some_values)]"", ""df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]"", ""df.loc[df['column_name'] != some_value]"", ""df.loc[~df['column_name'].isin(some_values)]"", ""df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),"", ""                   'B': 'one one two three two two one three'.split(),"", ""print(df.loc[df['A'] == 'foo'])"", ""print(df.loc[df['B'].isin(['one','three'])])"", ""df = df.set_index(['B'])"", ""print(df.loc['one'])"", ""df.loc[df.index.isin(['one','two'])]""]"
17095620,Outputting difference in two Pandas dataframes side by side - highlighting the difference,"ne = (df1 != df2).any(1)nene_stacked = (df1 != df2).stack()changed = ne_stacked[ne_stacked]changed.index.names = ['id', 'col']changeddifference_locations = np.where(df1 != df2)changed_from = df1.values[difference_locations]changed_to = df2.values[difference_locations]pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)",ne = (df1 != df2).any(1) ne_stacked = (df1 != df2).stack(),"['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne', 'ne_stacked = (df1 != df2).stack()', 'changed = ne_stacked[ne_stacked]', ""changed.index.names = ['id', 'col']"", 'changed', 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]']","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]","['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', ""changed.index.names = ['id', 'col']"", 'difference_locations = np.where(df1 != df2)', 'changed_from = df1.values[difference_locations]', 'changed_to = df2.values[difference_locations]', ""pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)""]"
17098736,How to store a dataframe using Pandas,"df.to_pickle(file_name)  df = pd.read_pickle(file_name)store = HDFStore('store.h5')store['df'] = df  store['df']  ",df.to_pickle(file_name) store = HDFStore('store.h5'),"['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)', ""store = HDFStore('store.h5')"", ""store['df'] = df  "", ""store['df']  ""]","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']","['df.to_pickle(file_name)  ', 'df = pd.read_pickle(file_name)']"
17134750,Convert DataFrame column type from string to datetime,"df['col'] = pd.to_datetime(df['col'])pd.to_datetime(pd.Series(['05/23/2005']))pd.to_datetime(pd.Series(['05/23/2005']), format=""%m/%d/%Y"")dtype: datetime64[ns]","df['col'] = pd.to_datetime(df['col']) pd.to_datetime(pd.Series(['05/23/2005'])) pd.to_datetime(pd.Series(['05/23/2005']), format=""%m/%d/%Y"")","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", 'dtype: datetime64[ns]']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']","[""df['col'] = pd.to_datetime(df['col'])"", ""pd.to_datetime(pd.Series(['05/23/2005']))"", 'pd.to_datetime(pd.Series([\'05/23/2005\']), format=""%m/%d/%Y"")']"
17141755,How to sort a dataFrame in python pandas by two or more columns?,"df.sort_values(['a', 'b'], ascending=[True, False])df.sort(['a', 'b'], ascending=[True, False])df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])df1.sort(['a', 'b'], ascending=[True, False])df1 = df1.sort(['a', 'b'], ascending=[True, False])df1.sort(['a', 'b'], ascending=[True, False], inplace=True)","df.sort_values(['a', 'b'], ascending=[True, False]) df.sort(['a', 'b'], ascending=[True, False]) df1.sort(['a', 'b'], ascending=[True, False]) df1 = df1.sort(['a', 'b'], ascending=[True, False]) df1.sort(['a', 'b'], ascending=[True, False], inplace=True)","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df.sort(['a', 'b'], ascending=[True, False])"", ""df1.sort(['a', 'b'], ascending=[True, False])"", ""df1 = df1.sort(['a', 'b'], ascending=[True, False])"", ""df1.sort(['a', 'b'], ascending=[True, False], inplace=True)""]","[""df.sort_values(['a', 'b'], ascending=[True, False])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]","[""df.sort_values(['a', 'b'], ascending=[True, False])"", ""df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])""]"
17242374,Pandas - how to get the data frame index as an array,"df = pd.DataFrame(index=['a', 'b'])df.index.valuesOut[2]: array(['a', 'b'], dtype=object)",df.index.values,"[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']","['df.index.values', ""Out[2]: array(['a', 'b'], dtype=object)""]",['df.index.values'],"[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']","[""df = pd.DataFrame(index=['a', 'b'])"", 'df.index.values']"
17531025,How to add pandas data to an existing csv file?,"with open('my_csv.csv', 'a') as f:    df.to_csv(f, header=False)0,1,2,31,4,5,6df = pd.read_csv('foo.csv', index_col=0)dfdf + 6with open('foo.csv', 'a') as f:             (df + 6).to_csv(f, header=False)0,1,2,31,4,5,60,7,8,91,10,11,12","with open('my_csv.csv', 'a') as f:    df.to_csv(f, header=False) with open('foo.csv', 'a') as f:             (df + 6).to_csv(f, header=False)","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","[""with open('my_csv.csv', 'a') as f:"", '    df.to_csv(f, header=False)', '0,1,2,3', '1,4,5,6', ""df = pd.read_csv('foo.csv', index_col=0)"", 'df', 'df + 6', ""with open('foo.csv', 'a') as f:"", '             (df + 6).to_csv(f, header=False)', '0,1,2,3', '1,4,5,6', '0,7,8,9', '1,10,11,12']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']","['    df.to_csv(f, header=False)', ""df = pd.read_csv('foo.csv', index_col=0)"", '             (df + 6).to_csv(f, header=False)']"
17619032,How to sort pandas data frame using values from several columns?,"import pandasdf = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])df.sort(['c1','c2'], ascending=[False,True])df.sort(['c1','c2'], ascending=[True,True])df.sort(['c1','c2'], ascending=[False,True])df.sort_values(['c1','c2'], ascending=[False,True])","df.sort(['c1','c2'], ascending=[False,True]) df.sort(['c1','c2'], ascending=[True,True]) df.sort(['c1','c2'], ascending=[False,True]) df.sort_values(['c1','c2'], ascending=[False,True])","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","['import pandas', ""df.sort(['c1','c2'], ascending=[False,True])"", ""df.sort(['c1','c2'], ascending=[True,True])"", ""df.sort(['c1','c2'], ascending=[False,True])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]","[""df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])"", ""df.sort_values(['c1','c2'], ascending=[False,True])""]"
17682662,How to convert a pandas DataFrame subset of columns AND rows into a numpy array?,"df[df.c > 0.5][['b', 'e']].valuesarray([[ 0.98836259,  0.82403141],       [ 0.337358  ,  0.02054435],       [ 0.29271728,  0.37813099],       [ 0.70033513,  0.69919695]])","df[df.c > 0.5][['b', 'e']].values","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values"", 'array([[ 0.98836259,  0.82403141],', '       [ 0.337358  ,  0.02054435],', '       [ 0.29271728,  0.37813099],', '       [ 0.70033513,  0.69919695]])']","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values""]","[""df[df.c > 0.5][['b', 'e']].values""]"
17682726,How to convert a pandas DataFrame subset of columns AND rows into a numpy array?,"df = DataFrame(np.random.rand(4,5), columns = list('abcde'))dfdf.loc[df['c']>0.5,['a','d']]df.loc[df['c']>0.5,['a','d']].valuesarray([[ 0.66970138,  0.45157274],       [ 0.95276167,  0.64325143],       [ 0.90071271,  0.50577509]])","df.loc[df['c']>0.5,['a','d']].values","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df = DataFrame(np.random.rand(4,5), columns = list('abcde'))"", 'df', ""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values"", 'array([[ 0.66970138,  0.45157274],', '       [ 0.95276167,  0.64325143],', '       [ 0.90071271,  0.50577509]])']","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]","[""df.loc[df['c']>0.5,['a','d']]"", ""df.loc[df['c']>0.5,['a','d']].values""]"
17729985,Replace value for a selected cell in pandas DataFrame without using index,"d.sales[d.sales==24] = 100dd.loc[d.sales == 12, 'sales'] = 99dd.sales = d.sales.replace(23, 24)d","d.sales[d.sales==24] = 100 d.loc[d.sales == 12, 'sales'] = 99 d.sales = d.sales.replace(23, 24)","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","['d.sales[d.sales==24] = 100', 'd', ""d.loc[d.sales == 12, 'sales'] = 99"", 'd', 'd.sales = d.sales.replace(23, 24)', 'd']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']","[""d.loc[d.sales == 12, 'sales'] = 99"", 'd.sales = d.sales.replace(23, 24)']"
17813222,How to plot two columns of a pandas data frame using points?,"df.plot(x='col_name_1', y='col_name_2', style='o')import numpy as npimport pandas as pdd = {'one' : np.random.rand(10),     'two' : np.random.rand(10)}df = pd.DataFrame(d)df.plot(style=['o','rx'])","df.plot(x='col_name_1', y='col_name_2', style='o') df.plot(style=['o','rx'])","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'import numpy as np', 'import pandas as pd', ""d = {'one' : np.random.rand(10),"", ""     'two' : np.random.rand(10)}"", ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]","[""df.plot(x='col_name_1', y='col_name_2', style='o')"", 'df = pd.DataFrame(d)', ""df.plot(style=['o','rx'])""]"
17841294,Pandas groupby: How to get a union of strings,"df = read_csv(StringIO(data),sep='\s+')dfdf.dtypesdf.groupby('A').apply(lambda x: x.sum())df.groupby('A')['C'].apply(lambda x: x.sum())df.groupby('A')['C'].apply(lambda x: ""{%s}"" % ', '.join(x))df.groupby('A').apply(f)A                             ","df.groupby('A')['C'].apply(lambda x: ""{%s}"" % ', '.join(x))","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","[""df = read_csv(StringIO(data),sep='\\s+')"", 'df', 'df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)"", 'A                             ']","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]","['df.dtypes', ""df.groupby('A').apply(lambda x: x.sum())"", ""df.groupby('A')['C'].apply(lambda x: x.sum())"", 'df.groupby(\'A\')[\'C\'].apply(lambda x: ""{%s}"" % \', \'.join(x))', ""df.groupby('A').apply(f)""]"
17950531,Converting a column within pandas dataframe from int to string,"df = DataFrame(np.arange(10).reshape(5,2),columns=list('AB'))dfdf.dtypesdf['A'].apply(str)df['A'].apply(str)[0]df.applymap(str)df.applymap(str).iloc[0,0]Out[22]: '0'",df['A'].apply(str) df.applymap(str),"['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","[""df = DataFrame(np.arange(10).reshape(5,2),columns=list('AB'))"", 'df', 'df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]', ""Out[22]: '0'""]","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']","['df.dtypes', ""df['A'].apply(str)"", ""df['A'].apply(str)[0]"", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']"
18023468,Pandas index column title or name,"df.index.namedf.index.name = 'foo'df.index.namedffoo              ",df.index.name,"['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name', 'df', 'foo              ']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']","['df.index.name', ""df.index.name = 'foo'"", 'df.index.name']"
18062521,Combining two Series into a DataFrame in pandas,"s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')pd.concat([s1, s2], axis=1)pd.concat([s1, s2], axis=1).reset_index()","pd.concat([s1, s2], axis=1) pd.concat([s1, s2], axis=1).reset_index()","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","['pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","['pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']","[""s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')"", ""s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')"", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']"
18129082,Python Pandas Error tokenizing data while reading csv file,"data = pd.read_csv('file1.csv', error_bad_lines=False)","data = pd.read_csv('file1.csv', error_bad_lines=False)","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]","[""data = pd.read_csv('file1.csv', error_bad_lines=False)""]"
18173074,Deleting DataFrame row in Pandas based on column value,df = df[df.line_race != 0],df = df[df.line_race != 0],[],['df = df[df.line_race != 0]'],[],[],[]
18327852,Find element's index in pandas Series,"myseries[myseries == 7]dtype: int64myseries[myseries == 7].index[0]3",myseries[myseries == 7].index[0],['myseries[myseries == 7].index[0]'],"['myseries[myseries == 7]', 'dtype: int64', 'myseries[myseries == 7].index[0]', '3']",['myseries[myseries == 7].index[0]'],['myseries[myseries == 7].index[0]'],['myseries[myseries == 7].index[0]']
18431417,groupby columns with NaN (missing) values,"df.fillna(-1)df.fillna(-1).groupby('b').sum()b    ",df.fillna(-1).groupby('b').sum(),"['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()"", 'b    ']","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]","['df.fillna(-1)', ""df.fillna(-1).groupby('b').sum()""]"
18695700,python pandas dataframe to dictionary,"df.set_index('id').to_dict()df.set_index('id')['value'].to_dict()",df.set_index('id').to_dict() df.set_index('id')['value'].to_dict(),"[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]","[""df.set_index('id').to_dict()"", ""df.set_index('id')['value'].to_dict()""]"
18837389,Convert Python dict into a dataframe,"pd.DataFrame(d)pd.DataFrame(d.items())  pd.DataFrame(d.items(), columns=['Date', 'DateValue'])s = pd.Series(d, name='DateValue')s.index.name = 'Date's.reset_index()","pd.DataFrame(d.items()) pd.DataFrame(d.items(), columns=['Date', 'DateValue']) s = pd.Series(d, name='DateValue')s.index.name = 'Date's.reset_index()","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", ""s = pd.Series(d, name='DateValue')"", ""s.index.name = 'Date'"", 's.reset_index()']","[""s.index.name = 'Date'"", 's.reset_index()']","[""s.index.name = 'Date'"", 's.reset_index()']","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", 's.reset_index()']","['pd.DataFrame(d)', 'pd.DataFrame(d.items())  ', ""pd.DataFrame(d.items(), columns=['Date', 'DateValue'])"", ""s = pd.Series(d, name='DateValue')"", ""s.index.name = 'Date'""]"
18942558,Add new column in Pandas DataFrame Python,"df['Col3'] = (df['Col2'] <= 1).astype(int)df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)df['Col3'] = 0condition = df['Col2'] > 1df.loc[condition, 'Col3'] = 42df.loc[~condition, 'Col3'] = 55","df['Col3'] = (df['Col2'] <= 1).astype(int) df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55) df['Col3'] = 0condition = df['Col2'] > 1df.loc[condition, 'Col3'] = 42df.loc[~condition, 'Col3'] = 55","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df['Col3'] = 0"", ""condition = df['Col2'] > 1"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]","[""df['Col3'] = (df['Col2'] <= 1).astype(int)"", ""df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)"", ""df.loc[condition, 'Col3'] = 42"", ""df.loc[~condition, 'Col3'] = 55""]"
19112890,Getting list of lists into pandas DataFrame,"df = DataFrame(table, columns=headers)df","df = DataFrame(table, columns=headers)",[],"['df = DataFrame(table, columns=headers)', 'df']",[],[],[]
19237920,subsetting a Python DataFrame,"k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')df = DataFrame({'gender': np.random.choice(['m', 'f'], size=10), 'price': poisson(100, size=10)})dfdf.query('gender == ""m"" and price < 100')k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')","k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']] k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", ""df = DataFrame({'gender': np.random.choice(['m', 'f'], size=10), 'price': poisson(100, size=10)})"", 'df', 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]","[""k1 = df.loc[(df.Product == p_id) & (df.Time >= start_time) & (df.Time < end_time), ['Time', 'Product']]"", ""df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')"", 'df.query(\'gender == ""m"" and price < 100\')', ""k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')""]"
19324591,Add missing dates to pandas dataframe,"import pandas as pdidx = pd.date_range('09-01-2013', '09-30-2013')s = pd.Series({'09-02-2013': 2,               '09-03-2013': 10,               '09-06-2013': 5,               '09-07-2013': 1})s.index = pd.DatetimeIndex(s.index)s = s.reindex(idx, fill_value=0)print(s)...","s = s.reindex(idx, fill_value=0)","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","['import pandas as pd', ""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""               '09-03-2013': 10,"", ""               '09-06-2013': 5,"", ""               '09-07-2013': 1})"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)', 'print(s)', '...']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']","[""idx = pd.date_range('09-01-2013', '09-30-2013')"", ""s = pd.Series({'09-02-2013': 2,"", 's.index = pd.DatetimeIndex(s.index)', 's = s.reindex(idx, fill_value=0)']"
19378497,Combine two columns of text in dataframe in pandas/python,"dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]","dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']","['dataframe[""period""] = dataframe[""Year""].map(str) + dataframe[""quarter""]']"
19385591,How to count number of rows in a group in pandas group by object?,"df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])","df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]","[""df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])""]"
19483025,Get list from pandas DataFrame column headers,"list(my_dataframe.columns.values)list(my_dataframe)",list(my_dataframe.columns.values) list(my_dataframe),['list(my_dataframe.columns.values)'],"['list(my_dataframe.columns.values)', 'list(my_dataframe)']",['list(my_dataframe.columns.values)'],['list(my_dataframe.columns.values)'],['list(my_dataframe.columns.values)']
19851521,Rename Pandas DataFrame Index,"df.index.names = ['Date']df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))dfdf1 = df.set_index('A')df1df1.rename(index={1: 'a'})df1.rename(columns={'B': 'BB'})df1.index.names = ['index']df1index       ",df.index.names = ['Date'] df1 = df.set_index('A') df1.rename(index={1: 'a'}) df1.rename(columns={'B': 'BB'}) df1.index.names = ['index'],"[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", 'df', ""df1 = df.set_index('A')"", 'df1', ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']"", 'df1', 'index       ']","[""df.index.names = ['Date']"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]","[""df.index.names = ['Date']"", ""df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))"", ""df1 = df.set_index('A')"", ""df1.rename(index={1: 'a'})"", ""df1.rename(columns={'B': 'BB'})"", ""df1.index.names = ['index']""]"
19960116,How to implement 'in' and 'not in' for Pandas dataframe,"dfcountries['UK', 'China']df.countries.isin(countries)df[df.countries.isin(countries)]df[~df.countries.isin(countries)]",pd.isin() something.isin(somewhere) ~something.isin(somewhere) df.countries.isin(countries) df[df.countries.isin(countries)] df[~df.countries.isin(countries)],"['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df', 'countries', ""['UK', 'China']"", 'df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']","['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']"
19961557,Construct pandas DataFrame from list of tuples,"df = pd.DataFrame(data)df.pivot(index=0, columns=1, values=2)0               df.pivot(index=0, columns=1, values=3)0                   ","df = pd.DataFrame(data)df.pivot(index=0, columns=1, values=2) df.pivot(index=0, columns=1, values=3)","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df.pivot(index=0, columns=1, values=2)', '0               ', 'df.pivot(index=0, columns=1, values=3)', '0                   ']","['df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']","['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']"
20084895,"Find unique values in a Pandas dataframe, irrespective of row or column location","df = DataFrame(np.random.randint(0,10,size=100).reshape(10,10))dfSeries(df.values.ravel()).unique()df = DataFrame(np.random.randint(0,10,size=10000).reshape(100,100))",Series(df.values.ravel()).unique() Series(df.values.ravel()).unique() np.unique(df.values.ravel()),['Series(df.values.ravel()).unique()'],"['df = DataFrame(np.random.randint(0,10,size=100).reshape(10,10))', 'df', 'Series(df.values.ravel()).unique()', 'df = DataFrame(np.random.randint(0,10,size=10000).reshape(100,100))']",['Series(df.values.ravel()).unique()'],['Series(df.values.ravel()).unique()'],['Series(df.values.ravel()).unique()']
20221655,How to write to an existing excel file without overwriting data (using pandas)?,"import pandasfrom openpyxl import load_workbookbook = load_workbook('Masterfile.xlsx')writer = pandas.ExcelWriter('Masterfile.xlsx', engine='openpyxl') writer.book = bookwriter.sheets = dict((ws.title, ws) for ws in book.worksheets)data_filtered.to_excel(writer, ""Main"", cols=['Diff1', 'Diff2'])writer.save()","book = load_workbook('Masterfile.xlsx')writer = pandas.ExcelWriter('Masterfile.xlsx', engine='openpyxl') writer.book = bookwriter.sheets = dict((ws.title, ws) for ws in book.worksheets)data_filtered.to_excel(writer, ""Main"", cols=['Diff1', 'Diff2'])writer.save()","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['import pandas', 'from openpyxl import load_workbook', ""book = load_workbook('Masterfile.xlsx')"", ""writer = pandas.ExcelWriter('Masterfile.xlsx', engine='openpyxl') "", 'writer.book = book', 'writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])', 'writer.save()']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']","['writer.sheets = dict((ws.title, ws) for ws in book.worksheets)', 'data_filtered.to_excel(writer, ""Main"", cols=[\'Diff1\', \'Diff2\'])']"
20461206,How to convert pandas index in a dataframe to a column?,"df['index1'] = df.indexdf.reset_index(level=0, inplace=True)dfdf.reset_index(level=['tick', 'obs'])tag                        ","df['index1'] = df.index df.reset_index(level=0, inplace=True) df.reset_index(level=['tick', 'obs'])","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', 'df', ""df.reset_index(level=['tick', 'obs'])"", 'tag                        ']","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]","[""df['index1'] = df.index"", 'df.reset_index(level=0, inplace=True)', ""df.reset_index(level=['tick', 'obs'])""]"
20491748,How to reset index in a pandas data frame?,df = df.reset_index(drop=True),df = df.reset_index(drop=True),['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)'],['df = df.reset_index(drop=True)']
20763459,Creating a Pandas DataFrame from a Numpy array: How do I specify the index column and column headers?,,"pd.DataFrame(data=data[1:,1:],    # values              index=data[1:,0],    # 1st column as index              columns=data[0,1:])  # 1st row as the column names",[],[''],[],[],[]
20868446,Changing a specific column name in pandas DataFrame,"df=df.rename(columns = {'two':'new_name'})dfDefinition: df.rename(self, index=None, columns=None, copy=True, inplace=False)ParametersSeries.renameReturns",df=df.rename(columns = {'two':'new_name'}),"[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'df', 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Parameters', 'Series.rename', 'Returns']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']","[""df=df.rename(columns = {'two':'new_name'})"", 'Definition: df.rename(self, index=None, columns=None, copy=True, inplace=False)', 'Series.rename']"
21232849,Import multiple csv files into pandas and concatenate into one DataFrame,"path =r'C:\DRO\DCL_rawdata_files' allFiles = glob.glob(path + ""/*.csv"")frame = pd.DataFrame()list_ = []for file_ in allFiles:    df = pd.read_csv(file_,index_col=None, header=0)    list_.append(df)frame = pd.concat(list_)","frame = pd.DataFrame()list_ = []for file_ in allFiles:    df = pd.read_csv(file_,index_col=None, header=0)    list_.append(df)frame = pd.concat(list_)","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","[""path =r'C:\\DRO\\DCL_rawdata_files' "", 'allFiles = glob.glob(path + ""/*.csv"")', 'list_ = []', 'for file_ in allFiles:', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']","['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']"
21266043,JSON to pandas DataFrame,"from urllib2 import Request, urlopenimport jsonfrom pandas.io.json import json_normalizepath1 = '42.974049,-81.205203|42.974298,-81.195755'request=Request('http://maps.googleapis.com/maps/api/elevation/json?locations='+path1+'&sensor=false')response = urlopen(request)elevations = response.read()data = json.loads(elevations)json_normalize(data['results'])",json_normalize(data['results']),[],"['from urllib2 import Request, urlopen', 'import json', 'from pandas.io.json import json_normalize', ""path1 = '42.974049,-81.205203|42.974298,-81.195755'"", ""request=Request('http://maps.googleapis.com/maps/api/elevation/json?locations='+path1+'&sensor=false')"", 'response = urlopen(request)', 'elevations = response.read()', 'data = json.loads(elevations)', ""json_normalize(data['results'])""]",[],[],[]
21291622,Convert floats to ints in Pandas?,"df= pd.DataFrame(range(5), columns=['a'])df.a = df.a.astype(float)dfpd.options.display.float_format = '{:,.0f}'.formatdf","df[list(""ABCD"")] = df[list(""ABCD"")].astype(int) df[list(""ABCD"")] = df[list(""ABCD"")].fillna(0.0).astype(int)","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","['df.a = df.a.astype(float)', 'df', ""pd.options.display.float_format = '{:,.0f}'.format"", 'df']","['df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]","[""df= pd.DataFrame(range(5), columns=['a'])"", 'df.a = df.a.astype(float)', ""pd.options.display.float_format = '{:,.0f}'.format""]"
21463854,Pandas: Chained assignments,"data['amount'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))data[""amount""] = data['amount'].fillna(mean_avg)data['amount'] = data['amount'].fillna(mean_avg)*2pd.set_option('chained_assignment',None)","data['amount'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean"")) data[""amount""] = data['amount'].fillna(mean_avg) data['amount'] = data['amount'].fillna(mean_avg)*2","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]","['data[\'amount\'] = data[""amount""].fillna(data.groupby(""num"")[""amount""].transform(""mean""))', 'data[""amount""] = data[\'amount\'].fillna(mean_avg)', ""data['amount'] = data['amount'].fillna(mean_avg)*2"", ""pd.set_option('chained_assignment',None)""]"
21800319,Python Pandas: Get index of rows which column matches certain value,"df[df['BoolCol'] == True].index.tolist()df[df['BoolCol']].index.tolist()df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},       index=[10,20,30,40,50])dfdf[df['BoolCol']].index.tolist()idx = df[df['BoolCol']].index.tolist()idxdf.loc[idx]df.loc[df['BoolCol']]np.flatnonzero(df['BoolCol'])df.iloc[np.flatnonzero(df['BoolCol'])]",df.index[df['BoolCol'] == True].tolist() df.index[df['BoolCol']].tolist() df.index[df['BoolCol']].tolist() idx = df.index[df['BoolCol']] df.loc[df['BoolCol']] df.iloc[np.flatnonzero(df['BoolCol'])],"[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", '       index=[10,20,30,40,50])', 'df', ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'idx', 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""np.flatnonzero(df['BoolCol'])"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.loc[df['BoolCol']]"", ""df.iloc[np.flatnonzero(df['BoolCol'])]""]","[""df[df['BoolCol'] == True].index.tolist()"", ""df[df['BoolCol']].index.tolist()"", ""df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},"", ""df[df['BoolCol']].index.tolist()"", ""idx = df[df['BoolCol']].index.tolist()"", 'df.loc[idx]', ""df.iloc[np.flatnonzero(df['BoolCol'])]""]"
22006514,Convert Columns to String in Pandas,"total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])df.to_json()df[0].to_json()Out[13]: '{""0"":""A"",""1"":""A"",""2"":""B""}'",total_rows['ColumnID'] = total_rows['ColumnID'].astype(str),"[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", 'df.to_json()', 'df[0].to_json()', 'Out[13]: \'{""0"":""A"",""1"":""A"",""2"":""B""}\'']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']","[""total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)"", ""df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])"", 'df.to_json()', 'df[0].to_json()']"
22276757,How to I change data-type of pandas data frame to string with a defined format,,image_name_data['id'] = image_name_data['id'].astype(int).astype('str') image_name_data['id'] = image_name_data['id'].map('{:.0f}'.format),[],[''],[],[],[]
22341390,get list from pandas dataframe column,"from pandas import *d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),    'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}df = DataFrame(d)dfList = df['one'].tolist()","dfList = df['one'].tolist() my_list = df[""cluster""].tolist()","[""dfList = df['one'].tolist()""]","['from pandas import *', ""d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),"", ""    'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}"", 'df = DataFrame(d)', ""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]","[""dfList = df['one'].tolist()""]"
22391554,count the frequency that a value occurs in a dataframe column,"df = pd.DataFrame({'a':list('abssbab')})df.groupby('a').count()a   df['a'].value_counts()dtype: int64df['freq'] = df.groupby('a')['a'].transform('count')df",df.groupby('a').count() df['a'].value_counts() df['freq'] = df.groupby('a')['a'].transform('count'),"[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]","[""df.groupby('a').count()"", 'a   ', ""df['a'].value_counts()"", 'dtype: int64', ""df['freq'] = df.groupby('a')['a'].transform('count')"", 'df']","[""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]","[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()""]","[""df = pd.DataFrame({'a':list('abssbab')})"", ""df.groupby('a').count()"", ""df['a'].value_counts()"", ""df['freq'] = df.groupby('a')['a'].transform('count')""]"
22475141,get list of pandas dataframe columns based on data type,"df = pd.DataFrame([[1, 2.3456, 'c', 'd', 78]], columns=list(""ABCDE""))dfdf.dtypesdtype: objectg = df.columns.to_series().groupby(df.dtypes).groupsg{dtype('int64'): ['A', 'E'], dtype('float64'): ['B'], dtype('O'): ['C', 'D']}{'object': ['C', 'D'], 'int64': ['A', 'E'], 'float64': ['B']}",g = df.columns.to_series().groupby(df.dtypes).groups,"['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df', 'df.dtypes', 'dtype: object', 'g = df.columns.to_series().groupby(df.dtypes).groups', 'g', ""{dtype('int64'): ['A', 'E'], dtype('float64'): ['B'], dtype('O'): ['C', 'D']}"", ""{'object': ['C', 'D'], 'int64': ['A', 'E'], 'float64': ['B']}""]","['df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']","['df = pd.DataFrame([[1, 2.3456, \'c\', \'d\', 78]], columns=list(""ABCDE""))', 'df.dtypes', 'g = df.columns.to_series().groupby(df.dtypes).groups']"
23307361,Pandas: Replacing column values in dataframe,"w['female'] = w['female'].map({'female': 1, 'male': 0})","w['female'] = w['female'].map({'female': 1, 'male': 0})","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]","[""w['female'] = w['female'].map({'female': 1, 'male': 0})""]"
23749057,Pandas DataFrame to list,"import pandas as pddf = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],                   'b':[3,5,6,2,4,6,7,8,7,8,9]})df['a'].values.tolist()[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]df['a'].tolist()[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]df['a'].drop_duplicates().values.tolist()[1, 3, 5, 7, 4, 6, 8, 9]list(set(df['a'])) [1, 3, 4, 5, 6, 7, 8, 9]",df['a'].values.tolist() df['a'].tolist() df['a'].drop_duplicates().values.tolist() list(set(df['a'])),"[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","['import pandas as pd', ""                   'b':[3,5,6,2,4,6,7,8,7,8,9]})"", ""df['a'].values.tolist()"", '[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]', ""df['a'].tolist()"", '[1, 3, 5, 7, 4, 5, 6, 4, 7, 8, 9]', ""df['a'].drop_duplicates().values.tolist()"", '[1, 3, 5, 7, 4, 6, 8, 9]', ""list(set(df['a'])) "", '[1, 3, 4, 5, 6, 7, 8, 9]']","[""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]","[""df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],"", ""df['a'].values.tolist()"", ""df['a'].tolist()"", ""df['a'].drop_duplicates().values.tolist()""]"
24147363,How do I create test and train samples from one dataframe with pandas?,"df = pd.DataFrame(np.random.randn(100, 2))msk = np.random.rand(len(df)) < 0.8train = df[msk]test = df[~msk]len(test)len(train)Out[16]: 79","train, test = train_test_split(df, test_size=0.2)","['df = pd.DataFrame(np.random.randn(100, 2))']","['msk = np.random.rand(len(df)) < 0.8', 'train = df[msk]', 'test = df[~msk]', 'len(test)', 'len(train)', 'Out[16]: 79']",[],"['df = pd.DataFrame(np.random.randn(100, 2))']","['df = pd.DataFrame(np.random.randn(100, 2))']"
24284680,Insert a row to pandas dataframe,,"df.loc[-1] = [2, 3, 4]  # adding a rowdf.index = df.index + 1  # shifting indexdf = df.sort_index()  # sorting by index",[],[''],[],[],[]
24793359,"Convert pandas dataframe to numpy array, preserving index",numpyMatrix = df.as_matrix(),numpyMatrix = df.as_matrix(),['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()'],['numpyMatrix = df.as_matrix()']
24888331,add one row in a pandas.DataFrame,"df = DataFrame(columns=('lib', 'qty1', 'qty2'))","df.loc[i] = [randint(-1,1) for n in range(3)]",[],"[""df = DataFrame(columns=('lib', 'qty1', 'qty2'))""]",[],[],[]
25254087,Pandas - Get first row value of a given column,"df_test.iloc[0]df_test['Btime'].iloc[0]df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])dfdf.ix[1, 'foo']Out[4]: 'C'",df_test.iloc[0] df_test['Btime'].iloc[0],"['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", 'df', ""df.ix[1, 'foo']"", ""Out[4]: 'C'""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]","['df_test.iloc[0]', ""df_test['Btime'].iloc[0]"", ""df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])""]"
25376997,How to add an extra row to a pandas dataframe,"df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ","df.loc[len(df)]=['8/19/2014','Jun','Fly','98765']","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]","[""df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] ""]"
25748826,Pandas: sum DataFrame rows for given columns,"df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})df['e'] = df.sum(axis=1)dfcol_list= list(df)col_list.remove('d')col_list['a', 'b', 'c']df['e'] = df[col_list].sum(axis=1)df","df['e'] = df.sum(axis=1) col_list= list(df)col_list.remove('d')df['e'] = df[col_list].sum(axis=1)","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df['e'] = df.sum(axis=1)"", 'df', 'col_list= list(df)', ""col_list.remove('d')"", 'col_list', ""['a', 'b', 'c']"", ""df['e'] = df[col_list].sum(axis=1)"", 'df']","[""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]","[""df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})"", ""df['e'] = df.sum(axis=1)"", ""df['e'] = df[col_list].sum(axis=1)""]"
25962187,How to read a 6 GB csv file with pandas,"chunksize = 10 ** 6for chunk in pd.read_csv(filename, chunksize=chunksize):    process(chunk)","for chunk in pd.read_csv(filename, chunksize=chunksize):    process(chunk)","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['chunksize = 10 ** 6', 'for chunk in pd.read_csv(filename, chunksize=chunksize):', '    process(chunk)']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']","['for chunk in pd.read_csv(filename, chunksize=chunksize):']"
26266451,How to count the Nan values in the column in Panda Data frame,"s = pd.Series([1,2,3, np.nan, np.nan])s.isnull().sum()df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})df.isnull().sum()dtype: int64",s.isnull().sum() df.isnull().sum(),"['s = pd.Series([1,2,3, np.nan, np.nan])', 's.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']","['s.isnull().sum()', 'df.isnull().sum()', 'dtype: int64']","['s.isnull().sum()', 'df.isnull().sum()']","['s = pd.Series([1,2,3, np.nan, np.nan])', 's.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']","['s.isnull().sum()', ""df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})"", 'df.isnull().sum()']"
26301947,Pandas to_html() truncates string contents,"pd.set_option('display.max_colwidth', -1)","pd.set_option('display.max_colwidth', -1)","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]","[""pd.set_option('display.max_colwidth', -1)""]"
27360130,How to delete rows from a pandas DataFrame based on a conditional expression,,"df = df.drop(some labels) df = df.drop(df[<some boolean condition>].index) df = df.drop(df[df.score < 50].index) df.drop(df[df.score < 50].index, inplace=True) df = df.drop(df[(df.score < 50) & (df.score > 20)].index)",[],[''],[],[],[]
27791362,pandas read_csv and filter columns with usecols,"import pandas as pdfrom StringIO import StringIOcsv = r""""""dummy,date,loc,xbar,20090101,a,1bar,20090102,a,3bar,20090103,a,5bar,20090101,b,1bar,20090102,b,3bar,20090103,b,5""""""df = pd.read_csv(StringIO(csv),        header=0,        index_col=[""date"", ""loc""],         usecols=[""date"", ""loc"", ""x""],        parse_dates=[""date""])","df = pd.read_csv(StringIO(csv),        header=0,        index_col=[""date"", ""loc""],         usecols=[""date"", ""loc"", ""x""],        parse_dates=[""date""])","['df = pd.read_csv(StringIO(csv),']","['import pandas as pd', 'from StringIO import StringIO', 'csv = r""""""dummy,date,loc,x', 'bar,20090101,a,1', 'bar,20090102,a,3', 'bar,20090103,a,5', 'bar,20090101,b,1', 'bar,20090102,b,3', 'bar,20090103,b,5""""""', 'df = pd.read_csv(StringIO(csv),', '        header=0,', '        index_col=[""date"", ""loc""], ', '        usecols=[""date"", ""loc"", ""x""],', '        parse_dates=[""date""])']","['df = pd.read_csv(StringIO(csv),']","['df = pd.read_csv(StringIO(csv),']","['df = pd.read_csv(StringIO(csv),']"
28648923,Change data type of columns in Pandas,"s = pd.Series(['1', '2', '4.7', 'pandas', '10'])sdtype: objectpd.to_numeric(s) pd.to_numeric(s, errors='coerce')dtype: float64pd.to_numeric(s, errors='ignore')a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]df = pd.DataFrame(a, columns=['col1','col2','col3'])dfdf[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)df.apply(pd.to_numeric, errors='ignore')df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')df.dtypesdtype: objectdf = df.infer_objects()df.dtypesdtype: object","pd.to_numeric(s) pd.to_numeric(s, errors='coerce') pd.to_numeric(s, errors='ignore') df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric) df.apply(pd.to_numeric, errors='ignore') df = df.infer_objects()","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","['s', 'dtype: object', 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", 'dtype: float64', ""pd.to_numeric(s, errors='ignore')"", ""a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]"", 'df', ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", 'df.dtypes', 'dtype: object', 'df = df.infer_objects()', 'df.dtypes', 'dtype: object']","['pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']","[""s = pd.Series(['1', '2', '4.7', 'pandas', '10'])"", 'pd.to_numeric(s) ', ""pd.to_numeric(s, errors='coerce')"", ""pd.to_numeric(s, errors='ignore')"", ""df = pd.DataFrame(a, columns=['col1','col2','col3'])"", ""df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)"", ""df.apply(pd.to_numeric, errors='ignore')"", ""df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')"", 'df.dtypes', 'df = df.infer_objects()', 'df.dtypes']"
28902170,pandas get rows which are NOT in other dataframe,"common = df1.merge(df2,on=['col1','col2'])print(common)df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]df1[~df1.isin(df2)].dropna()df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})df1[~df1.isin(df2)].dropna()","common = df1.merge(df2,on=['col1','col2'])df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))] df1[~df1.isin(df2)].dropna() df1[~df1.isin(df2)].dropna()","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'print(common)', 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']","[""common = df1.merge(df2,on=['col1','col2'])"", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', ""df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})"", 'df1[~df1.isin(df2)].dropna()']"
29319200,Selecting/Excluding sets of columns in Pandas,,"df.drop(df.columns[[1, 2]], axis=1, inplace=True) df1 = df1.drop(['B', 'C'], axis=1) df1 = df[['a','d']]",[],[''],[],[],[]
29530601,Python pandas: check if any value is NaN in DataFrame,"df.isnull().values.any()df = pd.DataFrame(np.random.randn(1000,1000))df[df > 0.9] = pd.np.nan",df.isnull().values.any() df.isnull().any().any() df.isnull().values.sum() df.isnull().sum().sum() df.isnull().values.any(),"['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']","['df.isnull().values.any()', 'df[df > 0.9] = pd.np.nan']",['df.isnull().values.any()'],"['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']","['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']"
30512931,pandas joining multiple dataframes on columns,"import pandas as pddfs = [df0, df1, df2, dfN]df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)","dfs = [df0, df1, df2, dfN]df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","['import pandas as pd', 'dfs = [df0, df1, df2, dfN]', ""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]","[""df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)""]"
30691921,Is there a way to (pretty) print the entire Pandas Series / DataFrame?,"with pd.option_context('display.max_rows', None, 'display.max_columns', 3):    print(df)","with pd.option_context('display.max_rows', None, 'display.max_columns', 3):","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):"", '    print(df)']","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]","[""with pd.option_context('display.max_rows', None, 'display.max_columns', 3):""]"
32558621,How to iterate over columns of pandas dataframe to run regression,"for column in df:    print(df[column])","for column in df:        print(df[column])",[],"['for column in df:', '    print(df[column])']",[],[],[]
32801170,How to count number of rows in a group in pandas group by object?,"df.groupby(key_columns).size()import pandas as pddf = pd.DataFrame([['a', 1],                           ['b', 2],                           ['c', 3],                           ['a', 4],                           ['b', 5]],                           columns=['col1', 'col2'])counts = df.groupby('col1').size(); countstype(counts)counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))counts_dftype(counts_df)df.dtypesdfdf[['col1', 'col2', 'col3', 'col4']]\            .groupby(['col1', 'col2']).agg(['mean', 'count'])groupby_object = df[['col1', 'col2', 'col3', 'col4']]\            .groupby(['col1', 'col2'])groupby_object.agg('mean')\             .rename(columns = lambda x: x + ' mean')\             .join(pd.DataFrame(groupby_object.size(),                                 columns=['counts']))","df.groupby(['col1','col2']).size() df.groupby(['col1', 'col2']).size().reset_index(name='counts') df.groupby(['col1', 'col2']).size() df.groupby(['col1', 'col2']).size().reset_index(name='counts')","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', 'import pandas as pd', ""                           ['b', 2],"", ""                           ['c', 3],"", ""                           ['a', 4],"", ""                           ['b', 5]], "", ""                          columns=['col1', 'col2'])"", ""counts = df.groupby('col1').size(); counts"", 'type(counts)', 'counts_df', 'type(counts_df)', 'df.dtypes', 'df', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""            .groupby(['col1', 'col2']).agg(['mean', 'count'])"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""            .groupby(['col1', 'col2'])"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", ""                                columns=['counts']))""]","['df.groupby(key_columns).size()', ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']","['df.groupby(key_columns).size()', ""df = pd.DataFrame([['a', 1],"", ""counts = df.groupby('col1').size(); counts"", ""counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))"", 'df.dtypes', ""df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\"", ""groupby_object.agg('mean')\\"", ""             .rename(columns = lambda x: x + ' mean')\\"", '             .join(pd.DataFrame(groupby_object.size(), ']"
34272155,Drop all duplicate rows in Python Pandas,"import pandas as pddf = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})df.drop_duplicates(subset=['A', 'C'], keep=False)","df.drop_duplicates(subset=['A', 'C'], keep=False)","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['import pandas as pd', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","[""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]","['df = pd.DataFrame({""A"":[""foo"", ""foo"", ""foo"", ""bar""], ""B"":[0,1,1,1], ""C"":[""A"",""A"",""B"",""A""]})', ""df.drop_duplicates(subset=['A', 'C'], keep=False)""]"
34297689,Remove rows with duplicate indices (Pandas DataFrame and TimeSeries),df3 = df3[~df3.index.duplicated(keep='first')],"df3 = df3[~df3.index.duplicated(keep='first')] df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') df3.groupby(df3.index).first() df3[~df3.index.duplicated(keep='first')]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]","[""df3 = df3[~df3.index.duplicated(keep='first')]""]"
36572039,Removing index column in pandas,"df.read_csv(filename ,  index = False)  ","df.to_csv(filename ,  index = False) df.read_csv(filename ,  index = False)  ","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']","['df.read_csv(filename ,  index = False)  ']"
37043071,"Convert pandas dataframe to numpy array, preserving index",,df=df.values,[],[''],[],[],[]
39358924,How to split a column into two columns?,"df['A'], df['B'] = df['AB'].str.split(' ', 1).strdf['AB'].str.split(' ', 1, expand=True)import pandas as pddf = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})dfdf['AB_split'] = df['AB'].str.split('-')dfupper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})upper_lower_dfupper_lower_df[""L""] = upper_lower_df[""U""].str.lower()upper_lower_dfdf['AB'].str[0]df['AB'].str[1]df['AB'].str.split('-', 1).str[0]df['AB'].str.split('-', 1).str[1]df['A'], df['B'] = df['AB'].str.split('-', 1).strdfdf['AB'].str.split('-', 1, expand=True)df = df[['AB']]dfdf.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))","df['A'], df['B'] = df['AB'].str.split(' ', 1).str df['AB'].str.split(' ', 1, expand=True) df['AB_split'] = df['AB'].str.split('-') df['AB'].str.split('-', 1).str[0] df['AB'].str.split('-', 1).str[1] df['A'], df['B'] = df['AB'].str.split('-', 1).str df['AB'].str.split('-', 1, expand=True) df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", 'import pandas as pd', 'df', ""df['AB_split'] = df['AB'].str.split('-')"", 'df', 'upper_lower_df', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', 'upper_lower_df', ""df['AB'].str[0]"", ""df['AB'].str[1]"", ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", 'df', ""df['AB'].str.split('-', 1, expand=True)"", ""df = df[['AB']]"", 'df', ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]","[""df['A'], df['B'] = df['AB'].str.split(' ', 1).str"", ""df['AB'].str.split(' ', 1, expand=True)"", ""df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})"", ""df['AB_split'] = df['AB'].str.split('-')"", 'upper_lower_df = pd.DataFrame({""U"": [""A"", ""B"", ""C""]})', 'upper_lower_df[""L""] = upper_lower_df[""U""].str.lower()', ""df['AB'].str.split('-', 1).str[0]"", ""df['AB'].str.split('-', 1).str[1]"", ""df['A'], df['B'] = df['AB'].str.split('-', 1).str"", ""df['AB'].str.split('-', 1, expand=True)"", ""df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))""]"
44736467,How to take column-slices of dataframe in pandas,"df.loc[:, 'foo':'sat']df.loc[:, 'foo':'cat':2]df.loc[:, :'bar']df.loc[:, 'quz'::3]df.loc[:, 'sat':'bar']df.loc[:, 'sat':'bar':-1]df.loc[:, slice('quz',None, 2)]df.loc[:, ['foo','bar','dat']]df.loc['w':'y', 'foo':'ant':3]wxy","df.loc[:, 'foo':'sat'] df.loc[:, 'foo':'cat':2] df.loc[:, :'bar'] df.loc[:, 'quz'::3] df.loc[:, 'sat':'bar'] df.loc[:, 'sat':'bar':-1] df.loc[:, slice('quz',None, 2)] df.loc[:, ['foo','bar','dat']] df.loc['w':'y', 'foo':'ant':3]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]"", 'w', 'x', 'y']","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]","[""df.loc[:, 'foo':'sat']"", ""df.loc[:, 'foo':'cat':2]"", ""df.loc[:, :'bar']"", ""df.loc[:, 'quz'::3]"", ""df.loc[:, 'sat':'bar']"", ""df.loc[:, 'sat':'bar':-1]"", ""df.loc[:, slice('quz',None, 2)]"", ""df.loc[:, ['foo','bar','dat']]"", ""df.loc['w':'y', 'foo':'ant':3]""]"