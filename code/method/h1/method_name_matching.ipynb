{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility to extract method name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FunctionCallVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_func_calls(tree):\n",
    "    func_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            callvisitor = FunctionCallVisitor()\n",
    "            callvisitor.visit(node.func)\n",
    "            func_calls.append(callvisitor.name)\n",
    "    return func_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load APIDoc and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot convert float NaN to integer\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "API_DOC_FILE_PATH = 'api_doc.pkl'\n",
    "DATASET_FILE_PATH = 'dataset_df.pkl'\n",
    "api_df = pickle.load( open( API_DOC_FILE_PATH, \"rb\" ))\n",
    "dataset_df = pickle.load( open( DATASET_FILE_PATH, \"rb\" ))\n",
    "\n",
    "def buildMethodNameSet(api_df):\n",
    "    method_set = set()\n",
    "    for index, row in api_df.iterrows():\n",
    "        method_set.add(row['MethodName'])\n",
    "    return method_set\n",
    "        \n",
    "\n",
    "def buildDatasetDSForEvaluation(dataset_df):\n",
    "    dataset_dict = dict()\n",
    "    total_solutions = 0\n",
    "    try:    \n",
    "        for idx, row in dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                total_solutions = total_solutions +1\n",
    "                tup = (int(row['SolutionId']), row['Solution'])\n",
    "                if answerId in dataset_dict:\n",
    "                    ls = dataset_dict[answerId]\n",
    "                    ls.append(tup)\n",
    "                    dataset_dict[answerId] = ls\n",
    "                else:\n",
    "                    ls = list()\n",
    "                    ls.append(tup)\n",
    "                    dataset_dict[answerId] = ls\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        \n",
    "    return dataset_dict, total_solutions\n",
    "    \n",
    "method_set = buildMethodNameSet(api_df)\n",
    "dataset_dict, total_solutions = buildDatasetDSForEvaluation(dataset_df)\n",
    "print total_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookUpAPIDoc(method_set, method_name):\n",
    "    if method_name in method_set:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "matched_solution_set = set()\n",
    "def lookUpAndMarkSolution(answerId, line):\n",
    "    solutionList = dataset_dict[int(answerId)]\n",
    "    for tup in solutionList:\n",
    "        if tup[1].strip() == line.strip():\n",
    "            matched_solution_set.add(answerId+str(tup[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17841294\n",
      "Accuracy = 81%\n",
      "Precision = 63%\n",
      "Recall = 88%\n",
      "F1 = 0.73\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_CODE_OUTPUT_FOLDER = '../../data-preprocess/neelesh/processed_answer_codes'\n",
    "\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for fil in os.listdir(PROCESSED_CODE_OUTPUT_FOLDER):\n",
    "    try:\n",
    "        solutionList = dataset_dict[int(fil)]\n",
    "        with open(os.path.join(PROCESSED_CODE_OUTPUT_FOLDER, fil), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            #print f\n",
    "            for line in lines:\n",
    "                actualSolution = False\n",
    "                predictedSolution = False\n",
    "                for tup in solutionList:\n",
    "                    if tup[1].strip() == line.strip():\n",
    "                        actualSolution = True\n",
    "                tree = ast.parse(line)\n",
    "                func_calls = get_func_calls(tree)\n",
    "                for func_call in func_calls:\n",
    "                    tokens = func_call.split('.')\n",
    "                    method_name = tokens[len(tokens)-1]\n",
    "                    if lookUpAPIDoc(method_set, method_name):\n",
    "                        predictedSolution = True\n",
    "                        break\n",
    "                if actualSolution and predictedSolution:\n",
    "                    TP = TP + 1\n",
    "                if (not actualSolution) and predictedSolution:\n",
    "                    FP = FP + 1\n",
    "                if (not actualSolution) and (not predictedSolution):\n",
    "                    TN = TN + 1\n",
    "                if actualSolution and (not predictedSolution):\n",
    "                    FN = FN + 1\n",
    "    except Exception as e:\n",
    "        print e\n",
    "acc = (TP+TN)*100/(TP+TN+FP+FN)\n",
    "Precision = TP*100/(TP + FP)\n",
    "Recall = TP*100/(TP+FN)\n",
    "F1 = (2*Precision*Recall)/(Precision+Recall)\n",
    "F1 = float(F1)/100\n",
    "print 'Accuracy = '+ str(acc) + '%'\n",
    "print 'Precision = '+ str(Precision) + '%'\n",
    "print 'Recall = '+ str(Recall) + '%'\n",
    "print 'F1 = '+ str(F1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
