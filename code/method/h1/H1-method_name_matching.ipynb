{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luigi migration. Task yet to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from jupyter_notebook import load_parameters \n",
    "\n",
    "\n",
    "pars = load_parameters()\n",
    "\n",
    "so_dump_processed_file = pars.get('input')\n",
    "output_file = pars.get('output')\n",
    "\n",
    "input_col = pars.get('input_col')\n",
    "\n",
    "api_doc_file = pars.get('api_doc_file')\n",
    "\n",
    "debug = pars.get('debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility to extract method name and line number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FunctionCallVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "        self._pos = -1 \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @property\n",
    "    def lineno(self):\n",
    "        return self._pos\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._pos = node.lineno # line number\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._pos = node.lineno # line number\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_func_calls(tree):\n",
    "    func_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            callvisitor = FunctionCallVisitor()\n",
    "            callvisitor.visit(node.func)\n",
    "            func_calls.append((callvisitor.name, callvisitor.lineno))\n",
    "    return func_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load APIDoc and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#api_doc_file = '../../data-import/build_api_doc_base/api_doc.csv'\n",
    "#so_dump_processed_file = '../../../data/stack-overflow/pandas-preprocessedcode-dataset-part3'\n",
    "#input_col = 'PreprocessedCode3'\n",
    "#output_file = '../../../data/stack-overflow/pandas-solutioncode-h1'\n",
    "\n",
    "api_df = pd.read_csv(api_doc_file, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "\n",
    "processed_stackoverflow_df = pd.read_pickle(so_dump_processed_file)\n",
    "\n",
    "def buildAPIDictionary(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['Description']\n",
    "            tokens = row['FullyQualifiedName'].split('.')\n",
    "        \n",
    "            for token in tokens:\n",
    "                methodContext = str(methodContext)+' '+token\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print('Error in method buildAPIDictionary',e)\n",
    "    return api_dict\n",
    "\n",
    "    \n",
    "api_dict = buildAPIDictionary(api_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContext(method_name):\n",
    "    try:\n",
    "        if method_name in api_dict.keys():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print('Error in method lookUpAPIDocForContext', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1 Method\n",
    "\n",
    "Look for API calls in Code Fragment:\n",
    "After analyzing the stackoverflow answers, it has been\n",
    "identified that, usually solutions are provided in terms of API\n",
    "method calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7779260 []\n",
      "7837947 ['    pct_change.append(...)']\n",
      "7849789 ['for date, row in df.T.iteritems():', '    n = len(dates)']\n",
      "8916746 ['df[(df.values > 1.5).any(1)]']\n",
      "8992714 []\n",
      "8997908 []\n",
      "9555766 []\n",
      "9557319 []\n",
      "9558852 []\n",
      "9577305 []\n",
      "9620832 ['data_2010 = pandas.read_csv(\"/path/to/2010.csv\")', 'data_2010.groupby(\"category\").agg([len, sum])']\n",
      "9623878 [\"df.pivot_table(rows='category', aggfunc=[len, np.sum])\", \"df.pivot_table(rows='category', aggfunc=[len, np.sum])\"]\n",
      "9652858 [\"DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\\\t')\", \"DataFrame.from_csv('c:/~/trainSetRel3.txt', sep='\\\\t', header=0)\"]\n",
      "9656288 []\n",
      "9677723 []\n",
      "9762084 []\n",
      "9772031 []\n",
      "9794891 ['df2.combine_first(df1)']\n",
      "10114652 ['merge(left, right)', \"merge(left, right, on='ST_NAME', sort=False)\"]\n",
      "10182172 []\n",
      "10202789 [\"df = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])\", \"df['A'].argmax()\", \"df['B'].argmax()\", \"df['C'].argmax()\", \"dfrm['A'].idxmax()\", \"dfrm.ix[dfrm['A'].idxmax()]\"]\n",
      "10213167 [\"df = pandas.DataFrame(np.random.randn(10,3),columns=['A','B','C'])\", 'df.idxmax()', \"df.ix[df['A'].idxmax()]\"]\n",
      "10374456 [\"g1.add_suffix('_Count').reset_index()\", 'DataFrame({\\'count\\' : df1.groupby( [ \"Name\", \"City\"] ).size()}).reset_index()']\n",
      "10377863 []\n",
      "10458386 []\n",
      "10465162 []\n",
      "10511230 []\n",
      "10511545 []\n",
      "10565742 ['hr = dr.map(lambda x: x.hour)', 'dt = p.DataFrame(rand(len(dr),2), dr)']\n",
      "10567298 []\n",
      "10666301 [\"data = pandas.DataFrame(np.random.rand(10,5), columns = list('abcde'))\"]\n",
      "10677896 [\"df = DataFrame(np.random.rand(4,5), columns = list('abcde'))\"]\n",
      "10716007 []\n",
      "10726275 [\"df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])\"]\n",
      "10739432 []\n",
      "10762516 [\"return pandas.Series({'pvalue': pvalue, 'mean_ratio': mean_ratio})\"]\n",
      "10781413 ['df.phone = df.phone.astype(str)']\n",
      "10859883 [\"df=df.dropna(axis=1,how='all')\"]\n",
      "10943545 []\n",
      "10964938 ['grouped = df.groupby(keys)', '    return (d * w).sum() / w.sum()', 'grouped.apply(wavg)']\n",
      "10972557 [\"pandas.concat([df['foo'].dropna(), df['bar'].dropna()]).reindex_like(df)\"]\n",
      "10982198 ['a.x2 = a.x2.shift(1)']\n",
      "11005208 []\n",
      "11067072 ['df.reindex_axis(sorted(df.columns), axis=1)']\n",
      "11073962 ['df.groupby(df.index.map(lambda t: t.minute))', \"df.groupby([df.index.map(lambda t: t.minute), 'Source'])\", \"df.groupby([df['Source'],pd.TimeGrouper(freq='Min')])\"]\n",
      "11077060 []\n",
      "11077215 []\n",
      "11107627 ['(x.reindex_like(y).fillna(0) + y.fillna(0)).fillna(0)']\n",
      "11112419 [\"df1 = pd.DataFrame([(1,2),(3,4),(5,6)], columns=['a','b'])\", \"df2 = pd.DataFrame([(100,200),(300,400),(500,600)], columns=['a','b'])\", 'df_add = df1.add(df2, fill_value=0)']\n",
      "11138275 [\"df_ora = pd.read_sql('select * from user_objects', con=ora_conn)    \", \"df_mysql = pd.read_sql('select * from VIEWS;', con=mysql_cn)    \"]\n",
      "11287278 ['df1 = df.ix[0,0:2].copy() # To avoid the case where changing df1 also changes df']\n",
      "11346337 [\"df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})\"]\n",
      "11354850 [\"df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\", \"df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\"]\n",
      "11362056 []\n",
      "11366429 []\n",
      "11366706 ['    newdf = DataFrame()', '    for idx, record in df[colName].iteritems():', '            newdf = concat([df[df[colName] == record], newdf], ignore_index=True)']\n",
      "11384667 [\"ax = x.plot(kind='bar', legend=False)\"]\n",
      "11385335 []\n",
      "11385780 []\n",
      "11395193 [\"data.groupby(lambda x: data['date'][x].year)\"]\n",
      "11397052 [\"data.groupby(data['date'].map(lambda x: x.year))\"]\n",
      "11415882 ['pandas.DataFrame(initialload, columns=list_of_column_names)']\n",
      "11420594 ['mask = (np.sin(df.velocity) / df.ix[:, 0:2].prod(axis=1)) > 0']\n",
      "11475486 [\"df = pandas.DataFrame(np.random.randn(5, 3), columns=['a', 'b', 'c'])\", \"df[df.apply(lambda x: x['b'] > x['c'], axis=1)]\"]\n",
      "11495086 []\n",
      "11531402 ['df[df[\\'A\\'].str.contains(\"hello\")]']\n",
      "11548224 []\n",
      "11589000 [\"for elem in dfrm['Category'].unique():\", \"for elem in dfrm['Category'].unique():\"]\n",
      "11603242 [\"frame.resample('1H').agg({'radiation': np.sum, 'tamb': np.mean})\", \"frame.resample('1H', how={'radiation': np.sum, 'tamb': np.mean})\"]\n",
      "11617194 []\n",
      "11617682 [\"parse = lambda x: datetime.strptime(x, '%Y%m%d %H')\", 'pd.read_csv(\"..\\\\\\\\file.csv\",  parse_dates = [[\\'YYYYMMDD\\', \\'HH\\']], ']\n",
      "11622769 []\n",
      "11637456 []\n",
      "11639358 ['left.join(right)']\n",
      "11643893 [\"df = DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])\", \"df.A.plot(ax=ax, style='b-')\", \"df.B.plot(ax=ax2, style='r-', secondary_y=True)\", \"df.C.plot(ax=ax3, style='g-')\"]\n",
      "11706782 []\n",
      "11707706 []\n",
      "11708610 []\n",
      "11708664 ['df.describe()', 'df.describe()', 'df.describe()', \"pd.set_option('display.precision', 2)\", 'df.describe()']\n",
      "11711637 [\"pd.set_option('display.height', 1000)\", \"pd.set_option('display.max_rows', 500)\", \"pd.set_option('display.max_columns', 500)\", \"pd.set_option('display.width', 1000)\"]\n",
      "11811425 []\n",
      "11856979 [\"df.set_index(['d'], append=True)\"]\n",
      "11858532 []\n",
      "11872393 []\n",
      "11874590 [\"df.apply(lambda x:'%s is %s' % (x['bar'],x['foo']),axis=1)\"]\n",
      "11882354 ['df.drop(rows)']\n",
      "11893375 ['df.mask(lambda x: x[0] < 0).mask(lambda x: x[1] > 0)']\n",
      "11927922 ['df = pandas.DataFrame(x)', \"my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(df)))\", \"df.plot(kind='bar', stacked=True, color=my_colors)\", 'my_colors = [(x/10.0, x/20.0, 0.75) for x in range(len(df))] # <-- Quick gradient example along the Red/Green dimensions.']\n",
      "11941772 [\"df.swaplevel(0,1).ix['c']\"]\n",
      "11942697 [\"df.xs('a', level=0)\", \"df.xs('c', level='group2')\"]\n",
      "11982843 ['a.reset_index().merge(b, how=\"left\").set_index(\\'index\\')']\n",
      "12022003 ['df2 = df.head(10)']\n",
      "12022047 ['data = read_table(\\'sample.txt\\', skiprows=3, header=None, sep=r\"\\\\s*\")']\n",
      "12025395 []\n",
      "12036847 ['df  = read_csv(filename, index_col = 0,header = 0)', 'self.datatable.setColumnCount(len(df.columns))', 'self.datatable.setRowCount(len(df.index))', 'for i in range(len(df.index)):', '    for j in range(len(df.columns)):']\n",
      "12056933 [\"            datatypes.append((col[0], 'U%d' % col[3]))\", \"            datatypes.append((col[0], 'S%d' % col[3]))\", \"            datatypes.append((col[0], 'f4'))\", \"            datatypes.append((col[0], 'O4'))\", \"            datatypes.append((col[0], 'i4'))\", '        data.append(tuple(row))', '        output = pandas.DataFrame.from_records(array)', '            output = output.set_index(index)']\n",
      "12060886 ['df = DataFrame(resoverall.fetchall())']\n",
      "12065904 []\n",
      "12077782 []\n",
      "12098586 [\"df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})\", \"df[df['A'].isin([3, 6])]\"]\n",
      "12100543 []\n",
      "12117333 [\"x = pandas.read_csv('weird.csv')\", 'y_pandas = pandas.DataFrame.from_records(y_np)']\n",
      "12133235 []\n",
      "12152759 ['df = DataFrame({1: [2,3,4], 2: [3,4,5]})', 'df[2].replace(4, 17)', 'df[2].replace(4, 17, inplace=True)']\n",
      "12169357 ['df = pd.DataFrame({\"A\": [1,2,3], \"B\": [-2, 8, 1]})', 'df[[\"A\", \"B\"]].max(axis=1)', 'df[\"C\"] = df[[\"A\", \"B\"]].max(axis=1)', 'df[\"C\"] = df.max(axis=1)']\n",
      "12170403 [\"df['new_col'] = range(1, len(df) + 1)\", 'df = df.reset_index()']\n",
      "12183507 ['my_series.apply((lambda x: your_func(a,b,c,d,...,x)))', 'my_series.apply(your_function, args=(2,3,4), extra_kw=1)']\n",
      "12184679 []\n",
      "12192021 [\"df = pandas.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))\", 'rows = random.sample(df.index, 10)', 'df_90 = df.drop(rows)']\n",
      "12193309 [\"tp = read_csv('large_dataset.csv', iterator=True, chunksize=1000)  # gives TextFileReader, which is iterable with chunks of 1000 rows.\", 'df = concat(tp, ignore_index=True)  # df is DataFrame. If errors, do `list(tp)` instead of `tp`']\n",
      "12201723 [\"df = pandas.DataFrame({'month': np.random.randint(0,11, 100), 'A': np.random.randn(100), 'B': np.random.randn(100)})\", \"df.join(df.groupby('month')['A'].sum(), on='month', rsuffix='_r')\"]\n",
      "12204428 ['A = pandas.DataFrame({', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)', 'A = A.reset_index(drop=True)']\n",
      "12207352 ['my_series = pandas.Series([1,2,2,3,3,3, \"fred\", 1.8, 1.8])', 'counts = my_series.value_counts()', 'len(counts)', 'sum(counts)']\n",
      "12250416 []\n",
      "12286958 ['df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)', 'plt.yticks(np.arange(0.5, len(df.index), 1), df.index)', 'plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)']\n",
      "12307162 []\n",
      "12322877 [\"df = pandas.DataFrame({'b':[2,2,4,5], 'c': [3,3,0,9]}, index=[1,1,3,7])\", 'df_unique = df.groupby(level=0).first()']\n",
      "12323599 ['df.drop_duplicates()']\n",
      "12326113 ['df1.apply(lambda x: x.asof(df2.index))']\n",
      "12329993 ['                cols.append(x)', '                cols.insert(0, x)']\n",
      "12332974 []\n",
      "12335016 []\n",
      "12336039 []\n",
      "12342180 []\n",
      "12356541 []\n",
      "12358601 ['new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]', \"df = pd.DataFrame(np.random.randn(6, 4), columns=['ddd', 'fff', 'aaa', 'ppp'])\", 'last_row = df.ix[df.last_valid_index()]', 'last_row.argsort()', 'df[last_row.argsort()]']\n",
      "12377080 ['df[\"isHammer\"] = map(is_hammer, df[\"Open\"], df[\"Low\"], df[\"Close\"], df[\"High\"])']\n",
      "12377083 [\"d.apply(lambda row: min([row['A'], row['B']])-row['C'], axis=1)\"]\n",
      "12394122 []\n",
      "12407691 ['test[\"x\"][5:10].plot()']\n",
      "12433236 []\n",
      "12449785 [\"plot(test['x'][5:10].values)\", \"plot(test['x'][5:10].reset_index(drop=True))\", \"test[5:10].set_index('x')['y'].plot()\"]\n",
      "12497577 [\"df.groupby(['A']).max()\"]\n",
      "12504527 [\"Sr1 = pd.Series([1,2,3,4], index = ['A', 'B', 'C', 'D'])\", \"Sr2 = pd.Series([5,6], index = ['A', 'C'])\", 'Sr1.add(Sr2, fill_value=0)']\n",
      "12505031 []\n",
      "12505089 [\"d1 = pd.DataFrame({'ticker' : ['spx 5/25/2001 p500', 'spx 5/25/2001 p600', 'spx 5/25/2001 p700']})\", 'd1.ticker.str.split().tolist()']\n",
      "12510334 []\n",
      "12525836 ['df_norm = (df - df.mean()) / (df.max() - df.min())', 'df_norm.mean()', 'df_norm.max() - df_norm.min()']\n",
      "12555491 [\"df1['e'] = df1['a'].map(lambda x: np.random.random())\"]\n",
      "12555510 [\"df1['e'] = Series(np.random.randn(sLength), index=df1.index)\", \"sLength = len(df1['a'])\", \"df1['e'] = p.Series(np.random.randn(sLength), index=df1.index)\", \"df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)\", 'df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)']\n",
      "12570410 ['P1Channels = data.filter(regex=\"P1\")', 'P1Sum = P1Channels.sum(axis=1)']\n",
      "12605055 [\"df['Date'].str[-4:].astype(int)\", \"df['Date'].str.extract('(?P<year>\\\\d{4})').astype(int)\", \"df['Date'] = df['Date'].apply(lambda x: int(str(x)[-4:]))\", \"df['Date'] = df['Date'].apply(convert_to_year)\"]\n",
      "12607018 []\n",
      "12627465 [\"cond = df['A'].str.contains('a') & (df['B'] == 20)\", 'df.drop(df[cond].index.values)']\n",
      "12681217 [\"pd.concat([Series(row['var2'], row['var1'].split(','))              \", '                    for _, row in a.iterrows()]).reset_index()']\n",
      "12707465 []\n",
      "12726468 [\"source = pd.DataFrame({'A': ['foo', 'bar'], 'B': [1, 2], 'C': [(1,2), (3,4)]})\"]\n",
      "12727919 []\n",
      "12741168 []\n",
      "12834193 []\n",
      "12846154 []\n",
      "12850453 ['bigdata = data1.append(data2, ignore_index=True)']\n",
      "12862196 [\"df2.pivot_table(values='X', rows='Y', cols='Z', \", '                         aggfunc=lambda x: len(x.unique()))']\n",
      "12874054 [\"df = male_trips.groupby('start_station_id').size()\"]\n",
      "12874135 ['count_series = male_trips.start_station_id.value_counts()', '                male_trips[male_trips.start_station_id.isin(stations.id.values)]']\n",
      "12882439 [\"df.to_csv('pandasfile.csv', float_format='%.3f')\", \"df.to_csv('pandasfile.csv', float_format='%g')\"]\n",
      "12961158 []\n",
      "12975518 []\n",
      "12992260 []\n",
      "13003524 []\n",
      "13020027 ['s.asfreq(BDay())', 's.ix[x:y].asfreq(BDay())', 's.ix[x:y].asfreq(BDay()).count()']\n",
      "13021797 ['df = DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})', 'df.columns.get_loc(\"pear\")']\n",
      "13036844 []\n",
      "13036848 ['grouped = df3.groupby(level=0)', 'df4 = grouped.last()', \"idx = pandas.MultiIndex.from_tuples([('a', letter) for letter in list('abcde')])\", \"df1 = pandas.DataFrame(np.random.normal(size=(5,2)), index=idx, columns=['colA', 'colB'])\", \"df1 = df1.append(df1.select(lambda idx: idx[1] in ['c', 'e']))\", 'groups = df1.groupby(level=df1.index.names)  ', 'groups.last() # or .first()']\n",
      "13052373 [\"    return DataFrame({'class': [row['class']] * row['count']})\", \"df.groupby('class', group_keys=False).apply(f)\", \"df.groupby('class', group_keys=False).apply(f)\"]\n",
      "13053267 []\n",
      "13053381 []\n",
      "13053967 []\n",
      "13059751 ['df.drop_duplicates(subset=\\'A\\', keep=\"last\")', \"df.groupby('A', group_keys=False).apply(lambda x: x.ix[x.B.idxmax()])\"]\n",
      "13070405 ['        ws.append(w)', '        wt.append(x*ws[i])']\n",
      "13086305 []\n",
      "13115473 [\"data.set_index('Date').diff()\"]\n",
      "13130357 []\n",
      "13148611 ['cols = df.columns.tolist()']\n",
      "13165753 []\n",
      "13181960 ['pd.concat([group for _, group in grouped if len(group) > 1])']\n",
      "13193256 ['df.to_records()', 'df.to_records().dtype', \"df.index = df.index.astype('i8')\", \"df.to_records().view([('ID', '<i8'), ('A', '<f8'), ('B', '<f8'), ('C', '<f8')])\"]\n",
      "13216688 []\n",
      "13226352 [\"df = pd.DataFrame(np.random.randn(6,2),index=pd.MultiIndex.from_tuples(list(zip(*np.arrays))),columns=['A','B'])\", \"df.xs('one')\", \"df.xs('B', axis=1)\"]\n",
      "13237914 [\"pandas.set_option('display.max_columns', 7)\", \"pandas.set_option('display.max_columns', None)\"]\n",
      "13252767 []\n",
      "13257677 [\"df = pd.DataFrame({'A':[1,1,2,2],'B':[1,2,1,2],'values':np.arange(10,30,5)})\", \"df['sum_values_A'] = df.groupby('A')['values'].transform(np.sum)\"]\n",
      "13270110 [\"df1 = DataFrame({'key':[1,1], 'col1':[1,2],'col2':[3,4]})\", \"df2 = DataFrame({'key':[1,1], 'col3':[5,6]})\", \"merge(df1, df2,on='key')[['col1', 'col2', 'col3']]\"]\n",
      "13295801 ['df.fillna(0)', 'df[1].fillna(0, inplace=True)']\n",
      "13315962 ['result = dataframe.mul(series, axis=0)']\n",
      "13316001 [\"df.insert(0, 'mean', df.mean(1))\"]\n",
      "13332682 ['x = p.Series()', '   x = x.set_value(i, i**2)']\n",
      "13337376 []\n",
      "13371090 ['ts = pd.Series([2,1,2,1,5], index=date_index)', 'ts.reindex(pd.date_range(min(date_index), max(date_index)))']\n",
      "13384494 [\"read_csv('sample.csv', dtype={'ID': object})\"]\n",
      "13385921 []\n",
      "13386025 ['        return text.strip()', '    return int(text.strip(\\'\" \\'))', 'table = pd.read_table(\"data.csv\", sep=r\\',\\',']\n",
      "13389808 [\"s.loc[('b', slice(2, 10))]\", \"s.loc[(slice('a', 'b'), slice(2, 10))]\"]\n",
      "13413842 []\n",
      "13413845 []\n",
      "13415772 ['df = DataFrame([[1, 2, 3], [4, 5, 6]])']\n",
      "13434501 ['df = pd.DataFrame(np.random.randn(10,3))', 'df.dropna()     #drop all rows that have any NaN values', \"df.dropna(how='all')     #drop only if ALL columns are NaN\", 'df.dropna(thresh=2)   #Drop row if it does not have at least two values that are **not** NaN', 'df.dropna(subset=[1])   #Drop only if NaN in specific column (as asked in the question)']\n",
      "13445630 ['d = d.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)']\n",
      "13446268 [\"pd.date_range(start, end, freq='M').shift(15, freq=pd.datetools.day)\"]\n",
      "13447176 [\"data[data.groupby('tag').pid.transform(len) > 1]\", 'data = pandas.DataFrame(', \"bytag = data.groupby('tag').aggregate(np.count_nonzero)\", \"print(data[data['tag'].isin(tags)])\"]\n",
      "13456432 ['test.append(pd.Series(200, index=[101]))']\n",
      "13485766 []\n",
      "13581730 ['pd.DataFrame.from_dict({(i,j): user_dict[i][j] ', 'for user_id, d in user_dict.iteritems():', '    user_ids.append(user_id)', \"    frames.append(pd.DataFrame.from_dict(d, orient='index'))\", 'pd.concat(frames, keys=user_ids)']\n",
      "13583024 []\n",
      "13592901 ['df.groupby(\"dummy\").agg({\"returns\": [np.mean, np.sum]})', \"df.groupby('dummy').agg({'returns':\"]\n",
      "13593882 ['pd.concat([cba, nab], axis=1, keys=keys)']\n",
      "13616382 [\"df.query('col1 <= 1 & 1 <= col1')\"]\n",
      "13653490 [\"iter_csv = pandas.read_csv('file.csv', iterator=True, chunksize=1000)\", \"df = pd.concat([chunk[chunk['field'] > constant] for chunk in iter_csv])\"]\n",
      "13655271 [\"pd.to_datetime('2008-02-27')\", 'df.index = pd.to_datetime(df.index)', \"df['date_col'] = df['date_col'].apply(pd.to_datetime)\"]\n",
      "13659944 [\"d.groupby(['ip', 'useragent']).count()\"]\n",
      "13665099 []\n",
      "13674286 [\"idx = pd.date_range('2011-05-01', '2011-07-01')\", 's = pd.Series(np.random.randn(len(idx)), index=idx)', \"ax.plot_date(idx.to_pydatetime(), s, 'v-')\"]\n",
      "13680953 ['df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])', 'df1.join(df2)', \"df1 = DataFrame([[1,'one'],[2,'two'],[3,'three'],[4,'four'],[5,'five']], columns=['number', 'name'])\", \"df2 = DataFrame([['a','one'],['b','too'],['c','three'],['d','fours'],['e','five']], columns=['letter', 'name'])\", \"df2['name'] = df2['name'].apply(lambda x: difflib.get_close_matches(x, df1['name'])[0])\", 'df1.merge(df2)']\n",
      "13682381 [\"data['result'] = data['result'].map(lambda x: x.lstrip('+-').rstrip('aAbBcC'))\"]\n",
      "13688105 [\"df['result'].str.lstrip('+-').str.rstrip('aAbBcC')\"]\n",
      "13703721 ['pd.to_datetime(str(dt64))', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)', 'pd.to_datetime(str(dt64)).replace(tzinfo=None)']\n",
      "13703930 ['dt64.tolist()']\n",
      "13704307 ['dt = datetime.utcnow()', 'datetime.utcfromtimestamp(ts)', 'np.datetime64(datetime.utcnow()).astype(datetime)', \"numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)\", \"numpy.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)\", \"dtype('<M8[ns]')\", 'datetime.utcfromtimestamp(dt64.astype(int) * ns)', \"dtype('<M8[s]')\", 'datetime.utcfromtimestamp(dt64.astype(int))']\n",
      "13713475 []\n",
      "13731128 ['[tuple(x) for x in data_set.to_records(index=False)]']\n",
      "13741439 [\"data['weekday'] = data['my_dt'].apply(lambda x: x.weekday())\"]\n",
      "13753918 [\"Timestamp(numpy.datetime64('2012-05-01T01:00:00.000000'))\", \"pandas.to_datetime('2012-05-01T01:00:00.000000+0100')\"]\n",
      "13758846 [\"df1 = pandas.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\"]\n",
      "13786327 ['todays_date = datetime.datetime.now().date()', \"index = pd.date_range(todays_date-datetime.timedelta(10), periods=10, freq='D')\", 'df_ = pd.DataFrame(index=index, columns=columns)', 'df_ = df_.fillna(0) # with 0s rather than NaNs', 'df = pd.DataFrame(data, index=index, columns=columns)']\n",
      "13788301 [\"np.round(dtindex_or_datetime_col.astype(np.int64), -9).astype('datetime64[ns]')\", \"t1 = Timestamp('2012-1-1 00:00:00')\", \"t2 = Timestamp('2012-1-1 00:00:00.000333')\", 'long(round(t2.value, -9)) # round milli-, micro- and nano-seconds', 'Timestamp(long(round(t2.value, -9)))', '    return Timestamp(long(round(ts.value, -9)))', 'dtindex.map(to_the_second)']\n",
      "13833239 [\"df.drop_duplicates(['foo','bar'])\", \"df.pivot('foo','bar','baz')\"]\n",
      "13839029 ['df.set_index(s.index).sort()', \"s = df['m'].replace({'March':0, 'April':1, 'Dec':3})\"]\n",
      "13842286 [\"df.xs('C')['x']=10\", \"df.xs('C', copy = False)['x']=10\"]\n",
      "13843741 []\n",
      "13851602 [\"df[df['column name'].map(len) < 2]\"]\n",
      "13854901 []\n",
      "13866073 [\"songs.sort_index(by=['Peak', 'Weeks'], ascending=[True, False])\"]\n",
      "13873014 ['ax = df1.plot()', 'df2.plot(ax=ax)']\n",
      "13876784 [\"df.groupby(['Month','Year']).mean().unstack()\", \"df.groupby(['Month','Year']).mean().unstack().plot()\"]\n",
      "13888546 []\n",
      "13893632 ['prices.lookup(orders.Date, orders.ticker)']\n",
      "13921674 []\n",
      "13937141 ['df[(df.one.isin(checkList)) | (df.two.isin(checkList))]']\n",
      "13938831 ['df = DataFrame({\"A\": [8,9,5,4], \"B\": [3,4,4,8], \"C\": [5,0,3,5], \"D\": [8,4,8,1]})', 'df.max()']\n",
      "13977244 [\"index = pd.date_range('1/1/2000', periods=8)\", \"df = pd.DataFrame( np.random.randn(8,3), index=index, columns=list('ABC'))  \", \"store.append('df_cols', df, axes='columns')\", \"store.select('df_cols', [Term('columns', '=', 'A')])\"]\n",
      "13998600 [\"df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)\", \"df.groupby('id')['x'].cumsum()\"]\n",
      "13999234 [\"store.select('df', [ Term('index', '>', Timestamp('20010105')), \", \"df.reindex(columns = ['A','B'])\"]\n",
      "14000420 [\"df['date'] = df['datetime'].apply(lambda x: x.strftime('%d%m%Y'))\", \"df['time'] = df['datetime'].apply(lambda x: x.strftime('%H%M%S'))\", \"df[['date', 'time', ... ]].to_csv('df.csv')\"]\n",
      "14016590 [\"index = df['b'].index[df['b'].apply(np.isnan)]\", 'df_index = df.index.values.tolist()', '[df_index.index(i) for i in index]']\n",
      "14033137 ['pd.isnull(df).any(1).nonzero()[0]']\n",
      "14058892 ['s = pd.Series(np.arange(10.0))', 'mask = np.logical_not(s.isin(x))', 's[-s.isin(x)]']\n",
      "14059783 [\"order_df['Value'] = order_df.apply(lambda row: (row['Prices']*row['Amount']\"]\n",
      "14060360 [\"f = DataFrame({'a': ['1','2','3'], 'b': ['2','3','4']})\"]\n",
      "14060625 [\"orders_df['C'] = orders_df.Action.apply(\"]\n",
      "14063022 [\"dr = pd.date_range(datetime(2009,1,1),datetime(2010,12,31),freq='H')\", 'dt = pd.DataFrame(rand(len(dr),2),dr)']\n",
      "14071265 [\"df['Values'] = values.where(df.Action == 'Sell', other=-values)\"]\n",
      "14110955 [\"df = pd.read_csv(io.BytesIO(text), delimiter = ' ', \", \"df.set_index(['STK_ID','RPT_Date'], inplace = True)\", \"index = [('000999','20121231')] + df.index.tolist()[1:]\", 'df.index = pd.MultiIndex.from_tuples(index, names = names)', 'df.reset_index(inplace = True)', \"df = df.set_index(['STK_ID','RPT_Date'])\"]\n",
      "14148511 []\n",
      "14163174 ['y = np.where(np.isnan(x), None, x)']\n",
      "14163209 ['df1 = df.where((pd.notnull(df)), None)', 'df = pd.DataFrame([1, np.nan])', 'df1 = df.where((pd.notnull(df)), None)', \"df1 = df.astype(object).replace(np.nan, 'None')\"]\n",
      "14179954 [\"testdataframe = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])\", '    testdataframe[col].plot(style=style, lw=lw, ax=ax)', \"testdataframe1 = pd.DataFrame(np.arange(12).reshape(4,3), columns=['A', 'B', 'C'])\", \"testdataframe2 = pd.DataFrame(np.random.normal(size=(4,3)), columns=['D', 'E', 'F'])\", 'testdataframe1.plot(style=styles1, ax=ax)', 'testdataframe2.plot(style=styles2, ax=ax)']\n",
      "14189912 [\"columns = pd.MultiIndex.from_arrays([['basic_amt']*4,\", 'df = pd.DataFrame([(1,1,2,4),']\n",
      "14193170 []\n",
      "14224489 []\n",
      "14225838 [\"        df.to_excel(writer,'sheet%s' % n)\"]\n",
      "14247708 ['df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])', 'df.isnull()', 'df.isnull().any(axis=1)', 'df[df.isnull().any(axis=1)]', 'df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])', 'pd.isnull(df)', 'pd.isnull(df).any(axis=1)', 'df[pd.isnull(df).any(axis=1)]']\n",
      "14248948 ['ser.value_counts()', 'ser.value_counts().reindex(ser[:3])']\n",
      "14268804 [\"    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))\", '   for chunk in pd.read_table(f, chunksize=50000):', \"             frame = chunk.reindex(columns = v['fields'], copy = False)    \", \"             store.append(g, frame, index=False, data_columns = v['dc'])\", 'frame = store.select(group_that_I_want)', 'store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)', \"store.select(group, where = ['field_1000=foo', 'field_1001>0'])\"]\n",
      "14287518 ['aCollection.insert((a[1].to_dict() for a in df.iterrows()))', \"pd.DataFrame(list(mongoCollection.find({'anAttribute':{'$gt':2887000, '$lt':2889000}})))\", \"aJoinDF = pandas.DataFrame(list(mongoCollection.find({'anAttribute':{'$in':Att_Keys}})))\", \"df = pandas.merge(df, aJoinDF, on=aKey, how='left')\", 'collection.update({primarykey:foo},{key:change})']\n",
      "14306902 [\"df = pd.DataFrame(np.random.randn(10,2), columns=['col1','col2'])\", \"df['col3'] = np.arange(len(df))**2 * 100 + 100\", \"df.plot(kind='scatter', x='col1', y='col2', s=df.col3)\", \"colors = np.where(df.col3 > 300, 'r', 'k')\", \"df.plot(kind='scatter', x='col1', y='col2', s=120, c=colors)\", 'subset_a = df[cond].dropna()', 'subset_b = df[~cond].dropna()', \"df['subset'] = np.select([df.col3 < 150, df.col3 < 400, df.col3 < 600],\"]\n",
      "14306921 [\"df.set_index(['Name', 'Destination'])\"]\n",
      "14307460 []\n",
      "14307961 ['    return basis.apply(applyToWindow)']\n",
      "14345875 [\"misc['product_desc'] = misc['product_desc'].str.replace('\\\\n', '')\"]\n",
      "14349645 []\n",
      "14349766 ['axes.set_xlim([np.floor(positions.min()), np.ceil(positions.max())])']\n",
      "14351567 [\"ax1.plot(np.random.rand(20), np.random.rand(20), 'ok')\", \"ax2.plot(np.random.rand(20), np.random.rand(20), 'ok')\"]\n",
      "14359211 ['splits = np.append(np.where(np.diff(a) != 0)[0],len(a)+1)+1']\n",
      "14360423 [\"df.reset_index().groupby('A')['index'].apply(np.array)\", \"df = DataFrame([3]*4+[4]*4+[1]*4, columns=['A'])\", \"df.reset_index().groupby('A')['index'].apply(np.array)\", \"grp = df.groupby('A')\", \"df['block'] = (df.A.shift(1) != df.A).astype(int).cumsum()\", \"df.reset_index().groupby(['A','block'])['index'].apply(np.array)\"]\n",
      "14363721 ['df = DataFrame(dict(x=[0,0,1,0,1], y=[1,0,1,1,0], z=[0,0,1,0,1]))', \"df = df.drop(['x','y'], axis=1)\"]\n",
      "14363758 ['df.drop(df.columns[1:], axis=1)']\n",
      "14365647 []\n",
      "14366084 ['            column[h].append(v)']\n",
      "14383654 ['df = pd.DataFrame(np.random.random((5, 5)))']\n",
      "14407329 []\n",
      "14428450 []\n",
      "14432914 ['price2 = price.reset_index()']\n",
      "14451264 [\"df = pd.DataFrame(range(50), columns  = ['filtercol'])\", 'out = pd.cut(df.filtercol, bins = filter_values)', 'counts = pd.value_counts(out)', 'counts.reindex(out.cat.categories)']\n",
      "14487936 ['df = pd.read_sql(sql, cnxn)']\n",
      "14508355 ['df.columns = df.columns.get_level_values(0)', \"df.columns = [' '.join(col).strip() for col in df.columns.values]\", \"[' '.join(col).strip() for col in df.columns.values]\"]\n",
      "14508639 ['mi.tolist()', 'ind = pd.Index([e[0] + e[1] for e in mi.tolist()])']\n",
      "14530027 [\"df.groupby('GRP').agg(f)\", \"f = {'A':['sum','mean'], 'B':['prod'], 'D': lambda g: df.ix[g.index].E.sum()}\", \"df.groupby('GRP').agg(f)\", \"cust = lambda g: g[df.ix[g.index]['C'] < 0.5].sum()\", \"df.groupby('GRP').agg(f)\"]\n",
      "14540509 ['ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]', 'ts.ix[ts.index.indexer_between_time(datetime.time(18), datetime.time(9),', \"rng = pd.date_range('1/1/2000', periods=24, freq='H')\", 'ts = pd.Series(pd.np.random.randn(len(rng)), index=rng)', 'ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))] ', 'df = pd.DataFrame(ts)', 'df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]']\n",
      "14568392 []\n",
      "14630250 []\n",
      "14657511 ['df = pd.read_csv(\"dup.csv\")', 'df[ids.isin(ids[ids.duplicated()])].sort(\"ID\")', 'pd.concat(g for _, g in df.groupby(\"ID\") if len(g) > 1)']\n",
      "14661768 ['df.drop(df.index[[1,3]])']\n",
      "14669654 ['df = pd.DataFrame([{\"a\": 1}, {\"a\": 2}])', 'df.tail(5)', 'df1.irow(slice(-3, None))']\n",
      "14688398 ['df = pd.DataFrame([])']\n",
      "14688529 []\n",
      "14714452 [\"df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')\", \"df['desired_output'] = df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')\"]\n",
      "14717374 ['df = pandas.DataFrame([1,2,3,4], columns=[\"data\"])']\n",
      "14717761 [\"df['desired_output'] = df.le(2.5)\"]\n",
      "14734148 []\n",
      "14734627 [\"gb.get_group('foo')\", 'gb[[\"A\", \"B\"]].get_group(\"foo\")', 'gb[\"C\"].get_group(\"foo\")']\n",
      "14745484 [\"df = pd.DataFrame(df.row.str.split(' ',1).tolist(),\"]\n",
      "14746845 [\"df.set_index('Firstlevel', append=True, inplace=True)\", \"df.reorder_levels(['Firstlevel', 'A', 'B'])\"]\n",
      "14760930 []\n",
      "14762651 ['r.plot([1,2,3],[1,2,3], xlab=\"X\", ylab=\"Y\")', \"r.assign('testX', df.A)\", \"r.assign('testY', df.B)\", \"r.assign('bob', rdf)\"]\n",
      "14789513 ['        for name, values in obj.iteritems():', '        return rpy2.robjects.vectors.DataFrame(od)', \"r.plot(rpy2.robjects.Formula('c3~c2'), data)\", 'p.plot()']\n",
      "14809026 []\n",
      "14809149 []\n",
      "14813733 [\"df  = DataFrame(data, index = ['first', 'second'], columns=['c1','c2'])\", 'df  = DataFrame(np.random.rand(2,2), index=i, columns=c)']\n",
      "14814282 ['pd.DataFrame(preprocessing.scale(data), index = data.index, columns = data.columns) ']\n",
      "14822703 [\"s = pd.Series([0,1,8,9], name = 'BayFail')\", 's.tolist()']\n",
      "14843650 ['df = pd.DataFrame(np.random.random((6, 5)) * 10,               ', \"ax = df.plot(kind='bar', stacked=True, align='center')\"]\n",
      "14861132 [\"sample.resample('60Min', how=conversion, base=30)\"]\n",
      "14887119 ['df = pandas.DataFrame({', \"fg.map(pyplot.scatter, 'Weight (kg)', 'Height (cm)').add_legend()\", '    categories = np.unique(df[catcol])', '    colors = np.linspace(0, 1, len(categories))', '    df[\"Color\"] = df[catcol].apply(lambda x: colordict[x])', \"    df = pd.DataFrame({'Height':np.random.normal(size=10),\"]\n",
      "14900065 [\"df4 = df3.drop_duplicates(subset='rownum', keep='last')\", \"df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')\"]\n",
      "14917572 ['df = pandas.DataFrame({\"s1_x\": scipy.randn(10), \"s1_y\": scipy.randn(10), \"s2_x\": scipy.randn(10), \"s2_y\": scipy.randn(10)})', \"df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\", 'df.stack(0).reset_index(1)', \"df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\", 'pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)', \"df = df.set_index('names')\", \"df.columns = pandas.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\", 'df.stack(0).reset_index(1)']\n",
      "14941170 []\n",
      "14942625 [\"sum_B_over_A = df.groupby('A').sum().B\", \"df.sort(['sum_B_over_A', 'A', 'B']).drop('sum_B_over_A', axis=1)\"]\n",
      "14946246 [\"grp = df.groupby('A')\", \"grp[['B']].transform(sum).sort('B')\", \"sort1 = df.ix[grp[['B']].transform(sum).sort('B').index]\", \"sort2 = sort1.groupby('A', sort=False).apply(f)\", 'sort2.reset_index(0, drop=True)']\n",
      "14964637 [\"df.xs(('B',), level='Alpha')\", \"df.xs(('B', False), level=('Alpha', 'Bool'))\", \"ix = df.index.get_level_values('Int').isin(ix_vals)\"]\n",
      "14985695 [\"df = pd.DataFrame(np.hstack([vals, vals]), columns=['Time', 'H1', 'N2', 'Time Relative', 'N2', 'Time'] )\", 'df.T.drop_duplicates().T', \"df2 = pd.read_table('dummy.csv')\", 'df2.T.drop_duplicates().T', \"df2 = pd.read_table('dummy.csv', header=None)\", 'df2.T.drop_duplicates().T']\n",
      "14988913 ['Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData))', 'Frame = Frame.append(pandas.DataFrame(data = SomeNewLineOfData), ignore_index=True)']\n",
      "14989047 [\"dates = np.asarray(pd.date_range('1/1/2000', periods=8))\", \"df1 = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])\", 'df2 = df1.copy()', 'df = df1.append(df2)']\n",
      "14992237 [\"df2.dropna(subset=['three', 'four', 'five'], how='all')\", 'subset=filter(lambda x: len(x) > 3, df2.columns)']\n",
      "15002718 ['df = pd.DataFrame([[1, 2], [3, 4]])', 'g = df.groupby(0)', 'g.first()', 'g.nth(0)  # first', 'g.nth(-1)  # last']\n",
      "15006495 ['df = pd.DataFrame({\"A\": range(1000), \"B\": range(1000)})', 'df = pd.DataFrame({i: range(1000) for i in range(100)})']\n",
      "15009160 ['len(z)']\n",
      "15026839 []\n",
      "15030455 ['df = pd.read_csv(StringIO(csv),']\n",
      "15070110 []\n",
      "15073977 ['df = pd.DataFrame(np.random.randn(5, 10))']\n",
      "15074395 [\"df = pd.DataFrame({'Name': ['foo', 'bar'] * 3,\", 'grouped = df.groupby([\"Name\", \"Rank\"])', 'df[\"GroupId\"] = df.groupby([\"Name\", \"Rank\"]).grouper.group_info[0]']\n",
      "15097125 ['    df = pd.read_sql_query(sql, con)']\n",
      "15100193 ['df = pd.read_csv(StringIO(csv),']\n",
      "15112264 ['df.values.T.tolist()']\n",
      "15125793 ['    return pd.Series(dict(col1=a, col2=b))']\n",
      "15139677 []\n",
      "15144847 [\"df = pd.DataFrame({'A':[9,10]*6,\"]\n",
      "15203886 [\"t = pd.Timestamp('2000-02-11 00:00:00')\", 'time.mktime(t.timetuple())', 'tsframe.index.astype(np.int64) // 10 ** 9']\n",
      "15204235 ['index.astype(np.int64)', 'index.astype(np.int64) // 10**9']\n",
      "15213171 ['df[columns] = df[columns].convert_objects(convert_numeric=True)', \"x = pd.read_csv(StringIO.StringIO(data), dtype={'a': np.float32}, delim_whitespace=True)\"]\n",
      "15220374 []\n",
      "15222976 [\"source.groupby(['Country','City']).agg(lambda x: stats.mode(x)[0][0])\"]\n",
      "15223034 [\"source = pd.DataFrame({'Country' : ['USA', 'USA', 'Russia','USA'], \", \"source.groupby(['Country','City']).agg(lambda x:x.value_counts().index[0])\"]\n",
      "15244074 ['df = pd.DataFrame()', \"        df = pd.concat( [df, pd.DataFrame([tuple(line.strip().split(','))])], ignore_index=True )\"]\n",
      "15248239 ['df = pd.DataFrame([p1, p2, p3])', \"df.duplicated('name')\"]\n",
      "15252012 ['pd.read_csv(\"ragged.csv\", names=my_cols, engine=\\'python\\')']\n",
      "15262146 [\"df.groupby('A_id').apply(lambda x: pd.Series(dict(\", \"    sum_up=(x.B == 'up').sum(),\", \"    sum_down=(x.B == 'down').sum(),\", \"    over_200_up=((x.B == 'up') & (x.C > 200)).sum()\"]\n",
      "15300930 [\"df['normed'] = df.groupby(grouper).transform(lambda x: x/x.mean())\"]\n",
      "15315507 [\"df = pd.DataFrame({'A': [randint(1, 9) for x in xrange(10)],\"]\n",
      "15322715 [\"idx = df.groupby('word')['count'].idxmax()\", \"df = pd.DataFrame({'word':'a the a an the'.split(),\", \"print(df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))\", \"df = pd.DataFrame({'word':'a the a an the'.split()*N,\", \"    return (df.groupby('word').apply(lambda subf: subf['tag'][subf['count'].idxmax()]))\", \"    idx = df.groupby('word')['count'].idxmax()\", \"df2 = df.loc[idx, ['word', 'tag']].set_index('word')\", \"df2.to_dict()['tag']\"]\n",
      "15322920 []\n",
      "15333283 [\"df.b.str.contains('^f')\"]\n",
      "15361537 []\n",
      "15362700 [\"df = pd.DataFrame({'x' : [1, 2, 3, 4], 'y' : [4, 5, 6, 7]})\"]\n",
      "15364468 []\n",
      "15375176 ['d = {\"my_label\": Series([\\'A\\',\\'B\\',\\'A\\',\\'C\\',\\'D\\',\\'D\\',\\'E\\'])}', 'df = DataFrame(d)', '    return len(values)', 'grouped_count = df.groupby(\"my_label\").my_label.agg(get_count)', 'data = grouped_count.apply(as_perc, total=df.my_label.count())']\n",
      "15411596 [\"table.groupby('YEARMONTH').CLIENTCODE.nunique()\", \"table.groupby('YEARMONTH').CLIENTCODE.nunique()\"]\n",
      "15433426 ['df = pd.read_csv(\"hourmelt.csv\", sep=r\"\\\\s+\")', 'df = pd.melt(df, id_vars=[\"Date\"])', \"df = df.rename(columns={'variable': 'hour'})\", \"df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)\", 'combined = df.apply(lambda x: ', \"                    pd.to_datetime(x['Date'], dayfirst=True) + \", 'df = pd.read_csv(\"hourmelt.csv\", sep=r\"\\\\s+\")', 'df = pd.melt(df, id_vars=[\"Date\"])', \"df = df.rename(columns={'variable': 'hour'})\", \"df['hour'] = df['hour'].apply(lambda x: int(x.lstrip('h'))-1)\", \"combined = df.apply(lambda x: pd.to_datetime(x['Date'], dayfirst=True) + timedelta(hours=int(x['hour'])), axis=1)\"]\n",
      "15455455 ['df = pd.Panel.from_dict(d).to_frame()', 'pd.concat(map(pd.DataFrame, d.itervalues()), keys=d.keys()).stack().unstack(0)']\n",
      "15466103 ['df = pd.DataFrame({', \"for key, grp in df.groupby(['A']):\", \"    plt.plot(grp['B'], label=key)\", \"    plt.plot(grp['D'], label='rolling ({k})'.format(k=key))\"]\n",
      "15467189 [\"df.select(lambda x: x[1] in ['SPY','GLD'])\"]\n",
      "15557663 ['df = pd.DataFrame(range(5))', 'df_no_2.reset_index(drop=True)']\n",
      "15558350 ['    for i in range(len(data)):', '            data[i] = (name, vec.astype(np.float64))', '    return pd.DataFrame.from_items(data)']\n",
      "15570546 [\"df = pd.read_csv(incsv, index_col=['Date'], parse_dates=True)\", \"dfsum = df.groupby('State', as_index=False).sum()\", \"dfsum.append(df).set_index(['State','City']).sort_index()\"]\n",
      "15574875 [\"table = pivot_table(df, values=['SalesToday', 'SalesMTD','SalesYTD'],\\\\\", \"table.stack('City')\"]\n",
      "15590006 [\"d1.groupby('ExamenYear').agg({'Participated': len, \", \"                              'Passed': lambda x: sum(x == 'yes')})\"]\n",
      "15611666 [\"      return pd.Series({'All': len(x['StudentID']),\", \"                       'Part': sum(x['Participated'] == 'yes'),\", \"                       'Pass' :  sum(x['Passed'] == 'yes')})\", \"d1['testValue'] = np.random.randn(len(d1))\", \"    return pd.Series({'All': len(x['StudentID']),\", \"        'Part': sum(x['Participated'] == 'yes'),\", \"        'Pass' :  sum(x['Passed'] == 'yes'),\", \"        'test' : x['testValue'].mean()})\", \"d1.groupby('ExamenYear').apply(ZahlOccurence_1)\"]\n",
      "15705958 [\"df.groupby(['Mt'], sort=False)['count'].max()\", \"idx = df.groupby(['Mt'])['count'].transform(max) == df['count']\", \"df['count_max'] = df.groupby(['Mt'])['count'].transform(max)\"]\n",
      "15723905 [\"df['col_name'] = df['col_name'].astype(object)\", 'df = df.astype(object)', \"df['col_name'] = df['col_name'].astype('category')\"]\n",
      "15723994 [\"df = pd.DataFrame({'a' : [1, 2, 3, 4, 5], 'b' : ['yes', 'no', 'yes', 'no', 'absent']})\"]\n",
      "15742147 [\"df.loc[df['Value'].idxmax()]\", 'df = df.reset_index()']\n",
      "15752582 [\"df.set_index('month')\", \"df = pd.DataFrame([[1, datetime(2011,1,1)], [2, datetime(2011,1,2)]], columns=['a', 'b'])\", \"df.set_index('b')\"]\n",
      "15756128 ['data2 = data1.reset_index()', 'data3 = data2.set_index([\"Bool\", \"Dir\", \"index\"])   # index is the new column created by reset_index', 'running_sum = data3.groupby(level=[0,1,2]).sum().groupby(level=[0,1]).cumsum()']\n",
      "15772263 ['pd.rolling_mean(df.resample(\"1D\", fill_method=\"ffill\"), window=3, min_periods=1)', 'df.resample(\"1d\").sum().fillna(0).rolling(window=3, min_periods=1).mean()']\n",
      "15772330 [\"df = pd.DataFrame({'A':range(10), 'B':range(10)})\", 'df.reindex(np.random.permutation(df.index))']\n",
      "15772356 []\n",
      "15778297 []\n",
      "15786557 ['    ncol, nrow = len(df.columns), len(df)', \"        up_pt   = pt_a.join(pt_b, how='inner')\", \"        down_pt = pt_c.join(pt_d, how='inner')\", \"        up_pt.insert(left_cols, '..', '..')\", \"        down_pt.insert(left_cols, '..', '..')\", '    overlap_qty = len(up_pt) + len(down_pt) - len(df)', '    down_pt = down_pt.drop(down_pt.index[range(overlap_qty)]) # remove overlap rows', \"    dt_str_list = down_pt.to_string().split('\\\\n') # transfer down_pt to string list\"]\n",
      "15799355 [\"df.groupby(pd.Grouper(freq='2D', level=-1))\", 'result = (df.groupby([level_values(i) for i in [0,1]]', \"                      +[pd.Grouper(freq='2D', level=-1)]).sum())\", '    return (df.groupby([level_values(i) for i in [0,1]]', \"                       +[pd.Grouper(freq='2D', level=-1)]).sum())\", '    df = df.reset_index(level=[0, 1])', \"    return df.groupby(['State','City']).resample('2D').sum()\", '    return (df.unstack(level=[0,1])', '    dates = pd.DatetimeIndex([DT.date(2012,1,1)+DT.timedelta(days = i) for i in range(4)]*4)', '    df = pd.DataFrame(', \"    dates = pd.date_range('2000-1-1', periods=N)\", '    index = pd.MultiIndex.from_product([states, cities, dates], ', '    df = pd.DataFrame(np.random.randint(10, size=(len(index),2)), index=index,', 'len(df)']\n",
      "15800314 [\"df = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'foo',\", \"    store.append('df',df,data_columns=['A','B','C'])\", \"    groups = store.select_column('df','A').unique()\", \"        grp = store.select('df',where = [ 'A=%s' % g ])\", \"        l.append(grp[['D','E','F']].sum())\"]\n",
      "15813787 [\"df.unstack(level=[0,1]).resample('2D', how='sum').stack(level=[2,1]).swaplevel(2,0)\"]\n",
      "15822811 [\"df1 = pd.DataFrame(dict(A = range(10000)),index=pd.date_range('20130101',periods=10000,freq='s'))\", 'df4 = pd.DataFrame()']\n",
      "15855998 ['cov = np.cov(a, b)', '    W = np.cumsum(W) * np.sqrt(dt)  # standard brownian motion ###', 'cov = np.cov(a, b)', 'plt.plot(a)', 'plt.plot(b)', \"df = pd.DataFrame({'a': a, 'b': b})\", \"beta2 = (df.corr() * df['b'].std() * df['a'].std() / df['a'].var()).ix[0, 1]\"]\n",
      "15863028 ['df = pd.DataFrame({\"date\": range(10, 64, 8)})', 'df = pd.DataFrame({\"date\": range(10, 64, 8)})']\n",
      "15889056 ['line = DataFrame({\"onset\": 30.0, \"length\": 1.3}, index=[3])', 'df2 = concat([df.ix[:2], line, df.ix[3:]]).reset_index(drop=True)']\n",
      "15911372 [\"ax = df.set_index('x')['y'].plot(style='o')\", \"    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\", '    for i, point in a.iterrows():']\n",
      "15916686 [\"df = df.div(df.QT, axis='index')\"]\n",
      "15923878 ['    return x.ix[random.sample(x.index, n)]']\n",
      "15943975 ['df = pd.DataFrame(np.arange(9).reshape(3,3))', 'len(df.index)']\n",
      "15948271 []\n",
      "15990537 [\"df1 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))\", \"df2 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))\", 'pd.concat(dict(df1 = df1, df2 = df2),axis=1)']\n",
      "15996274 []\n",
      "15998251 ['s = Series([True, True, True, False])']\n",
      "15998993 ['s = pd.Series([True, True, False, True])', 's = pd.Series([True, True, False, True]*10000)']\n",
      "16033048 [\"df['lat_long'] = df[['lat', 'long']].apply(tuple, axis=1)\"]\n",
      "16068497 []\n",
      "16074407 []\n",
      "16089219 ['df = df.sort_index(axis=1)']\n",
      "16099579 []\n",
      "16104482 [\"df = DataFrame(randn(5,2),index=range(0,10,2),columns=list('AB'))\"]\n",
      "16104567 [\"df = DataFrame([ Timestamp('20010101'), Timestamp('20040601') ])\", \"df = DataFrame([ Timestamp('20010101'), \", \"                          Timestamp('20040601') ],columns=['age'])\", \"df['today'] = Timestamp('20130419')\", \"df['years'] = df['diff'].apply(lambda x: float(x.item().days)/365)\"]\n",
      "16134561 [\"df = pd.DataFrame(a, columns=['one', 'two', 'three'])\", \"df[['two', 'three']] = df[['two', 'three']].astype(float)\"]\n",
      "16168245 []\n",
      "16176457 ['df = pd.DataFrame([1, 2, 3], index=[dt.datetime(2013, 1, 1), dt.datetime(2013, 1, 3), dt.datetime(2013, 1, 5)])', 'start = df.index.searchsorted(dt.datetime(2013, 1, 2))', 'end = df.index.searchsorted(dt.datetime(2013, 1, 4))']\n",
      "16179190 ['df.sort_index()']\n",
      "16202796 []\n",
      "16242202 [\"df = pd.DataFrame({'textcol' : np.random.rand(5)})\", \"df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))\", \"pd.concat([df, df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1}))], axis=1)\"]\n",
      "16245109 [\"df.merge(df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1})), \"]\n",
      "16255680 ['    cursor = db[collection].find(query)', '    df =  pd.DataFrame(list(cursor))']\n",
      "16266318 ['times = pd.to_datetime(df.timestamp_col)', 'df.groupby([times.hour, times.minute]).value_col.sum()']\n",
      "16271849 ['df = pd.DataFrame(list(BlogPost.objects.all().values()))', 'df = pd.DataFrame(list(BlogPost.objects.filter(date__gte=datetime.datetime(2012, 5, 1)).values()))', \"df = pd.DataFrame(list(BlogPost.objects.all().values('author', 'date', 'slug')))\"]\n",
      "16327135 ['df = pd.DataFrame({\"A\": [1,2,3], \"B\": [2,3,4]})']\n",
      "16342396 []\n",
      "16345735 [\"df = pd.DataFrame({'id': [1,1,2,2,1,2,1,1], 'x':[10,20,100,200,np.nan,np.nan,300,np.nan]})\", \"df['x'] = df.groupby(['id'])['x'].ffill()\"]\n",
      "16354103 []\n",
      "16354730 [\"df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)\"]\n",
      "16359854 [\"df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,\", \"df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)\", \"labels = np.array('White Yellow Amber Red'.split())\", \"df = df.pivot(index='ID', columns='status', values='quantity')\", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])', \"df = pd.DataFrame({'ID': ('STRSUB BOTDWG'.split())*4,\", \"df['status'] = pd.cut(df['Days Late'], bins=[-1, 14, 35, 56, 365], labels=False)\", \"labels = np.array('White Yellow Amber Red'.split())\", \"df = df.pivot(index='ID', columns='status', values='quantity')\", 'df = df.reindex(columns=labels[::-1], index=df.index[::-1])']\n",
      "16377383 [\"for title, group in df.groupby('ModelID'):\", \"    group.plot(x='saleDate', y='MeanToDate', title=title)\"]\n",
      "16393023 [\"df['korisnika'].plot(ax=axs[0])\", \"df['osiguranika'].plot(ax=axs[1])\"]\n",
      "16398361 []\n",
      "16433953 [\"pd.set_option('display.height', 500)\", \"pd.set_option('display.max_rows', 500)\"]\n",
      "16476974 []\n",
      "16477603 [\"df.to_sql(con=con, name='table_name_for_df', if_exists='replace', flavor='mysql')\"]\n",
      "16522626 []\n",
      "16545324 [\"df['a_bsum'] = df.groupby('A')['B'].transform(sum)\", \"df.sort(['a_bsum','C'], ascending=[True, False]).drop('a_bsum', axis=1)\"]\n",
      "16576030 ['df[abc_columns].applymap(categories.get)', \"abc_categories = map(lambda x: x + '_category', abc_columns)\", 'df[abc_categories] = df[abc_columns].applymap(categories.get)', \"abc_columns = [col for col in df.columns if str(col).startswith('abc')]\"]\n",
      "16597375 ['df = pd.DataFrame()', 'data = pd.DataFrame({\"A\": range(3)})', 'df.append(data)', 'df = df.append(data)']\n",
      "16616454 []\n",
      "16629125 [\"df1 = pd.DataFrame({'x':x})\", \"df2 = df1.set_index('x', drop=False)\", 'df3 = df2.sort_index()']\n",
      "16629243 [\"df = DataFrame(randn(1000000,2),columns=list('AB'))\", \"    df.to_hdf('test_fixed.hdf','test',mode='w')\", \"    pd.read_csv('test.csv',index_col=0)\", \"    df.to_csv('test.csv',mode='w')    \", \"    pd.read_hdf('test_fixed.hdf','test')\", \"    df.to_hdf('test_table.hdf','test',format='table',mode='w')\", \"    pd.read_hdf('test_table.hdf','test')\"]\n",
      "16637572 ['  df = pd.read_csv(f)', \"  df.to_hdf('file.h5',f,df)\", \"pd.read_hdf('my_store.h5','a_table_node',['index>100'])\"]\n",
      "16637607 [\"s = Series([list('ABC'),list('DEF'),list('ABEF')])\", 's.apply(lambda x: Series(1,index=x)).fillna(0)']\n",
      "16641346 ['df = DataFrame(randn(1000000,10))']\n",
      "16648510 [\"df = DataFrame('10.0%',index=range(100),columns=range(10))\", \"df.replace('%','',regex=True).astype('float')/100\"]\n",
      "16667215 ['df.rename(columns=lambda x: x[1:], inplace=True)']\n",
      "16672514 ['pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)', 'pd.read_csv(s, parse_dates=[0], dayfirst=True)']\n",
      "16673019 [\"s = pd.Series(['12/1/2012', '30/01/2012'])\", \"pd.to_datetime(s, format='%d/%m/%Y')\", 's.apply(pd.to_datetime, dayfirst=True)']\n",
      "16684166 ['a.c1[a.c1 == 8].index.tolist()']\n",
      "16689573 ['df.mean(axis=1)']\n",
      "16729635 ['df.a = df.a.astype(float).fillna(0.0)']\n",
      "16729808 []\n",
      "16735476 [\"df = DataFrame(dict(A = Series(['1.0','1']), B = Series(['1.0','foo'])))\", 'df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']\n",
      "16735536 [\"df = DataFrame(randn(5,3),columns=list('ABC'))\"]\n",
      "16780413 [\"df['delta'] = (df['tvalue']-df['tvalue'].shift()).fillna(0)\", \"df['ans'] = df['delta'].apply(lambda x: x  / np.timedelta64(1,'m')).astype('int64') % (24*60)\"]\n",
      "16789254 [\"df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])\", \"df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 0])\"]\n",
      "16789834 ['paramdata.to_csv(sys.stdout)']\n",
      "16824270 ['df.unstack()']\n",
      "16824696 [\"df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])\", 's = df.xs(3)', 'df.append(s)']\n",
      "16826250 []\n",
      "16827257 ['bar_0_10 = ax.bar(np.arange(0,10), np.arange(1,11), color=\"k\")', 'bar_10_100 = ax.bar(np.arange(0,10), np.arange(30,40), bottom=np.arange(1,11), color=\"g\")']\n",
      "16834949 [\"df = pd.DataFrame(randn(6, 3), index=arrays, columns=['A', 'B', 'C'])\"]\n",
      "16853161 [\"df['time'] = df['time'].astype('datetime64[ns]')\"]\n",
      "16854430 [\"pd.to_datetime(df['time'])\", \"df['time'] = pd.to_datetime(df['time'])\"]\n",
      "16884805 [\"data_table = df.to_html(float_format=lambda x: '%6.2f' % x,\", 'data_table = data_table.replace(\\'border=\"1\"\\',\\'border=\"0\"\\')', \"data_table = data_table.replace('nan', '')\"]\n",
      "16896091 ['dfs = {sheet_name: xl_file.parse(sheet_name) ', 'dfs = pd.read_excel(file_name, sheetname=None)']\n",
      "16923367 [\"df.to_csv(file_name, sep='\\\\t')\", \"df.to_csv(file_name, sep='\\\\t', encoding='utf-8')\"]\n",
      "16949498 ['df = pandas.DataFrame({\"a\": np.random.random(100),', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(np.digitize(df.a, bins))', 'groups.mean().b', 'df = pandas.DataFrame({\"a\": np.random.random(100), ', 'bins = np.linspace(df.a.min(), df.a.max(), 10)', 'groups = df.groupby(pandas.cut(df.a, bins))']\n",
      "16949500 ['df = DataFrame({\"a\": np.random.random(100), \"b\": np.random.random(100), \"id\":   np.arange(100)})', 'a_bins = df.a.groupby(cut(df.a,bins))', 'b_bins = df.b.groupby(cut(df.b,bins))']\n",
      "16958464 ['df=pandas.DataFrame(dfdict)', 'df.to_csv(\"dfTest.txt\",\"\\\\t\",header=True,cols=[\"b\",\"a\",\"c\"])', 'df.to_csv(\"dfTest.txt\",\"\\\\t\",header=True,cols=[\"b\",\"a\",\"c\"], engine=\\'python\\')']\n",
      "16958649 []\n",
      "16988624 [\"pd.read_csv('a', dtype=object, index_col=0)\", \"pd.read_csv('a', index_col=0)\"]\n",
      "16990140 []\n",
      "16993415 ['pd.DataFrame([s1, s2]).min()']\n",
      "16999397 [\"    pd.DataFrame(np.random.randn(10,2),columns=list('AB')).to_csv(f)\", '        df = pd.read_csv(f,index_col=0)', '        df.index = pd.Series(df.index) + nrows', \"        store.append('foo',df)\", \"pd.read_hdf('test.h5','foo')\", \"pd.read_hdf('test.h5','foo',start=12,stop=15)\"]\n",
      "17001474 []\n",
      "17005204 ['pd.Series(a, a._fields)', 'df = pd.DataFrame(l, columns=l[0]._fields)', \"df.set_index(['ticker', 'date'], inplace=True)\"]\n",
      "17027507 ['pd.DatetimeIndex([i.replace(tzinfo=None) for i in t])', '    return Timestamp(datetime.replace(self, **kwds),']\n",
      "17056022 []\n",
      "17063653 ['df = xl.parse(\"Sheet1\")', 'df.head()', 'parsed = pd.io.parsers.ExcelFile.parse(xl, \"Sheet1\")']\n",
      "17068439 [\"df = DataFrame(randn(5,1),columns=['value'])\"]\n",
      "17068462 [\"df = pd.DataFrame({'value': np.arange(-5,5)})\", \"df['value'] = df['value'].clip(0, None)\"]\n",
      "17071908 [\"df.loc[df['column_name'].isin(some_values)]\", \"df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]\", \"df.loc[~df['column_name'].isin(some_values)]\", \"df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\", \"                   'B': 'one one two three two two one three'.split(),\", \"print(df.loc[df['B'].isin(['one','three'])])\", \"df = df.set_index(['B'])\", \"df.loc[df.index.isin(['one','two'])]\"]\n",
      "17073442 [\"pd.to_datetime(df['from_date'].astype(str))\", \"df['from_date'] = pd.to_datetime(df['from_date'].astype(str))\", \"pd.to_datetime(df['from_date'].astype(str))  # do same for to_date\"]\n",
      "17085016 ['df.index = df.index.droplevel(2)']\n",
      "17085044 ['df.reset_index(level=2, drop=True)']\n",
      "17086321 ['df = DataFrame(d)']\n",
      "17092113 [\"df = pandas.DataFrame(columns=['a','b','c','d'], index=['x','y','z'])\", \"df.loc['y'] = pandas.Series({'a':1, 'b':5, 'c':2, 'd':3})\"]\n",
      "17092718 []\n",
      "17092986 []\n",
      "17095620 ['ne = (df1 != df2).any(1)', 'ne_stacked = (df1 != df2).stack()', 'difference_locations = np.where(df1 != df2)', \"pd.DataFrame({'from': changed_from, 'to': changed_to}, index=changed.index)\"]\n",
      "17096675 ['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,21,20])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,21,20])', 'df = pd.concat([df1,df2]) ', \"df.set_index(['id', 'Name'], inplace=True)\", \"    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)\", \"changes = df.groupby(level=['id', 'Name']).agg(report_diff)\"]\n",
      "17097397 [\"df.replace('-', None)\"]\n",
      "17097777 ['~df[\"col\"].str.contains(word)']\n",
      "17098736 ['df.to_pickle(file_name)  # where to save it, usually as a .pkl', 'df = pd.read_pickle(file_name)']\n",
      "17098885 []\n",
      "17106156 [\"df[0].plot(ax=axes[0,0], style='r', label='Series'); axes[0,0].set_title(0)\", 'df[1].plot(ax=axes[0,1]); axes[0,1].set_title(1)', 'df[2].plot(ax=axes[1,0]); axes[1,0].set_title(2)', 'df[3].plot(ax=axes[1,1]); axes[1,1].set_title(3)']\n",
      "17115229 [\"df.replace({'set': mapping, 'tesst': mapping})\"]\n",
      "17116976 [\"s = df['Seatblocks'].str.split(' ').apply(Series, 1).stack()\", \"s.index = s.index.droplevel(-1) # to line up with df's index\", 'df.join(s)', \"df.join(s.apply(lambda x: Series(x.split(':'))))\"]\n",
      "17128356 []\n",
      "17134750 [\"df['col'] = pd.to_datetime(df['col'])\", \"pd.to_datetime(pd.Series(['05/23/2005']))\", 'pd.to_datetime(pd.Series([\\'05/23/2005\\']), format=\"%m/%d/%Y\")']\n",
      "17135044 ['    df.to_csv(f, header=False)', \"df.to_csv(f, mode='a', header=False)\"]\n",
      "17141755 [\"df.sort_values(['a', 'b'], ascending=[True, False])\", \"df1 = pd.DataFrame(np.random.randint(1, 5, (10,2)), columns=['a','b'])\"]\n",
      "17142595 [\"df.replace(['very bad', 'bad', 'poor', 'good', 'very good'], \"]\n",
      "17148934 ['s = pd.Series([1, 1, 2, 1, 2, 2, 3])', 's.value_counts()', 's.groupby(lambda i: np.floor(2*s[i]) / 2).count()']\n",
      "17150734 ['s = Series(randn(100))', 'Series(counts, index=bins[:-1])']\n",
      "17156183 [\"df = DataFrame(cur.fetchall(), columns=['instrument', 'price', 'date'])\", \"df.set_index('date', drop=False)\"]\n",
      "17156233 ['df = pd.read_sql_table(table_name, engine)', 'df = pd.read_sql_query(\"SELECT instrument, price, date FROM my_prices;\", engine)', \"df.reset_index().pivot('date', 'instrument', 'price')\"]\n",
      "17158735 []\n",
      "17159276 [\"dat.index = pd.to_datetime(dat.pop('datetime'), utc=True)\", \"dat.index = dat.index.tz_localize('UTC').tz_convert('US/Pacific')\", \"dat.set_index('label', append=True).swaplevel(0, 1)\", \"dat.index.levels[1] = dat.index.get_level_values(1).tz_localize('UTC').tz_convert('US/Pacific')\"]\n",
      "17169776 [\"df = pd.DataFrame(prcpSeries, columns=['prcp'])\", \"df = prcpSeries.to_frame(name='prcp')\", \"df1 = pd.DataFrame(prcpSeries, columns=['prcp'])\", \"df2 = pd.DataFrame(tmaxSeries, columns=['tmax'])\", \"df = pd.concat([df1, df2, ...], join='outer', axis=1)\", \"dfA = pd.DataFrame([1,2], columns=['A'])\", \"dfB = pd.DataFrame([1], columns=['B'])\", \"pd.concat([dfA, dfB], join='outer', axis=1)\"]\n",
      "17171819 []\n",
      "17194149 [\"df = pd.DataFrame([[1,2], [3,4]], columns=['a', 'b'])\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17211698 []\n",
      "17216674 []\n",
      "17241104 []\n",
      "17242374 [\"df = pd.DataFrame(index=['a', 'b'])\"]\n",
      "17243346 ['g.index = g.index.swaplevel(1, 2)', 'g.index = g.index.swaplevel(1, 2)', \"g = df.groupby(['Manufacturer', 'Product Launch Date', 'Product Name']).sum()\"]\n",
      "17244095 ['df.index.get_loc(ds)']\n",
      "17287046 ['df[df > df.quantile(0.8)].dropna()', 'list(df[df > df.quantile(0.8)].dropna().index)']\n",
      "17298454 [\"medals = df.pivot_table('no of medals', ['Year', 'Country'], 'medal')\", \"medals.reindex_axis(['Gold', 'Silver', 'Bronze'], axis=1)\"]\n",
      "17302673 []\n",
      "17315875 []\n",
      "17322585 [\"df = DataFrame(randn(20,4),columns=list('ABCD'))\", \"df[(df['A']>0) & (df['B']>0) & (df['C']>0)].count()\", \"len(df[(df['A']>0) & (df['B']>0) & (df['C']>0)])\"]\n",
      "17347945 []\n",
      "17383140 []\n",
      "17383325 ['df = DataFrame(dict(A = True, B = False),index=range(3))', 'df.astype(int)', 'df.astype(int).dtypes']\n",
      "17426500 ['Series(df.Letter.values,index=df.Position).to_dict()', \"df = DataFrame(randint(0,10,10000).reshape(5000,2),columns=list('AB'))\"]\n",
      "17439693 ['df.groupby(df.index).sum()', 'df.reset_index().groupby(\"city_id\").sum()', 'df.groupby(df.index)', 'df.groupby(df.index).max()', 'df.groupby(df.index).mean()']\n",
      "17468012 [\"dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\", \"df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\", \"dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\", \"df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\"]\n",
      "17468154 []\n",
      "17478495 ['df.replace([np.inf, -np.inf], np.nan)', 'df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"col1\", \"col2\"], how=\"all\")', 'df = pd.DataFrame([1, 2, np.inf, -np.inf])', 'df.replace([np.inf, -np.inf], np.nan)']\n",
      "17491690 ['DF = pd.read_sql_query(\"SELECT ID, NAME AS Nickname, ADDRESS AS Residence FROM tablez\", cnxn)']\n",
      "17496530 ['        rows_list.append(dict1)', 'df = pd.DataFrame(rows_list)               ']\n",
      "17531025 ['    df.to_csv(f, header=False)', \"df = pd.read_csv('foo.csv', index_col=0)\", '             (df + 6).to_csv(f, header=False)']\n",
      "17534256 []\n",
      "17534682 ['s_bad = pd.Series([1, None], dtype=object)', 's_good = pd.Series([1, np.nan])', 's_bad.sum()', 's_good.sum()']\n",
      "17591423 ['    return pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())']\n",
      "17619032 [\"df = pandas.DataFrame([{'c1':3,'c2':10},{'c1':2, 'c2':30},{'c1':1,'c2':20},{'c1':2,'c2':15},{'c1':2,'c2':100}])\", \"df.sort_values(['c1','c2'], ascending=[False,True])\"]\n",
      "17645475 ['pandas.date_range(\"11:00\", \"21:30\", freq=\"30min\")', 'pandas.date_range(\"11:00\", \"21:30\", freq=\"30min\").time', 'array([datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0),', '       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30),', '       datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0),', '       datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30),', '       datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0),', '       datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30),', '       datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0),', '       datetime.time(21, 30)], dtype=object)']\n",
      "17666287 [\"g = df.groupby(['A', 'B'])\", \"df1 = df.set_index(['A', 'B'])\", \"df1['D'] = g.size()  # unfortunately this doesn't play nice with as_index=False\", 'df1.reset_index()']\n",
      "17679517 [\"df.groupby(['col5', 'col2']).size()\", \"df.groupby(['col5', 'col2']).size().groupby(level=1).max()\"]\n",
      "17679980 [\"df.groupby(['col5','col2']).size().reset_index().groupby('col2')[[0]].max()\"]\n",
      "17682662 []\n",
      "17682665 [\"df = pd.DataFrame(np.random.rand(4,5), columns = list('abcde'))\"]\n",
      "17682726 [\"df = DataFrame(np.random.rand(4,5), columns = list('abcde'))\"]\n",
      "17690795 ['a = pd.Series([pd.to_datetime(date) for date in date_stngs])', 'pd.to_datetime(pd.Series(date_stngs))']\n",
      "17690868 ['pd.to_datetime(pd.Series(date_stngs))', 'dates = [(dt.datetime(1960, 1, 1)+dt.timedelta(days=i)).date().isoformat() for i in range(20000)]']\n",
      "17692156 ['df.stack().value_counts()']\n",
      "17702833 [\"df = pd.DataFrame({'Status':['Delivered', 'Delivered', 'Undelivered',\", \"df['Status'].map(d)\"]\n",
      "17709453 [\"df['Counts'] = df.groupby(['Color'])['Value'].transform('count')\", \"df = pd.DataFrame({'Color': 'Red Red Blue'.split(), 'Value': [100, 150, 50]})\", \"df['Counts'] = df.groupby(['Color'])['Value'].transform('count')\"]\n",
      "17712440 [\"df = pd.DataFrame(np.random.randn(4,4), columns=list('ABCD'))\", 'df.mean()', 'df.mean().sort_values()', 'df.reindex_axis(df.mean().sort_values().index, axis=1)']\n",
      "17729985 ['d.sales = d.sales.replace(23, 24)']\n",
      "17758115 ['df = pd.DataFrame({\"A\": 1e4*np.arange(100), \"num\": np.random.random(100)})', 'df.ix[(df.num-x).abs().argsort()[:5]]', 'df.ix[(df.num-x).abs().argsort()[:5]]']\n",
      "17778786 ['df = pd.DataFrame(data)', 'c = df.corr().abs()', 's = c.unstack()']\n",
      "17779230 []\n",
      "17811984 []\n",
      "17813222 [\"df.plot(x='col_name_1', y='col_name_2', style='o')\", 'df = pd.DataFrame(d)', \"df.plot(style=['o','rx'])\"]\n",
      "17813277 []\n",
      "17819427 []\n",
      "17840195 [\"df = pd.DataFrame({'A': [a], 'B': [b]})\", \"df = pd.DataFrame({'A': a, 'B': b}, index=[0])\"]\n",
      "17840197 [\"df2 = pd.DataFrame({'A':[a],'B':[b]})\"]\n",
      "17841294 [\"df = read_csv(StringIO(data),sep='\\\\s+')\", \"df.groupby('A').apply(lambda x: x.sum())\", \"df.groupby('A')['C'].apply(lambda x: x.sum())\", 'df.groupby(\\'A\\')[\\'C\\'].apply(lambda x: \"{%s}\" % \\', \\'.join(x))', \"df.groupby('A').apply(f)\"]\n",
      "17841308 [\"d.groupby('A')['B'].apply(list)\"]\n",
      "17877159 [\"ax[1].bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1]-bins[0]), color='grey')\"]\n",
      "17910713 [\"df.to_csv(file_name, header=False, mode = 'a')\"]\n",
      "17923621 ['x = df.reset_index()', \"x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B'])\", \"x.loc[(x.B>=111.0)&(x.B<=500.0)].set_index(['A','B']).index\"]\n",
      "17926411 [\"df.groupby(['col1','col2'])['col3'].nunique().reset_index()\"]\n",
      "17926436 ['df.groupby([0,1])[2].apply(lambda x: len(x.unique()))']\n",
      "17933417 ['np.genfromtxt((\"\\\\t\".join(i) for i in csv.reader(open(\\'myfile.csv\\'))), delimiter=\"\\\\t\")']\n",
      "17942117 ['pd.read_csv(StringIO(s), quotechar=\\'\"\\', skipinitialspace=True)']\n",
      "17950081 ['df.drop(label)', 'df.drop(label, inplace=True)', 'df.drop(df.index[:3], inplace=True)', 'df.drop(df.head(3).index, inplace=True)']\n",
      "17950531 [\"df = DataFrame(np.arange(10).reshape(5,2),columns=list('AB'))\", \"df['A'].apply(str)\", \"df['A'].apply(str)[0]\", 'df.applymap(str)', 'df.applymap(str).iloc[0,0]']\n",
      "17958424 [\"s = pd.Series(['a', 'ab', 'c', 11, np.nan])\", \"s.str.startswith('a', na=False)\", \"s.loc[s.str.startswith('a', na=False)]\"]\n",
      "17961468 []\n",
      "17973255 [\"pattern = '|'.join(mylist)\", 'frame.a.str.contains(pattern)']\n",
      "17975690 []\n",
      "17977609 ['xl.parse(sheet_name)  # read a specific sheet to DataFrame']\n",
      "17978188 [\"pd.to_datetime(df['Date'] + ' ' + df['Time'])\"]\n",
      "17978414 [\"df1.merge(df2[list('xab')])\"]\n",
      "17995122 [\"df['size'] = df.groupby(['A','B']).transform(np.size)\"]\n",
      "18013682 []\n",
      "18023468 []\n",
      "18023485 []\n",
      "18039175 []\n",
      "18046682 []\n",
      "18061253 [\"dr = date_range('1/1/2010', periods=3, freq=3 * datetools.bday)\", 'ts = Series(raw, index=dr)', 'ts.asfreq(datetools.BDay())', 'ts.resample(datetools.BDay())']\n",
      "18062430 ['s1 = Series(randn(5),index=[1,2,4,5,6])', 's2 = Series(randn(5),index=[1,2,4,5,6])', 'DataFrame(dict(s1 = s1, s2 = s2)).reset_index()']\n",
      "18062521 [\"s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')\", \"s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')\", 'pd.concat([s1, s2], axis=1)', 'pd.concat([s1, s2], axis=1).reset_index()']\n",
      "18067431 []\n",
      "18079695 ['pd.Series(list(set(s1).intersection(set(s2))))', 'Series(list(set(s1) & set(s2)))']\n",
      "18080142 ['pd.Series(np.intersect1d(pd.Series([1,2,3,5,42]), pd.Series([4,5,6,20,42])))']\n",
      "18090009 ['nbytes = sum(block.values.nbytes for block in df.blocks.values())']\n",
      "18090393 [\"DataFrame(randn(1000000,20)).to_csv('test.csv')\", \"DataFrame(randn(1000000,20)).to_hdf('test.h5','df',complevel=9,complib='blosc')\"]\n",
      "18101965 [\"df.to_html(classes='my_class')\", \"df.to_html(classes=['my_class', 'my_other_class'])\", \"df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})\", \"HTML(df.to_html(classes='my_class'))\", \"        ''' + df.to_html(classes='df'))\", \"df = pd.DataFrame({'a': np.arange(10), 'b': np.random.randn(10)})\", \"    f.write(df.to_html(classes='df'))\"]\n",
      "18103894 [\"result_df = df.loc[(df.index.get_level_values('A') > 1.7) & (df.index.get_level_values('B') < 666)]\", \"result_df.index.get_level_values('A')\", 'df = store.select(STORE_EXTENT_BURSTS_DF_KEY)', 'len(df)', 'df_without_index = df.reset_index()']\n",
      "18108357 ['  dfs.append(psql.read_frame(sql, cnxn))', '  if len(dfs[-1]) < chunk_size:', 'full_df = pd.concat(dfs)']\n",
      "18129082 [\"data = pd.read_csv('file1.csv', error_bad_lines=False)\"]\n",
      "18145399 [\"df = df.drop('column_name', 1)\", \"df.drop('column_name', axis=1, inplace=True)\", 'df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.Index ']\n",
      "18162021 ['df = pandas.DataFrame([']\n",
      "18162196 ['df = pd.DataFrame(sample).reset_index().rename(columns={\"index\": \"item\"})', 'df = pd.melt(df, \"item\", var_name=\"user\").dropna()', 'df = df[[\"user\", \"item\", \"value\"]].reset_index(drop=True)', 'df = pd.DataFrame(sample)', 'df = pd.DataFrame(sample).reset_index().rename(columns={\"index\": \"item\"})', 'df = pd.melt(df, \"item\", var_name=\"user\").dropna()', 'df = df[[\"user\", \"item\", \"value\"]].reset_index(drop=True)']\n",
      "18172249 []\n",
      "18173074 []\n",
      "18173088 []\n",
      "18176957 ['df2 = pd.DataFrame(index=df1.index)']\n",
      "18184990 ['ds1 = set([ tuple(line) for line in df1.values.tolist()])', 'ds2 = set([ tuple(line) for line in df2.values.tolist()])', 'ds1.difference(ds2)', 'pd.DataFrame(list(ds1.difference(ds2)))']\n",
      "18196299 []\n",
      "18199337 ['df = pd.DataFrame(np.arange(1,7).reshape(2,3),', \"                  index=pd.Series([2,5], name='b'))\", 'print(np.where(df.index==5)[0])', \"print(np.where(df['c']==6)[0])\"]\n",
      "18215499 [\"days = x.astype('timedelta64[D]')\"]\n",
      "18233876 [\"df = DataFrame(dict(date = [Timestamp('20130101'),Timestamp('20130131'),Timestamp('20130331'),Timestamp('20130330')],value=randn(4))).set_index('date')\", \"df.index = df.index.to_period('M').to_timestamp('M')\"]\n",
      "18259236 ['df.unstack()', \"df = df.unstack().reset_index(name='value')\", \"df.rename(columns={'level_0': 'month', 'level_1': 'year'}, inplace=True)\"]\n",
      "18261958 ['grouped.filter(lambda x: len(x) > 1)']\n",
      "18283014 ['df.apply(you_function, axis=1)', \"df = pd.DataFrame({'a': np.arange(3),\", 'df.apply(func, axis=1)']\n",
      "18290143 ['df1 = pd.DataFrame([[1, 2], [3, 4]])', 'df2 = pd.DataFrame(df1)', 'df1 = pd.DataFrame([[1, 2], [3, 4]])', 'df2 = pd.DataFrame(df1, copy=True)']\n",
      "18316830 ['s.apply(lambda x: type(x))', 'Series(s.reset_index().apply(f, axis=1).values, index=s.index)']\n",
      "18317067 []\n",
      "18327852 []\n",
      "18334025 ['myseries = pd.Series([1,4,0,7,5], index=[0,1,2,3,4])', 'Index(myseries).get_loc(7)', 'Index(myseries).get_loc(10)', 'Index([1,1,2,2,3,4]).get_loc(2)', 'Index([1,1,2,1,3,2,4]).get_loc(2)', 's = Series(randint(0,10,10000))', 's = Series(randint(0,10,10000))']\n",
      "18357933 [\"g = data.groupby('tag')\", 'g.filter(lambda x: len(x) > 1)  # pandas 0.13.1', 'g.filter(lambda x: len(x) > 1)  # pandas 0.12']\n",
      "18360223 [\"df.index.values.tolist()  # an ndarray method, you probably shouldn't depend on this\"]\n",
      "18366911 [\"pd.read_csv(StringIO(s), sep=',', comment='#', skiprows=1)\", \"pd.read_csv(StringIO(s), sep=',', comment='#')\", \"pd.read_csv(StringIO(s2), comment='#', sep=',').dropna(how='all')\"]\n",
      "18369312 []\n",
      "18405221 ['df = pd.DataFrame (data)']\n",
      "18431417 ['df.fillna(-1)', \"df.fillna(-1).groupby('b').sum()\"]\n",
      "18434234 [\"df['foo'] = df['foo'].astype(float)\"]\n",
      "18434403 ['s.convert_objects(convert_numeric=True)']\n",
      "18467097 ['            return dslice.mean()', '    data = DataFrame(data.copy())', '    dfout = DataFrame()', '        idx = Series(data.index.to_pydatetime(), index=data.index)', '            result = idx.apply(f)', \"            dfout = dfout.join(result, how='outer')\", 'vals = np.arange(len(idx)).astype(float)', 's = Series(vals, index=idx)']\n",
      "18500854 [\"d = pandas.read_csv('foo.csv', dtype={'BAR': 'S10'})\"]\n",
      "18505101 [\"ds.div(ds['sum'], axis=0)\", \"ds.join(ds.div(ds['sum'], axis=0), rsuffix='_perc')\"]\n",
      "18518561 []\n",
      "18527067 [\"times = pd.to_datetime(df.YYYYMMDD + ' ' + df.HH, format=format)\", 'df.set_index(times, inplace=True)', \"df = df.drop(['YYYYMMDD','HH'], axis=1)\"]\n",
      "18528589 ['data_frame.to_csv(output)', 'pt = prettytable.from_csv(output)']\n",
      "18554949 ['df.groupby(\"date\").agg({\"duration\": np.sum, \"user_id\": pd.Series.nunique})', 'df.groupby(\"date\").agg({\"duration\": np.sum, \"user_id\": lambda x: x.nunique()})']\n",
      "18580496 ['df = DataFrame(randn(10, len(cols)), columns=cols)', 'df.a.quantile(0.95)', 'df[df.a < df.a.quantile(.95)]']\n",
      "18588980 []\n",
      "18594595 ['df.div(df.sum(axis=1), axis=0)']\n",
      "18611535 ['    step_percentage = 100. / len(g)', \"            sys.stdout.write('\\\\033[D \\\\033[D' * 4 + format(progress, '3.0f') + '%')\", '    res = g.apply(logged_func, *args, **kwargs)', \"    sys.stdout.write('\\\\033[D \\\\033[D' * 4 + format(100., '3.0f') + '%' + '\\\\n')\", \"g = df_users.groupby(['userID', 'requestDate'])\"]\n",
      "18624069 ['s.reset_index()', 's.reset_index(0).reset_index(drop=True)', 'df = s.reset_index()', 's.reset_index().drop(1, axis=1)']\n",
      "18624323 [\"rng = pd.date_range('1/1/2011', periods=72, freq='M')\", \"H2 = pd.DataFrame(np.arange(len(rng)), index=rng, columns=['SOLD_PRICE'])\", \"H5 = H3.resample('Q', how='count')\", 'print(H6.head())']\n",
      "18646275 ['df = pd.DataFrame(np.arange(1,10).reshape(3,3))', \"df['newcol'] = arr.toarray().tolist()\"]\n",
      "18646802 [\"p = pd.Panel({'df': df, 'csc': csc})\", 'p.xs(0)']\n",
      "18661440 [\"        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')\"]\n",
      "18666142 [\"df = pd.DataFrame([[1, {'a': 2}], [2, {'a': 1, 'b': 3}]])\", 'df[1].apply(pd.Series)', 'dict_col = df.pop(1)  # here 1 is the column name', 'pd.concat([df, dict_col.apply(pd.Series)], axis=1)']\n",
      "18674915 ['df.insert(idx, col_name, value)']\n",
      "18677517 [\"string = Series(np.random.choice(df.string.values, size=100), name='string')\", \"visits = Series(poisson(1000, size=100), name='date')\", \"date = Series(np.random.choice([df.date[0], now(), Timestamp('1/1/2001'), Timestamp('11/15/2001'), Timestamp('12/1/01'), Timestamp('5/1/01')], size=100), dtype='datetime64[ns]', name='date')\", \"df = DataFrame({'string': string, 'visits': visits, 'date': date})\", 'df.head()', \"resamp = df.set_index('date').groupby('string').resample('M', how='sum')\", 'resamp.head()', \"g = resamp.groupby(level='date').apply(lambda x: x / x.sum())\", 'g.head()', \"h = g.sortlevel('date').head()\", 'h.sum()', 'resamp.dropna()', 'resamp.dropna().reset_index()', 'g.dropna()', 'g.dropna().reset_index()', \"g.dropna().reset_index().reindex(columns=['visits', 'string', 'date'])\"]\n",
      "18689514 [\"s.groupby(level=['first','second']).sum()\"]\n",
      "18689589 []\n",
      "18689712 [\"s = pd.Series(['apple', np.nan, 'banana'])\", 'pd.isnull(s)', \"s = Series([Timestamp('20130101'),np.nan,Timestamp('20130102 9:30')],dtype='M8[ns]')\", 'pd.isnull(s)']\n",
      "18691949 ['df.mean()', 'df.fillna(df.mean())']\n",
      "18695700 [\"df.set_index('id').to_dict()\", \"df.set_index('id')['value'].to_dict()\"]\n",
      "18714509 ['df = pd.DataFrame(np.random.rand(10))']\n",
      "18714869 ['df.loc[sample(df.index, 1000)]']\n",
      "18793067 ['restaurant_review_frame.join(restaurant_ids_dataframe, on=\\'business_id\\', how=\\'left\\', lsuffix=\"_review\")']\n",
      "18799713 [\"pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')\"]\n",
      "18835121 [\"df.iloc[df.index.get_level_values('A') == 1]\", \"df1.iloc[:, df1.columns.get_level_values('A') == 1]\"]\n",
      "18835174 ['df = DataFrame(np.random.randn(10, 4))', \"df.columns = [np.random.choice(['a', 'b'], size=4).tolist(), np.random.choice(['c', 'd'], size=4)]\", \"df.xs('a', level='A', axis=1)\", \"df.xs('a', level='A', axis=1, drop_level=False)\"]\n",
      "18837378 [\"df = pd.DataFrame(data.items(), columns=['Date', 'DateValue'])\", \"df['Date'] = pd.to_datetime(df['Date'])\"]\n",
      "18837389 ['pd.DataFrame(d)', 'pd.DataFrame(d.items())  # or list(d.items()) in python 3', \"pd.DataFrame(d.items(), columns=['Date', 'DateValue'])\", \"s = pd.Series(d, name='DateValue')\", 's.reset_index()']\n",
      "18837709 [\"df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\", \"grouped = df.groupby('A')\"]\n",
      "18852224 [\"df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])\", \"count_appkey = df.groupby('AppKey')['AppKey'].transform('count')\"]\n",
      "18852410 [\"df.groupby('AppKey').filter(lambda x: x.count() == 1)\", \"df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['AppKey', 'B'])\", \"df.groupby('AppKey').filter(lambda x: x.count() == 1)\"]\n",
      "18878267 ['HTML( style + df.to_html( formatters=frmt ) )', \"HTML(style + df.to_html(formatters=frmt, classes='right_aligned_df'))\", \"HTML(df.to_html(classes='pink_df'))\"]\n",
      "18878413 ['dfm.index = range(1,len(dfm) + 1)']\n",
      "18878425 [\"df = DataFrame(randn(10, 2), columns=['a', 'delt'])\", 'df.reindex(index=arange(1, len(df) + 1))', 'df.index = arange(1, len(df) + 1)']\n",
      "18885319 [\"crime2013 = pd.read_csv(z.open('crime_incidents_2013_CSV.csv'))\"]\n",
      "18916457 ['pd.read_csv(Reader(gen()))']\n",
      "18937023 ['Counter(\" \".join(r1).split(\" \")).items()']\n",
      "18937309 [\"df['text'].str.lower().str.split()\", \"df['text'].str.lower().str.split().apply(results.update)\"]\n",
      "18937417 [\"df=pd.DataFrame(r1,columns=['text'])\", 'df.text.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0)']\n",
      "18942558 [\"df['Col3'] = (df['Col2'] <= 1).astype(int)\", \"df['Col3'] = df['Col2'].map(lambda x: 42 if x > 1 else 55)\"]\n",
      "18973430 ['barlist=plt.bar([1,2,3,4], [1,2,3,4])', 'ax.bar([1,2,3,4], [1,2,3,4])', 'barlist=filter(lambda x: isinstance(x, matplotlib.patches.Rectangle), childrenLS)']\n",
      "18975065 ['s = pd.Series(', 'plt.title(\"Total Delay Incident Caused by Carrier\")', 'pd.Series.plot(']\n",
      "18992172 []\n",
      "19031661 ['data_records = [rec.__dict__ for rec in query.all()]', 'df = pandas.DataFrame.from_records(data_records)']\n",
      "19062640 []\n",
      "19071572 [\"df=pd.DataFrame(array, columns=('Test1', 'toto', 'test2', 'riri'))\", \"cols = [c for c in df.columns if c.lower()[:4] != 'test']\"]\n",
      "19071679 [\"df = DataFrame({'Test1': randn(10), 'Test2': randn(10), 'awesome': randn(10)})\", \"df.select(lambda x: not re.search('Test\\\\d+', x), axis=1)\"]\n",
      "19078773 ['df = data.groupby(...).agg(...)', 'df.columns = df.columns.droplevel(0)', 'df.columns = [\"_\".join(x) for x in df.columns.ravel()]', 'print(data.head())', \"df = data.groupby('Seed').agg(\", 'print(df.head())', 'df.columns = df.columns.droplevel(0)', 'print(df.head())', \"df = data.groupby('Seed').agg(\", 'df.columns = [\"_\".join(x) for x in df.columns.ravel()]']\n",
      "19089210 []\n",
      "19103754 ['df = pd.read_csv(\"test_data2.csv\", index_col=[0,1], skipinitialspace=True)']\n",
      "19106012 [\"s = Series(date_range(Timestamp('now'), periods=2))\", \"s.map(lambda x: x.strftime('%d-%m-%Y'))\", \"s.map(methodcaller('strftime', '%d-%m-%Y'))\", \"s.map(methodcaller('date'))\", \"s.map(methodcaller('date')).values\", 's.map(Timestamp.date)', 'flam = lambda x: x.date()', \"s2 = Series(date_range('20010101', periods=1000000, freq='T'))\"]\n",
      "19112890 ['df = DataFrame(table, columns=headers)']\n",
      "19125531 [\"dfNew = merge(df, df2[cols_to_use], left_index=True, right_index=True, how='outer')\", 'cols_to_use = df2.columns.difference(df.columns)']\n",
      "19126566 [\"    pd.set_option('display.max_rows', len(x))\", \"    pd.reset_option('display.max_rows')\"]\n",
      "19155860 []\n",
      "19170098 ['f_recs[f_recs[\\'Behavior\\'].str.contains(\"nt|nv\", na=False)]']\n",
      "19213836 []\n",
      "19214708 [\"aggregated_df.reset_index().to_json(orient='index')\"]\n",
      "19226617 ['df = pandas.read_csv(\"test.csv\")', 'df = pandas.read_csv(\"test.csv\")']\n",
      "19226745 [\"df['First_Name'] = df['ID'].map(fnames)\", \"df['Last_Name'] = df['ID'].map(lnames)\", \"df['First_Name'] = df['ID'].map(lambda x: names[x][0])\"]\n",
      "19231939 [\"df = DataFrame(data['values'])\", 'df.head()', \"df['date'] = pd.to_datetime(df['date'],unit='s')\", 'df.head()']\n",
      "19237920 [\"df[['Time', 'Product']].query('Product == p_id and Month < mn and Year == yr')\", \"df = DataFrame({'gender': np.random.choice(['m', 'f'], size=10), 'price': poisson(100, size=10)})\", 'df.query(\\'gender == \"m\" and price < 100\\')', \"k1 = df[['Time', 'Product']].query('Product == p_id and start_time <= Time < end_time')\"]\n",
      "19238029 ['data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)', 'data = DataFrame(vals, columns = cols)', 'data.reindex_axis(sorted(data.columns, key=lambda x: float(x[1:])), axis=1)']\n",
      "19271841 [\"df.groupby('a')['a'].transform('count')\", \"df.groupby('a').transform('count')\", \"df2.groupby('a').transform('count')\", \"type(df2.groupby('a').transform('count'))\", \"df2.groupby('a')['a'].transform('count')\", \"type(df.groupby('a')['a'].transform('count'))\"]\n",
      "19295539 []\n",
      "19295726 []\n",
      "19324591 [\"idx = pd.date_range('09-01-2013', '09-30-2013')\", \"s = pd.Series({'09-02-2013': 2,\", 's = s.reindex(idx, fill_value=0)']\n",
      "19349005 []\n",
      "19351003 [\"pd.to_datetime((df.Y*10000+df.M*100+df.D).apply(str),format='%Y%m%d')\", \"pd.to_datetime(df.Y*10000+df.M*100+df.D,format='%Y%m%d')\"]\n",
      "19368360 []\n",
      "19378497 ['dataframe[\"period\"] = dataframe[\"Year\"].map(str) + dataframe[\"quarter\"]']\n",
      "19385591 [\"df[['col1', 'col2', 'col3', 'col4']].groupby(['col1', 'col2']).agg(['mean', 'count'])\"]\n",
      "19403897 [\"df = pd.DataFrame({'A':'foo foo foo bar bar bar'.split(),\", \"df['C'] = df.groupby(['A'])['B'].transform(\", '                     lambda x: pd.qcut(x, 3, labels=range(1,4)))']\n",
      "19415186 []\n",
      "19464054 ['a.loc[a.shift(-1) != a]', 'a.loc[a.diff() != 0]', 'a.loc[a.shift() != a]']\n",
      "19473752 []\n",
      "19482988 []\n",
      "19483025 []\n",
      "19483602 ['my_dataframe.columns.values.tolist()']\n",
      "19486140 ['pd.read_fwf(data, colspecs=[(0,3),(4,8)], converters = {1: str})']\n",
      "19523512 []\n",
      "19555675 ['dtf = pd.DataFrame.from_records(d,columns=h)', 'dtf2.plot()']\n",
      "19585378 ['for row in df.iterrows():', '    temp.append(data.tolist())', 'df.apply(lambda x: x.tolist(), axis=1)', 'df.values.tolist()']\n",
      "19585413 ['map(list, df.values)']\n",
      "19592693 [\"df.reset_index().pivot('index','Letter','N').hist()\"]\n",
      "19599661 []\n",
      "19599776 []\n",
      "19600533 [\"pandas.pivot_table(df,values='count',index='site_id',columns='week')\"]\n",
      "19603918 []\n",
      "19609945 []\n",
      "19609954 ['followers_df.reset_index()', 'followers_df.reindex(index=range(0,20))']\n",
      "19611857 [\"r = requests.get('https://docs.google.com/spreadsheet/ccc?key=0Ak1ecr7i0wotdGJmTURJRnZLYlV3M2daNTRubTdwTXc&output=csv')\", \"df = pd.read_csv(StringIO(data), index_col=0,parse_dates=['Quradate'])\", 'df.head()']\n",
      "19619020 ['ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)', 'df1[ind].append(df2[ind])']\n",
      "19632099 ['pd.read_csv(\"whitespace.csv\", header=None, delimiter=r\"\\\\s+\")']\n",
      "19633103 []\n",
      "19726078 ['data.columns = map(str.lower, data.columns)', 'data.columns = [x.lower() for x in data.columns]', \"data = pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})\", 'data.columns = map(str.lower, data.columns)']\n",
      "19736406 ['DataFrame(dict([ (k,Series(v)) for k,v in d.items() ]))']\n",
      "19739768 []\n",
      "19758398 [\"data.rename(columns={'gdp':'log(gdp)'}, inplace=True)\"]\n",
      "19782137 [\"df.to_csv('filename.csv', header=False)\", \"df.to_csv('filename.tsv', sep='\\\\t', index=False)\"]\n",
      "19791302 [\"data = pd.DataFrame({'Names': ['Joe', 'John', 'Jasper', 'Jez'] *4, 'Ob1' : np.random.rand(16), 'Ob2' : np.random.rand(16)})\", 'UniqueNames = data.Names.unique()']\n",
      "19798528 [\"frame = DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\", 'f = lambda x: x.max() - x.min()', 'frame.apply(f)', 'frame.applymap(format)', \"frame['e'].map(format)\"]\n",
      "19809616 [\"df.set_index(keys=['name'], drop=False,inplace=True)\", \"names=df['name'].unique().tolist()\"]\n",
      "19818942 [\"df.groupby('Mt').first()\", \"df.groupby('Mt', as_index=False).first()\", \"df.sort('count', ascending=False).groupby('Mt', as_index=False).first()\"]\n",
      "19819118 [\"df.iloc[df.groupby(['Mt']).apply(lambda x: x['count'].idxmax())]\"]\n",
      "19821311 []\n",
      "19828967 []\n",
      "19851521 [\"df = pd.DataFrame([[1, 2, 3], [4, 5 ,6]], columns=list('ABC'))\", \"df1 = df.set_index('A')\", \"df1.rename(index={1: 'a'})\", \"df1.rename(columns={'B': 'BB'})\"]\n",
      "19861545 ['select  = df.apply(lambda r : any([isinstance(e, basestring) for e in r  ]),axis=1) ']\n",
      "19867768 []\n",
      "19895152 [\"df.groupby('C').quantile(.95)\"]\n",
      "19900276 ['    if len(frame.columns) == 1:', '    grouped = frame.groupby(frame.columns[0])']\n",
      "19913845 [\"df['color'] = np.where(df['Set']=='Z', 'green', 'red')\", \"df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\", \"df['color'] = np.where(df['Set']=='Z', 'green', 'red')\", \"df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\", \"df['color'] = np.select(conditions, choices, default='black')\"]\n",
      "19915115 [\"df['newcolumn'] = df.apply(fab, axis=1)\"]\n",
      "19918849 ['csvdata_old = csvdata.copy()', 'assert_frame_equal(csvdata, csvdata_old)', '    assert_frame_equal(csvdata, csvdata_old)']\n",
      "19922732 []\n",
      "19928288 []\n",
      "19937902 [\"T1 = pd.merge(T1, T2, on=T1.index, how='outer')\"]\n",
      "19960116 ['df.countries.isin(countries)', 'df[df.countries.isin(countries)]', 'df[~df.countries.isin(countries)]']\n",
      "19960136 ['not_in = df[df.apply(criterion, axis=1)]']\n",
      "19961557 ['df = pd.DataFrame(data)', 'df.pivot(index=0, columns=1, values=2)', 'df.pivot(index=0, columns=1, values=3)']\n",
      "19961872 [\"df = pandas.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std'])\", \"df = df.set_index(['R_Number', 'C_Number'])\", \"df.set_index(['R_Number', 'C_Number']).Avg.unstack(level=1)\"]\n",
      "19966142 ['df[\"value\"] = df.groupby(\"name\").transform(lambda x: x.fillna(x.mean()))']\n",
      "19969224 [\"ax2.plot(ax.get_xticks(),df[['sales_gr','net_pft_gr']].values, linestyle='-', marker='o', linewidth=2.0)\"]\n",
      "19973722 []\n",
      "19976286 ['df = pd.DataFrame({\"A\": [10,20,30], \"B\": [20, 30, 10]})']\n",
      "19982756 [\"df.set_index(['fileName','phrase'],inplace=True)\"]\n",
      "19991632 ['df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]})']\n",
      "19996208 ['df = pd.DataFrame({\"A\": [10,20,30,40,50], \"B\": [20, 30, 10, 40, 50], \"C\": [32, 234, 23, 23, 42523]})']\n",
      "20006954 [\"df_data['vals'] = df_data['vals'].map(lambda x: '%2.1f' % x)\", \"df_data.to_csv(outfile, index=False, header=False, float_format='%11.6f')\"]\n",
      "20012628 []\n",
      "20015080 ['pd.DataFrame(points, columns=Point._fields)']\n",
      "20019449 []\n",
      "20024879 ['df.T.to_dict().values()', \"df = pandas.DataFrame({'col1': ['A', 'B', 'C', 'A', 'A', 'B'], 'col2': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar']})\", \"df.to_dict('records')\"]\n",
      "20027386 [\"df['col'] = 'str' + df['col'].astype(str)\", \"df = pd.DataFrame({'col':['a',0]})\", \"df['col'] = 'str' + df['col'].astype(str)\"]\n",
      "20032254 []\n",
      "20033218 [\"frame['HighScore'] = frame[['test1','test2','test3']].apply(max, axis=1)\"]\n",
      "20033232 [\"frame['HighScore'] = frame[['test1','test2','test3']].max(axis=1)\"]\n",
      "20038973 [\"'[%s]' % ','.join(test.splitlines())\", \"test_100 = '\\\\n'.join([test] * 100)\", \"test_1000 = '\\\\n'.join([test] * 1000)\"]\n",
      "20039057 []\n",
      "20043785 [\"df = pd.DataFrame(list(range(5)), columns=['a'])\", 'df[\\'a\\'] = df[\\'a\\'].apply(lambda x: \\'<a href=\"http://example.com/{0}\">link</a>\\'.format(x))', 'HTML(df.to_html(escape=False))']\n",
      "20051631 ['pd.factorize(df.b)', \"df['c'] = pd.factorize(df.b)[0]\"]\n",
      "20059818 ['data = pandas.read_sql(sql, cnn)']\n",
      "20067665 [\"df.groupby('id').first()\", \"df.groupby('id').first().reset_index()\", \"df.groupby('id').head(2).reset_index(drop=True)\"]\n",
      "20069379 [\"df.groupby('id').head(2)\", \"df.groupby('id').head(2).reset_index(drop=True)\"]\n",
      "20076611 []\n",
      "20084843 [\"    store.append('df',df,index=False)\", \"    store.append('df',df)\", 'df = concat([DataFrame(np.random.randn(10000000,10)),DataFrame(np.random.randint(0,10,size=50000000).reshape(10000000,5))],axis=1)', \"df = pd.read_hdf('test.h5','df')\"]\n",
      "20084895 ['df = DataFrame(np.random.randint(0,10,size=100).reshape(10,10))', 'Series(df.values.ravel()).unique()', 'df = DataFrame(np.random.randint(0,10,size=10000).reshape(100,100))']\n",
      "20096494 []\n",
      "20096827 ['df.gdp = df.gdp.shift(-1)']\n",
      "20107825 []\n",
      "20120225 [\"df1 = pd.pivot_table(df, values=['D'], rows=['B'], aggfunc=np.sum)\", \"df2 = pd.pivot_table(df, values=['E'], rows=['B'], aggfunc=np.mean)\", 'pd.concat((df1, df2), axis=1)', \"df3 = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc=[np.sum, np.mean])\", \"df.groupby('B').aggregate({'D':np.sum, 'E':np.mean})\"]\n",
      "20154429 [\"pd.read_csv(r'D:/Temp/tt.csv')\", \"pd.read_csv(r'D:/Temp/tt.csv', names=list('abcdef'))\"]\n",
      "20159305 [\"df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])\", \"df.groupby('A').sum()\", \"df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])\", \"df = pd.read_csv('my_secret_file.csv')  # ideally with lots of parsing options\"]\n",
      "20167984 [\"df = pd.DataFrame.from_dict({'A': {1: datetime.datetime.now()}})\", 'records = json.loads(df.T.to_json()).values()', 'db.myCollection.insert(records)', \"df['A'] = pd.to_datetime(df['A'])\"]\n",
      "20168416 []\n",
      "20181686 ['df.groupby([\"score\", \"type\"]).sum()', 'df.groupby([\"score\", \"type\"], as_index=False).sum()']\n",
      "20199798 [\"df[df.groupby(level=0).transform(len)['type'] > 1]\"]\n",
      "20200594 [\"df.groupby(level=0).filter(lambda x: len(x) > 1)['type']\"]\n",
      "20206825 [\"x.merge(x.merge(y, how='left', on='state', sort=False))\", \"x.reset_index().merge(y, how='left', on='state', sort=False).sort('index')\"]\n",
      "20221655 ['data_filtered.to_excel(writer, \"Main\", cols=[\\'Diff1\\', \\'Diff2\\'])']\n",
      "20228113 ['df = pd.concat([df1, df2])', 'df = df.reset_index(drop=True)', 'df_gpby = df.groupby(list(df.columns))', 'idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]', 'df.reindex(idx)']\n",
      "20230859 ['df.drop(column_name, axis=1)']\n",
      "20231632 ['collist = df.columns.tolist()']\n",
      "20233649 []\n",
      "20235451 ['s = pd.Series([1,2,3,4,np.NaN,5,np.NaN])', 's[~s.isnull()]', 's.dropna()']\n",
      "20250947 [\"df['col1'].update(pd.Series(di))\", \"df = pd.DataFrame({'col1':['w', 10, 20],\", \"df['col1'].update(pd.Series(di))\", \"df = pd.DataFrame({'col1':['w', 10, 20],\", \"df['col1'].replace(di, inplace=True)\", \"df['col1'].put(di.keys(), di.values())\", \"df = pd.DataFrame({'col1':['w', 10, 20],\", \"df['col1'].put(di.keys(), di.values())\"]\n",
      "20250996 [\"df = pd.DataFrame({'col2': {0: 'a', 1: 2, 2: np.nan}, 'col1': {0: 'w', 1: 1, 2: 2}})\", 'df.replace({\"col1\": di})']\n",
      "20297639 ['df = pd.DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})', 'len(df.columns)']\n",
      "20301769 ['df.drop(df.columns[i], axis=1)']\n",
      "20304311 []\n",
      "20312816 [\"x.set_index('name').index.get_duplicates()\"]\n",
      "20333894 []\n",
      "20334902 []\n",
      "20341058 ['pd.DataFrame(list(my_dict.iteritems()),']\n",
      "20375692 [\"pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')\", \"pd.merge(frame_1, frame_2, how = 'left', left_on = 'county_ID', right_on = 'countyid')\"]\n",
      "20384317 []\n",
      "20410720 ['pd.concat([s, s.shift(), s.shift(2)], axis=1)', 'pd.concat([s, s.shift(), s.shift(2)], axis=1).dropna()']\n",
      "20444256 ['data.reindex(index=data.index[::-1])']\n",
      "20455090 []\n",
      "20459839 []\n",
      "20461206 ['df.reset_index(level=0, inplace=True)', \"df.reset_index(level=['tick', 'obs'])\"]\n",
      "20461929 ['similarities = euclidean_distances(data.astype(np.float64))', 'mds.fit(data.astype(np.float64))', 'similarities = euclidean_distances(data.astype(np.float32))', 'mds.fit(data.astype(np.float32))']\n",
      "20481080 [\"df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])\", \"df['date'] = pd.to_datetime(['21-11-2013', '22-11-2013'])\"]\n",
      "20491748 ['df = df.reset_index(drop=True)']\n",
      "20496583 []\n",
      "20523271 ['df = pd.DataFrame(np.random.randn(m, n),', \"    _ = ax.text(j, i, '{0:.2f}'.format(df.iloc[i, j]),\"]\n",
      "20557179 []\n",
      "20566408 ['[list(x) for x in dt.T.itertuples()]']\n",
      "20574460 ['df_asint = df.astype(int)']\n",
      "20603020 [\"dat1 = pd.DataFrame({'dat1': [9,5]})\", \"dat2 = pd.DataFrame({'dat2': [7,6]})\", 'dat1.join(dat2)']\n",
      "20612691 []\n",
      "20619971 [\"x = pd.DataFrame({'cat':('A','A','B'), 'val':(10,20,30)})\", \"labels, levels = pd.factorize(x['cat'])\", \"x = x.set_index('cat')\"]\n",
      "20627316 []\n",
      "20637559 ['pd.read_csv(StringIO(s), skiprows=[1], header=None)', 'pd.read_csv(StringIO(s), skiprows=1, header=None)']\n",
      "20638258 ['pd.DataFrame(d)']\n",
      "20639234 []\n",
      "20644369 [\"df = DataFrame(np.random.randn(5,2),columns=list('AB'))\", 'dfa = df.ix[:,[1,0]].copy()']\n",
      "20644575 [\"df = pd.DataFrame([[1,2],[3,4]], columns=list('ab'))\"]\n",
      "20648462 [\"df['diffs'] = df['value'].diff()\", 'mask = df.ticker != df.ticker.shift(1)', \"df.filter(['ticker', 'date', 'value'])\", \"df.set_index(['ticker','date'], inplace=True)\", 'df.sort_index(inplace=True)', '    df.diffs[idx] = df.value[idx].diff()']\n",
      "20657592 ['s = pd.Series([1,2,3,2,2,3,5,2,3,2,np.nan])', \"ax.hist(s.dropna(), alpha=0.9, color='blue')\"]\n",
      "20670901 ['df = pd.read_json(s)', 'df.apply(lambda x: pd.lib.infer_dtype(x.values))', 'types = df.apply(lambda x: pd.lib.infer_dtype(x.values))']\n",
      "20671047 [\"data3['diffs'] = data3.groupby('ticker')['value'].transform(Series.diff)\", 'data3.sort_index(inplace=True)']\n",
      "20687887 []\n",
      "20687984 []\n",
      "20690383 []\n",
      "20693013 []\n",
      "20701559 []\n",
      "20739897 [\"np.diff(index)/np.timedelta64(1, 's')\", \"np.diff(index)/np.timedelta64(1, 'm')\"]\n",
      "20763459 []\n",
      "20808449 []\n",
      "20842283 ['DataFrame(...).ix[row_indexer,column_indexer]', 'Series(...).ix[row_indexer]']\n",
      "20868446 [\"df=df.rename(columns = {'two':'new_name'})\"]\n",
      "20869270 []\n",
      "20870801 []\n",
      "20937592 ['df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', 'df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', \"df['cost'] = df['cost'].map('${:,.2f}'.format)\"]\n",
      "20965090 [\"df['cum_sum'] = df.val1.cumsum()\", \"df['cum_perc'] = 100*df.cum_sum/df.val1.sum()\"]\n",
      "20970328 [\"df['state'].apply(lambda x: x[len(x)/2-1:len(x)/2+1])\"]\n",
      "20995313 ['df = pd.DataFrame({\"class\":[1,1,1,2,2], \"value\":[1,2,3,4,5]})', 'df[df[\"class\"]==1].sum()', 'df[df[\"class\"]==1].sum()[\"value\"]', 'df[df[\"class\"]==1].count()[\"value\"]']\n",
      "20995428 [\"df = pd.DataFrame({'a': [1, 2, 3]})\", 'df[df.a > 1].sum()   ', 'df[(df.a > 1) & (df.a < 3)].sum()']\n",
      "21000675 ['    return assert_frame_equal(df1.sort(axis=1), df2.sort(axis=1), check_names=True, **kwds )']\n",
      "21007047 [\"sorted = df.sort_index(by='data_date')\", \"result = sorted.drop_duplicates('obj_id', take_last=True).values\"]\n",
      "21020411 []\n",
      "21023125 ['pd.DataFrame(df.values*df2.values, columns=df.columns, index=df.index)']\n",
      "21032532 [\"df = pd.DataFrame(['a b c']*100000, columns=['col']);\", \"df = pd.DataFrame(['a b c']*100000, columns=['col']);\", \"df = pd.DataFrame(['a b c']*100000, columns=['col']);\", \"df = pd.DataFrame(['a b c']*100000, columns=['col']);\", \"df = pd.DataFrame(['a b c']*100000, columns=['col']);\"]\n",
      "21033789 ['series = pandas.Series(np.random.normal(size=2000))']\n",
      "21055161 [\"df['A'].str.contains(r'^(?:(?!Hello|World).)*$')\", 'df = pd.DataFrame({\"A\": [\"Hello\", \"this\", \"World\", \"apple\"]})', \"df['A'].str.contains(r'^(?:(?!Hello|World).)*$')\", \"df[df['A'].str.contains(r'^(?:(?!Hello|World).)*$')]\"]\n",
      "21055176 ['df = pd.DataFrame({\"A\": [\"Hello\", \"this\", \"World\", \"apple\"]})', 'df.A.str.contains(\"Hello|World\")', 'df[~df.A.str.contains(\"Hello|World\")]']\n",
      "21059308 ['        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '        pad = np.empty(window_size - min_periods)', '    return dd.min(axis=1)', '    return dd2here.min()', '    s = pd.Series(np.random.randn(n).cumsum())', '    df = pd.concat([s, rolling_dd], axis=1)', '    df.plot(linewidth=3, alpha=0.4)', \"    plt.plot(my_rmdd, 'g.')\"]\n",
      "21140339 [\"pd.set_option('display.float_format', lambda x: '%.3f' % x)\", 'Series(np.random.randn(3))*1000000000', \"Series(np.random.randn(3)).apply(lambda x: '%.3f' % x)\"]\n",
      "21165116 ['df.loc[:, (df != 0).any(axis=0)]', 'df = pd.DataFrame([[1,0,0,0], [0,0,1,0]])', '(df != 0).any(axis=0)', 'df.loc[:, (df != 0).any(axis=0)]', 'df = df.loc[:, (df != 0).any(axis=0)]']\n",
      "21175114 ['s1 = pd.Series([4,5,6,20,42])', 's2 = pd.Series([1,2,3,5,42])', 'pd.Series(list(set(s1).intersection(set(s2))))', 'pd.Series(np.intersect1d(s1,s2))', 'pd.Series(np.intersect1d(s1.values,s2.values))']\n",
      "21189441 ['    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = basis.apply(applyToWindow)', 'df = pd.DataFrame({\"RollBasis\":np.random.uniform(0,1000000,100000), \"ToRoll\": np.random.uniform(0,10,100000)})', '    windows_min = basis.min()', '    windows_max = basis.max()', '    window_starts = pd.Series(window_starts, index = window_starts)', '    indexed_what = pd.Series(what.values,index=basis.values)', '        indexer = indexed_what.index.slice_indexer(val,val+window,1)', '    rolled = window_starts.apply(applyToWindow)']\n",
      "21197863 ['df.convert_objects(convert_numeric=True)', 'df.convert_objects(convert_numeric=True).dtypes']\n",
      "21204417 ['a = (np.random.rand(30)*1000000*1000).astype(np.int64)*1000000', 'b = (np.random.rand(10)*1000000*1000).astype(np.int64)*1000000', 'idx = np.searchsorted(t1, t2) - 1', 'df = pd.DataFrame({\"t1\":t1[idx][mask], \"t2\":t2[mask]})', 'pl.vlines(pd.Series(t1), 0, 1, colors=\"g\", lw=1)']\n",
      "21221138 [\"mpl.style.use('ggplot')\"]\n",
      "21232849 ['frame = pd.DataFrame()', '    df = pd.read_csv(file_,index_col=None, header=0)', '    list_.append(df)', 'frame = pd.concat(list_)']\n",
      "21242140 [\"pd.concat([df1['c'], df2['c']], axis=1, keys=['df1', 'df2'])\"]\n",
      "21244212 ['df[df.apply(lambda x: min(x) == max(x), 1)]']\n",
      "21244355 ['df[df.apply(pd.Series.nunique, axis=1) == 1]', 'df.apply(pd.Series.nunique, axis=1)']\n",
      "21247312 ['pd.crosstab(df.A, df.B).apply(lambda r: r/r.sum(), axis=1)']\n",
      "21248050 ['mydf.groupby([\\'cat\\', \"class\"]).val.sum().reset_index()', 'mydf.groupby([\\'cat\\', \"class\"]).val.sum().reset_index(level=1)', 'mydf.groupby([\\'cat\\', \"class\"], as_index=False).val.sum()']\n",
      "21260328 []\n",
      "21263149 []\n",
      "21266043 []\n",
      "21271103 [\"pd.read_csv(file, sep='\\\\t', header=None, names=headers, dtype=dtypes)\", \"pd.read_csv(file, sep='\\\\t', header=None, names=headers, parse_dates=True)\"]\n",
      "21272615 []\n",
      "21275962 []\n",
      "21285575 ['df = pd.DataFrame(data)', \"df2 = df.filter(regex='spike')\"]\n",
      "21287539 []\n",
      "21290084 []\n",
      "21291383 ['df = pd.DataFrame(np.random.rand(3,4), columns=list(\"ABCD\"))', 'df[list(\"ABCD\")] = df[list(\"ABCD\")].astype(int)', 'df[list(\"ABCD\")] = df[list(\"ABCD\")].fillna(0.0).astype(int)']\n",
      "21291622 [\"df= pd.DataFrame(range(5), columns=['a'])\", 'df.a = df.a.astype(float)']\n",
      "21295630 []\n",
      "21296915 [\"df.row.str.extract('(?P<fips>\\\\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))')\"]\n",
      "21315199 []\n",
      "21317570 ['pandas.concat([df1,df2]).drop_duplicates().reset_index(drop=True)']\n",
      "21317700 [\"MultiIndex.from_arrays(cartesian_product([range(3),list('ab')]))\", 'df = DataFrame(dict(A = np.arange(6), ', '                             C = np.ones(6)+np.arange(6)%2)']\n",
      "21320011 [\"s = pd.Series(list('abc'))\", 's.unique()', \"'a' in s.unique()\"]\n",
      "21324222 [\"df = pd.read_csv('test.csv', header=[0, 1], skipinitialspace=True, tupleize_cols=True)\", 'df.columns = pd.MultiIndex.from_tuples(df.columns)']\n",
      "21361994 ['    pl.plot(pl.randn(100))']\n",
      "21415990 []\n",
      "21441621 ['df.groupby(pd.cut(df[\"B\"], np.arange(0, 1.0+0.155, 0.155))).sum()']\n",
      "21463854 ['data[\\'amount\\'] = data[\"amount\"].fillna(data.groupby(\"num\")[\"amount\"].transform(\"mean\"))', 'data[\"amount\"] = data[\\'amount\\'].fillna(mean_avg)', \"data['amount'] = data['amount'].fillna(mean_avg)*2\", \"pd.set_option('chained_assignment',None)\"]\n",
      "21487560 [\"ax = df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')\"]\n",
      "21487868 [\"df2 = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])\", \"df2.plot(lw=2,colormap='jet',marker='.',markersize=10,title='Video streaming dropout by category')\"]\n",
      "21489607 ['ax = cum_edits.plot()']\n",
      "21500413 ['res = pd.DataFrame(json.loads(out))', 'res.drop_duplicates()']\n",
      "21546823 ['data = pd.read_csv(\\'output_list.txt\\', sep=\" \", header=None)']\n",
      "21607530 ['df.rename(columns=lambda x: x.strip())']\n",
      "21608417 []\n",
      "21649359 []\n",
      "21655221 [\"df = pd.DataFrame(np.random.normal(10,1,30).reshape(10,3), index = pd.date_range('2010-01-01', freq = 'M', periods = 10), columns = ('one', 'two', 'three'))\"]\n",
      "21655256 ['df = pd.DataFrame(dict(x=x, y=y, label=labels))', \"groups = df.groupby('label')\", \"    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\", 'df = pd.DataFrame(dict(x=x, y=y, label=labels))', \"groups = df.groupby('label')\", 'plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)', \"colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')\", \"    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\"]\n",
      "21689542 []\n",
      "21709413 ['df = pd.DataFrame({', \"df_grouped = df.groupby(['sp', 'mt']).agg({'count':'max'})\", 'df_grouped = df_grouped.reset_index()', \"df_grouped = df_grouped.rename(columns={'count':'count_max'})\", \"df = pd.merge(df, df_grouped, how='left', on=['sp', 'mt'])\"]\n",
      "21720133 [\"df = pd.DataFrame([[1, 'a', 2.]])\", \"df.loc[:, df.dtypes == object] = df.loc[:, df.dtypes == object].fillna('')\"]\n",
      "21734254 [\"d = {'Age' : pd.Series([36., 42., 6., 66., 38.]) }\", 'df = pd.DataFrame(d)']\n",
      "21738682 ['dt.datetime.today().strftime(\"%m/%d/%Y\")']\n",
      "21751529 []\n",
      "21755752 ['df.append(df.sum(numeric_only=True), ignore_index=True)', \"baz = 2*df['qux'].sum() + 3*df['bar'].sum()\"]\n",
      "21768034 ['g = g.reset_index()', \"g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()\"]\n",
      "21771438 ['np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))']\n",
      "21772078 ['df.applymap(np.isreal)', 'df.applymap(np.isreal).all(1)', 'df[~df.applymap(np.isreal).all(1)]', 'np.argmin(df.applymap(np.isreal).all(1))', 'df.applymap(lambda x: isinstance(x, (int, float)))']\n",
      "21787325 [\"s1 = pd.merge(df1, df2, how='left', on=['Year', 'Week', 'Colour'])\", \"df = pd.merge(s1, df3[['Week', 'Colour', 'Val3']],\"]\n",
      "21800319 [\"df[df['BoolCol'] == True].index.tolist()\", \"df[df['BoolCol']].index.tolist()\", \"df = pd.DataFrame({'BoolCol': [True, False, False, True, True]},\", \"df[df['BoolCol']].index.tolist()\", \"idx = df[df['BoolCol']].index.tolist()\"]\n",
      "21869063 [\"pandas.set_option('expand_frame_repr', False)\", \"mydf = pandas.DataFrame.from_csv('myfile.csv', header=1)\", \"pandas.set_option('display.max_columns', 0) # Display any number of columns\", \"pandas.set_option('display.max_rows', 0) # Display any number of rows\"]\n",
      "21902162 [\"a = pandas.DataFrame.from_csv('st1.csv', sep=' ')\", \"a = pandas.DataFrame.from_csv('st1.csv', index_col=None)\"]\n",
      "21916253 []\n",
      "21940107 [\"df = pd.DataFrame({'R':px2[:,0],'G':px2[:,1],'B':px2[:,2]})\"]\n",
      "21942746 []\n",
      "21961491 [\"df['date_int'] = df.date.astype(np.int64)\", \"training.plot(kind='scatter',x='date',y='rate', color=df.account.map(color_d))\"]\n",
      "21989204 [\"ax = var.total.plot(label='Variance')\", \"ax = shares.average.plot(secondary_y=True, label='Average Age')\", \"ax.plot(var.index.to_datetime(), var.total, 'b', label='Variance')\", \"ax2.plot(shares.index.to_datetime(), shares.average, 'g' , label='Average Age')\"]\n",
      "22006514 [\"total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)\", \"df = pd.DataFrame([['A', 2], ['A', 4], ['B', 6]])\", 'df.to_json()', 'df[0].to_json()']\n",
      "22018873 []\n",
      "22019831 [\"df.to_csv('output.csv', columns = header)\"]\n",
      "22033314 ['mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)', 'mask = np.all(np.isnan(arr) | arr == 0, axis=1)']\n",
      "22033364 ['mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)']\n",
      "22070926 [\"df = pd.DataFrame(np.random.randn(400, 4), columns=['one', 'two', 'three', 'four'])\", 'ax1 = df.cumsum().plot()']\n",
      "22082596 ['df1.change.shift(1)', 'df1.change.shift(1) - df1.change', \"df.groupby('case')['change'].apply(lambda x: x.shift(1) - x)\"]\n",
      "22084742 ['    print(min(timeit.Timer(func, setup).repeat(3, 100000)))', 'value = [val[5] for col,val in dictionary.iteritems()]']\n",
      "22086347 []\n",
      "22089870 []\n",
      "22104034 []\n",
      "22127685 [\"origin.pivot(index='label', columns='type')['value']\", \"origin.pivot_table(values='value', index='label', columns='type')\", \"origin.groupby(['label', 'type'])['value'].aggregate('mean').unstack()\"]\n",
      "22132649 [\"df['A'] = pd.to_datetime(df['A'])\", \"df['B'] = pd.to_datetime(df['B'])\"]\n",
      "22135309 ['    data = pd.DataFrame(json.loads(line) for line in f)']\n",
      "22137890 ['df.applymap(atof)', \"df.read_csv('foo.tsv', sep='\\\\t', thousands=',')\"]\n",
      "22149930 []\n",
      "22161058 ['        if len(args) == 1 and isinstance(args[0], MyDF):', '        for attr in self._attributes_.split(\",\"):', 'mydf_cp2 = mydf.copy()']\n",
      "22166224 []\n",
      "22181298 ['    x = pd.DataFrame(np.random.randn(20, 5))', '    return render_template(\"analysis.html\", name=filename, data=x.to_html())']\n",
      "22211821 [\"df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150], columns=['A'])\", 'df.sort_index(inplace=True)', 'print(df.to_string())']\n",
      "22221272 []\n",
      "22221675 [\"df = pd.DataFrame( {'a':['A','A','B','B','B','C'], 'b':[1,2,5,5,4,6]})\", \"df.groupby('a')['b'].apply(list)\"]\n",
      "22233719 ['cols = pd.MultiIndex.from_tuples([(\"a\", \"b\"), (\"a\", \"c\")])', 'df = pd.DataFrame([[1,2], [3,4]], columns=cols)', 'df.columns = df.columns.droplevel()']\n",
      "22233851 ['    x = pd.DataFrame(np.random.randn(20, 5))']\n",
      "22235393 ['df.describe()', 'df.describe().transpose()']\n",
      "22238380 [\"data['result'] = data['result'].map(lambda x: str(x)[:-1])\", \"data['result'] = data['result'].map(lambda x: str(x)[2:])\"]\n",
      "22247593 [\"df['x'].str.lower()\"]\n",
      "22257615 ['df = DataFrame(np.random.randn(10,2))', 'df.describe()', 'df.info()', 'len(df.index)-df.count()', 'df.isnull().sum()']\n",
      "22258061 []\n",
      "22259008 ['skip = sorted(random.sample(xrange(n),n-s))', 'df = pandas.read_csv(filename, skiprows=skip)', 'n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)', 'skip = sorted(random.sample(xrange(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list', 'df = pandas.read_csv(filename, skiprows=skip)']\n",
      "22264337 [\"xt = xt.astype('object') # Comment this to fix the error\"]\n",
      "22276757 []\n",
      "22341390 [\"d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),\", \"    'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\", 'df = DataFrame(d)', \"dfList = df['one'].tolist()\"]\n",
      "22365284 [\"df1.join(df2, how='inner')\", 'merge(df1.reset_index(),', '      df2.reset_index(),']\n",
      "22368682 [\"aggregated = df.groupby(['model', 'training_examples']).aggregate(np.mean)\", \"aggregated.plot(x='training_examples', y='accuracy', label='model')\", \"for index, group in df.groupby(['model']):\", \"    group_agg = group.groupby(['training_examples']).aggregate(np.mean)\", \"    group_agg.plot(y='accuracy', label=index)\"]\n",
      "22391554 [\"df = pd.DataFrame({'a':list('abssbab')})\", \"df.groupby('a').count()\", \"df['a'].value_counts()\", \"df['freq'] = df.groupby('a')['a'].transform('count')\"]\n",
      "22455322 []\n",
      "22471217 [\"df = pd.DataFrame([[1, 2.3456, 'c']])\", 'np.round(df.loc[:, msk], 2)', 'df.loc[:, msk] = np.round(df.loc[:, msk], 2)']\n",
      "22475141 ['df = pd.DataFrame([[1, 2.3456, \\'c\\', \\'d\\', 78]], columns=list(\"ABCDE\"))', 'g = df.columns.to_series().groupby(df.dtypes).groups', \"{dtype('int64'): ['A', 'E'], dtype('float64'): ['B'], dtype('O'): ['C', 'D']}\"]\n",
      "22484249 ['df1.plot(ax=axes[0,0])', 'df2.plot(ax=axes[0,1])']\n",
      "22485573 [\"df['Name'].isin(['Alice', 'Bob'])\", \"df[df.Name.isin(['Alice', 'Bob'])]\"]\n",
      "22487898 []\n",
      "22496075 []\n",
      "22543333 [\"plt.style.use('ggplot')\"]\n",
      "22546459 []\n",
      "22547347 [\"df = DataFrame(randint(4, size=(n, 2)), columns=list('ab'))\", 'df.isin([1, 2])', 'df.isin([1, 2]).any(1)', 'df.loc[df.isin([1, 2]).any(1)]']\n",
      "22553757 ['nms.dropna(thresh=2)', 'nms = nms.dropna(thresh=2)', 'nms[nms.name.notnull()]', 'nms[nms.name.notnull()]']\n",
      "22588340 ['value = re.sub(r\"[^0-9]+\", \"\", value)']\n",
      "22591024 [\"df = pd.DataFrame(['$40,000*','$40000 conditions attached'], columns=['P'])\", \"df['P'] = df['P'].str.replace(r'\\\\D+', '').astype('int')\"]\n",
      "22591267 []\n",
      "22596982 []\n",
      "22605281 ['df = pd.read_csv(TESTDATA, sep=\";\")']\n",
      "22642484 [\"df = pd.DataFrame([[1., 2.], [3., 4.]], columns=['A', 'B'])\", \"df2 = pd.DataFrame([[5., 10.]], columns=['A', 'B'])\", 'df.div(df2)', 'df.div(df2.iloc[0])']\n",
      "22643040 ['df1 = pd.DataFrame(data1)', 'df2 = pd.DataFrame(data2) ', \"df1.div(df2.ix[0],axis='columns')\"]\n",
      "22650075 [\"df = pd.DataFrame({'a':[0,0,1,1], 'b':[0,1,0,1]})\", 'df = df[(df.T != 0).any()]']\n",
      "22650162 ['df.loc[~(df==0).all(axis=1)]', 'df.loc[(df!=0).any(axis=1)]']\n",
      "22651188 []\n",
      "22653050 ['df.reset_index().values', \"df.reset_index().values.ravel().view(dtype=[('index', int), ('A', float), ('B', float), ('C', float)])\"]\n",
      "22657894 [\"df = df.rename(columns=lambda x: x.replace('$', ''))\", \"df.rename(columns=lambda x: x.replace('$', ''), inplace=True)\"]\n",
      "22674279 []\n",
      "22676213 [\"left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key')\", \"right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key')\", \"left.join(right, lsuffix='_l', rsuffix='_r')\", \"left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]})\", \"right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]})\", \"left.merge(right, on=('key'), suffixes=('_l', '_r'))\"]\n",
      "22677264 []\n",
      "22697903 []\n",
      "22702814 []\n",
      "22719983 [\"df['bar'] = df['bar'].str.cat(df['foo'].values.astype(str), sep=' is ')\"]\n",
      "22720823 [\"df = pd.DataFrame([[1, 3], [2, 4]], columns=['A', 'B'])\", \"df2 = pd.DataFrame([[1, 5], [1, 6]], columns=['A', 'C'])\", \"df.merge(df2, how='left')  # merges on columns A\", \"df2.drop_duplicates(subset=['A'])  # you can use take_last=True\", \"df.merge(df2.drop_duplicates(subset=['A']), how='left')\"]\n",
      "22798849 [\"df.to_csv(filename, date_format='%Y%m%d')\"]\n",
      "22798911 ['df = pd.read_clipboard().iloc[1:]', 'df = pd.melt(df, id_vars=[\"date\"], var_name=\"condition\")', 'ax = df.groupby([\"condition\", \"date\"]).mean().unstack(\"condition\").plot()', 'x = np.arange(len(df.date.unique()))', 'for cond, cond_df in df.groupby(\"condition\"):', '    low = cond_df.groupby(\"date\").value.apply(np.percentile, 25)', '    high = cond_df.groupby(\"date\").value.apply(np.percentile, 75)', '    ax.fill_between(x, low, high, alpha=.2, color=palette.pop(0))']\n",
      "22799358 [\"pd.DataFrame(out.tolist(), columns=['out-1','out-2'], index=out.index)\"]\n",
      "22799830 [\"pivoted = df.pivot('salesman', 'product', 'price')\"]\n",
      "22799916 [\"df['idx'] = df.groupby('Salesman').cumcount()\", \"df['prod_idx'] = 'product_' + df.idx.astype(str)\", \"df['prc_idx'] = 'price_' + df.idx.astype(str)\", \"product = df.pivot(index='Salesman',columns='prod_idx',values='product')\", \"prc = df.pivot(index='Salesman',columns='prc_idx',values='price')\", 'reshape = pd.concat([product,prc],axis=1)', \"reshape['Height'] = df.set_index('Salesman')['Height'].drop_duplicates()\", \"df['idx'] = df.groupby('Salesman').cumcount()\", \"    df['tmp_idx'] = var + '_' + df.idx.astype(str)\", \"    tmp.append(df.pivot(index='Salesman',columns='tmp_idx',values=var))\", 'reshape = pd.concat(tmp,axis=1)']\n",
      "22825954 [\"ts = pd.Timestamp('2014-01-23 00:00:00', tz=None)\", 'ts.to_pydatetime()', \"rng = pd.date_range('1/10/2011', periods=3, freq='D')\", 'rng.to_pydatetime()']\n",
      "22836353 [\"df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])\", \"df.plot(ax=ax, kind='bar', legend=False)\", \"hatches = ''.join(h*len(df) for h in 'x/O.')\"]\n",
      "22840737 []\n",
      "22845857 ['    n_df = len(dfall)', '    n_col = len(dfall[0].columns) ', '    n_ind = len(dfall[0].index)', '        axe = df.plot(kind=\"bar\",', '        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))', 'df1 = pd.DataFrame(np.random.rand(4, 5),', 'df2 = pd.DataFrame(np.random.rand(4, 5),', 'df3 = pd.DataFrame(np.random.rand(4, 5),', 'dfall = pd.concat([pd.melt(i.reset_index(),', 'dfall.set_index([\"Name\", \"index\", \"variable\"], inplace=1)', 'dfall[\"vcs\"] = dfall.groupby(level=[\"Name\", \"index\"]).cumsum()', 'dfall.reset_index(inplace=True) ', 'dfall.head(6)', 'for i, g in enumerate(dfall.groupby(\"variable\")):']\n",
      "22848472 []\n",
      "22898920 []\n",
      "22918691 []\n",
      "22920808 []\n",
      "22924683 [\"df = pandas.DataFrame(columns=['to','fr','ans'])\", \"df.to = [pandas.Timestamp('2014-01-24 13:03:12.050000'), pandas.Timestamp('2014-01-27 11:57:18.240000'), pandas.Timestamp('2014-01-23 10:07:47.660000')]\", \"df.fr = [pandas.Timestamp('2014-01-26 23:41:21.870000'), pandas.Timestamp('2014-01-27 15:38:22.540000'), pandas.Timestamp('2014-01-23 18:50:41.420000')]\", \"(df.fr-df.to).astype('timedelta64[h]')\"]\n",
      "22940775 [\"df.loc[df.groupby('obj_id').data_date.idxmax(),:]\"]\n",
      "22964673 ['d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)']\n",
      "22974440 [\"data=data.where(data=='-', None) \"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22992568 ['df[df[\\'stridx\\'].str.contains(\"Hello|Britain\")]']\n",
      "23005564 []\n",
      "23088780 ['df1 = pd.read_fwf(io.BytesIO(texts[0]), widths=[5,7,25,17,20], parse_dates=[4])', 'df2 = pd.read_fwf(io.BytesIO(texts[1]), widths=[5,7,25,17,20], parse_dates=[4])', \"    return x[0] if x[0] == x[1] else '{} | {}'.format(*x)\", 'my_panel = pd.Panel(dict(df1=df1,df2=df2))', '    elif pd.isnull(x[0]) and pd.isnull(x[1]):', '    elif pd.isnull(x[0]) and ~pd.isnull(x[1]):', '    elif ~pd.isnull(x[0]) and pd.isnull(x[1]):', 'HTML(my_panel.apply(report_diff, axis=0).to_html(escape=False))']\n",
      "23104436 [\"df.to_sql('table_name', engine)\"]\n",
      "23112008 []\n",
      "23143081 [\"df['dA'] = df['A'] - df['A'].shift(-1)\"]\n",
      "23143110 ['df = pd.DataFrame({\"A\": [9, 4, 2, 1], \"B\": [12, 7, 5, 4]})', 'df[\"dA\"] = df[\"A\"].diff(-1)']\n",
      "23146038 []\n",
      "23151722 ['row_iterator = df.iterrows()']\n",
      "23178185 []\n",
      "23198160 [\"df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1); df\"]\n",
      "23200666 [\"df=pd.DataFrame({'Data':np.random.normal(size=200)})  #example dataset of normally distributed data. \", \"df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] #keep only the ones that are within +3 to -3 standard deviations in the column 'Data'.\", 'df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] #or if you prefer the other way around', 'S=pd.Series(np.random.normal(size=200))', 'S[~((S-S.mean()).abs()>3*S.std())]']\n",
      "23202269 ['df = pd.DataFrame(np.random.randn(100, 3))', 'df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]']\n",
      "23235618 [\"df = df[pd.notnull(df['EPS'])]\"]\n",
      "23282290 ['df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))']\n",
      "23296545 []\n",
      "23307361 [\"w['female'] = w['female'].map({'female': 1, 'male': 0})\"]\n",
      "23317595 [\"foo = lambda x: pd.Series([i for i in reversed(x.split(','))])\", \"rev = df['City, State, Country'].apply(foo)\", \"rev.rename(columns={0:'Country',1:'State',2:'City'},inplace=True)\"]\n",
      "23331659 []\n",
      "23331896 ['dt = tablename.c.arr_date >= datetime.date.today() # Give me convenience or...', 'q = session.query(tablename).\\\\', '    df = DataFrame(query.all());']\n",
      "23354240 [\"pd.melt(x, id_vars=['farm', 'fruit'], var_name='year', value_name='value')\"]\n",
      "23377155 [\"df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,\", \"state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})\", \"state = df.groupby(['state']).agg({'sales': 'sum'})\", \"state_office.div(state, level='state') * 100\"]\n",
      "23377232 [\"df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,\", \"state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})\", 'state_pcts = state_office.groupby(level=0).apply(lambda x:', '                                                 100 * x / float(x.sum()))']\n",
      "23394497 ['se = pd.Series([1,2,3])']\n",
      "23394706 ['df.loc[df.groupby(\"item\")[\"diff\"].idxmin()]', 'df.sort(\"diff\").groupby(\"item\", as_index=False).first()']\n",
      "23428804 [\"df2 = df.groupby(['Name', 'Abuse/NFF'])['Name'].count().unstack('Abuse/NFF').fillna(0)\", \"df2[['abuse','nff']].plot(kind='bar', stacked=True)\"]\n",
      "23451304 [\"df['zscore'] = (df.a - df.a.mean())/df.a.std(ddof=0)\"]\n",
      "23464103 []\n",
      "23478395 [\"df = df.reindex(df.index.rename(['Date']))\"]\n",
      "23479973 ['    for yi in np.unique(y):', '        class_xs.append((yi, elems))', '        if len(this_xs) > use_elems:', '        y_ = np.empty(use_elems)', '        xs.append(x_)', '        ys.append(y_)']\n",
      "23483221 ['df = pd.DataFrame(', 'sorterIndex = dict(zip(sorter,range(len(sorter))))', \"df['Tm_Rank'] = df['Tm'].map(sorterIndex)\", \"df.drop('Tm_Rank', 1, inplace = True)\", \"df['Tm_Rank'] = df['Tm'].map(sorterIndex)\", \"df.drop('Tm_Rank', 1, inplace = True)\"]\n",
      "23509622 [\"windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -\", \"df = df.merge(windows,on='company',how='left')\", \"windows['beg_date'] = (windows['end_date'].values.astype('datetime64[D]') -\", \"    g = g.merge(windows,on='company',how='left')\", \"    return g.groupby('end_date')['measure'].sum()\", \"df = df.merge(windows,on=['company','date'],how='outer')\", \"df['end_date'] = df.groupby('company')['end_date'].apply(lambda x: x.bfill())\", 'df = df[df.end_date.notnull()]', \"df['beg_date'] = (df['end_date'].values.astype('datetime64[D]') -\"]\n",
      "23522030 ['series = [pd.Series(mat[name][:, 1]) for name in Variables]', 'df = pd.concat(series, axis=1)']\n",
      "23534505 []\n",
      "23544011 [\"pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')\", \"(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[s]')\", \"(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')).astype('timedelta64[D]')\", \"(pd.to_timedelta(np.arange(5),unit='d')+pd.to_timedelta(1,unit='s')) / np.timedelta64(1,'D')\"]\n",
      "23549599 []\n",
      "23600844 []\n",
      "23671390 ['df1 = pd.DataFrame(np.array([', 'df2 = pd.DataFrame(np.array([', 'df3 = pd.DataFrame(np.array([', \"pd.merge(pd.merge(df1,df2,on='name'),df3,on='name')\", \"df1.merge(df2,on='name').merge(df3,on='name')\"]\n",
      "23691168 [\"gb = df.groupby('ZZ')    \", '[gb.get_group(x) for x in gb.groups]']\n",
      "23691692 ['df = pandas.DataFrame({\"a\": np.random.random(100), ', 'groups = df.groupby(pandas.cut(df.a, 10))', 'print(groups.mean().b)']\n",
      "23696169 ['data = pd.DataFrame({ \"A\":np.random.normal(0.8,0.2,20),', '    x = np.random.normal(i+1, 0.04, len(y))', '    plt.plot(x, y, mfc = [\"orange\",\"blue\",\"yellow\"][i], mec=\\'k\\', ms=7, marker=\"o\", linestyle=\"None\")', '    x = np.random.normal(i, 0.02, len(y))', \"    plt.plot(x, y, 'r.', alpha=0.2)\"]\n",
      "23709208 ['df = pd.DataFrame({\"A\":[\"foo\", \"foo\", \"foo\", \"bar\"], \"B\":[0,1,1,1], \"C\":[\"A\",\"A\",\"B\",\"A\"]})', 'df.groupby([\"A\", \"C\"]).filter(lambda df:df.shape[0] == 1)']\n",
      "23732825 []\n",
      "23733522 ['df = pd.read_csv(\\'values.csv\\', delimiter=\\',\\', encoding=\"utf-8-sig\")']\n",
      "23739252 []\n",
      "23741480 []\n",
      "23741704 []\n",
      "23743582 ['DataFrame().fillna(value=nan, inplace=True)', 'my_dataframe.fillna(value=nan, inplace=True)']\n",
      "23747587 ['df[df.b.isnull()]']\n",
      "23749057 [\"df = pd.DataFrame({'a':[1,3,5,7,4,5,6,4,7,8,9],\", \"df['a'].values.tolist()\", \"df['a'].tolist()\", \"df['a'].drop_duplicates().values.tolist()\"]\n",
      "23787275 [\"df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'],index_col='Date')\", 'df_train_fly = pd.date_range(start, end, freq=\"W-FRI\")', \"df_train_fly = pd.DataFrame(pd.Series(df_train_fly), columns=['Date'])\", \"merged = df_train_csv.join(df_train_fly.set_index(['Date']), on = ['Date'], how = 'right', lsuffix='_x')\", \"df_train_csv = pd.read_csv('./train.csv',parse_dates=['Date'])\", \"merged = df_train_csv.join(df_train_fly, on = ['Date'], how = 'right', lsuffix='_x')\", \"merged = df_train_csv.join(df_train_fly, how = 'right', lsuffix='_x')\", \"merged = df_train_csv.merge(df_train_fly.set_index(['Date']), left_index=True, right_index=True, how = 'right', lsuffix='_x')\"]\n",
      "23787861 [\"df['bar'].fillna(df['foo'], inplace=True)\", \"df1 = pd.DataFrame({'a':[1,2],'b':[3,4]}, index = [1,2])\", \"df2 = pd.DataFrame({'b':[5,6]}, index = [3,4])\", 'dftot = pd.concat((df1, df2))', \"filldf = pd.DataFrame({'a':[7,7,7,7]})\"]\n",
      "23807740 [\"ix = pd.DatetimeIndex(start=date(2012, 1, 1), end=date(2012, 1, 31), freq='D')\", 'df2.reindex(ix)']\n",
      "23836353 [\"df['ID'] = df['ID'].apply(lambda x: '{0:0>15}'.format(x))\", \"df['ID'] = df['ID'].apply(lambda x: x.zfill(15))\"]\n",
      "23853569 ['read_csv(..., nrows=999999)', 'read_csv(..., skiprows=1000000, nrows=999999)']\n",
      "23887956 ['pd.concat([x]*5)', 'pd.concat([x]*5, ignore_index=True)']\n",
      "23901625 []\n",
      "23922119 ['df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],']\n",
      "23925229 [\"df = pd.DataFrame(data=my_data, columns=['y', 'dummy', 'x'])\", \"just_dummies = pd.get_dummies(df['dummy'])\", 'step_1 = pd.concat([df, just_dummies], axis=1)      ', \"step_1.drop(['dummy', 'c'], inplace=True, axis=1)\", 'step_1 = step_1.applymap(np.int) ']\n",
      "23966229 [\"df.groupby(pd.TimeGrouper('5Min'))['val'].mean()\", \"df.groupby(pd.TimeGrouper('5Min'))['val'].apply(lambda x: len(x) > 3)\", \"new = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['val'])\", \"df['period'] = new.index.get_level_values(0)\"]\n",
      "24029921 ['df.append([df_try]*5,ignore_index=True)']\n",
      "24037972 [\"mydf['Cigarettes'] = mydf['Cigarettes'].str.replace(' ', '')\", \"mydf['CigarNum'] = mydf['Cigarettes'].apply(numcigar.get).astype(float)\", \"mydf['CigarNum'] = mydf['Cigarettes'].replace(numcigar)\", \"mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)\", \"mydf['CigarNum'] = pd.to_numeric(mydf['CigarNum'], errors='coerce')\"]\n",
      "24040239 [\"df = DataFrame({'a': randint(3, size=10)})\", 'dfa, sa = df.align(s, axis=0)']\n",
      "24041761 [\"is_none = df.set_index(['Company', 'date'], inplace=True)\", \"df = df.set_index(['Company', 'date'], inplace=True)\", \"df.set_index(['Company', 'date'], inplace=True)\"]\n",
      "24043138 [\"df.set_index('filename', inplace=True)\", \"df2.set_index('filename', inplace=True)\", 'df.update(df2)']\n",
      "24074316 [\"df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\"]\n",
      "24082767 [\"d = {'date': Series([date1]*5 + [date2]*5), 'template': Series(range(5)*2),\", \"'score': Series([random() for i in range(10)]) } \", 'data = DataFrame(d)', \"    dates_f = [dt.datetime.strptime(date,'%Y%m%d') for date in dates]\", '    ax.plot(dates_f, dat[\\'score\\'], label = \"Template: {0}\".format(temp))']\n",
      "24083253 ['pd.groupby(b,by=[b.index.month,b.index.year])', \"df.groupby(pd.TimeGrouper(freq='M'))\"]\n",
      "24098354 [\"df.groupby(level=[0,1]).apply(lambda x: x.set_index('Date').resample('2D', how='sum'))\", \"df['Date'] = pd.to_datetime(df['Date'])\"]\n",
      "24098903 ['data.groupby(\"template\").plot(x=\"date\", y=\"score\")']\n",
      "24112443 [\"df = pd.DataFrame( {'A' : [1, 1, 1, 1, 2, 2, 3], 'B' : [10, 12, 11, 10, 11, 12, 14], 'C' : [22, 20,     8, 10, 13, 10, 0]})\", \"df2=df.groupby(['A']).apply(lambda tdf: pd.Series(  dict([[vv,tdf[vv].unique().tolist()] for vv in tdf if vv not in ['A']])  )) \"]\n",
      "24147363 ['df = pd.DataFrame(np.random.randn(100, 2))', 'msk = np.random.rand(len(df)) < 0.8', 'len(test)', 'len(train)']\n",
      "24151789 []\n",
      "24196288 []\n",
      "24216489 ['df = pd.DataFrame( {\"A\": [7001, 8001, 9001]} )', 'df[\"B\"] = df[\"A\"].map(equiv)', 'df = pd.DataFrame( {\"A\": [7001, 8001, 9001, 10000]} )', 'df[\"B\"] = df[\"A\"].map(equiv)']\n",
      "24222837 [\"st['a'] = map(lambda path, row: path + 2 * row, st['path'], st['row'])\", \"table['title'] = map(lambda title,\"]\n",
      "24242333 []\n",
      "24251426 [\"dashboard_df = pd.read_csv(p_file, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\"]\n",
      "24273597 [\"df = pd.DataFrame([[1, 2], [3, 4]], ['a', 'b'], ['A', 'B'])\"]\n",
      "24283087 []\n",
      "24284515 [\"pd.DataFrame(np.array([[2, 3, 4]]), columns=['A', 'B', 'C']).append(df, ignore_index=True)\", \"df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)\", \"df2 = pd.DataFrame(columns=['A', 'B', 'C'], index=index)\"]\n",
      "24284680 []\n",
      "24287210 []\n",
      "24368660 [\"ptest = p.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) \", \"ptest.set_index('id')['value'].to_dict()\"]\n",
      "24370510 [\"ptest = pd.DataFrame([['a',1],['a',2],['b',3]], columns=['id', 'value']) \"]\n",
      "24386746 [\"frame['c'] = frame.fillna(0)['a'] + frame.fillna(0)['b']\", \"frame['c'] = frame.a.fillna(0) + frame.b.fillna(0)\"]\n",
      "24387164 ['frame[\"c\"] = frame[[\"a\", \"b\"]].sum(axis=1)']\n",
      "24396554 []\n",
      "24418294 ['df = psql.read_sql((\\'select \"Timestamp\",\"Value\" from \"MyTable\" \\'']\n",
      "24436783 []\n",
      "24446716 [\"df['date']  = pd.to_datetime(df['date'])\", \"df_masked = df[(df['date'] > datetime.date(2012,4,1)) & (df['date'] < datetime.date(2012,4,4))]\"]\n",
      "24475214 []\n",
      "24489283 [\"idx = pd.MultiIndex.from_product([['John', 'Josh', 'Alex'], list('abcde')], \", 'large = pd.DataFrame(data=np.random.randn(15, 2), ', \"small = large.loc[['Jo'==d[0:2] for d in large.index.get_level_values('Person')]]\", \"small.index.get_level_values('Person').unique()\", \"large.index.get_level_values('Person').unique()\"]\n",
      "24489602 ['df = df[df.line_race.notnull()]']\n",
      "24496435 [\"df.index.get_level_values('co').unique()\"]\n",
      "24517695 []\n",
      "24537997 [\"df = pd.DataFrame([ pd.Timestamp('20010101'), pd.Timestamp('20040605') ])\", \"(df.ix[0]-df.ix[1]).astype('timedelta64[Y]')\"]\n",
      "24542540 [\"pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D':np.sum, 'E':np.mean})\"]\n",
      "24609894 [\"columns = pd.MultiIndex.from_arrays(arrays, names=['foo', 'bar'])\", \"df =pd.DataFrame(np.zeros((3,6)),columns=columns,index=pd.date_range('20000103',periods=3))\", 'h = \"<!DOCTYPE html> <html> <body> <p> \" + df.to_html() + \" </p> </body> </html>\";', 'frame.render(painter)']\n",
      "24674675 ['plot = dtf.plot()']\n",
      "24775756 []\n",
      "24792087 ['df = pd.DataFrame({\"t\": pd.date_range(\\'2014-01-01\\', periods=5, freq=\\'H\\')})', 'pd.DatetimeIndex(df.t).normalize()', \"df['date'] = pd.DatetimeIndex(df.t).normalize()\", 'df.t.dt.normalize()', 'pd.DatetimeIndex(df.t).normalize()']\n",
      "24793359 ['numpyMatrix = df.as_matrix()']\n",
      "24804512 []\n",
      "24826569 ['data.groupby(level=[0, 1]).sum()']\n",
      "24828425 ['df.select_dtypes(include=[np.float64])']\n",
      "24870404 []\n",
      "24871316 []\n",
      "24888331 [\"df = DataFrame(columns=('lib', 'qty1', 'qty2'))\"]\n",
      "24902313 []\n",
      "24907560 [\"df = pd.DataFrame({'a': np.random.randn(1000),\", \"                   'd': pd.date_range('2000-1-1', periods=1000)})\", \"df.select_dtypes(['float64','int64'])\"]\n",
      "24913075 [\"df = pd.DataFrame(index=np.arange(0, numberOfRows), columns=('lib', 'qty1', 'qty2') )\"]\n",
      "24933234 [\"df = pd.DataFrame(np.random.randn(10000, 4), columns=list('ABCD'))\", '    return len(df) == 0', '    return len(df.index) == 0']\n",
      "24980809 [\"po_grouped_df = poagg_df.groupby(['EID','PCODE'], as_index=False)\", \"pd.merge(acc_df, pol_df, on=['EID','PCODE'], how='inner',suffixes=('_Acc','_Po'))\"]\n",
      "24988227 ['reform = {(outerKey, innerKey): values for outerKey, innerDict in dictionary.iteritems() for innerKey, values in innerDict.iteritems()}', 'pandas.DataFrame(reform)']\n",
      "25023460 []\n",
      "25025065 []\n",
      "25030617 [\"f = pd.read_sql_query('SELECT * FROM mytable', engine, index_col = 'ID')\"]\n",
      "25050179 []\n",
      "25057724 []\n",
      "25058102 ['df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df_concat = pd.concat((df1, df2))', 'by_row_index = df_concat.groupby(df_concat.index)', 'df_means = by_row_index.mean()']\n",
      "25059471 [\"df = DataFrame(np.random.randn(10, 4), columns=list('abcd'))\", 'df2 = df.copy()']\n",
      "25059620 ['df1 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df2 = pd.DataFrame(dict(x=np.random.randn(100), y=np.random.randint(0, 5, 100)))', 'df = pd.concat([df1, df2])', 'foo = df.groupby(level=0).mean()', 'foo.head()']\n",
      "25060811 [\"ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))\", 'ser.plot()', \"ser = pandas.Series(range(10), pandas.date_range(end='2014-01-01', periods=10))\", 'ser.plot()']\n",
      "25122293 [\"cols.insert(0, cols.pop(cols.index('Mid')))\", \"df.drop(labels=['Mid'], axis=1,inplace = True)\", \"df.insert(0, 'Mid', mid)\"]\n",
      "25129265 [\"sales['time_hour'] = sales.timestamp.apply(lambda x: x.hour)\"]\n",
      "25129655 []\n",
      "25146337 ['t = pandas.tslib.Timestamp.now()', 't.to_datetime()', \"df.date_time.map(lambda x: x.strftime('%Y-%m-%d'))\"]\n",
      "25149272 []\n",
      "25162895 []\n",
      "25190070 ['df = pd.DataFrame(np.random.random((4,4)))', \"df.columns = pd.MultiIndex.from_product([[1,2],['A','B']])\"]\n",
      "25206286 []\n",
      "25208947 [\"df['label'].str.join(sep='*').str.get_dummies(sep='*')\"]\n",
      "25211834 ['head(iris, 10)', 'tail(iris, 10)', 'iris = pd.DataFrame(datasets.load_iris().data)', 'iris.head(10)', 'iris.tail(10)', 'iris.ix[:,1:2].head(10)']\n",
      "25213438 []\n",
      "25213614 []\n",
      "25217425 []\n",
      "25230582 [\"pd.to_csv('your.csv', index=False)\"]\n",
      "25254087 [\"df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])\"]\n",
      "25289109 ['df_long = pd.melt(df, \"b\", var_name=\"a\", value_name=\"c\")']\n",
      "25352191 [\"pd.set_option('display.max_colwidth', -1)\"]\n",
      "25376997 [\"df.loc[len(df)]=['8/19/2014','Jun','Fly','98765'] \"]\n",
      "25401328 ['df = DataFrame(data)', \"df.xs('A').plot(kind='bar',ax=a[0])\", \"df.xs('B').plot(kind='bar',ax=a[1])\", \"df.xs('C').plot(kind='bar',ax=a[2])\"]\n",
      "25412939 [\"summed_group.unstack(level=0).plot(kind='bar', subplots=True)\"]\n",
      "25415404 [\"pd.set_option('display.expand_frame_repr', False)\"]\n",
      "25440505 []\n",
      "25442201 []\n",
      "25442986 [\"df.to_sql('table', engine, chunksize=20000)\"]\n",
      "25449186 []\n",
      "25454051 [\"y=(pd.Series(iris.target, name='target')==2).astype(int)\", \"x=pd.DataFrame(iris.data, columns=['var1','var2','var3', 'var4'])\", \"y=(pd.Series(iris.target, name='target')==2).astype(int)\"]\n",
      "25478896 ['for index, row in rche_df.iterrows():', '        row = row.copy()']\n",
      "25479955 [\"df['Minimum'] = df.loc[:, ['B0', 'B1', 'B2']].min(axis=1)\", \"df['Minimum'] = df.loc[:, cols_to_use].min(axis=1)\"]\n",
      "25493765 [\"df.merge(df1, on='sku', how='left')\", \"df.merge(df1, left_index=True, right_index=True, how='left')\", \"df['dept']=df.sku.map(df1.dept)\"]\n",
      "25509805 []\n",
      "25535803 []\n",
      "25561094 []\n",
      "25562948 ['        self.fill = pd.Series([X[c].value_counts().index[0]', \"            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\", '        return X.fillna(self.fill)', 'X = pd.DataFrame(data)']\n",
      "25574089 [\"df.rename(columns={'two':'new_name'}, inplace=True)\"]\n",
      "25588487 ['ax = df.plot()']\n",
      "25612064 [\"df = pd.DataFrame({'M':[1,2,3,4], 'D':[6,7,8,9], 'Y':[1990,1991,1992,1993]})\", 'dates2 = pd.Series(y+m+d)', 'df = pd.concat([df]*1000)', '    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)']\n",
      "25630681 [\"pd.set_option('display.width', desired_width)\"]\n",
      "25643178 ['df.drop(colsToDrop, axis=1)']\n",
      "25646414 [\"(td / np.timedelta64(1, 'D')).astype(int)\"]\n",
      "25698756 [\"df.replace({'\\\\n': '<br>'}, regex=True)\", \"df = pd.DataFrame({'a': ['1\\\\n', '2\\\\n', '3'], 'b': ['4\\\\n', '5', '6\\\\n']})\", \"df.replace({'\\\\n': '<br>'}, regex=True)\"]\n",
      "25701576 [\"df = pds.DataFrame(np.random.rand(14,4), columns=['a', 'b', 'c', 'd'])\", '    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))', '    data = pool.map(myfunction, chunk)']\n",
      "25703030 ['df = pd.DataFrame(np.random.rand(15, 5), index=[0]*15)', 'df.groupby(np.arange(len(df))//10)']\n",
      "25715719 []\n",
      "25716383 []\n",
      "25733562 ['df.reset_index(inplace=True)  ']\n",
      "25748741 []\n",
      "25748826 [\"df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]})\", \"df['e'] = df.sum(axis=1)\", \"df['e'] = df[col_list].sum(axis=1)\"]\n",
      "25774395 []\n",
      "25774932 [\"s=Series([2,4,4,3],index=['a','b','c','d'])\", 's.idxmax()', 's[s==s.max()]']\n",
      "25789512 [\"df['New_Sample'] = df.Sample.apply(lambda x: x[:1])\"]\n",
      "25797313 [\"pd.to_timedelta(16, unit='h')\"]\n",
      "25798359 [\"data1.groupby(['Bool', 'Dir', 'Date']).sum().groupby(level=[0, 1]).cumsum()\", \"data1.groupby(['Bool', 'Dir']).apply(lambda x: x['Data'].cumsum())\"]\n",
      "25799781 []\n",
      "25916109 ['df = DataFrame({\"A\":[0,0.5,1.0,3.5,4.0,4.5], \"B\":[1,4,6,2,4,3], \"C\":[3,2,1,0,5,3]})', 'df.set_index(\"A\")', 'df.set_index(\"A\").reindex(new_index)', 'df.set_index(\"A\").reindex(new_index).reset_index()']\n",
      "25935024 []\n",
      "25959539 ['df.head(5) # will print out the first 5 rows', 'df.tail(5) # will print out the 5 last rows']\n",
      "25962187 ['for chunk in pd.read_csv(filename, chunksize=chunksize):']\n",
      "26000515 [\"df = pd.DataFrame({'x':np.random.rand(10), 'y':np.random.rand(10)}, \", \"df.plot('x', 'y', kind='scatter', ax=ax)\", 'for k, v in df.iterrows():', \"df.plot('x', 'y', kind='scatter', ax=ax, s=120, linewidth=0, \", '        c=range(len(df)), colormap=cmap)', 'for k, v in df.iterrows():']\n",
      "26017289 [\"chunks=pd.read_table('aphro.csv',chunksize=1000000,sep=';',\\\\\", 'df=pd.DataFrame()']\n",
      "26042312 [\"data = pd.read_csv(fname, encoding='cp1252')\"]\n",
      "26064898 [\"df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)\"]\n",
      "26098292 [\"pd.DataFrame({'email':sf.index, 'list':sf.values})\"]\n",
      "26121238 []\n",
      "26133621 []\n",
      "26139658 ['df = pd.DataFrame(dict(carat=carat, price=price, color=color))', \"ax.scatter(df['carat'], df['price'], c=df['color'].apply(lambda x: colors[x]))\", 'df = pd.DataFrame(dict(carat=carat, price=price, color=color))', \"grouped = df.groupby('color')\", \"    group.plot(ax=ax, kind='scatter', x='carat', y='price', label=key, color=colors[key])\"]\n",
      "26147330 [\"df = pd.DataFrame([(1,2,3), ('foo','bar','baz'), (4,5,6)])\", 'df.reindex(df.index.drop(1))']\n",
      "26206622 [\"g = df.groupby('Date')\", 'df.value / g.value.transform(\"sum\") * df.wt', 'df[\\'wa\\'] = df.value / g.value.transform(\"sum\") * df.wt', 'g.wa.sum()', 'g.wa.transform(\"sum\")']\n",
      "26240208 []\n",
      "26244925 [\"frame[frame.duplicated(['key1', 'key2'], keep=False)].groupby(('key1', 'key2')).min()\", \"frame.duplicated(['key1', 'key2'])\", \"frame.duplicated(['key1', 'key2'], take_last=True)\", \"frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])\", \"frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])]\", \"frame[frame.duplicated(['key1', 'key2'], take_last=True) | frame.duplicated(['key1', 'key2'])].groupby(('key1', 'key2')).min()\"]\n",
      "26266031 ['df.merge(pd.DataFrame(data = [s.values] * len(s), columns = s.index), left_index=True, right_index=True)', 'df.merge(pd.DataFrame(data = [s.values] * len(df), columns = s.index, index=df.index), left_index=True, right_index=True)']\n",
      "26266439 ['count_nan = len(df) - df.count()']\n",
      "26266451 ['s = pd.Series([1,2,3, np.nan, np.nan])', 's.isnull().sum()', \"df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})\", 'df.isnull().sum()']\n",
      "26272425 [\"df = pd.DataFrame({'a':[1,2,np.nan], 'b':[np.nan,1,np.nan]})\"]\n",
      "26286140 []\n",
      "26301947 [\"pd.set_option('display.max_colwidth', -1)\"]\n",
      "26310294 [\"df = pd.DataFrame(columns=['col1', 'col2'])\", \"df = df.append(pd.Series(['a', 'b'], index=['col1','col2']), ignore_index=True)\", \"df = df.append(pd.Series(['d', 'e'], index=['col1','col2']), ignore_index=True) \"]\n",
      "26311118 ['df = pd.DataFrame()', \"df = df.append({'foo':1, 'bar':2}, ignore_index=True)\"]\n",
      "26320276 []\n",
      "26332512 [\"df=pd.DataFrame({'a':[1,2,3],'b':[4,5,6]})\", 'df.columns=pd.MultiIndex.from_tuples(columns)']\n",
      "26347456 ['df.drop(df.columns[[1, 69]], axis=1, inplace=True)']\n",
      "26356675 ['df.filter(regex=\"[^BD]\")', 'df.filter(regex=\"^(?!(B|D)$).*$\")', 'df.filter(regex=\"^(?!({0})$).*$\".format(\\'|\\'.join(exclude_cols)))']\n",
      "26394108 ['ser = pd.Series(np.random.normal(size=1000))']\n",
      "26415620 ['df = pandas.DataFrame(x_scaled)']\n",
      "26422495 ['    return s/s.max()', 'frame.apply(f, axis=0)']\n",
      "26457238 []\n",
      "26465555 [\"df.sort_index(ascending=False).groupby('A').agg([np.mean, lambda x: x.iloc[1] ])\"]\n",
      "26474062 []\n",
      "26495839 []\n",
      "26510251 []\n",
      "26521726 [\"df1 = xls.parse('Sheet1')\", \"df2 = xls.parse('Sheet2')\"]\n",
      "26535881 ['df = pd.DataFrame({\"value\": [3,4,9,10,11,np.nan,12]})', 'df.query(\"(value < 10) and (value > @pi)\")', 'df.query(\"(value < 10) or (value == @nan)\")', 'df.query(\"(value < 10) or (value != value)\")']\n",
      "26538379 ['df = pd.read_csv(\"test.csv\")', 'df[\"sum\"] = df.sum(axis=1)', 'df_new = df.loc[:,\"value1\":\"value3\"].div(df[\"sum\"], axis=0)', 'df.loc[:,\"value1\":\"value3\"] = df.loc[:,\"value1\":\"value3\"].div(df[\"sum\"], axis=0)', 'df = pd.read_csv(\"test.csv\")', 'df.loc[:,\"value1\":\"value3\"] = df.loc[:,\"value1\":\"value3\"].div(df.sum(axis=1), axis=0)']\n",
      "26544349 []\n",
      "26577689 [\"s[s.str.contains('|'.join(searchfor))]\"]\n",
      "26599892 [\"df = pandas.read_csv(fileName, sep='delimiter', header=None)\"]\n",
      "26640189 []\n",
      "26647211 []\n",
      "26649199 ['g.sum()', 'pd.DatetimeIndex(df.Date).to_period(\"M\")  # old way', 'per = df.Date.dt.to_period(\"M\")  # new way to get the same', 'g = df.groupby(per)', \"g.sum()  # dang not quite what we want (doesn't fill in the gaps)\"]\n",
      "26654201 [\"df_a.join(df_b, on='mukey', how='left', lsuffix='_left', rsuffix='_right')\", \"df_a.merge(df_b, on='mukey', how='left')\"]\n",
      "26658301 [\"df = pd.DataFrame([[1,2,3],[4,5,6]], columns=['a','b','c'])\", \"df['d'] = df.apply(rowFunc, axis=1)\", \"df['rowIndex'] = df.apply(rowIndex, axis=1)\"]\n",
      "26667043 []\n",
      "26681726 [\"df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],\", '    f.write(template.format(df.to_latex()))', \"df = pd.DataFrame({'d': [1., 1., 1., 2., 2., 2.],\", '    f.write(df.to_html())']\n",
      "26716759 ['df = pd.read_csv(\"file\")']\n",
      "26716774 [\"df.set_index('ID').T.to_dict('list')\"]\n",
      "26721808 []\n",
      "26724581 []\n",
      "26724725 [\"rpt[rpt['STK_ID'].str.contains(r'^600[0-9]{3}$')] # ^ means start of string\", \"str.contains('pandas', case=False)\"]\n",
      "26763793 [\"raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')\"]\n",
      "26763810 [\"df = pd.DataFrame(['05SEP2014:00:00:00.000'],columns=['Mycol'])\", \"df['Mycol'] = df['Mycol'].apply(lambda x: \", \"                                    dt.datetime.strptime(x,'%d%b%Y:%H:%M:%S.%f'))\"]\n",
      "26778637 ['df2 = df.loc[np.repeat(df.index.values,df.n)]', 'df2 = df2.drop(\"n\",axis=1).reset_index(drop=True)']\n",
      "26787032 [\"df_csv = df0_fa.to_csv('revenue/data/test.csv',mode = 'w', index=False)\"]\n",
      "26803731 [\"{'RAY Index': {datetime.date(2014, 11, 3): {'PX_LAST': 1199.46,\", \"datetime.date(2014, 11, 4): {'PX_LAST': 1195.323, 'PX_OPEN': 1197.69},\", \"datetime.date(2014, 11, 5): {'PX_LAST': 1200.936, 'PX_OPEN': 1195.32},\", \"datetime.date(2014, 11, 6): {'PX_LAST': 1206.061, 'PX_OPEN': 1200.62}},\", \"'SPX Index': {datetime.date(2014, 11, 3): {'PX_LAST': 2017.81,\", \"datetime.date(2014, 11, 4): {'PX_LAST': 2012.1, 'PX_OPEN': 2015.81},\", \"datetime.date(2014, 11, 5): {'PX_LAST': 2023.57, 'PX_OPEN': 2015.29},\", \"datetime.date(2014, 11, 6): {'PX_LAST': 2031.21, 'PX_OPEN': 2023.33}}}\", 'pd.Panel(d)', \"pd.Panel(d)['SPX Index']\", 'pd.Panel(d).to_frame().reset_index()', 'pd.Panel(d).transpose(2,0,1).to_frame().reset_index()']\n",
      "26816746 []\n",
      "26838140 [\"df1 = df.replace(np.nan, '', regex=True)\"]\n",
      "26849064 ['df[df[\\'A\\'].str.contains(\"Hello|Britain\")]', 'df[df[\\'A\\'].str.contains(\"Hello|Britain\")==True]']\n",
      "26851412 [\"df = pd.DataFrame([['hello', 'hello world'], ['abcd', 'defg']], columns=['a','b'])\", \"df.apply(lambda x: x['a'] in x['b'], axis=1)\"]\n",
      "26865524 []\n",
      "26873148 [\"data = pd.DataFrame(np.cumsum(np.random.normal(size=(100,2)),axis=0),columns=['A','B'])\", \"data.plot(secondary_y=['B'])\"]\n",
      "26887820 ['df.apply (lambda row: label_race (row),axis=1)', \"df['race_label'] = df.apply (lambda row: label_race (row),axis=1)\"]\n",
      "26893083 []\n",
      "26893443 [\"yes_records_sample['name'].isnull()\"]\n",
      "26918510 ['Series.apply(func, convert_dtype=True, args=(), **kwds)', 'x = my_series.apply(my_function, args = (arg1,))']\n",
      "26977495 [\"np.unique(df[['Col1', 'Col2']])\", \"np.unique(df[['Col1', 'Col2']].values)\", \"pd.unique(df[['Col1', 'Col2']].values.ravel())\", 'df1 = pd.concat([df]*100000) # DataFrame with 500000 rows']\n",
      "27009771 ['        return [series_list.index(i) ', 'df = pd.DataFrame([', \"df.iloc[sort_by_month(df.index.get_level_values('month'))]\", \"pd.Series(list(df['sales'])).iloc[sort_by_last_digit(df['sales'])]\"]\n",
      "27018394 ['df[cols] = df[cols].ffill()', 'df = pd.DataFrame(data=d)', 'print(df.head())', 'df[col] = df[col].ffill()', 'print(df.head())']\n",
      "27023500 ['s = Series([\"a\",\"b\",\"c\",\"a\"], dtype=\"category\")']\n",
      "27026479 [\"df = pd.DataFrame({'mygroup' : np.random.randint(1000, size=n), \", \"grouped = df.groupby('mygroup')\", '    dflist.append(group)', 'serial_list = map(myFunc, dflist)', 'parallel_list = lview.map(myFunc, dflist)', 'combinedDf = pd.concat(parallel_list)']\n",
      "27027632 ['    return pd.concat(retLst)', \"    df = pd.DataFrame({'a': [6, 2, 2], 'b': [4, 5, 6]},index= ['g1', 'g1', 'g2'])\"]\n",
      "27050186 ['            return obj.tolist()']\n",
      "27060328 [\"df['BrandName'].replace(['ABC', 'AB'], 'A')\", \"df['BrandName'] = df['BrandName'].replace(['ABC', 'AB'], 'A')\"]\n",
      "27066284 []\n",
      "27117982 []\n",
      "27126593 [\"df = pd.DataFrame({'a':np.arange(5)})\", \"df1 = pd.DataFrame({'b':np.arange(4)})\", 'pd.concat([df,df1], ignore_index=True, axis=1)']\n",
      "27139421 []\n",
      "27144549 [\"dataframe = read_csv('projects.csv')\", \"dataframe = read_csv('projects.csv', converters={'project_id': lambda x: str(x)})\"]\n",
      "27203245 [\"df = pd.DataFrame(np.arange(10).reshape((5,2)), columns=['A', 'B'])\", \"df.to_hdf(filename, 'data', mode='w', format='table')\", \"df2 = pd.DataFrame(np.arange(10).reshape((5,2))*10, columns=['A', 'B'])\", \"df2.to_hdf(filename, 'data', append=True)\", \"print(pd.read_hdf(filename, 'data'))\", \"    df = pd.DataFrame(np.arange(10).reshape((5,2)) * 10**i, columns=['A', 'B'])\", \"    store.append('data', df)\"]\n",
      "27203304 [\"    a = numpy.load(os.path.join('input', filename))\", '    training_input.append(a)', \"    training_output.append(numpy.load(os.path.join('output', filename)))\"]\n",
      "27232309 ['pd.read_csv(sio, dtype={\"user_id\": int, \"username\": object})']\n",
      "27236748 []\n",
      "27242735 []\n",
      "27255567 ['df = pd.DataFrame(', 'df.Tm = df.Tm.astype(\"category\")', 'df.Tm.cat.set_categories(sorter, inplace=True)', 'df.sort_values([\"Tm\"])  ## \\'sort\\' changed to \\'sort_values\\'']\n",
      "27266225 [\"s = df.apply(lambda x: pd.Series(x['samples']),axis=1).stack().reset_index(level=1, drop=True)\", \"df.drop('samples', axis=1).join(s)\", \"res = df.set_index(['subject', 'trial_num'])['samples'].apply(pd.Series).stack()\", 'res = res.reset_index()']\n",
      "27275344 [\"filter_col = [col for col in df if col.startswith('foo')]\", \"df[df.columns[pd.Series(df.columns).str.startswith('foo')]]\", \"df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]]==1]\", \"df.loc[df[df[df.columns[pd.Series(df.columns).str.startswith('foo')]] == 1].dropna(how='all', axis=0).index]\"]\n",
      "27275479 [\"df.loc[:, df.columns.str.startswith('foo')]\", \"df.filter(regex=r'^foo\\\\.', axis=1)\", \"df.loc[(df == 1).any(axis=1), df.filter(regex=r'^foo\\\\.', axis=1).columns]\"]\n",
      "27282644 []\n",
      "27321764 [\"df.plot(kind='bar', stacked=True, width=1)\"]\n",
      "27325729 [\"pd.read_csv('test.csv', sep='|', skiprows=range(1, 10))\"]\n",
      "27360130 []\n",
      "27361326 ['df.sort_index(axis=1, inplace=True)']\n",
      "27362540 []\n",
      "27368948 ['p=pd.Series([1,2,3])', 'p.apply(lambda x: pd.Series([x, x]))', 'p.map(lambda x: pd.Series([x, x]))', 'p=pd.Series([1,0,3,4,2])', 'p.map(p)']\n",
      "27385043 [\"df = pd.DataFrame([[i] for i in range(10)], columns=['num'])\"]\n",
      "27412913 []\n",
      "27422749 [\"grouped = df.groupby('A')\"]\n",
      "27475029 ['df[\\'que\\'] = df.apply(lambda x : x[\\'one\\'] if x[\\'one\\'] >= x[\\'two\\'] and x[\\'one\\'] <= x[\\'three\\'] else \"\", axis=1)', \"df['que'] = df.apply(que, axis=1)\"]\n",
      "27475046 [\"df['que'] = df['que'].fillna(0)\"]\n",
      "27475514 ['C = np.where(cond, A, B)', \"df = pd.DataFrame(a, columns=['one', 'two', 'three'])\", \"df['que'] = np.where((df['one'] >= df['two']) & (df['one'] <= df['three'])\", \"df['que'] = np.select(conditions, choices, default=np.nan)\", \"df = pd.DataFrame(a, columns=['one', 'two', 'three'])\", 'df2 = df.astype(float)']\n",
      "27489248 [\"df = pandas.read_csv(csv, index_col='index')\", \"groups = df.groupby(by=['A'])\", \"print(groups.apply(lambda g: g[g['B'] == g['B'].max()]))\"]\n",
      "27520877 [\"df = pd.DataFrame(values, columns=['Type A', 'Type B'], index=['Index 1','Index 2'])\", \"df.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Video streaming dropout by category')\"]\n",
      "27579192 [\"df1 = DataFrame({'col1':[1,2,3], 'col2':[2,3,4]})\", \"df2 = DataFrame({'col1':[4,2,5], 'col2':[6,3,5]})\"]\n",
      "27617290 ['data = pd.DataFrame(list(collection.find()))']\n",
      "27667801 []\n",
      "27680109 [\"df = DataFrame({'x': [1,2]})\", 'df_sub_copy = df[0:1].copy()']\n",
      "27747726 [\"pd.read_csv(file, sep='\\\\t', header=None, names=headers, dtype=dtypes)\", \"pd.read_csv(file, sep='\\\\t', header=None, names=headers, dtype=dtypes)\"]\n",
      "27759140 [\"df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1]})\", \"df = pd.DataFrame({'a': [0, -1, 2], 'b': [-3, 2, 1],\"]\n",
      "27769102 []\n",
      "27787977 []\n",
      "27791362 ['df = pd.read_csv(StringIO(csv),']\n",
      "27802006 ['grouped = (df', \"        g.set_index('date')        \", \"grouped.columns=grouped.columns.droplevel()   # drop the 'col1' part of the multi-index column names\", \"grouped.plot(kind='bar')\"]\n",
      "27844045 [\"df_agg = df.groupby(['job','source']).agg({'count':sum})\", \"g = df_agg['count'].groupby(level=0, group_keys=False)\", 'res = g.apply(lambda x: x.order(ascending=False).head(3))', 'g.nlargest(3)']\n",
      "27889133 []\n",
      "27889674 ['df = pd.read_sql_query(\\'select * from \"Stat_Table\"\\',con=engine)']\n",
      "27905350 ['df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])', \"df.fillna(method='ffill')\", \"df.fillna(method='ffill', inplace=True)\"]\n",
      "27905354 ['df = pd.DataFrame([[1, 2, 3], [4, None, None], [None, None, 9]])', \"df = df.fillna(method='ffill')\"]\n",
      "27951930 [\"df.groupby('A').transform(lambda x: (x['C'] - x['D']))\", \"df.groupby('A').transform(lambda x: (x['C'] - x['D']).mean())\", \"zscore = lambda x: (x - x.mean()) / x.std() # Note that it does not reference anything outside of 'x' and for transform 'x' is one column.\", \"df.groupby('A').transform(zscore)\", \"df.groupby('A')['C'].transform(zscore)\", \"df.groupby('A').apply(zscore)\", \"df['sum_C'] = df.groupby('A')['C'].transform(sum)\", \"df.groupby('A')['C'].apply(sum)\", \"df[df.groupby(['B'])['D'].transform(sum) < -1]\"]\n",
      "27954411 [\"df = pd.DataFrame({'NAME': list('abcdef'),\", \"df.select_dtypes(include=['bool'])\", \"mylist = list(df.select_dtypes(include=['bool']).columns)\"]\n",
      "27975191 [\"mask = df['ids'].str.contains('ball')    \"]\n",
      "27975230 ['df[df[\\'ids\\'].str.contains(\"ball\")]']\n",
      "27975789 [\"df[df['ids'].str.contains('ball', na = False)] # valid for (at least) pandas version 0.17.1\"]\n",
      "27987908 [\"    B_maxes = df.groupby('A').B.transform(max)\"]\n",
      "27999688 []\n",
      "28006809 ['df = pd.DataFrame([[1,2,3],[3,4,5]])', 'lol = df.values.tolist()']\n",
      "28009526 ['df = df.reset_index()', \"df['weekday'] = pd.Series(df.index).dt.dayofweek\", \"df['weekday'] = df.reset_index()['Timestamp'].dt.dayofweek\"]\n",
      "28020783 []\n",
      "28135445 ['pd.concat([df_a,df_b], axis=1)', 'df_a.merge(df_b, left_index=True, right_index=True)', 'df_a.join(df_b)']\n",
      "28142820 [\"df.loc[df['column_name'].isin(some_values)]\", \"df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\", \"               'B': 'one one two three two two one three'.split(),\", \"print(df.loc[df['B'].isin(['one','three'])])\", \"df = df.set_index(['A'])\"]\n",
      "28150450 ['len(df.columns)', 'len(df.index)']\n",
      "28155580 ['newdf = df.select_dtypes(include=numerics)']\n",
      "28159296 [\"df = pd.DataFrame( np.random.randn(30,3), columns = ['a','b','c'])\", \"df_filtered = df.query('a>0').query('0<b<2')\", \"df_filtered = df.query('a>0 and 0<b<2')\"]\n",
      "28161433 [\"df = pd.DataFrame( {'Symbol':['A','A','A'] ,\", \"df['Date'] =pd.to_datetime(df.Date)\", \"df.sort_values(by='Date') # This now sorts in date order\"]\n",
      "28182629 [\"b = DataFrame(a.var1.str.split(',').tolist(), index=a.var2).stack()\", \"b = b.reset_index()[[0, 'var2']] # var1 variable is currently labeled 0\"]\n",
      "28192263 [\"[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)]\", \"my_series.select_dtypes(include=['O']) \", \"list(my_series.select_dtypes(include=['O']).columns) \", \"[my_series[c].value_counts() for c in list(my_series.select_dtypes(include=['O']).columns)] \"]\n",
      "28199556 [\"df = pd.DataFrame(randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],\", \"df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\", 'df.shape[0] - df.dropna().shape[0]', 'df.isnull().values.ravel().sum()']\n",
      "28200127 []\n",
      "28202781 ['M.set_value(index,column,new_value)']\n",
      "28218909 []\n",
      "28227679 ['        yield r[0], get(r, 1), get(r, 2), get(r, 3)', '        result.append((r[0], get(r, 1), get(r, 2), get(r, 3)))', 'df = pd.DataFrame.from_records(', 'df = pd.DataFrame.from_records(', '      ((r[0], get(r, 1), get(r, 2), get(r, 3)) for r in rows), ']\n",
      "28229188 [\"merged = pd.merge(DataFrameA,DataFrameB, on=['Code','Date'])\", \"i = pd.to_datetime(pd.date_range('20140601',periods=2))\", \"df = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col1': [10,100]})\", \"df2 = pd.DataFrame({'code': ['ABC','EFG'], 'date':i,'col2': [10,200]})\", \"pd.merge(df, df2, on =['code','date'])\"]\n",
      "28236391 [\"df.loc[df['a'] == 1, 'b'].sum()\", \"df.groupby('a')['b'].sum()[1]\"]\n",
      "28252957 [\"data['result'].replace(regex=True,inplace=True,to_replace=r'\\\\D',value=r'')\"]\n",
      "28267291 ['        doc_dict = author_attr.copy()', '        doc_dict.update(doc.attrib)', 'doc_df = pd.DataFrame(list(iter_docs(etree)))']\n",
      "28272238 ['s = pd.Series(test)']\n",
      "28299215 ['p_df = pd.DataFrame({\"class\": [1,1,2,2,1], \"a\": [2,3,2,3,2]})', \"bp = p_df.groupby('class').plot(kind='kde', ax=ax)\", 'p_df = pd.DataFrame({\"class\": classes, \"vals\": vals})', \"for label, df in p_df.groupby('class'):\", '    df.vals.plot(kind=\"kde\", ax=ax, label=label)']\n",
      "28312011 ['df = pd.DataFrame([[\"foo1\"], [\"foo2\"], [\"bar\"], [np.nan]], columns=[\\'a\\'])', 'df.a.str.contains(\"foo\")', 'df.a.str.contains(\"foo\", na=False)', 'df.loc[df.a.str.contains(\"foo\", na=False)]']\n",
      "28371611 []\n",
      "28371706 ['nlines = int(nlines.split()[0]) ', '    df = pd.read_csv(in_csv,  ', '    sql.to_sql(df, ']\n",
      "28384887 ['        return self.transform(X)']\n",
      "28390992 [\"df = df.fillna('')\", \"df.column1 = df.column1.fillna('')\"]\n",
      "28417338 [\"r['iris'].head()\", 'print(iris.head())', 'print(df.head())']\n",
      "28419871 ['df = pd.read_csv(file_name)', 'df.head()']\n",
      "28466662 [\"df = pd.DataFrame({'cat':['a','b','c','d'],'val':[1,2,5,10]})\", \"df1 = pd.get_dummies(pd.DataFrame({'cat':['a'],'val':[1]}))\", 'dummies_frame = pd.get_dummies(df)', 'df1.reindex(columns = dummies_frame.columns, fill_value=0)']\n",
      "28479181 ['dfTest = pd.DataFrame({', \"dfTest[['A','B']] = dfTest[['A','B']].apply(\"]\n",
      "28507257 []\n",
      "28538738 [\"df.drop(df.ix[:,'Unnamed: 24':'Unnamed: 60'].head(0).columns, axis=1)\", \"df = pd.DataFrame(columns=['a','Unnamed: 1', 'Unnamed: 1','foo'])\", \"~df.columns.str.contains('Unnamed:')\", \"df[df.columns[~df.columns.str.contains('Unnamed:')]]\"]\n",
      "28540395 []\n",
      "28541443 []\n",
      "28565940 []\n",
      "28590865 []\n",
      "28595765 ['test3 = pd.concat([test1, test2], axis=1)']\n",
      "28611938 []\n",
      "28648525 []\n",
      "28648923 [\"s = pd.Series(['1', '2', '4.7', 'pandas', '10'])\", \"pd.to_numeric(s) # or pd.to_numeric(s, errors='raise')\", \"pd.to_numeric(s, errors='coerce')\", \"pd.to_numeric(s, errors='ignore')\", \"df = pd.DataFrame(a, columns=['col1','col2','col3'])\", \"df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)\", \"df.apply(pd.to_numeric, errors='ignore')\", \"df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')\", 'df = df.infer_objects()']\n",
      "28652153 [\"df.pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')  # desired?\", 'df1 = df.set_index([0, 1, 2])', 'df1.unstack(2)', \"df1.reset_index().pivot_table(values=3, index=[0, 1], columns=2, aggfunc='mean')\"]\n",
      "28677342 ['c = values.cumsum() - ALLOWANCE', 'c.diff().fillna(math.max(0, values[0] - ALLOWANCE))']\n",
      "28677358 ['s = (values.cumsum() - ALLOWANCE).clip_lower(0)', 'desired = s.diff().fillna(s)']\n",
      "28680078 ['df = pd.DataFrame(dict(A=[5,3,5,6], C=[\"foo\",\"bar\",\"fooXYZbar\", \"bat\"]))', 'df[df.C.str.contains(\"XYZ\") == False]']\n",
      "28731311 ['sheet1 = xls.parse(0)', 'sheet2 = xls.parse(1)']\n",
      "28756099 [\"cw = pd.read_csv('ChickWeight.csv')\"]\n",
      "28783971 [\"df['dt'].values.astype('<M8[h]')\", \"df['dt2'] = df['dt'].values.astype('<M8[h]')\"]\n",
      "28847219 [\"gb.get_group('foo')\"]\n",
      "28881373 [\"df['col_3'] = df.col_1.combine(df.col_2, func=get_sublist)\", \"df['col_3'] = df.col_1.astype(object).combine(df.col_2, func=get_sublist)\"]\n",
      "28882020 ['    numberChunks = len(df) // chunkSize + 1', '        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])']\n",
      "28900208 []\n",
      "28902170 [\"common = df1.merge(df2,on=['col1','col2'])\", 'df1[(~df1.col1.isin(common.col1))&(~df1.col2.isin(common.col2))]', 'df1[~df1.isin(df2)].dropna()', \"df2 = pd.DataFrame(data = {'col1' : [2, 3,4], 'col2' : [11, 12,13]})\", 'df1[~df1.isin(df2)].dropna()']\n",
      "28917065 ['x.plot(kind=\"bar\").legend(bbox_to_anchor=(1.2, 0.5))', 'x.plot(kind=\"bar\").legend(*args, **kwargs)']\n",
      "28931750 [\"ax = freq_series.plot(kind='bar')\", 'labels = [\"label%d\" % i for i in xrange(len(rects))]']\n",
      "28986536 [\"df['range'] = df['range'].str.replace(',','-')\", \"df['range'].replace(',','-',inplace=True)\", \"df = pd.DataFrame({'range':['(2,30)',',']})\", \"df['range'].replace(',','-', inplace=True)\"]\n",
      "28991603 [\"dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]\", \"df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\"]\n",
      "29036738 ['df[\"date\"] = df[\"date\"].astype(\"datetime64\")', 'df.groupby(df[\"date\"].dt.month).count().plot(kind=\"bar\")', 'df.groupby([df[\"date\"].dt.year, df[\"date\"].dt.month]).count().plot(kind=\"bar\")']\n",
      "29039484 [\"ts = df.set_index('DateTime')\"]\n",
      "29074073 [\"pd.set_option('display.width', pd.util.terminal.get_terminal_size()[0])\"]\n",
      "29108799 [\"rpt.query('STK_ID in (600809,600141,600329)')\", \"rpt.query('60000 < STK_ID < 70000')\"]\n",
      "29177664 ['df.Temp_Rating.fillna(df.Farheit, inplace=True)', \"df.columns = 'File heat Observations'.split()\"]\n",
      "29218694 [\"np.dtype('datetime64[ns]') == np.dtype('<M8[ns]')\"]\n",
      "29233885 [\"for key, grp in df.groupby(['color']):\", \"    ax = grp.plot(ax=ax, kind='line', x='x', y='y', c=key)\", '    labels.append(key)']\n",
      "29233999 []\n",
      "29242900 [\"df.filter(regex='[A-CEG-I]')\"]\n",
      "29247205 []\n",
      "29262040 ['for i, row in df.iterrows():', \"  df.set_value(i,'ifor',ifor_val)\"]\n",
      "29281494 ['        ret_list = p.map(func, [group for name, group in dfGrouped])', '    return pandas.concat(ret_list)']\n",
      "29287549 ['df = pd.read_csv(file_path, header=None, usecols=[3,6])']\n",
      "29314880 [\"df = pd.DataFrame(np.random.randn(10, 2), columns=list('AB'))\", \"df['Tenant'].replace('', np.nan, inplace=True)\", \"df.dropna(subset=['Tenant'], inplace=True)\"]\n",
      "29319200 []\n",
      "29319460 []\n",
      "29321298 []\n",
      "29334672 []\n",
      "29370182 [\"df['date'] = pd.to_datetime(df['date'])  \", 'df = pd.DataFrame(np.random.random((200,3)))', \"df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')\", 'df = pd.DataFrame(np.random.random((200,3)))', \"df['date'] = pd.date_range('2000-1-1', periods=200, freq='D')\", \"df = df.set_index(['date'])\"]\n",
      "29370709 [\"df['stats'].str[1:-1].str.split(',', expand=True).astype(float)\", \"df['stats'].apply(pd.Series)\", \"df['stats'].str[1:-1].str.split(',').apply(pd.Series).astype(float)\"]\n",
      "29383624 ['data=pd.read_csv(\"File_path\", sep=\\'\\\\t\\')']\n",
      "29432741 []\n",
      "29442936 [\"df = pd.DataFrame([[1, 2.2, 'three']], columns=['A', 'B', 'C'])\", \"df.select_dtypes(include=['int'])\", 'df.select_dtypes(include=[np.number])', 'df.select_dtypes(exclude=[object])']\n",
      "29461151 [\"yourdf.to_excel(writer,'Sheet5')\", \"yourdf.to_csv('PythonExport.csv', sep=',')\", \"  yourdf.to_excel(writer,'Sheet5')\"]\n",
      "29464365 [\"pd.merge(df1, df2, on=['A', 'B', 'C', 'D'], how='inner')\", \"df1 = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'))\", 'df2.reset_index(drop=True,inplace=True)', 'df2.reset_index(drop=True,inplace=True)', \"pd.merge(df1, df2, on=common_cols, how='inner')\", 'df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)', \"temp_df = pd.merge(df2, df12, on=df2.columns.tolist(), how='left')\", \"temp_df[temp_df['key'].isnull()].drop('key', axis=1)\"]\n",
      "29465238 [\"df.replace({'\\\\n': '<br>'}, regex=True)\", \"df = pd.DataFrame({'a': ['1\\\\n', '2\\\\n', '3'], 'b': ['4\\\\n', '5', '6\\\\n']})\", \"df.replace({'\\\\n': '<br>'}, regex=True)\"]\n",
      "29494537 ['df.columns.tolist()']\n",
      "29499109 ['ax = df[[\\'V1\\',\\'V2\\']].plot(kind=\\'bar\\', title =\"V comp\", figsize=(15, 10), legend=True, fontsize=12)', 'ax = df[[\\'V1\\',\\'V2\\']].plot(kind=\\'bar\\', title =\"V comp\", figsize=(15, 10), legend=True, fontsize=12)']\n",
      "29500330 [\"grouped = df.groupby('A')\", 'df = grouped.aggregate(lambda x: tuple(x))']\n",
      "29517089 []\n",
      "29517102 []\n",
      "29522443 ['for chunk in pd.read_sql_query(sql , engine, chunksize=5):']\n",
      "29528483 ['df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)']\n",
      "29528804 ['df = pd.read_sql(query.statement, query.session.bind)']\n",
      "29530303 []\n",
      "29530559 ['df = pd.DataFrame(np.random.randn(10,6))', 'df.isnull().any().any()', 'df.isnull().sum()', 'df.isnull().sum().sum()']\n",
      "29530601 ['df.isnull().values.any()', 'df = pd.DataFrame(np.random.randn(1000,1000))']\n",
      "29533502 ['    ts = Series(y_ax,index=x_ax)', \"    ts.plot(kind='bar', figsize=(15,5))\"]\n",
      "29533687 [\"    pd.Series(y_ax, index=x_ax).plot(kind='bar', ax=axs[i])\", \"    axs[i].set_title('Plot number {}'.format(i+1))\"]\n",
      "29541211 [\"df['Total'] = df.sum(axis=1)\"]\n",
      "29546836 ['    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', \"df = pandas.DataFrame(data={'lon1':lon1,'lon2':lon2,'lat1':lat1,'lat2':lat2})\"]\n",
      "29548349 ['    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', '    t0 = time.time()', '    t1 = time.time()', 'size = len(lat1)', 'output = np.empty(size, dtype=np.double)', 't2 = time.time()', 't3 = time.time()', '    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])', '    t0 = time.time()', '    t1 = time.time()', '    size = len(lat1)', '    output = np.empty(size, dtype=np.double)', '    t2 = time.time()', '    t3 = time.time()', '    n = len(lon1)', '    kms = np.empty(n, dtype=np.double)', '       lon1_v, lat1_v, lon2_v, lat2_v = map(']\n",
      "29550458 [\"df = pd.DataFrame({'a':[1,2], 'b':[(1,2), (3,4)]})\", \"df['b'].apply(pd.Series)\", \"df[['b1', 'b2']] = df['b'].apply(pd.Series)\"]\n",
      "29576803 ['df = pd.read_csv(StringIO(s), sep=\"\\\\s+\")', 'df.iloc[np.random.permutation(len(df))]']\n",
      "29585283 [\"flights.groupby(['year', 'month', 'day'])\"]\n",
      "29651514 ['    result = df.copy()', '        max_value = df[feature_name].max()', '        min_value = df[feature_name].min()']\n",
      "29657079 ['conn_indices = np.where(a_numpy)', 'igraph.plot(G, layout=\"rt\", labels=True, margin=80)']\n",
      "29665452 ['HTML(df2.to_html())']\n",
      "29673192 ['a = pd.DataFrame([[1,2,3],[3,1,1],[4,0,2]], index=node_names, columns=node_names)', 'g = igraph.Graph.Adjacency((A > 0).tolist())', \"df_from_g = pd.DataFrame(g.get_adjacency(attribute='weight').data,\", '(df_from_g == a).all().all()  # --> True']\n",
      "29675706 [\"i = pd.date_range('2013-1-1',periods=100,freq='s')\", '        plt.plot(pd.Series(data=np.random.randn(100), index=i))']\n",
      "29737663 ['df.plot(x=\\'x\\', y=\\'y\\', style=\".\")']\n",
      "29763653 []\n",
      "29765839 []\n",
      "29766187 []\n",
      "29774704 [\"df.index.get_level_values('name_sub_index')\"]\n",
      "29794993 [\"df['D'] = df['U'].map(d)\"]\n",
      "29815523 ['df.T.to_dict().values()']\n",
      "29816143 [\"df.to_dict('records')\"]\n",
      "29836852 [\"df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])\", 'df.groupby(\"A\").filter(lambda x: len(x) > 1)']\n",
      "29837754 [\"df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})\", \"df['J3'] = df.apply(sublst,axis=1)\", \"df = pd.DataFrame({'ID':['1','2','3'], 'J1': [0,2,3], 'J2':[1,4,5]})\", \"df['J3'] = df.apply(lambda row:lst[row['J1']:row['J2']],axis=1)\"]\n",
      "29902819 []\n",
      "29910919 []\n",
      "29916004 [\"df = df[['mean'] + df.columns[:-1].tolist()]\"]\n",
      "29919489 ['df.idxmax(axis=1)']\n",
      "29922207 []\n",
      "29930255 ['ser = Series(arr)', 'bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))', 'bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))', 'bins = np.insert(bins, 0, 0)']\n",
      "29955358 ['s = pd.Series(np.arange(5))', \"df = pd.DataFrame({'a':np.random.randn(4), 'b':np.random.randn(4)})\", 'df + pd.Series(np.arange(4))']\n",
      "29956221 ['print(iris.head())', \"iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\"]\n",
      "29971188 ['df1.count()']\n",
      "29990874 ['qs = MyModel.objects.all()']\n",
      "29999590 []\n",
      "30010004 ['df.reindex([\"Z\", \"C\", \"A\"])', 'df.sort_index(ascending=False)', 'df = df.sort_index(ascending=False)']\n",
      "30022658 []\n",
      "30025025 []\n",
      "30027273 [\"lambdafunc = lambda x: pd.Series([x['mytime'].hour,\", \"                                           x['mydate'].isocalendar()[1],\", \"                                           x['mydate'].weekday()])\", \"df[['hour', 'weekday', 'weeknum']] = df.apply(lambdafunc, axis=1)\"]\n",
      "30053435 [\"df = pd.DataFrame(index=range(0,4),columns=['A'], dtype='float')\"]\n",
      "30053507 []\n",
      "30059290 ['df.isnull().sum(axis=1)', 'df.isnull().sum(axis=1).tolist()']\n",
      "30063996 ['df = DataFrame({\"a\": [1,2,2,4,2], \"b\": [nan, nan, nan, 3, 3]})']\n",
      "30065040 []\n",
      "30087487 ['df.to_html(classes = \\'my_class\" id = \"my_id\\')']\n",
      "30111487 ['mat = dataset.as_matrix()', 'results = pandas.DataFrame([dataset.index,labels]).T']\n",
      "30132313 [\"dates = pd.to_datetime(pd.Series(['20010101', '20010331']), format = '%Y%m%d')\", \"dates.apply(lambda x: x.strftime('%Y-%m-%d'))\", \"dates.dt.strftime('%Y-%m-%d')\"]\n",
      "30135182 ['start = pd.to_datetime(\"5-1-2012\")', 'idx = pd.date_range(start, periods= 365)', \"df = pd.DataFrame({'A':np.random.random(365), 'B':np.random.random(365)})\", \"df_ts = df.resample('W', how= 'max')\", \"ax = df_ts.plot(kind='bar', x=df_ts.index, stacked=True)\", \"ticklabels = ['']*len(df_ts.index)\", \"ticklabels[::4] = [item.strftime('%b %d') for item in df_ts.index[::4]]\", \"ticklabels[::12] = [item.strftime('%b %d\\\\n%Y') for item in df_ts.index[::12]]\"]\n",
      "30201213 [\"data = read_table('sample.txt', skiprows=3, header=None, delim_whitespace=True)\"]\n",
      "30208749 []\n",
      "30214901 ['pd.qcut(factors, 5).value_counts()', 'pd.cut(factors, 5).value_counts()']\n",
      "30222759 [\"df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})\", \"df['my_dates'] = pd.to_datetime(df['my_dates'])\", \"df = pd.DataFrame({'my_dates':['2015-01-01','2015-01-02','2015-01-03'],'myvals':[1,2,3]})\", \"df['my_dates'] = pd.to_datetime(df['my_dates'])\", \"df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])\"]\n",
      "30267328 ['fruit_data = pd.DataFrame({', '        output = X.copy()', '            for colname,col in output.iteritems():', '        return self.fit(X,y).transform(X)', \"MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))\"]\n",
      "30292938 [\"        df.to_csv(csvFilePath, mode='a', index=False, sep=sep)\", '    elif len(df.columns) != len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns):', '        raise Exception(\"Columns do not match!! Dataframe has \" + str(len(df.columns)) + \" columns. CSV file has \" + str(len(pd.read_csv(csvFilePath, nrows=1, sep=sep).columns)) + \" columns.\")', '    elif not (df.columns == pd.read_csv(csvFilePath, nrows=1, sep=sep).columns).all():', \"        df.to_csv(csvFilePath, mode='a', index=False, sep=sep, header=False)\"]\n",
      "30304735 ['xcell.style = xcell.style.copy(**style_kwargs)']\n",
      "30319249 ['X_train_imp = imp.transform(X_train)', '    X_test_imp = imp.transform(X_test)']\n",
      "30327470 []\n",
      "30328738 [\"(df.groupby(['cluster', 'org'], as_index=False).mean()\", \"df.groupby(['cluster']).mean()\", \"df.groupby(['cluster', 'org']).mean()\"]\n",
      "30355286 ['df2 = pd.DataFrame(data=None, columns=df1.columns,index=df1.index)']\n",
      "30357382 [\"df['Cat1'].fillna(df['Cat2'])\"]\n",
      "30370897 [\"df = pd.DataFrame({'a': [1, 2, 1, 2, 1, 1, 0], 'b': range(7)})\", '        key.append(deref(it).first)', '        sum_.append(deref(it).second)', \"    df = pd.DataFrame({'key': key, 'sum': sum_})\", \"    df.set_index('key', inplace=True)\"]\n",
      "30378303 []\n",
      "30380922 ['df.rename(columns=dict(zip(old_names, new_names)), inplace=True)']\n",
      "30424537 ['df = pd.DataFrame({ ', \"    'd':np.repeat( range(3), 2 ),\", \"    'f':pd.date_range('1/1/2011', periods=6, freq='D'),\", \"    'g':np.random.choice( pd.date_range('1/1/2011', periods=365, \", 'stocks = pd.DataFrame({ ', \"    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\", \"    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\", \"    'price':(np.random.randn(100).cumsum() + 10) })\", 'stocks.head(5)', \"stocks.groupby('ticker').head(2)\"]\n",
      "30454743 [\"y = df.pop('output')\"]\n",
      "30470630 []\n",
      "30511605 []\n",
      "30512931 [\"df_final = reduce(lambda left,right: pd.merge(left,right,on='name'), dfs)\"]\n",
      "30514678 [\"df1.columns = [c.replace(' ', '_') for c in df1.columns]\"]\n",
      "30522778 ['percentile_list = pd.DataFrame(', 'percentile_list = pd.DataFrame(np.column_stack([lst1, lst2, lst3]), ']\n",
      "30523225 []\n",
      "30525128 []\n",
      "30531939 [\"df = pd.DataFrame({'a':[1,2,1,2], 'b':[3,4,3,5]})\", 'df.drop_duplicates()']\n",
      "30535957 [\"s1 = pd.merge(df1, df2, how='inner', on=['user_id'])\"]\n",
      "30546734 [\"df.columns = df.columns.str.replace('$','')\"]\n",
      "30557040 ['bigdata = pd.concat([data1, data2], ignore_index=True)']\n",
      "30566899 [\"df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\"]\n",
      "30587837 ['df.loc[idx[:,mask_1],idx[mask_2,:]].fillna(value=0,inplace=True)', 'df.update(df.loc[idx[:,mask_1],idx[[mask_2],:]].fillna(value=0))']\n",
      "30590280 [\"df = pd.DataFrame({'d': [1, 2, 3]}, index=['FOO', 'BAR', 'BAZ'])\", 'df.index = df.index.map(str.lower)', 'pd.Series(df.index.map(str.lower))', 'df.index.str.lower()']\n",
      "30633167 []\n",
      "30647987 ['df.plot(subplots=True, layout=(1,2))']\n",
      "30652445 []\n",
      "30653988 [\"data.to_sql(name='sample_table2', con=engine, if_exists = 'append', index=False)\"]\n",
      "30691921 [\"with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\"]\n",
      "30717361 []\n",
      "30733959 ['dataGrid = pandas.DataFrame({1: {1: 1, 3: 2},', \"        dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)\", '        dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))', '        dataGrid = dataGrid.sort_index(axis=1)', \"        dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)\"]\n",
      "30740087 ['df_num = df.select_dtypes(include=[np.float])', 'df_num = df.select_dtypes(exclude=[np.number])']\n",
      "30777185 [\"df.insert(len(df.columns), 'e', pd.Series(np.random.randn(sLength),  index=df.index))\"]\n",
      "30778300 []\n",
      "30781664 []\n",
      "30788360 []\n",
      "30788555 []\n",
      "30808571 [\"df = pd.DataFrame(np.array([[2,4,4],[4,3,3],[5,9,1]]),columns=['d','t','didi'])\", 'df.filter(regex=(\"d.*\"))']\n",
      "30808690 [\"df = pd.DataFrame([[10, 14, 12, 44, 45, 78]], columns=['a', 'b', 'c', 'd1', 'd2', 'd3'])\", \"df.select(lambda col: col.startswith('d'), axis=1)\"]\n",
      "30858753 []\n",
      "30926717 [\"df = pd.DataFrame(columns=['A'])\", \"pd.concat([df,pd.DataFrame(columns=list('BCD'))])\"]\n",
      "30943503 [\"df = pd.DataFrame(np.random.randint(10, size=(5,1)), columns=['A'])\", \"df.reindex(columns=list('ABCD'))\", \"df.reindex(columns=list('DCBA'))\", \"df.reindex(columns=list('ABCD'), fill_value=0)\"]\n",
      "30971633 []\n",
      "30991980 []\n",
      "31017785 ['df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],', 'df = df.applymap(\"${0:.2f}\".format)']\n",
      "31026736 []\n",
      "31029857 [\"df['colour'].value_counts().plot(kind='bar')\"]\n",
      "31029861 [\"df.groupby('colour').size().plot(kind='bar')\"]\n",
      "31033603 []\n",
      "31036962 ['a=pd.DataFrame({\"var1\":\"a,b,c d,e,f\".split(),\"var2\":[1,2]})', 's = a.var1.str.split(\",\").apply(pd.Series, 1).stack()', 's.index = s.index.droplevel(-1)', 'a.join(s)']\n",
      "31037040 ['df = pd.DataFrame(columns=mycolumns)', '    df.loc[len(df)] = row']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31037360 ['df[\"weight\"].mean()']\n",
      "31061820 []\n",
      "31075478 [\"df['si_name'] = R.index.get_level_values('si_name') \"]\n",
      "31076657 [\"frame[frame.filename.str.match('*.'+MetaData+'.*') & frame.file_path.str.match('C:\\\\test\\\\test.txt')]\"]\n",
      "31097813 [\"series = pd.Series([1,2], index=['a','b'])\", 'df = pd.DataFrame([series])', 'list_of_series = [pd.Series([1,2],index=cols), pd.Series([3,4],index=cols)]', 'df = pd.DataFrame(list_of_series, columns=cols)', \"list_of_series = [pd.Series([1,2],index=['a','b']), pd.Series([3,4],index=['a','c'])]\", 'df = pd.concat(list_of_series, axis=1).transpose()']\n",
      "31105951 []\n",
      "31173785 [\"df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\"]\n",
      "31206596 [\"df = pd.DataFrame({'x': [1,2,3,4,5], \"]\n",
      "31247247 [\"df.to_csv(r'c:\\\\data\\\\pandas.txt', header=None, index=None, sep=' ', mode='a')\"]\n",
      "31247279 []\n",
      "31257931 []\n",
      "31296878 [\"table.query('column_name == some_value | column_name2 == some_value2')\", 'df = pd.DataFrame(d)', \"df.query('foo == 222 | bar == 444')\"]\n",
      "31297540 []\n",
      "31331100 []\n",
      "31331449 [\"df.to_csv('path', header=True, index=False, encoding='utf-8')\"]\n",
      "31351465 ['tokenized=map(lambda msg, ft1, ft2: features([msg,ft1,ft2]), posts.message,posts.feature_1, posts.feature_2)', \"posts = pd.read_csv('post.csv')\", 'y = posts[\"score\"].values.astype(np.float32) ', \"X_columns=vectorizer.get_feature_names()+posts[['feature_1','feature_2']].columns.tolist()\"]\n",
      "31357733 ['df = pd.DataFrame(np.random.randn(100,5))', 'ax = df.plot()', \"ax.set_yticklabels(['{:3.2f}%'.format(x*100) for x in vals])\"]\n",
      "31364094 ['df.A.plot() #no need to specify for first axis', 'df.B.plot(ax=plt.gca())', 'df.C.plot(ax=plt.gca())']\n",
      "31364127 ['df.mycolumn.map(func)', 'df.apply(func, axis=1)', 'df = dd.read_csv(...)', 's = pd.Series([10000]*120)']\n",
      "31384328 ['    corr = df.corr()', '    plt.xticks(range(len(corr.columns)), corr.columns);', '    plt.yticks(range(len(corr.columns)), corr.columns);']\n",
      "31396042 ['cols = df.columns.tolist()', \"cols.insert(0, cols.pop(cols.index('Mid')))\", 'df = df.reindex(columns= cols)']\n",
      "31431997 ['df.drop(df.columns[[0,1,3]], axis=1, inplace=True)', 'df.drop(df.columns[[0]], axis=1, inplace=True)', \"df.pop('column-name')\", \"df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])\"]\n",
      "31458385 ['data = map(lambda x: x.rstrip(), data)', 'data_json_str = \"[\" + \\',\\'.join(data) + \"]\"', 'data_df = pd.read_json(data_json_str)']\n",
      "31480994 []\n",
      "31502974 [\"df = pd.DataFrame(np.random.randn(100, 3), columns=list('ABC'))\", 'df[df.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]', 'df[((df.B - df.B.mean()) / df.B.std()).abs() < 3]']\n",
      "31512025 [\"df['First Season'] = (df['First Season'] > 1990).astype(int)\"]\n",
      "31541600 [\"df = pd.DataFrame(pd.np.random.choice(['1.0', '0.6666667', '150000.1'],(100000, 10)))\", 'df = pd.DataFrame(pd.np.random.choice([1.0, 0.6666667, 150000.1],(100000, 10)))']\n",
      "31543407 []\n",
      "31549924 [\"toy_df = pd.DataFrame(data=np.random.rand(5,3), columns = ('a', 'b' ,'c'), index = pd.DatetimeIndex(start='01-01-2015',periods=5, freq='d'))       \", 'for i in range(0,len(toy_df.columns)):', '    ts_list_of_list.append(toy_df.index.T)', 'vals_list_of_list = toy_df.values.T.tolist()', 'for (name, series) in toy_df.iteritems():', '    name_for_display = np.tile(name, [len(toy_df.index),1])', \"    source = ColumnDataSource({'x': toy_df.index, 'y': series.values, 'series_name': name_for_display, 'Date': toy_df.index.format()})\", '    hover = p.select(dict(type=HoverTool))']\n",
      "31553791 [\"df['ID'] = df['ID'].str.zfill(15)\"]\n",
      "31569866 [\"df.groupby(['Name','Type','ID']).count().reset_index()\", \"df['Count'] = df.groupby(['Name'])['ID'].transform('count')\", 'df.drop_duplicates()']\n",
      "31570270 []\n",
      "31573180 []\n",
      "31585881 [\"df['Age_fill'][(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1)] \\\\\"]\n",
      "31593712 ['s = pd.Series(np.nan, index=[49,48,47,46,45, 1, 2, 3, 4, 5])', \"s2 = pd.Series(np.nan, index=['a','b','c','d','e', 1, 2, 3, 4, 5])\", 'df = pd.DataFrame(np.nan, ', \"df.iloc[:df.index.get_loc('c') + 1, :4]\"]\n",
      "31594055 [\"df = pd.DataFrame(index=['a', 'b', 'c'], columns=['time', 'date', 'name'])\"]\n",
      "31610890 ['df = pd.read_clipboard()']\n",
      "31611678 []\n",
      "31617974 []\n",
      "31679396 ['person_u = list(sort(frame.person.unique()))', 'thing_u = list(sort(frame.thing.unique()))', \"data = frame['count'].tolist()\", \"row = frame.person.astype('category', categories=person_u).cat.codes\", \"col = frame.thing.astype('category', categories=thing_u).cat.codes\", 'sparse_matrix = csr_matrix((data, (row, col)), shape=(len(person_u), len(thing_u)))']\n",
      "31839240 ['df = pd.DataFrame()', \"df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\"]\n",
      "31859215 [\"df = pd.DataFrame({'A':['a', 'b', 'c'], 'B':[54, 67, 89]}, index=[100, 200, 300])\", \"df2 = df.set_index([df.index,'A'])\"]\n",
      "31885295 [\"df = pd.DataFrame({'col_two' : [0.0001, 1e-005 , 1e-006, 1e-007],\"]\n",
      "31907749 [\"pd.date_range('2011-01-05', '2011-01-09', freq=BDay())\", \"pd.bdate_range('2011-01-05', '2011-01-09')\"]\n",
      "31931208 []\n",
      "31939145 ['df.apply(LabelEncoder().fit_transform)', 'fit = df.apply(lambda x: d[x.name].fit_transform(x))', 'fit.apply(lambda x: d[x.name].inverse_transform(x))', 'df.apply(lambda x: d[x.name].transform(x))']\n",
      "31971245 ['ser = pd.Series(np.random.normal(size=100))', 'ser = ser.sort_values()', 'ser[len(ser)] = ser.iloc[-1]', 'cum_dist = np.linspace(0.,1.,len(ser))', 'ser_cdf = pd.Series(cum_dist, index=ser)', \"ser_cdf.plot(drawstyle='steps')\"]\n",
      "32000194 ['dataf = (DataFrame(mtcars).', '(DataFrame(flights).']\n",
      "32011969 [\"df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':list('abcab'),  'col3':list('ababb')})\", \"df['col2'] = df['col2'].astype('category')\", \"df['col3'] = df['col3'].astype('category')\", \"cat_columns = df.select_dtypes(['category']).columns\", 'df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)']\n",
      "32012129 [\"grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])\", \"grouper['Event'].count()\", \"grouper['Event'].count().unstack()\", \"grouper = df.groupby([pd.TimeGrouper('1H'), 'Location'])\", \"result = grouper['Event'].count().unstack('Location').fillna(0)\"]\n",
      "32066997 ['grp = data.groupby(by=[data.datetime_col.map(lambda x : (x.hour, x.minute))])', 'grp.count()', 'grp = data.groupby(by=[data.datetime_col.map(lambda x : x.hour),', '                       data.datetime_col.map(lambda x : x.minute)])']\n",
      "32094352 [\"c_maxes = df.groupby(['A', 'B']).C.transform(max)\", \"df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)\"]\n",
      "32103253 [\"df = pd.DataFrame({'foo':list('ABC')}, index=[0,2,1])\"]\n",
      "32103678 ['total_rows=len(df.axes[0])', 'total_cols=len(df.axes[1])']\n",
      "32107505 ['dt = datetime.now()', 'd = datetime.date(datetime.now())', \"df1 = pd.DataFrame([{'c1': 'alpha', 'c2': 1}, {'c1': 'beta', 'c2': 2}])\", \"df2 = pd.DataFrame([{'c1': dt, 'c2': d}, {'c1': dt, 'c2': d}])\", \"    df1.to_excel(writer,'Sheet1')\", \"    df2.to_excel(writer,'Sheet2')\"]\n",
      "32131398 []\n",
      "32152755 ['df.ix[:, df.columns.difference(exclude)].hist() ']\n",
      "32244161 [\"matplotlib.style.use('ggplot')\", 'df = pd.DataFrame({ \\'celltype\\':[\"foo\",\"bar\",\"qux\",\"woz\"], \\'s1\\':[5,9,1,7], \\'s2\\':[12,90,13,87]})', 'df.set_index([\"celltype\"],inplace=True)', \"df.plot(kind='bar',alpha=0.75, rot=0)\"]\n",
      "32245025 []\n",
      "32245026 []\n",
      "32307259 ['df1 = pd.DataFrame({\"Name\":[\"Alice\", \"Bob\", \"Mallory\", \"Mallory\", \"Bob\" , \"Mallory\"],', 'g1 = df1.groupby([\"Name\", \"City\"], as_index=False).count()']\n",
      "32322596 ['columns = [row.replace(\"$\",\"\") for row in columns]', 'df.rename(columns=dict(zip(columns, things)), inplace=True)', 'df.head() #to validate the output', \"df = pd.DataFrame({'$a':[1,2], '$b': [10,20],'$c':['bleep','blorp'],'$d':[1,2],'$e':['texa$','']})\", 'df.head()', '    return df.rename(columns=col_dict)', '    return df.rename(columns=col_dict, inplace=True)', '    return df.rename(columns=lambda x: x[1:], inplace=True)', \"    return df.rename(columns=lambda x: x.replace('$', ''))\", \"    return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)\", '    return df.rename(columns=dict(zip(on, nn)), inplace=True)', \"    return df.columns.str.replace('$','')\", '    columns = [row.replace(\"$\",\"\") for row in columns]', \"    return df.rename(columns=dict(zip(columns, '')), inplace=True)\", \"    df.columns = [col.strip('$') for col in df.columns]\"]\n",
      "32344037 []\n",
      "32366268 ['grouped = df.groupby([times.hour, times.minute])']\n",
      "32397818 [\"df.groupby('id')['value'].nlargest(2)\"]\n",
      "32399908 []\n",
      "32400969 ['s=requests.get(url).content', \"c=pd.read_csv(io.StringIO(s.decode('utf-8')))\"]\n",
      "32401251 ['c = pd.read_csv(\"https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\")']\n",
      "32444187 ['df = pd.concat(list_of_dataframes)']\n",
      "32469151 [\"df = pd.DataFrame({'listcol':[[1,2,3],[4,5,6]]})\", 'X = pd.concat([pd.DataFrame(v, index=np.repeat(k,len(v))) ', '            for k,v in df.listcol.to_dict().items()])    ']\n",
      "32470490 [\"df = (pd.DataFrame({'name': ['A.J. Price'] * 3, \", 'df.reset_index(inplace=True)', \"_ = df.apply(lambda row: [rows.append([row['name'], row['opponent'], nn]) \", \"df_new = pd.DataFrame(rows, columns=df.columns).set_index(['name', 'opponent'])\"]\n",
      "32489918 []\n",
      "32529152 [\"df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})\", \"df['period'] = df[['Year', 'quarter']].apply(lambda x: ''.join(x), axis=1)\"]\n",
      "32536193 ['stocks = pd.DataFrame({ ', \"    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\", \"    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\", \"    'price':(np.random.randn(100).cumsum() + 10) })\", 'stocks.head(5).to_dict()', \"{'date': {0: Timestamp('2011-01-01 00:00:00'),\", \"  1: Timestamp('2011-01-01 00:00:00'),\", \"  2: Timestamp('2011-01-01 00:00:00'),\", \"  3: Timestamp('2011-01-01 00:00:00'),\", \"  4: Timestamp('2011-01-02 00:00:00')},\", 'pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()', \"{'date': {0: Timestamp('2011-01-01 00:00:00'),\", \"  1: Timestamp('2011-01-01 00:00:00'),\", \"  2: Timestamp('2011-01-01 00:00:00'),\", \"  3: Timestamp('2011-01-01 00:00:00'),\", \"  4: Timestamp('2011-01-02 00:00:00'),\", \"  5: Timestamp('2011-01-24 00:00:00'),\", \"  6: Timestamp('2011-01-25 00:00:00'),\", \"  7: Timestamp('2011-01-25 00:00:00'),\", \"  8: Timestamp('2011-01-25 00:00:00'),\", \"  9: Timestamp('2011-01-25 00:00:00')},\", 'stocks.info()', \"df = stocks.set_index(['date', 'ticker'])\", 'd = df.reset_index().to_dict()', \"df_new = pd.DataFrame(d).set_index(['date', 'ticker'])\", 'df_new.head()']\n",
      "32558621 []\n",
      "32583988 []\n",
      "32591786 [\"df = pd.read_excel('Book1.xlsx',sheetname='Sheet1',header=0,converters={'names':str,'ages':str})\"]\n",
      "32591799 ['pandas.read_excel(my_file, converters = {my_str_column: str})']\n",
      "32606673 ['df = pandas.DataFrame(data)', 'df_7 = df.sample(n=7)']\n",
      "32645303 ['df = pd.DataFrame(df) # into Pandas DataFrame', \"df['sum'] = df.sum(axis= 1)\"]\n",
      "32658847 []\n",
      "32662331 []\n",
      "32680162 [\"df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})\"]\n",
      "32700453 [\"days = pd.DataFrame({'date':list_of_days})\", \"stores = pd.DataFrame({'store_id':list_of_stores})\", \"days_and_stores = days.merge(stores, how='left', on = 'key')\", \"days_and_stores.drop('key',1, inplace=True)\"]\n",
      "32748510 [\"df = pd.DataFrame(np.random.randn(100,2), columns=list('AB'))\", \"df.plot(kind='hist', normed=1, bins=20, stacked=False, alpha=.5)\"]\n",
      "32750237 [\"x['cat2'] = x['cat'].astype('category')\"]\n",
      "32751357 [\"df.groupby(['Country', 'Item_Code']).agg({'Y1961': np.sum, 'Y1962': [np.sum, np.mean]})  # Added example for two output columns from a single input column\", \"df.groupby(['Code', 'Country', 'Item_Code', 'Item', 'Ele_Code', 'Unit']).agg({'Y1961': np.sum, 'Y1962': np.sum, 'Y1963': np.sum})\"]\n",
      "32751412 ['df.groupby([\\'Country\\', \\'Item_Code\\'])[[\"Y1961\", \"Y1962\", \"Y1963\"]].sum()']\n",
      "32752318 [\"df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))\", \"df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))\"]\n",
      "32760406 []\n",
      "32761138 ['indexed.where(col(\"index\").isin(set(indexes)))', 'indexed.where(\"index in ({0})\".format(\",\".join(str(x) for x in indexes)))', 'indexed = (df.rdd # Extract rdd', 'indexed.where(col(\"index\").isin(indexes))']\n",
      "32763707 ['df.loc[\"2011-01-07\", :datetime.time(15, 0)] = np.inf', 'df.loc[\"2011-01-10\", datetime.time(13, 30):] = np.inf', 'df.loc[\"2011-01-07\": \"2011-01-10\", :].idxmin(axis=1)']\n",
      "32764796 [\"first, last = ('2011-01-07', datetime.time(15)), ('2011-01-10', datetime.time(13, 30))\", 'df.stack().loc[first: last].min()', 'first_row = df.index.get_loc(first[0])', 'last_row = df.index.get_loc(last[0])', '    result = df.loc[first[0], first[1]: last[1]].min()', '    first_row_min = df.loc[first[0], first[1]:].min()', '    last_row_min = df.loc[last[0], :last[1]].min()', '    middle_min = df.iloc[first_row + 1:last_row].min().min()', '    result = min(first_row_min, last_row_min, middle_min)']\n",
      "32770800 ['df.shift(1)', 'df.shift(2).iloc[:, 4:]', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)', 'pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1).min(1)', 'pd.concat([df.iloc[:, :1].min(1),', '                    df.shift(1).min(1),', '                    df.shift(2).iloc[:, 4:].min(1)],']\n",
      "32773145 [\"lambdafunc = lambda x: pd.Series([x['mytime'].hour,\", \"                                  x['mydate'].isocalendar()[1],\", \"                                  x['mydate'].weekday()])\", 'newcols = df.apply(lambdafunc, axis=1)', 'newdf = df.join(newcols) ']\n",
      "32783825 ['data.groupby(data.date.dt.year)']\n",
      "32801170 ['df.groupby(key_columns).size()', \"df = pd.DataFrame([['a', 1],\", \"counts = df.groupby('col1').size(); counts\", \"counts_df = pd.DataFrame(df.groupby('col1').size().rename('counts'))\", \"df[['col1', 'col2', 'col3', 'col4']]\\\\\", \"groupby_object = df[['col1', 'col2', 'col3', 'col4']]\\\\\", \"groupby_object.agg('mean')\\\\\", \"             .rename(columns = lambda x: x + ' mean')\\\\\", '             .join(pd.DataFrame(groupby_object.size(), ']\n",
      "32801924 []\n",
      "32802014 [\"df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\", \"df2 = pd.DataFrame({'A1': ['A4', 'A5', 'A6', 'A7'],\", 'df1.reset_index(drop=True, inplace=True)', 'df2.reset_index(drop=True, inplace=True)', 'df = pd.concat( [df1, df2], axis=1) ']\n",
      "32850652 ['df[\"flips\"], df[\"row_name\"] = zip(*df[\"row\"].str.split().tolist())']\n",
      "32909107 ['df.drop(df.columns[cols],axis=1,inplace=True)']\n",
      "32944421 []\n",
      "32961145 ['    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '        dcols = frame[v].to_dict(orient=\"list\")', '        vs = dcols.values()', '        lvs = len(vs)', '                    dups.append(ks[i])', 'frame = frame.drop(dups, axis=1)', '    groups = frame.columns.to_series().groupby(frame.dtypes).groups', '        lcs = len(cs)', '                    dups.append(cs[i])']\n",
      "32970117 ['df.memory_usage()', 'df.memory_usage(index=True).sum()']\n",
      "32993553 ['df = pd.read_csv(filename.tar.gz, compression=\\'gzip\\', header=0, sep=\\',\\', quotechar=\\'\"\\')']\n",
      "33000983 [\"df = pd.DataFrame({'value': np.arange(-1000000,1000000)})\", \"df = pd.DataFrame({'value': np.arange(-1000000,1000000)})\"]\n",
      "33004253 ['df = pd.DataFrame(randn(15, 20))', 'df1 = pd.DataFrame(randn(10, 5))', 'df2 = pd.DataFrame(randn(5, 10))', '        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   ', '        row = row + len(dataframe.index) + spaces + 1', '        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   ']\n",
      "33011646 []\n",
      "33020669 []\n",
      "33040290 [\"df = pd.DataFrame({'a':list('tuhimerisabhain')})\", 'df.a.value_counts()', 'df.a.value_counts()']\n",
      "33050438 [\"df.to_pickle('123.pkl')    #to save the dataframe, df to 123.pkl\", \"df1 = pd.read_pickle('123.pkl') #to load 123.pkl back to the dataframe df\"]\n",
      "33054358 [\"df = pd.DataFrame({'ID':[100,101,102,201,202],'wt':[.5,.75,1,.5,1],'value':[60,80,100,100,80]},index=index)\", 'df.groupby(df.index).apply(lambda x: np.average(x.wt, weights=x.value))']\n",
      "33086953 [\"df1.merge(df2,how='left', left_on='Column1', right_on='ColumnA')\"]\n",
      "33088410 ['df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)']\n",
      "33109272 ['x = pandas.Series(np.random.randn(10))', 'stats.skew(x)', 'x.skew()', 'stats.skew(x, bias=False)']\n",
      "33133356 [\"pandas.to_datetime('today')\", \"Timestamp('2015-10-14 00:00:00')\"]\n",
      "33149986 []\n",
      "33161955 [\"df = pd.read_csv('somefile.csv', low_memory=False)\"]\n",
      "33165860 ['df2 = df2.reset_index(drop=True)']\n",
      "33168054 []\n",
      "33178896 [\"sub2['income'].fillna((sub2['income'].mean()), inplace=True)\"]\n",
      "33247007 ['df = pd.DataFrame([list(range(5))], columns=[\"a{}\".format(i) for i in range(5)])']\n",
      "33250288 ['df = pd.DataFrame(np.random.randn(4,4)* 4 + 3)', 'df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))', \"df.groupby(['grp'])[[0,1,2,3]].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\"]\n",
      "33259038 [\"dfWIM = pd.DataFrame({'AXLES': np.random.normal(8, 2, 5000).astype(int)})\", 'ncount = len(dfWIM)', \"plt.title('Distribution of Truck Configurations')\", \"    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), \"]\n",
      "33271634 ['df.groupby([\"Group\", \"Size\"]).size()', 'df.groupby([\"Group\", \"Size\"]).size().reset_index(name=\"Time\")']\n",
      "33324058 ['p = pol_ext.interpolate(d)']\n",
      "33346694 [\"df = pd.DataFrame({'a':[0,0,1,2,2,2], 'b':[1,2,3,4,np.NaN,4], 'c':np.random.randn(6)})\", \"print(df.groupby(['a'])['b'].count())\", \"print(df.groupby(['a'])['b'].size())\"]\n",
      "33374834 ['sheet1 = xlsx.parse(0)']\n",
      "33375383 []\n",
      "33381151 [\"frame[frame.duplicated(['key1','key2'],keep=False)]\"]\n",
      "33381246 [\"df = pd.DataFrame(['a','b','c','d','a','b'])\", 'df[df.duplicated(keep=False)]']\n",
      "33387356 ['df[~df.index.duplicated()]']\n",
      "33404243 ['original = pandas.DataFrame({', \"additional = pandas.DataFrame({'Name': data})\", 'new = pandas.concat([original, additional], axis=1) ', 'new = pandas.concat([original, additional], ignore_index=False, axis=1) ', 'print(new.head())']\n",
      "33480745 []\n",
      "33555435 ['your_dataframe = your_dataframe.reindex(columns=sequence)']\n",
      "33570065 []\n",
      "33577649 []\n",
      "33590284 []\n",
      "33687073 [\"df['MyColumnName'] = df['MyColumnName'].astype('float64') \"]\n",
      "33763855 []\n",
      "33768634 ['sample_dataframe = your_dataframe.sample(n=how_many_rows_you_want)']\n",
      "33777664 [\"df['quantity'] = df['quantity'].apply(lambda x: x*-1)\"]\n",
      "33780558 []\n",
      "33782239 [\"df = pd.DataFrame(np.random.uniform(0,1,(10)), columns=['a'])\", 'x = df.quantile(0.5)[0]']\n",
      "33782409 []\n",
      "33786696 [\"df1 = pandas.DataFrame(data = {'col1' : [1, 2, 3, 4, 5], 'col2' : [10, 11, 12, 13, 14]})\", \"df2 = pandas.DataFrame(data = {'col1' : [1, 3, 4], 'col2' : [10, 12, 13]})\", 'df1.loc[~df1.set_index(list(df1.columns)).index.isin(df2.set_index(list(df2.columns)).index)]']\n",
      "33795876 [\"df1 = df.apply(pd.to_numeric, args=('coerce',))\", \"df1 = df.apply(pd.to_numeric, errors='coerce')\"]\n",
      "33798922 [\"pd.set_option('max_colwidth', 800)\"]\n",
      "33814054 []\n",
      "33837592 [\"df.sort_values(['b', 'c'], ascending=[True, False], inplace=True)\"]\n",
      "33872824 [\"df.columns = [col.strip('$') for col in df.columns]\"]\n",
      "33873209 ['df = pd.DataFrame(data=[1,2,3],']\n",
      "33913961 [\"df = pd.DataFrame({'Year': ['2014', '2015'], 'quarter': ['q1', 'q2']})\"]\n",
      "33952294 [\"df = pd.read_csv(StringIO(data), sep=' ', keep_default_na=False, na_values=['_'])\", 'df.CHAIN.apply(type)']\n",
      "33957850 [\"df['column'] = df['column'].astype('str') \", \"df['column_new'] = df['column'].str.split(',') \"]\n",
      "33967359 [\"dates.dt.strftime('%Y-%m-%d')\"]\n",
      "33986975 []\n",
      "33993078 [\"misc['product_desc'] = misc['product_desc'].replace(to_replace='\\\\n', value='', regex=True)\"]\n",
      "33997632 [\"titanic.reindex(columns=['sex','age','fare'])\"]\n",
      "34013098 []\n",
      "34082664 ['df[df.EPS.notnull()]', 'df[~df.EPS.isnull()]']\n",
      "34092032 ['Cov = pd.read_csv(\"path/to/file.txt\", sep=\\'\\\\t\\', ', 'Frame=pd.DataFrame([Cov], columns = [\"Sequence\", \"Start\", \"End\", \"Coverage\"])']\n",
      "34094058 ['Cov = pd.read_csv(\"path/to/file.txt\", sep=\\'\\\\t\\', header=None)']\n",
      "34097939 []\n",
      "34110546 [\"pivoted = pandas.pivot_table(data, values='score', columns='template', index='date')\", 'pivoted.plot()']\n",
      "34130874 []\n",
      "34192820 []\n",
      "34262133 ['pd.DataFrame(df.to_records()) # multiindex become columns and new index is integers only']\n",
      "34272155 ['df = pd.DataFrame({\"A\":[\"foo\", \"foo\", \"foo\", \"bar\"], \"B\":[0,1,1,1], \"C\":[\"A\",\"A\",\"B\",\"A\"]})', \"df.drop_duplicates(subset=['A', 'C'], keep=False)\"]\n",
      "34277514 []\n",
      "34282362 ['    if len(lst) >= max_len:', '    lst.append(d)', '    df = pd.DataFrame(lst)', '        store.append(key, df)', '    lst.clear()']\n",
      "34297689 [\"df3 = df3[~df3.index.duplicated(keep='first')]\"]\n",
      "34311080 [\"t = pd.DataFrame({'a': range(0, 10000), 'b': range(10000, 20000)})\", 'A = time.time()', 'for i,r in t.iterrows():', \"    C.append((r['a'], r['b']))\", 'B.append(time.time()-A)', 'A = time.time()', 'for ir in t.itertuples():', '    C.append((ir[1], ir[2]))    ', 'B.append(time.time()-A)', 'A = time.time()', '    C.append((r[0], r[1]))', 'B.append(time.time()-A)']\n",
      "34333886 [\"df_1 = pd.merge(df_1, df_2, on=['field_x', 'field_y'], how = 'left')\", \"df_1 = df_1.drop(['key1','key2'], axis=1)\"]\n",
      "34365537 ['df = pd.DataFrame(np.random.randint(0, int(1e8), (10000, 1000)))', 'df.groupby(0).progress_apply(lambda x: x**2)', \"df_users.groupby(['userID', 'requestDate']).apply(feature_rollup)\", \"df_users.groupby(['userID', 'requestDate']).progress_apply(feature_rollup)\"]\n",
      "34402423 ['display(salaries.head())', 'display(teams.head())']\n",
      "34457902 [\"dummies = pd.get_dummies(df['Category']).rename(columns=lambda x: 'Category_' + str(x))\", 'df = pd.concat([df, dummies], axis=1)', \"df = df.drop(['Category'], inplace=True, axis=1)\"]\n",
      "34466473 [\"df = pd.DataFrame({'$a':['a', 'b', 'c', 'd', 'a'], '$b': np.arange(5)})\", \"df.describe(include = 'all')\", 'df.describe(include = [np.number])', \"df.describe(include = ['O'])\"]\n",
      "34530065 []\n",
      "34531543 []\n",
      "34548894 []\n",
      "34551914 ['list(data_set.itertuples(index=False))']\n",
      "34555201 [\"f_states=   pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states') \"]\n",
      "34576537 [\"df.drop(['col_name_1','col_name_2',...,'col_name_N'],inplace=True,axis=1,errors='ignore')\"]\n",
      "34592295 []\n",
      "34614046 ['df.drop(df.index[[1,3]], inplace=True)']\n",
      "34683105 [\"new = old[['A', 'C', 'D']].copy()\", \"new = old.filter(['A','B','D'], axis=1)\", \"new = old.drop('B', axis=1)\"]\n",
      "34687479 ['t = pd.date_range(start=\"2013-05-18 12:00:00\", periods=2, freq=\\'H\\',', 't.tz_localize(None)', 't.tz_convert(None)', 't = pd.date_range(start=\"2013-05-18 12:00:00\", periods=10000, freq=\\'H\\',']\n",
      "34756965 ['df.hist(bins=20, weights=np.ones_like(df[df.columns[0]]) * 100. / len(df))']\n",
      "34790248 [\"df = df.sort_values(by=['c1','c2'], ascending=[False,True])\"]\n",
      "34794112 [\"df.replace('N/A',np.NaN)\"]\n",
      "34812293 [\"df.loc['Total']= df.sum()\"]\n",
      "34863702 [\"df['id'].map(str.strip)\", \"df['id'].str.strip()\", \"s = pd.Series(['  a', 10])\", 's.astype(str).map(str.strip)', 's.str.strip()']\n",
      "34879805 ['df.sample(frac=1)', 'df = df.sample(frac=1).reset_index(drop=True)']\n",
      "34883876 [\"df['UNIXTIME'] = pd.to_datetime(df['UNIXTIME'], unit='ms')\"]\n",
      "34896797 [\"df[df.columns[1:-1]].apply(lambda x: x.corr(df['special_col']))\"]\n",
      "34896835 [\"data[data.columns[1:]].corr()['special_col'][:-1]\"]\n",
      "34897294 ['df.corr().iloc[:-1,-1]', \"df.corr().ix['special_col', :-1]\"]\n",
      "34916691 [\"res = df.apply(lambda x: x.fillna(0) if x.dtype.kind in 'biufc' else x.fillna('.'))\"]\n",
      "34962199 [\"df['a'] = df['a'].apply(lambda x: x + 1)\"]\n",
      "34962592 [\"df = pd.DataFrame({'a': [100, 1000], 'b': [200, 2000], 'c': [300, 3000]})\"]\n",
      "34996876 ['df = DataFrame(table)', 'df = df.transpose()']\n",
      "35068123 ['df.columns = df.columns.str.slice(1)']\n",
      "35087831 [\"dff = pd.read_csv(StringIO(raw), sep='\\\\s+')\"]\n",
      "35106735 []\n",
      "35138807 ['df = pd.DataFrame(np.arange(1,7).reshape(2,3),', \"                  index=pd.Series([2,5], name='b'))\", 'df.index.get_loc(5)']\n",
      "35139819 []\n",
      "35203149 ['df1 = pd.DataFrame(df, columns=columns)']\n",
      "35203658 ['df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]']\n",
      "35212740 [\"data = pd.read_csv('file1.csv', error_bad_lines=False)\", \"        data = pd.read_csv('file1.csv',skiprows=line)\", \"        errortype = e.message.split('.')[0].strip()                                \", \"           cerror      = e.message.split(':')[1].strip().replace(',','')\", \"           nums        = [n for n in cerror.split(' ') if str.isdigit(n)]\", '           expected.append(int(nums[0]))', '           saw.append(int(nums[2]))', '           line.append(int(nums[1])-1)']\n",
      "35219658 []\n",
      "35240942 []\n",
      "35245297 [\"index = ['Row'+str(i) for i in range(1, len(values)+1)]\", 'df = pandas.DataFrame(values, index=index)']\n",
      "35246041 [\"test = pd.read_csv('https://docs.google.com/spreadsheets/d/' + \", 'test.head(5)  # Same result as @TomAugspurger']\n",
      "35282530 [\"df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))\", \"df.query('(a < b) & (b < c)')\", \"df.query('color not in @exclude')\"]\n",
      "35318270 [\"mean_ratings = data.pivot_table('rating', rows='title', cols='gender', aggfunc='mean')\", \"mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')\"]\n",
      "35368792 ['df.index = df.index.map(unicode) ', 'df.index = df.index.map(str)']\n",
      "35385805 [\"df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df], \"]\n",
      "35387028 []\n",
      "35387129 ['df1 = df1.assign(e=e.values)', \"df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\", 'df.assign(mean_a=df.a.mean(), mean_b=df.b.mean())', \"df1 = pd.DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])\", 'mask = df1.applymap(lambda x: x <-0.7)', 'df1 = df1[-mask.any(axis=1)]', \"sLength = len(df1['a'])\", 'e = pd.Series(np.random.randn(sLength))', 'df1 = df1.assign(e=e.values)']\n",
      "35415751 [\"df.groupby(['year', 'month', 'item'])['value'].sum().unstack('item')\", \"df.pivot_table(values='value', index=['year', 'month'], columns='item')\"]\n",
      "35416021 [\"df.set_index(['year', 'month', 'item']).unstack(level=-1)\"]\n",
      "35446404 ['df = pd.DataFrame(np.random.randn(100,5))', 'ax = df.plot()', \"ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \"]\n",
      "35453836 ['ax = data.plot(...)']\n",
      "35476539 []\n",
      "35509134 [\"list.append(['e','f'])\", \"df=pd.DataFrame(list,columns=['col1','col2'])\"]\n",
      "35523946 []\n",
      "35531218 ['train=df.sample(frac=0.8,random_state=200)', 'test=df.drop(train.index)']\n",
      "35583219 [\"f = pandas.DataFrame(data = {'Animal':['cow','horse'], 'Color':['blue', 'red']})\", \"f.append({'Animal':'mouse', 'Color':'black'}, ignore_index=True)\"]\n",
      "35616082 ['a.to_frame().join(b.to_frame())']\n",
      "35619846 []\n",
      "35715029 ['df = df.reset_index() ', \"df.ix[df.duplicated('first') , 'first'] = ''\"]\n",
      "35768306 [\"df.sort_values(['Peak', 'Weeks'], ascending=[True, False], inplace=True)\"]\n",
      "35783766 ['s.loc[(~np.isfinite(s)) & s.notnull()] = np.nan', \"df = pd.DataFrame(np.ones((3, 3)), columns=list('ABC'))\", 'df.sum()', 'df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()']\n",
      "35784666 ['df.sample(frac=1)']\n",
      "35850749 []\n",
      "35902487 [\"ax.axvline(pd.to_datetime('2015-11-01'), color='r', linestyle='--', lw=2)\", \"xposition = [pd.to_datetime('2010-01-01'), pd.to_datetime('2015-12-31')]\"]\n",
      "35970794 [\"df = pd.DataFrame.from_records([{ 'A':a,'B':b }])\", \"df = pd.DataFrame.from_records([{ 'A':a,'B':b }], index='A')\"]\n",
      "36001191 ['pd.isnull(np.array([np.nan, 0], dtype=float))', 'pd.isnull(np.array([np.nan, 0], dtype=object))']\n",
      "36012306 []\n",
      "36013757 []\n",
      "36014326 []\n",
      "36041831 [\"df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': ['q1', 'q2']})\", \"df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\", \"df = pd.DataFrame({'Year': ['2014', '2015'], 'Quarter': [1, 2]})\", \"df['YearQuarter'] = df[['Year','Quarter']].apply(lambda x : '{}q{}'.format(x[0],x[1]), axis=1)\"]\n",
      "36059898 [\"df['Age_group'] = np.where(df.Age<18, 'under 18',\", \"                           np.where(df.Age<40,'under 40', '>40'))\"]\n",
      "36073837 [\"df.groupby('id').nth(1) \"]\n",
      "36074520 []\n",
      "36082588 [\"df = pd.DataFrame(columns=['Year', 'Month ', 'Value'])\", 'print(df.columns.tolist())', 'df.columns = df.columns.str.strip()', 'df.columns.tolist()']\n",
      "36091388 ['        samples.append(line)']\n",
      "36149967 []\n",
      "36184396 []\n",
      "36188131 []\n",
      "36226137 ['pd.isnull(df).sum() > 0', 'df.isnull().any()', 'df.columns[df.isnull().any()].tolist()', 'df.loc[:, df.isnull().any()]']\n",
      "36236885 ['w.female.replace(to_replace=dict(female=1, male=0), inplace=True)']\n",
      "36257640 ['pd.read_sql(session.query(Complaint).filter(Complaint.id == 2).statement,session.bind) ']\n",
      "36319915 [\"ax = df['myvar'].plot(kind='bar')\"]\n",
      "36372667 []\n",
      "36373866 [\"pd.set_option('display.large_repr', 'truncate')\", \"pd.set_option('display.max_columns', 0)\"]\n",
      "36416258 ['all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent', 'df_from_each_file = (pd.read_csv(f) for f in all_files)', 'concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)']\n",
      "36434248 ['df.apply(pd.value_counts)']\n",
      "36475297 [\"dfTest = pd.DataFrame({'A':[14.00,90.20,90.95,96.27,91.21],\"]\n",
      "36513262 ['df = df.drop(\"toDROP\",1)']\n",
      "36519122 [\"df = pd.DataFrame(np.random.randn(5,3), columns=list('abc'))\", 'pd.read_csv(io.StringIO(df.to_csv()))', 'pd.read_csv(io.StringIO(df.to_csv(index=False)))', 'pd.read_csv(io.StringIO(df.to_csv()), index_col=0)']\n",
      "36539513 [\"pd.DataFrame( OrderedDict( { 'foo': pd.Series(foo), 'bar': pd.Series(bar) } ) )\", \"pd.DataFrame( OrderedDict( { 'a': pd.Series(a), 'b': pd.Series(b), 'c': pd.Series(c) } ) )\", \"pd.DataFrame( OrderedDict( (('a', pd.Series(a)), ('b', pd.Series(b)), ('c', pd.Series(c))) ) )\"]\n",
      "36572039 ['df.read_csv(filename ,  index = False)  ']\n",
      "36590692 [\"df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')\", \"df = pandas.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=2)\"]\n",
      "36682678 [\"df = df.xs('a', axis=1, drop_level=True)\"]\n",
      "36685531 []\n",
      "36694513 [\"data = pd.DataFrame({'test_data': [1,2,3,4,5]})\", \"data.to_excel(writer, sheet_name='test', index=False)\"]\n",
      "36704460 [\"df['RN'] = df.sort_values(['data1','data2'], ascending=[True,False]) \\\\\"]\n",
      "36709634 []\n",
      "36710126 []\n",
      "36725677 [\"df = pd.DataFrame({'col1':[1,2,3,4,5], 'col2':[2,4,6,8,10]})\"]\n",
      "36816769 ['out.apply(pd.Series)']\n",
      "36893675 [\"merged = df1.merge(df2, indicator=True, how='outer')\"]\n",
      "36911306 [\"df['period'] = df['Year'].astype(str) + df['quarter']\", \"df['period'] = df[['Year','quarter']].astype(str).sum(axis=1)\", 'df = pd.concat([df] * 10**5)']\n",
      "36922103 ['x = pd.Series([1])']\n",
      "36922486 [\"df = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\", '(df.C > 0.25).any() or (df.C < -0.25).any()', '(df.C > 0.25).all() or (df.C < -0.25).all()', 'df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]']\n",
      "36951842 [\"grouped_df = df.groupby('A')\"]\n",
      "36955053 ['df = pd.DataFrame(np.random.randint(100, size=(100, 6)), ', \"                  index=['R{}'.format(i) for i in range(100)])\", 'df.head()', \"df.loc[:, df.columns.isin(list('BCD'))]\"]\n",
      "36957431 [\"w.female.replace(['male', 'female'], [1, 0], inplace=True)\"]\n",
      "36958937 [\"df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')\"]\n",
      "37000877 []\n",
      "37012035 ['df.info()', 'df.head()']\n",
      "37043071 []\n",
      "37069701 [\"yourdf.drop(['columnheading1', 'columnheading2'], axis=1, inplace=True)\"]\n",
      "37097791 []\n",
      "37103131 [\"df = pd.DataFrame({'year': [2015, 2016],\"]\n",
      "37199623 ['df = pd.DataFrame(data)', 'df_normalized = pd.DataFrame(np_scaled)']\n",
      "37226672 []\n",
      "37282998 [\"df = DataFrame({'a': [-1, 100, -2]})\", 'df.clip(lower=0)']\n",
      "37293283 [\"        columnsToEncode = list(df.select_dtypes(include=['category','object']))\"]\n",
      "37327506 ['pd.Series(test).where(lambda x : x!=1).dropna()']\n",
      "37347783 [\"pd.set_option('display.max_columns', None)\", \"pd.set_option('display.max_rows', None)\", \"pd.describe_option('display')\"]\n",
      "37384347 ['np_df = df.as_matrix()']\n",
      "37426982 [\"df = pd.DataFrame({'cat': ['a', 'b', 'a']})\", \"dummies = pd.get_dummies(df, prefix='', prefix_sep='')\", 'dummies = dummies.T.reindex(cats).T.fillna(0)']\n",
      "37441204 [\"df2 = df[df.columns.difference(['B', 'D'])]\"]\n",
      "37442692 ['df.isnull().T.any().T.sum()', 'nan_rows = df[df.isnull().T.any().T]']\n",
      "37447530 []\n",
      "37451867 [\"cat=pd.Series(list('aba'),index=range(1,4))\", \"cat=cat.astype('category',categories=list('abc'))\", 'pd.get_dummies(cat)']\n",
      "37453925 [\"pd.read_csv(file, sep='\\\\t', header=None, names=headers, dtype=dtypes, parse_dates=parse_dates)\", 'date_parser = pd.datetools.to_datetime()']\n",
      "37562101 []\n",
      "37592047 [\"df = pd.DataFrame({'ItemQty': {0: 3, 1: 25}, \", \"print (df.drop('Seatblocks', axis=1)\", '             df.Seatblocks', \"df = pd.DataFrame(['a b c']*100000, columns=['col'])\", \"df = pd.DataFrame(['a b c']*10, columns=['col'])\", 'print (df.head())', 'print (df.col.str.split(expand=True))']\n",
      "37602937 [\"df.groupby(['Name','Type','ID'], as_index=False).count()\"]\n",
      "37644056 [\"df.xs('A', level='Col', axis=1)\", \"df.loc[:, (slice(None), 'A')]\"]\n",
      "37647160 []\n",
      "37654890 []\n",
      "37655063 []\n",
      "37717675 [\"df.drop('b', axis=1)\"]\n",
      "37749078 [\"cols = pd.MultiIndex.from_arrays([['basic_amt']*4,\", 'df = pd.DataFrame([(1,1,2,4),', 'df.columns = df.columns.droplevel(0)', 'df = df.rename_axis(None, axis=1)', \"df.columns = ['_'.join(col) for col in df.columns]\"]\n",
      "37757763 []\n",
      "37793940 ['a = pd.Series(range(100) + ([0]*20))', '    return (np.random.random(len(a_series))*a_series.std()/noise_reduction)-(a_series.std()/(2*noise_reduction))', 'a_deciles = pd.qcut(a + jitter(a), 10, labels=False)', 'a_deciles = pd.qcut(a, 10, labels=False)']\n",
      "37806819 ['aapl.head()', 'aapl.tail()', \"aapl.to_csv('d:/temp/aapl_data.csv')\"]\n",
      "37851232 []\n",
      "37891437 ['left.join(right, on=key_or_keys)', \"pd.merge(left, right, left_on=key_or_keys, right_index=True, how='left', sort=False)\"]\n",
      "37992805 ['s = pd.Series(np.arange(4)**2, index=np.arange(4))', 's2 = pd.Series(new_items)', 's = s.append(s2); s']\n",
      "38025280 []\n",
      "38034085 ['dfNew = df.merge(df2, left_index=True, right_index=True,']\n",
      "38055014 []\n",
      "38105540 [\"data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\"]\n",
      "38134049 [\"df[['a', 'b']] = df[['a','b']].fillna(value=0)\"]\n",
      "38156594 [\"x = np.empty((10,), dtype=[('x', np.uint8), ('y', np.float64)])\", 'df = pd.DataFrame(x)']\n",
      "38185759 [\"df = pd.DataFrame({'A': [1, 2, 3], 'B': [1.0, 2.0, 3.0], \", 'df.select_dtypes(include=[np.number])']\n",
      "38231651 [\"df = pd.DataFrame({'a':[1,2,3], 'b':[{'c':1}, {'d':3}, {'c':5, 'd':6}]})\", \"df['b'].apply(pd.Series)\", \"pd.concat([df.drop(['b'], axis=1), df['b'].apply(pd.Series)], axis=1)\", \"pd.concat([df.drop('b', axis=1), pd.DataFrame(df['b'].tolist())], axis=1)\"]\n",
      "38251063 ['    m = len(df)', \"df = pd.DataFrame(np.random.rand(10, 5), columns=list('ABCDE'))\"]\n",
      "38251213 ['train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])', 'np.split(a, [int(.8 * len(a)), int(.9 * len(a))])']\n",
      "38258390 [\"memloc = pd.DataFrame({'df1': list(map(id, df1['letter'])),\", \"                       'df2': list(map(id, df2['letter'])), })\", 'diffs = memloc.diff(); diffs.head(30)', \"diffs['df1'].value_counts()\", \"len(diffs['df1'].value_counts())\", \"diffs['df2'].value_counts().head()\", \"len(diffs['df2'].value_counts())\"]\n",
      "38278787 [\"s = pd.Series(['1.0', '2', -3])\", 'pd.to_numeric(s)', \"s = pd.Series(['apple', '1.0', '2', -3])\", \"pd.to_numeric(s, errors='ignore')\", \"pd.to_numeric(s, errors='coerce')\"]\n",
      "38341066 []\n",
      "38348167 [\"BaseData = pd.DataFrame({ 'Customer' : ['Acme','Mega','Acme','Acme','Mega','Acme'],\", \"for name, group in BaseData.groupby('Customer'):\", \"    RecordtoAdd.update({'Customer' : name}) #\", \"    RecordtoAdd.update({'Num Unique Products' : len(pd.unique(group['Product']))})      \", \"    RecordtoAdd.update({'List Unique Products' : pd.unique(group['Product'])})                   \", '    rows_list.append(RecordtoAdd)', 'AnalysedData = pd.DataFrame(rows_list)']\n",
      "38421614 ['    assert (df1.columns == df2.columns).all(), \\\\', '    if df1.equals(df2):', '        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())', '        ne_stacked = diff_mask.stack()', '        difference_locations = np.where(diff_mask)', \"        return pd.DataFrame({'from': changed_from, 'to': changed_to},\", \"df1 = pd.read_table(DF1, sep='\\\\s+', index_col='id')\", \"df2 = pd.read_table(DF2, sep='\\\\s+', index_col='id')\"]\n",
      "38440332 ['        n_smp = y.value_counts().min()', '        n_smp = int(size / len(y.value_counts().index))', '    for label in y.value_counts().index:', '        subsample += samples[indexes].tolist()']\n",
      "38466059 []\n",
      "38467449 []\n",
      "38470963 ['                    result = self.apply(f, reduce=False)', '                result = result.astype(np.float64)', \"            elif filter_type == 'bool' and notnull(result).all():\", '                result = result.astype(np.bool_)', '    return Series(result, index=labels)']\n",
      "38490727 ['se = pd.Series(mylist)']\n",
      "38503561 [\"df = pd.DataFrame([['A','C','A','B','C','A','B','B','A','A'], ['ONE','TWO','ONE','ONE','ONE','TWO','ONE','TWO','ONE','THREE']]).T\", \"group_data = df.groupby(['Alphabet','Words'])['COUNTER'].sum() #sum function\"]\n",
      "38510820 []\n",
      "38544742 []\n",
      "38579700 [\"(df['A'] + df['B']).where((df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])\", 'np.where(m, A, B)', 'A.where(m, B)', \"pd.DataFrame.where(cond=(df['A'] < 0) | (df['B'] > 0), self=df['A'] + df['B'], other=df['A'] / df['B'])\", \"pd.DataFrame.where(df['A'] + df['B'], (df['A'] < 0) | (df['B'] > 0), df['A'] / df['B'])\"]\n",
      "38580576 []\n",
      "38650886 []\n",
      "38709267 [\"df.plot(kind='bar', stacked=True, colormap='Paired')\"]\n",
      "38713212 ['df.T.apply(tuple).apply(list)', \"pd.Series(df.T.to_dict('list'))\", 'df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),', '                  pd.MultiIndex.from_product([letters, letters]),']\n",
      "38713387 ['print (pd.Series(df.values.tolist(), index=df.index))', 'df = pd.DataFrame(np.random.choice(range(10), (52 ** 2, 52)),', '                  pd.MultiIndex.from_product([letters, letters]),']\n",
      "38750433 ['    df[k] = df[k].astype(v)']\n",
      "38757990 ['df = pd.read_csv(\\'output_list.txt\\', sep=\" \", header=None, names=[\"a\", \"b\", \"c\"])']\n",
      "38776854 [\"df = pd.DataFrame({'$a':[1,2], '$b': [3,4],'$c':[5,6], '$d': [7,8], '$e': [9,10]})\", \"matchPattern = '|'.join(map(re.escape, delimiters))\", 'df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]']\n",
      "38801975 [\"HTML('<style>{}</style>'.format(CSS))\"]\n",
      "38886211 ['df = pd.DataFrame({True:[1,2,3],False:[3,4,5]}); df', \"df2 = pd.DataFrame({'A':[1,2,3],'B':[3,4,5]}); df2\"]\n",
      "38889524 [\"df = pd.DataFrame({'closing_price': np.random.randint(95, 105, 10)})\", \"df.query('99 <= closing_price <= 101')\", 'df.query(qry)']\n",
      "38900352 []\n",
      "38902835 [\"df = pd.DataFrame({'A':range(5), 'B':range(5)})\", \"print('df: {0}'.format(df))\", \"print('\\\\n\\\\ndf: {0}'.format(df))\", 'df = df.reset_index(drop=True)']\n",
      "38931854 ['df.columns = df.columns.str.lower()', 'df.columns = df.columns.str.lower()']\n",
      "38935669 [\"df.groupby('col1').agg({'col2': 'max', 'col3': 'min'})\", \"df.groupby('col1', as_index=False).agg({'col2': 'max', 'col3': 'min'})\", \"df.groupby('col1').agg({'col2': 'max', 'col3': 'min'}).reset_index()\", \"agg_df = df.groupby('col1').agg({'col2': ['max', 'min', 'std'], \", \"agg_df.xs('max', axis=1, level=1)  # select the maximum of all columns\", \"df.groupby('col1')['col2'].agg({'max_col2': 'max'})\", \"df.groupby('col1')['col2'].agg(['max']).rename(columns={'max': 'col2_max'})\", \"agg_df.columns = ['_'.join(col) for col in agg_df.columns]\", \"df.assign(new_col=df.eval('col2 * col3')).groupby('col1').agg('max') \", \"df.assign(new_col=df.eval('col2 * col3')).groupby('col1')['new_col'].agg('max')\", \"df.groupby('col1').apply(lambda x: (x.col2 * x.col3).max())\"]\n",
      "38951835 [\"pandas.read_csv(filename, sep='\\\\t', lineterminator='\\\\r')\", \"df = pandas.read_csv(doc, sep='\\\\t')\"]\n",
      "39104306 [\"print('pairwise dense output:\\\\n {}\\\\n'.format(similarities))\", \"print('pairwise sparse output:\\\\n {}\\\\n'.format(similarities_sparse))\", 'A_sparse.transpose()']\n",
      "39116381 ['    plt.plot(np.arange(10) + i)', '    plt.plot(np.arange(10, 0, -1) + i)']\n",
      "39132900 [\"df.groupby(['id', 'group', 'term']).size().unstack(fill_value=0)\", 'df = pd.DataFrame(dict(id=np.random.choice(100, 1000000),']\n",
      "39162006 [\"df = pd.DataFrame(np.random.randint(0,5,(6, 2)), columns=['col1','col2'])\", \"df.set_index(['ind1','ind2'], inplace=True)\", \"df.groupby([df.index.get_level_values(0),'col1']).count()\"]\n",
      "39186403 [\"grouped = df.groupby('Location').resample('H')['Event'].count()\", 'grouped.unstack(level=0).fillna(0)']\n",
      "39192113 [\"df[df.columns.difference(['b'])]\"]\n",
      "39206377 []\n",
      "39237712 [\"df = df.reindex_axis(['mean',0,1,2,3,4], axis=1)\", 'df = df.reindex_axis(sorted(df.columns), axis=1)', \"df = df.reindex_axis(['opened'] + list([a for a in df.columns if a != 'opened']), axis=1)\"]\n",
      "39246607 ['f.sort_values(by=[\"c1\",\"c2\"], ascending=[False, True])']\n",
      "39247824 ['grouped = s.groupby(s)', 'grouped = s.groupby(lambda x: s[x])']\n",
      "39251401 ['df = pd.DataFrame(', \"    index=pd.date_range('2010-01-01', freq='M', periods=10),\"]\n",
      "39259437 [\"df['col_3'] = df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)\"]\n",
      "39276195 ['df.a.quantile(.95)  # as you already noticed here it is \".95\" not \"95\"']\n",
      "39287161 []\n",
      "39310387 []\n",
      "39347475 [\"df.append(dict(date='2016-04-01', sleep=11.2, calories=2740))\", \"df.append(dict(date='2016-04-02', sleep=7.3, calories=3600))\", \"df.append(dict(date='2016-04-03', sleep=8.3, calories=3500))\", 'df = pd.DataFrame(df)', \"    return ['background-color: #FF0000' if i==len(s)-1 else '' for i in range(len(s))]\", 's = df.style.apply(highlight_last_row)']\n",
      "39358752 ['df = pd.DataFrame()', '    for k, cell in six.iteritems(mpl_table._cells):', '            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])']\n",
      "39358924 [\"df['A'], df['B'] = df['AB'].str.split(' ', 1).str\", \"df['AB'].str.split(' ', 1, expand=True)\", \"df = pd.DataFrame({'AB': ['A1-B1', 'A2-B2']})\", \"df['AB_split'] = df['AB'].str.split('-')\", 'upper_lower_df = pd.DataFrame({\"U\": [\"A\", \"B\", \"C\"]})', 'upper_lower_df[\"L\"] = upper_lower_df[\"U\"].str.lower()', \"df['AB'].str.split('-', 1).str[0]\", \"df['AB'].str.split('-', 1).str[1]\", \"df['A'], df['B'] = df['AB'].str.split('-', 1).str\", \"df['AB'].str.split('-', 1, expand=True)\", \"df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))\"]\n",
      "39363715 [\"df_ = pd.cut(df[['A', 'B']].stack(), 5, labels=list(range(5))).unstack()\", \"df_.columns = df_.columns.to_series() + 'bkt'\", 'pd.concat([df, df_], axis=1)', 'df = pd.DataFrame(dict(A=(np.random.randn(10000) * 100 + 20).astype(int),', '                       B=(np.random.randn(10000) * 100 - 20).astype(int)))', \"df.index = df.index.to_series().astype(str).radd('city')\", \"df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()\", \"df_.columns = df_.columns.to_series() + 'bkt'\", 'df = pd.DataFrame(data, columns=[\"A\", \"B\"])', \"df.index = df.index.to_series().astype(str).radd('city')\", \"df_ = pd.cut(df[['A', 'B']].stack(), 30, labels=list(range(30))).unstack()\", \"df_.columns = df_.columns.to_series() + 'bkt'\", \"df = pd.DataFrame(data, columns=list('ABCDE'))\", \"df.index = df.index.to_series().astype(str).radd('city')\", 'df_ = pd.cut(df.stack(), b, labels=list(range(b))).unstack()', '    return CustomJS(args=dict(source=source), code=code.format(like, n))']\n",
      "39366792 ['dat1 = pd.concat([dat1, dat2], axis=1)']\n",
      "39370553 []\n",
      "39371897 []\n",
      "39377643 []\n",
      "39405540 [\"mydf = mydf.reindex( mydf.columns.tolist() + ['newcol1','newcol2'])  # version >= 0.20.0\", \"mydf = mydf.reindex( mydf.columns.values + ['newcol1','newcol2'])  # version < 0.20.0\"]\n",
      "39474812 [\"df.apply(lambda r : pd.datetime.combine(r['date_column_name'],r['time_column_name']),1)\"]\n",
      "39478896 [\"df = pandas.read_csv('somefile.txt')\", 'df = df.fillna(0)']\n",
      "39482402 []\n",
      "39563662 ['pd.read_json(jsonfile, lines=True)']\n",
      "39621872 [\"df=pd.DataFrame({'A':np.random.rand(2)-1,'B':np.random.rand(2)},index=['val1','val2'] )\", \"ax = df.plot(kind='bar', color=['r','b']) \", '    val = \"{:+.2f}\".format(b.y1 + b.y0)        ']\n",
      "39628860 ['df2 = df.copy()']\n",
      "39634150 ['df_row_merged = pd.concat([df_a, df_b], ignore_index=True)', 'df_col_merged =pd.concat([df_a, df_b], axis=1)']\n",
      "39657077 ['df.columns = [col_dict.get(x, x) for x in df.columns]', \"df.rename(columns={'gdp':'log(gdp)'}, inplace=True)\"]\n",
      "39673666 []\n",
      "39762850 []\n",
      "39770407 []\n",
      "39820329 [\"df = df[df[['col_1','col_2']].apply(lambda x: f(*x), axis=1)]\"]\n",
      "39830464 [\"df = pd.read_csv(StringIO(data), dtype='category')\"]\n",
      "39837358 []\n",
      "39891994 [\"df['column']=df['column'].fillna(value)\"]\n",
      "39923958 ['print(df.to_string())']\n",
      "39946744 ['    df = df.dropna(subset=[column])', '    for i, presplit in enumerate(df[column].astype(str)):', '        values = presplit.split(sep)', '        if keep and len(values) > 1:', '            indexes.append(i)', '            new_values.append(presplit)', '            indexes.append(i)', '            new_values.append(value)', '    new_df = df.iloc[indexes, :].copy()']\n",
      "40005797 ['df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv\")', 'df.head()', \"df['single_input_vector'] = df[input_cols].apply(tuple, axis=1).apply(list)\", \"df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\", \"df['cumulative_input_vectors'] = df.single_input_vector.cumsum()\", \"df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)\", 'max_sequence_length = df.cumulative_input_vectors.apply(len).max()', 'padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()', \"df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)\", 'X_train = np.hstack(X_train_init).reshape(len(df),max_sequence_length,len(input_cols))', 'y_train = np.hstack(np.asarray(df.output_vector)).reshape(len(df),len(output_cols))', 'output_dim = len(y_train[0])', 'model.add(LSTM(4, input_dim = input_dim, input_length = input_length))', \"model.add(Dense(output_dim, activation='relu'))\"]\n",
      "40008322 [\"df.loc[:, df.columns.to_series().str.contains('a').tolist()]\"]\n",
      "40110335 []\n",
      "40145561 []\n",
      "40208359 ['df = pd.DataFrame([list(range(5))], columns=[\"a{}\".format(i) for i in range(5)])']\n",
      "40209737 [\"df.rolling(5,min_periods=5).sum().dropna().resample('3D').first()\"]\n",
      "40214434 ['df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,1,2,2]})', \"quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\", \"quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\", \"df = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])\"]\n",
      "40225796 [\"df.columns = pd.MultiIndex.from_product([df.columns, ['C']])\"]\n",
      "40228738 ['corr = dataframe.corr()']\n",
      "40429755 [\"s = pd.Series(list('abc'))\", \"s.isin(['a'])\", \"s[s.isin(['a'])].empty\", \"s[s.isin(['z'])].empty\", \"df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\", \"df.isin({'A': [1, 3], 'B': [4, 7, 12]})\"]\n",
      "40435354 ['df = df.loc[:,~df.columns.duplicated()]']\n",
      "40442778 [\"df = df[df['closing_price'].between(99, 101, inclusive=True)]\"]\n",
      "40449726 ['    idx_cols = df.columns.difference(lst_cols)', '    lens = df[lst_cols[0]].str.len()', '    if (lens > 0).all():', '        return pd.DataFrame({', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        return pd.DataFrame({', '            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())', '            for col in idx_cols', '        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\\', '          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\\', \"explode(df.assign(var1=df.var1.str.split(',')), 'var1')\", \"df.assign(var1=df.var1.str.split(','))\", \"x = df.assign(**{lst_col:df[lst_col].str.split(',')})\"]\n",
      "40501868 []\n",
      "40535454 ['    df.to_excel(writer, sheet_name=sheetname)  # send df to writer', '        max_len = max((', '            series.astype(str).map(len).max(),  # len of largest item', '            len(str(series.name))  # len of column name/header']\n",
      "40593226 [\"pd.crosstab(df.A,df.B, normalize='index')\"]\n",
      "40629420 [\"df.sort_values('count', ascending=False).drop_duplicates(['Sp','Mt'])\"]\n",
      "40679977 []\n",
      "40746465 [\"df.to_sql('temp_table', engine, if_exists='replace')\"]\n",
      "40762674 ['df.merge(s.to_frame(), left_index=True, right_index=True)']\n",
      "40770463 ['GB=DF.groupby([(DF.index.year),(DF.index.month)]).sum()', \"GB.plot('abc','xyz',kind='scatter')\"]\n",
      "40817489 [\"df.query('3.3 <= A <= 6.6') # for closed interval                       \", \"df.query('3.3 < A < 6.6') # for open interval                         \", \"df.query('2.0 <= A <= 4.0')                                        \", \"df.query('111 <= B <= 500')                                        \", \"df.query('0 < A < 4 and 150 < B < 400')                            \"]\n",
      "40818627 ['DataFrame.replace(', \"df['BrandName'].replace(\"]\n",
      "40834052 [\"df_filtered = df.query('a == 4 & b != 2')\"]\n",
      "40872584 [\"grpd = df.groupby(['A','B']).size().to_frame('size')\"]\n",
      "40943143 ['df = df.to_frame().reset_index()', \"df = df.rename(columns= {0: 'list'})\"]\n",
      "40962126 [\"df = pd.DataFrame({'A' : list('wwwwxxxx'), \", \"df.groupby(['A', 'B']).agg({'C':['mean', 'median'], 'D':'max'})\", \"df.groupby(['A', 'B']).agg({'C':{'C_mean': 'mean', 'C_median': 'median'}, \"]\n",
      "41022840 []\n",
      "41150420 []\n",
      "41173392 []\n",
      "41191127 ['idx = np.where(~mask,np.arange(mask.shape[1]),0)']\n",
      "41191278 [\"df.groupby('id')['x'].rolling(2).mean()\", \"df.groupby('id')['x'].apply(pd.rolling_mean, 2, min_periods=1)\", \"df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)\", \"df['x'] = df.groupby('id')['x'].rolling(2).mean().reset_index(0,drop=True)\"]\n",
      "41210491 ['out, bins  = pd.cut(s, bins=bin_range, include_lowest=True, right=False, retbins=True)', 'out.value_counts(sort=False).plot.bar()', 'out.value_counts().head()', 'out.value_counts(sort=False).plot.bar()']\n",
      "41218519 []\n",
      "41226605 [\"data = pd.read_json('/path/to/file.json', lines=True)\"]\n",
      "41228272 [\"df['deltaT'] = df.index.to_series().diff().dt.seconds.div(60, fill_value=0)\", 'ser_diff = df.index.to_series().diff()', 'ser_diff.dt.seconds.div(60, fill_value=0)', 'ser_diff.dt.total_seconds().div(60, fill_value=0)']\n",
      "41228807 [\"s = pd.Series(pd.timedelta_range(start='1 days', end='12 days', freq='3000T'))\"]\n",
      "41452422 []\n",
      "41464194 ['    rng = np.arange(len(a))', '    edge_left = a.searchsorted(a - dleft)', \"    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])\", '    return (starts & ends).cumsum()', '    s = a.argsort()', '        y = np.empty(s.size, dtype=np.int64)', '        y = s.argsort()', '    rng = np.arange(len(a))', '    edge_left = a.searchsorted(a - dleft)', \"    edge_right = np.append(0, a.searchsorted(a + dright, side='right')[:-1])\", '    return (starts & ends).cumsum()[y]', 'print(delta_cluster(b, 2, 1)[b.argsort()])']\n",
      "41517319 []\n",
      "41529411 [\"newDF = pd.DataFrame() #creates a new dataframe that's empty\", 'newDF = newDF.append(oldDF, ignore_index = True) # ignoring index is optional']\n",
      "41532180 ['normalized_df=(df-df.mean())/df.std()', 'normalized_df=(df-df.min())/(df.max()-df.min())']\n",
      "41554866 [\"sum(pd.isnull(df1['col1']))\"]\n",
      "41607207 []\n",
      "41629653 [\"df = pd.DataFrame(np.random.randn(3, 2), columns=['A','B'])\"]\n",
      "41678874 [\"df['col1'].map(di)\", \"df['col1'].update( df['col1'].map(di) )   # note: series update is an inplace operation\", \"df = pd.DataFrame({ 'col1': np.random.choice( range(1,9), 100000 ) })\"]\n",
      "41786821 [\"df[df.duplicated(['ID'], keep=False)]\"]\n",
      "41802199 ['df = pd.DataFrame(np.random.random((30, 3)))', \"df['date'] = pd.date_range('2017-1-1', periods=30, freq='D')\", 'in_range_df = df[df[\"date\"].isin(pd.date_range(\"2017-01-15\", \"2017-01-20\"))]']\n",
      "41816244 [\"df.select_dtypes(include=['float64']).apply(your_function)\", \"df.select_dtypes(exclude=['string','object']).apply(your_other_function)\"]\n",
      "41845355 [\"df[(df['date']>datetime.date(2016,1,1)) & (df['date']<datetime.date(2016,3,1))]  \"]\n",
      "41876593 ['df = pd.DataFrame(data)', \"print(df.filter(like='spike').columns)\", \"print(df.filter(regex='spike|spke').columns)\"]\n",
      "41880513 ['c=pd.read_csv(url)']\n",
      "41890871 ['    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '    skew = pd.DataFrame(v2.T.dot(v1) / s2.T.dot(s1) / m, df.columns, df.columns)', 'df.skew()', '    s1 = sigma = v.std(0, keepdims=True)', '    means = v.mean(0, keepdims=True)', '        kurt = pd.DataFrame(v3.T.dot(v1) / s3.T.dot(s1) / m, df.columns, df.columns)', '        kurt = pd.DataFrame(v2.T.dot(v2) / s2.T.dot(s2) / m, df.columns, df.columns)']\n",
      "41929910 [\"df = df.groupby(['from','to']).datetime\", \"df = df.join(df.groupby(['from','to'])\", '               .apply(lambda x: x.sort_values().diff().dt.seconds // 60)']\n",
      "41929939 [\"result = df.sort_values(['from','to','datetime'])\\\\\"]\n",
      "41929958 ['df.assign(', '    timediff=df.sort_values(']\n",
      "42094658 [\"pd.concat([df], keys=['Foo'], names=['Firstlevel'])\"]\n",
      "42133330 []\n",
      "42180357 ['data_file = pd.read_excel(\\'path_to_file.xls\\', sheetname=\"sheet_name\")']\n",
      "42247228 []\n",
      "42293737 [\"pd.set_option('display.max_columns', None)  \"]\n",
      "42305299 ['        self.n = float(len(self.a))', \"        adx = np.searchsorted(self.a, score_list, side='right')\", '            pct.append( (float(idx) / self.n) * 100.0 )']\n",
      "42335527 []\n",
      "42392805 []\n",
      "42401977 ['    return pd.read_excel(filename)', \"    df_list = pool.map(reader, file_list) #creates a list of the loaded df's\", \"    df = pd.concat(df_list) # concatenates all the df's into a single df\"]\n",
      "42426751 ['    df', '                    \"date\": lambda x: \"{:%m/%d/%Y}\".format(pd.to_datetime(x, unit=\"D\"))']\n",
      "42476224 []\n",
      "42516230 ['df = pd.DataFrame(np.random.randint(4, size=(5,1)))', 'print ((df[0] == 0).idxmax())', 'df.loc[(df[0] == 0).idxmax(), 0] = 100', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])', 'df = df.reset_index()', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', \"df = df.set_index('index')\", 'df = pd.DataFrame(np.random.randint(4, size=(5,1)), index=[1,2,2,3,4])', 'df.index = [np.arange(len(df.index)), df.index]', 'df.loc[(df[0] == 3).idxmax(), 0] = 200', 'df = df.reset_index(level=0, drop=True)', 'df = pd.DataFrame([4,0,4,7,4], index=[1,2,2,3,4])', 'mask = (df[0] == 0).cumsum().cumsum()']\n",
      "42545576 ['        b[i,j] += a[:,i,j].sum()']\n",
      "42550516 [\"df = pd.DataFrame( {'a':np.random.randint(0,60,600), 'b':[1,2,5,5,4,6]*100})\", \"         keys,values=df.sort_values('a').values.T\", '         ukeys,index=np.unique(keys,True)', '         arrays=np.split(values,index[1:])', \"         df2=pd.DataFrame({'a':ukeys,'b':[list(a) for a in arrays]})\"]\n",
      "42652112 [\"df1 = pd.read_table(DF1, sep='\\\\s+')\", \"df2 = pd.read_table(DF2, sep='\\\\s+')\", 'df=pd.concat(dfs_dictionary)', 'df.drop_duplicates(keep=False)']\n",
      "42796283 ['presidents = pd.DataFrame({\"name\": [\"Bush\", \"Obama\", \"Trump\"],', \"terms = pd.DataFrame({'start_date': pd.date_range('2001-01-20', periods=5, freq='48M'),\", \"                      'end_date': pd.date_range('2005-01-21', periods=5, freq='48M'),\", 'war_declarations = pd.DataFrame({\"date\": [datetime(2001, 9, 14), datetime(2003, 3, 3)],', \"terms.to_sql('terms', conn, index=False)\", \"presidents.to_sql('presidents', conn, index=False)\", \"war_declarations.to_sql('wars', conn, index=False)\", 'df = pd.read_sql_query(qry, conn)']\n",
      "42837693 ['df = df.append({']\n",
      "42874900 []\n",
      "42879831 []\n",
      "42932524 []\n",
      "42965916 [\"color_labels = df['color'].unique()\", \"plt.scatter(df['carat'], df['price'], c=df['color'].map(color_map))\"]\n",
      "42977946 ['corr = dataframe.corr()']\n",
      "42978156 []\n",
      "43093390 ['q = df[\"col\"].quantile(0.99)']\n",
      "43180437 [\"df['protected'] = pd.Series(['no', 'no', 'no', 'yes'])\", \"df['protected'] = pd.Series(['no', 'no', 'no', 'yes']).values\", \"df['protected'] = list(pd.Series(['no', 'no', 'no', 'yes']))\", \"df['protected'] = pd.Series(['no', 'no', 'no', 'yes'], index=df.index)\", \"protected_series = pd.Series(['no', 'no', 'no', 'yes'])\", 'df.reset_index(drop=True)', 'protected_series.reset_index(drop=True)', \"df.assign(protected=pd.Series(['no', 'no', 'no', 'yes']))\"]\n",
      "43190411 []\n",
      "43289220 ['data_df = pd.DataFrame(columns = data_columns)', 'df_temp = pd.DataFrame([[wheel_number, car_name, minutes_spent]],columns = data_columns)', 'data_df = data_df.append(df_temp, ignore_index=True) ']\n",
      "43421391 ['df_sliced = df.take(list(indexes_to_keep))']\n",
      "43547088 ['df = pd.DataFrame(np.random.rand(6, 4),', \"                 columns=pd.Index(['A', 'B', 'C', 'D'],\", \"ax = df.plot(kind='bar',figsize=(10,4), rot = 0)\", 'rects_locs = map(lambda x: x.get_x() +x.get_width()/2., ax.patches)', 'new_ticks = reduce(lambda x, y: x + y, map(lambda x: [x] * df.shape[0], df.columns.tolist()))']\n",
      "43547282 ['df = pd.DataFrame(np.random.rand(6, 4),', \"                 columns=pd.Index(['A', 'B', 'C', 'D'], \", \"df.plot(kind='bar',figsize=(10,4))\", '    pos.append(bar.get_x()+bar.get_width()/2.)', 'for i in range(len(pos)):', '    l = df.columns.values[i//len(df.index.values)]', '    lab.append(l)']\n",
      "43553043 ['df = pd.DataFrame(data.data, columns=data.feature_names)', 'df.head()']\n",
      "43559496 [\"x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])\", \"x = pd.DataFrame(list(zip(range(4), range(4))), columns=['a', 'b'])\", \"q = x.loc[:, 'a'].copy()\"]\n",
      "43577783 ['a_new, idx = np.unique(a_cummax, return_index=True)']\n",
      "43578010 []\n",
      "43578378 ['np.unique(aux, return_index=True)[1]']\n",
      "43578600 ['    a_new, idx = np.unique(a_cummax, return_index=True)', '            a_new.append(a)', '            idx.append(i)']\n",
      "43665978 ['    df = pd.DataFrame(np.random.randn(2 * 10 ** 7))', '    d1 = d1.copy()']\n",
      "43821531 [\"index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\", \"df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\", \"print (df.groupby(['second', 'A']).sum())\"]\n",
      "43896119 [\"df['month_year'] = df.date_column.dt.to_period('M')\"]\n",
      "43897124 [\"df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\", \"df.groupby('A').B.agg({'foo': 'count'})\", \"df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\", \"df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\", \"df.groupby('A').agg({'B': 'sum', 'C': 'min'}).rename(columns={'B': 'foo', 'C': 'bar'})\", \"(df.groupby('A')\", \"df.groupby('A').agg({'B': {'min': lambda x: x.min(), 'max': lambda x: x.max()}})\", \"df.groupby('A').agg({'B': [np.min, np.max]})\", \"df.groupby('A').agg({'B': [lambda x: x.min(), lambda x: x.max]})\"]\n",
      "43968774 [\"df.iloc[2, df.columns.get_loc('ColName')] = 3\", \"IBM.iat[2, IBM.columns.get_loc('PNL')] = 3\", \"df.set_value(df.index[2], 'ColName', 3)\", \"df.set_value(2, df.columns.get_loc('ColName'), 3, takable=True)\"]\n",
      "44123892 []\n",
      "44208076 ['c = count()']\n",
      "44208229 ['pd.Series(tups).factorize()[0]']\n",
      "44311454 []\n",
      "44724677 [\"df1.to_csv('file.csv', index=False)\", \"df2.to_csv('file.csv', mode='a', columns=False, index=False)\", \"df3.to_csv('file.csv', mode='a', columns=False, index=False)\", \"df = pd.read_csv('file.csv')\", \"df1.to_csv('file.csv', index=False)\", \"df2.to_csv('file1.csv', index=False)\", \"df3.to_csv('file2.csv', index=False)\", \"concat('file.csv', 'file1.csv')\", \"concat('file.csv', 'file2.csv')\", \"concat('file.csv', 'file3.csv')\", \"df = pd.read_csv('file.csv')\"]\n",
      "44736467 [\"df.loc[:, slice('quz',None, 2)]\"]\n",
      "44800142 ['df1.to_csv(filename)', \"df2.to_csv(filename, mode='a', columns=False)\", \"df3.to_csv(filename, mode='a', columns=False)\", 'df_concat = pd.read_csv(filename)']\n",
      "44913631 ['df = pd.DataFrame({\"A\":[0,1,0], \"B\":[2,0,5]}, columns=list(\\'AB\\'))']\n",
      "44948390 ['chunks = pd.read_csv(file, sep=\"/\", header=0, dtype=str, chunksize = 100000)', '    chunk.to_csv(\\'chunk_{}.csv\\'.format(it), sep=\"/\") ']\n",
      "44998387 ['[x for x in combinations(df.columns, 2) if (df[x[0]] == df[x[-1]]).all()]', 'cross = pd.DataFrame((dftv == dftv[:, None]).all(-1), cols, cols)', 's = cross.where(np.tri(*cross.shape, k=-1)).unstack()', 's[s == 1].index.tolist()']\n",
      "44999009 ['    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()', '    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))', '    sidx = view1D(a.T).argsort()', '    m = np.concatenate(([False], (b[:,1:] == b[:,:-1]).all(0), [False] ))', '    C = df.columns[sidx].tolist()']\n",
      "45013739 [\"    df.sort_values('id', inplace=True)\", \"    frame.to_csv('{}'.format(n))\", 'pool.join()']\n",
      "45193340 ['df.apply(lambda x: pd.Series(x.nsmallest(n).index))']\n",
      "45193636 ['a = np.argsort(-df.values, axis=0)[-3:]', 'b = pd.DataFrame(df.index[a][::-1], columns=df.columns)']\n",
      "45333133 ['pd.concat([d1, d2], axis=1)[list(interleave([d1, d2]))]']\n",
      "45333267 ['    N = (len(c1)+len(c2))', '    out = np.empty((d1.shape[0],N),dtype=out_dtype)', '    df_out = pd.DataFrame(out, columns=cols, index=d1.index)']\n",
      "45357725 [\"df = df.drop('your_column', axis=1)\", \"df = df.drop(['col_1','col_2','col_3'], axis=1)\"]\n",
      "45494714 ['df = pd.DataFrame(np.random.randint(10, size=(10, 3)))', 'df[np.array(lst).astype(bool)]']\n",
      "45494718 []\n",
      "45494808 ['df = pd.DataFrame(np.random.randint(10, size=(10, 3)))', 'df[list(map(bool, lst))]', 'results.div(results.min(1), 0).round(2).pipe(lambda d: d.assign(Best=d.idxmin(1)))', 'results.plot(loglog=True, lw=3, ax=a1)', 'results.div(results.min(1), 0).round(2).plot.bar(logy=True, ax=a2)', 'ayh = lambda d, l: d[np.array(l).astype(bool)]', 'pir = lambda d, l: d[list(map(bool, l))]', \"    return d.query('@a != 0')\", 'results = pd.DataFrame(', \"    columns='ayh wvo pir mxu wen'.split(),\", '    d = pd.concat([df] * i, ignore_index=True)', \"        stmt = '{}(d, l)'.format(j)\", \"        setp = 'from __main__ import d, l, {}'.format(j)\", '        results.set_value(i, j, timeit(stmt, setp, number=10))']\n",
      "45494910 ['df.query(\"index * @a > 0\")', 'df.query(\"@a != 0\")']\n",
      "45568211 []\n",
      "45741989 [\"    encoding = kwargs.pop('encoding', 'utf-8')\", \"    if encoding is not None and encoding.lower().replace('-', '') != 'utf8':\", \"                text, encoding=(kwargs.get('encoding') or\", \"                                get_option('display.encoding'))\", '            index_names = data.splitlines()[index_names_row].split()', \"            kwargs.update({'skiprows': skiprows})\", '    df = read_fwf(StringIO(data), **kwargs)', \"    unnamed_cols = df.columns[df.columns.str.contains(r'Unnamed:')].tolist()\", '        idx_cols = df.columns[range(len(index_names))].tolist()', '        idx_cols = df.columns[range(len(unnamed_cols))].tolist()', '        index_names = [None] * len(idx_cols)', '    df[idx_cols] = df[idx_cols].ffill()', '    df = df.set_index(idx_cols).rename_axis(index_names)']\n",
      "45871837 ['cum_r = (1 + r).cumprod()', 'cum_r = (1 + r).cumprod()', 't = (r.index.is_quarter_end / cum_r).cumsum()']\n"
     ]
    }
   ],
   "source": [
    "def H1(df):\n",
    "    \n",
    "    # Do not process questions\n",
    "    if df.PostTypeId == 1:\n",
    "        df['Solution'] = 'NA'\n",
    "    \n",
    "    else:\n",
    "        # Parse code and inspect the function\n",
    "        code_snippet = df[input_col]\n",
    "        tree = ast.parse(code_snippet)        \n",
    "        func_calls = get_func_calls(tree)\n",
    "\n",
    "        solution_lines = set()\n",
    "        for function, lineno in func_calls:   \n",
    "            # print(function)\n",
    "            tokens = function.split('.')\n",
    "            method_name = tokens[len(tokens)-1]\n",
    "            if lookUpAPIDocForContext(method_name):\n",
    "                # Use a set to not add the same line twice\n",
    "                solution_lines.add(lineno - 1)\n",
    "                \n",
    "        solution = []\n",
    "        snippet_per_line = code_snippet.split(os.linesep)\n",
    "        solution_lines = sorted(solution_lines)\n",
    "        for i in solution_lines:\n",
    "            solution.append(snippet_per_line[i])\n",
    "                \n",
    "                \n",
    "        #print(solution)\n",
    "        df['Solution'] = solution\n",
    "        #df['Solution'] = os.linesep.join(solution)\n",
    "    return df\n",
    "\n",
    "\n",
    "solution_df = processed_stackoverflow_df.apply(H1, axis=1)\n",
    "\n",
    "\n",
    "for index, row in solution_df.iterrows():\n",
    "    if row['Solution'] != 'NA':\n",
    "        print(row['Id'], row['Solution'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "solution_df.to_pickle(output_file)\n",
    "\n",
    "if debug:\n",
    "    solution_df.to_csv(output_file + \".csv\", encoding='ISO-8859-1', sep=\",\", doublequote=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
