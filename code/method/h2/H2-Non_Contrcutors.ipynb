{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luigi migration. Task yet to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PARS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-44f3659d427f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mapi_doc_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'api_doc_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/neelesh/Professional/GitRepository/IdentifySolution/snippet-optimization/jupyter_notebook.py\u001b[0m in \u001b[0;36mload_parameters\u001b[0;34m(environment_variable)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menvironment_variable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PARS'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from jupyter_notebook import load_parameters \n",
    "\n",
    "\n",
    "pars = load_parameters()\n",
    "\n",
    "api_doc_file = pars.get('api_doc_file')\n",
    "tagged_dataset_file = pars.get('tagged_dataset_file')\n",
    "so_dump_processed_file = pars.get('so_dump_processed_file')\n",
    "output_file = pars.get('output_file')\n",
    "\n",
    "debug = pars.get('debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility to extract method name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FunctionCallVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self._name = deque()\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return '.'.join(self._name)\n",
    "    \n",
    "    @name.deleter\n",
    "    def name(self):\n",
    "        self._name.clear()\n",
    "    \n",
    "    def visit_Name(self, node):\n",
    "        self._name.appendleft(node.id)\n",
    "    \n",
    "    def visit_Attribute(self, node):\n",
    "        try:\n",
    "            self._name.appendleft(node.attr)\n",
    "            self._name.appendleft(node.value.id)\n",
    "        except AttributeError:\n",
    "            self.generic_visit(node)\n",
    "            \n",
    "def get_func_calls(tree):\n",
    "    func_calls = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            callvisitor = FunctionCallVisitor()\n",
    "            callvisitor.visit(node.func)\n",
    "            func_calls.append(callvisitor.name)\n",
    "    return func_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load APIDoc and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in method buildTaggedDatasetDSForEvaluation cannot convert float NaN to integer\n"
     ]
    }
   ],
   "source": [
    "api_doc_file = '../../data-import/build_api_doc_base/api_doc.csv'\n",
    "tagged_dataset_file = '../../../data/stack-overflow/Dataset - Pandas.csv'\n",
    "so_dump_processed_file = '../../../data/stack-overflow/pandas-preprocessedcode-dataset-part3'\n",
    "\n",
    "api_df = pd.read_csv(api_doc_file, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "tagged_dataset_df = pd.read_csv(tagged_dataset_file, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "processed_stackoverflow_df = pd.read_pickle(so_dump_processed_file)\n",
    "\n",
    "def buildAPIDictionary(api_df):\n",
    "    api_dict = dict()\n",
    "    try:\n",
    "        \n",
    "        for index, row in api_df.iterrows():\n",
    "            methodContext = row['SubCategory']\n",
    "            #tokens = row['FullyQualifiedName'].split('.')\n",
    "        \n",
    "            #for token in tokens:\n",
    "               #methodContext = str(methodContext)+' '+token\n",
    "            api_dict[row['MethodName']] = methodContext\n",
    "    except Exception as e:\n",
    "        print('Error in method buildAPIDictionary',e)\n",
    "    return api_dict\n",
    "        \n",
    "\n",
    "def buildTaggedDatasetDSForEvaluation(tagged_dataset_df):\n",
    "    dataset_dict = dict()\n",
    "    total_solutions = 0\n",
    "    try:    \n",
    "        for idx, row in tagged_dataset_df.iterrows():\n",
    "            answerId = row['AnswerId']\n",
    "            if answerId != 0:\n",
    "                total_solutions = total_solutions +1\n",
    "                tup = (int(row['SolutionId']), row['Solution'])\n",
    "                if answerId in dataset_dict:\n",
    "                    ls = dataset_dict[answerId]\n",
    "                    ls.append(tup)\n",
    "                    dataset_dict[answerId] = ls\n",
    "                else:\n",
    "                    ls = list()\n",
    "                    ls.append(tup)\n",
    "                    dataset_dict[answerId] = ls\n",
    "    except Exception as e:\n",
    "        print('Error in method buildTaggedDatasetDSForEvaluation',e)\n",
    "        \n",
    "    return dataset_dict, total_solutions\n",
    "\n",
    "def buildStackOverflowDumpDict(processed_stackoverflow_df):\n",
    "    stackoverflow_dict = dict()\n",
    "    try:\n",
    "        for idx, row in processed_stackoverflow_df.iterrows():\n",
    "            postTypeId = row['PostTypeId']\n",
    "            if postTypeId == 2:\n",
    "                answerId = row['Id']\n",
    "                stackoverflow_dict[answerId] = row['PreprocessedCode']\n",
    "    except Exception as e:\n",
    "        print('Error in method buildStackOverflowDumpDict', e)\n",
    "    return stackoverflow_dict\n",
    "    \n",
    "api_dict = buildAPIDictionary(api_df)\n",
    "tagged_dataset_dict, total_solutions = buildTaggedDatasetDSForEvaluation(tagged_dataset_df)\n",
    "stackoverflow_dict = buildStackOverflowDumpDict(processed_stackoverflow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpAPIDocForContextH2(method_name):\n",
    "    try:\n",
    "        if method_name in api_dict.keys() and api_dict[method_name] == \"Constructor\":\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print('Error in method lookUpAPIDocForContext', e)\n",
    "        \n",
    "        \n",
    "def lookUpAPIDocForContextH1H2(method_name):\n",
    "    try:\n",
    "        if method_name in api_dict.keys():\n",
    "            if api_dict[method_name] == \"Constructor\":\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print('Error in method lookUpAPIDocForContext', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyH2():\n",
    "    df_columns = ['ansId', 'line', 'actual','predicted']\n",
    "    result_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    df_row_id = 0\n",
    "\n",
    "\n",
    "    for key in tagged_dataset_dict.keys():\n",
    "        try:            \n",
    "            solutionList = tagged_dataset_dict[key]\n",
    "            content = str(stackoverflow_dict[key])\n",
    "            lines = content.split(os.linesep)\n",
    "            for line in lines:\n",
    "                actualSolution = False\n",
    "                predictedSolution = False\n",
    "                for tup in solutionList:\n",
    "                    if tup[1].strip() == line.strip():\n",
    "                        actualSolution = True\n",
    "                \n",
    "                tree = ast.parse(line)\n",
    "                \n",
    "                func_calls = get_func_calls(tree)\n",
    "                \n",
    "                for func_call in func_calls:\n",
    "                    tokens = func_call.split('.')\n",
    "                    method_name = tokens[len(tokens)-1]\n",
    "                    if lookUpAPIDocForContextH2(method_name):\n",
    "                        predictedSolution = True\n",
    "                        break\n",
    "                result_df.loc[df_row_id] = [key,line, actualSolution, predictedSolution]\n",
    "                df_row_id = df_row_id + 1\n",
    "        except Exception as e:\n",
    "            print('Error in method evaluate', e)\n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 41386927\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 39923012\n",
      "Error in method evaluate 37787724\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 46526249\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n"
     ]
    }
   ],
   "source": [
    "result_df = applyH2()\n",
    "output_file = '../../../data/results/result_df_h2'\n",
    "debug = True\n",
    "\n",
    "result_df.to_pickle(output_file)\n",
    "\n",
    "if debug:\n",
    "    result_df.to_csv(output_file + \".csv\", encoding='ISO-8859-1', sep=\",\", doublequote=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyH1H2():\n",
    "    df_columns = ['ansId', 'line', 'actual','predicted']\n",
    "    result_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    df_row_id = 0\n",
    "\n",
    "\n",
    "    for key in tagged_dataset_dict.keys():\n",
    "        try:            \n",
    "            solutionList = tagged_dataset_dict[key]\n",
    "            content = str(stackoverflow_dict[key])\n",
    "            lines = content.split(os.linesep)\n",
    "            for line in lines:\n",
    "                actualSolution = False\n",
    "                predictedSolution = False\n",
    "                for tup in solutionList:\n",
    "                    if tup[1].strip() == line.strip():\n",
    "                        actualSolution = True\n",
    "                \n",
    "                tree = ast.parse(line)\n",
    "                \n",
    "                func_calls = get_func_calls(tree)\n",
    "                \n",
    "                for func_call in func_calls:\n",
    "                    tokens = func_call.split('.')\n",
    "                    method_name = tokens[len(tokens)-1]\n",
    "                    if lookUpAPIDocForContextH1H2(method_name):\n",
    "                        predictedSolution = True\n",
    "                        break\n",
    "                result_df.loc[df_row_id] = [key,line, actualSolution, predictedSolution]\n",
    "                df_row_id = df_row_id + 1\n",
    "        except Exception as e:\n",
    "            print('Error in method evaluate', e)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 41386927\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 39923012\n",
      "Error in method evaluate 37787724\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate unexpected EOF while parsing (<unknown>, line 1)\n",
      "Error in method evaluate unexpected indent (<unknown>, line 1)\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n",
      "Error in method evaluate 46526249\n",
      "Error in method evaluate invalid syntax (<unknown>, line 1)\n"
     ]
    }
   ],
   "source": [
    "result_df = applyH1H2()\n",
    "output_file = '../../../data/results/result_df_h1h2'\n",
    "debug = True\n",
    "\n",
    "result_df.to_pickle(output_file)\n",
    "\n",
    "if debug:\n",
    "    result_df.to_csv(output_file + \".csv\", encoding='ISO-8859-1', sep=\",\", doublequote=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
