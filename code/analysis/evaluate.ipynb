{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luigi Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PARS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f782600511bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_notebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/neelesh/Professional/GitRepository/IdentifySolution/snippet-optimization/jupyter_notebook.py\u001b[0m in \u001b[0;36mload_parameters\u001b[0;34m(environment_variable)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menvironment_variable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PARS'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from jupyter_notebook import load_parameters \n",
    "\n",
    "pars = load_parameters()\n",
    "\n",
    "input_file = pars.get('input')\n",
    "output_file = pars.get('output')\n",
    "\n",
    "# Dealing with multiple outputs\n",
    "\n",
    "dataset = pars.get('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Code</th>\n",
       "      <th>PreprocessedCode</th>\n",
       "      <th>PreprocessedCode2</th>\n",
       "      <th>PreprocessedCode3</th>\n",
       "      <th>Solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7779260.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;p&gt;When I try to merge two dataframes by rows ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-15T08:21:17.460</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>append two data frame with pandas</td>\n",
       "      <td>25479.0</td>\n",
       "      <td>bigdata = data1.append(data2)\\nException: Inde...</td>\n",
       "      <td>bigdata = data1.append(data2)\\nException: Inde...</td>\n",
       "      <td>bigdata = data1.append(data2)\\nException: Inde...</td>\n",
       "      <td>bigdata = data1.append(data2)</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>11617194.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>&lt;p&gt;I want to perform my own complex operations...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-20T14:46:14.633</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>&lt;python&gt;&lt;performance&gt;&lt;for-loop&gt;&lt;pandas&gt;</td>\n",
       "      <td>What is the most efficient way to loop through...</td>\n",
       "      <td>195364.0</td>\n",
       "      <td>Date,Open,High,Low,Close,Volume,Adj Close\\n201...</td>\n",
       "      <td>Date,Open,High,Low,Close,Volume,Adj Close\\n201...</td>\n",
       "      <td>Date,Open,High,Low,Close,Volume,Adj Close\\n201...</td>\n",
       "      <td>2011-10-19,27.37,27.47,27.01,27.13,42880000,27...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>8916746.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;p&gt;I have a dataframe &lt;code&gt;df&lt;/code&gt; in panda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-18T19:41:27.017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;python&gt;&lt;csv&gt;&lt;numpy&gt;&lt;tab-delimited&gt;&lt;pandas&gt;</td>\n",
       "      <td>selecting across multiple columns with python ...</td>\n",
       "      <td>19805.0</td>\n",
       "      <td>df_greater_than10 = df[df[\"colA\"] &gt; 10]\\n</td>\n",
       "      <td>df_greater_than10 = df[df[\"colA\"] &gt; 10]\\n</td>\n",
       "      <td>df_greater_than10 = df[df[\"colA\"] &gt; 10]\\n</td>\n",
       "      <td>df_greater_than10 = df[df[\"colA\"] &gt; 10]</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>8997908.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;p&gt;I recently came across the &lt;a href=\"http://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-24T17:59:53.850</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>&lt;python&gt;&lt;r&gt;&lt;join&gt;&lt;data.table&gt;&lt;pandas&gt;</td>\n",
       "      <td>Why are pandas merges in python faster than da...</td>\n",
       "      <td>16173.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>9557319.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>&lt;p&gt;I used Enthought's python distribution as a...</td>\n",
       "      <td>2013-12-04T20:55:59.357</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-03-04T14:25:36.287</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;python&gt;&lt;numpy&gt;&lt;scipy&gt;&lt;enthought&gt;&lt;pandas&gt;</td>\n",
       "      <td>Open source Enthought Python alternative</td>\n",
       "      <td>6585.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  AcceptedAnswerId  AnswerCount  \\\n",
       "0          27            27         7779260.0          2.0   \n",
       "1          31            31        11617194.0          7.0   \n",
       "2          49            49         8916746.0          2.0   \n",
       "3          54            54         8997908.0          3.0   \n",
       "4          73            73         9557319.0          8.0   \n",
       "\n",
       "                                                Body               ClosedDate  \\\n",
       "0  <p>When I try to merge two dataframes by rows ...                      NaN   \n",
       "1  <p>I want to perform my own complex operations...                      NaN   \n",
       "2  <p>I have a dataframe <code>df</code> in panda...                      NaN   \n",
       "3  <p>I recently came across the <a href=\"http://...                      NaN   \n",
       "4  <p>I used Enthought's python distribution as a...  2013-12-04T20:55:59.357   \n",
       "\n",
       "   CommentCount CommunityOwnedDate             CreationDate  FavoriteCount  \\\n",
       "0             7                NaN  2011-10-15T08:21:17.460            4.0   \n",
       "1             3                NaN  2011-10-20T14:46:14.633          108.0   \n",
       "2             0                NaN  2012-01-18T19:41:27.017           12.0   \n",
       "3            16                NaN  2012-01-24T17:59:53.850           58.0   \n",
       "4             5                NaN  2012-03-04T14:25:36.287            6.0   \n",
       "\n",
       "     ...     PostTypeId Score                                         Tags  \\\n",
       "0    ...              1    25                             <python><pandas>   \n",
       "1    ...              1   187      <python><performance><for-loop><pandas>   \n",
       "2    ...              1    26  <python><csv><numpy><tab-delimited><pandas>   \n",
       "3    ...              1   134        <python><r><join><data.table><pandas>   \n",
       "4    ...              1    19    <python><numpy><scipy><enthought><pandas>   \n",
       "\n",
       "                                               Title  ViewCount  \\\n",
       "0                  append two data frame with pandas    25479.0   \n",
       "1  What is the most efficient way to loop through...   195364.0   \n",
       "2  selecting across multiple columns with python ...    19805.0   \n",
       "3  Why are pandas merges in python faster than da...    16173.0   \n",
       "4           Open source Enthought Python alternative     6585.0   \n",
       "\n",
       "                                                Code  \\\n",
       "0  bigdata = data1.append(data2)\\nException: Inde...   \n",
       "1  Date,Open,High,Low,Close,Volume,Adj Close\\n201...   \n",
       "2          df_greater_than10 = df[df[\"colA\"] > 10]\\n   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                    PreprocessedCode  \\\n",
       "0  bigdata = data1.append(data2)\\nException: Inde...   \n",
       "1  Date,Open,High,Low,Close,Volume,Adj Close\\n201...   \n",
       "2          df_greater_than10 = df[df[\"colA\"] > 10]\\n   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                   PreprocessedCode2  \\\n",
       "0  bigdata = data1.append(data2)\\nException: Inde...   \n",
       "1  Date,Open,High,Low,Close,Volume,Adj Close\\n201...   \n",
       "2          df_greater_than10 = df[df[\"colA\"] > 10]\\n   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                   PreprocessedCode3  Solution  \n",
       "0                      bigdata = data1.append(data2)        NA  \n",
       "1  2011-10-19,27.37,27.47,27.01,27.13,42880000,27...        NA  \n",
       "2            df_greater_than10 = df[df[\"colA\"] > 10]        NA  \n",
       "3                                                           NA  \n",
       "4                                                           NA  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_file = '../../data/stack-overflow/pandas-solutioncode-h1'\n",
    "#output_file = '../../data/stack-overflow/result1.txt'\n",
    "#dataset = '../../data/stack-overflow/Dataset - Pandas.csv'\n",
    "#dataset = pd.read_csv(dataset, encoding='ISO-8859-1', error_bad_lines=False)\n",
    "\n",
    "result_df = pd.read_pickle(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTaggedDatasetDSForEvaluation(tagged_dataset_df):\n",
    "    taggedDSEvalDict = dict()\n",
    "    try:\n",
    "        for index, row in tagged_dataset_df.iterrows():\n",
    "            Id = row['AnswerId']\n",
    "            if Id != 0:\n",
    "                \n",
    "                if Id in taggedDSEvalDict:\n",
    "                    solutionList = taggedDSEvalDict[Id]\n",
    "                else:\n",
    "                    solutionList = list()                    \n",
    "                lineList = list()\n",
    "                lines = row['Solution'].split('\\n')\n",
    "                for line in lines:\n",
    "                    if line.strip() != '':\n",
    "                        pair = [line, False]\n",
    "                        lineList.append(pair)\n",
    "                solutionList.append(lineList)\n",
    "                taggedDSEvalDict[Id]= solutionList\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return taggedDSEvalDict\n",
    "\n",
    "\n",
    "def buildResultSetForEvaluation(result_df):\n",
    "    resultSetDict = dict()\n",
    "    try:\n",
    "        for index, row in result_df.iterrows():\n",
    "            ansId = row['Id']\n",
    "            solutionLinesTuple = list()                    \n",
    "            predictedLines = row['Solution']\n",
    "            for line in predictedLines:\n",
    "                if line.strip() != '':\n",
    "                    pair = [line, False]\n",
    "                    solutionLinesTuple.append(pair)\n",
    "            resultSetDict[ansId]= solutionLinesTuple\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(ansId, e)\n",
    "    return resultSetDict\n",
    "\n",
    "def markTheLines(taggedDSEvalDict, resultSetDict):\n",
    "    for Id, pairs in resultSetDict.items():\n",
    "        try:\n",
    "            solutionList = taggedDSEvalDict[Id] # Error\n",
    "            for respair in pairs:\n",
    "                for solution in solutionList:\n",
    "                    for tagpair in solution:\n",
    "                        if tagpair[0].strip() == respair[0].strip():\n",
    "                            tagpair[1] = True\n",
    "                            respair[1] = True\n",
    "        except KeyError:\n",
    "            pass # Ignore it for now\n",
    "    return taggedDSEvalDict, resultSetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17841294 'float' object has no attribute 'split'\n",
      "0.7081625046589639\n"
     ]
    }
   ],
   "source": [
    "def evaluate(result_df):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    taggedDSEvalDict =  buildTaggedDatasetDSForEvaluation(dataset)\n",
    "    resultSetDict = buildResultSetForEvaluation(result_df)\n",
    "    taggedDSEvalDict, resultSetDict = markTheLines(taggedDSEvalDict, resultSetDict)\n",
    "    for Id, pairs in resultSetDict.items():\n",
    "        try:\n",
    "            MA = True\n",
    "            for pair in pairs:\n",
    "                MA = MA and pair[1]\n",
    "            if MA:\n",
    "                MP = False\n",
    "\n",
    "                solutions = taggedDSEvalDict[Id]\n",
    "                for solution in solutions:\n",
    "                    MPS = True\n",
    "                    for tagpair in solution:\n",
    "                        MPS = MPS and tagpair[1]\n",
    "                    MP = MP or MPS\n",
    "                if MP:\n",
    "                    TP = TP + 1\n",
    "                else:\n",
    "                    FP = FP + 1\n",
    "\n",
    "            else:\n",
    "                FP = FP + 1\n",
    "        except KeyError:\n",
    "            pass # Ignore it for now\n",
    "            \n",
    "    return float(TP)/(TP+FP)\n",
    "\n",
    "precision = evaluate(result_df)\n",
    "precision = precision * 100\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(output_file + '.txt', 'w') as f:\n",
    "    f.write('%.2f' % precision)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
