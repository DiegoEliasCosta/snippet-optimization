<h2>Note, there is a better answer (below) based on the latest Pandas</h2>

<p><a href="https://stackoverflow.com/a/34297689/1638871" title="This should be the accepted answer">This should be the accepted answer.</a></p>

<h2>My original answer, which is now outdated, kept for reference.</h2>

<p>A simple solution is to use <code>drop_duplicates</code></p>

<pre><code>df4 = df3.drop_duplicates(subset='rownum', keep='last')
</code></pre>

<p>For me, this operated quickly on large data sets.</p>

<p>This requires that 'rownum' be the column with duplicates.  In the modified example, 'rownum' has no duplicates, therefore nothing gets eliminated.  What we really want is to have the 'cols' be set to the index.  I've not found a way to tell drop_duplicates to only consider the index.</p>

<p>Here is a solution that adds the index as a dataframe column, drops duplicates on that, then removes the new column:</p>

<pre><code>df3 = df3.reset_index().drop_duplicates(subset='index', keep='last').set_index('index')
</code></pre>

<p>And if you want things back in the proper order, just call <code>sort</code> on the dataframe.</p>

<pre><code>df3 = df3.sort()
</code></pre>
