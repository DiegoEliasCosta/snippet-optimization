{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from jupyter_notebook import load_parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pars = load_parameters()\n",
    "\n",
    "input_file = pars.get('input')\n",
    "output_file = pars.get('output')\n",
    "\n",
    "input_col = pars.get('input_col')\n",
    "output_col = pars.get('output_col')\n",
    "\n",
    "debug = pars.get('debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process In-Out Terminal-Like Code\n",
    "The goal of this function is to remove tags related ot notebook or terminal-like codes\n",
    "\n",
    "Example:\n",
    "```python\n",
    "In [11]: df\n",
    "df.append()\n",
    "Out[11]: \n",
    "A B C D \n",
    "2000-01-03 -0.59885 -0.18141 -0.68828 -0.77572\n",
    "2000-01-04 0.83935 0.15993 0.95911 -1.12959\n",
    "\n",
    "In [12]: df[(df.values > 1.5).any(1)]\n",
    "Out[12]: \n",
    "A B C D \n",
    "2000-01-05 2.8021 -0.1086 -1.62114 -0.2017\n",
    "2000-01-06 0.7167 -0.2671 1.36029 1.7425\n",
    "```\n",
    "\n",
    "Should extract only:\n",
    "```python\n",
    "df\n",
    "df.append()\n",
    "df[(df.values > 1.5).any(1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Mixed In-Out and In-In Code\n",
    "\n",
    "``` python\n",
    "In [2]: st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
    "\n",
    "\n",
    "In [2]: st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
    "666.523324013\n",
    "\n",
    "In [3]: type(initialload)\n",
    "Out[3]: numpy.ndarray\n",
    "\n",
    "In [4]: initialload.shape\n",
    "\n",
    "Out[4]: (4809584,)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "terminal_out_in_regex = \"(Out\\[.+?\\]:.*?In \\[.+?\\]:)\"\n",
    "sequence_out = re.compile(terminal_out_in_regex, re.DOTALL)\n",
    "\n",
    "terminal_in_regex = \"(In \\[.+?\\]:)\"\n",
    "sequence_in = re.compile(terminal_in_regex, re.DOTALL)\n",
    "\n",
    "terminal_out_regex = \"(Out\\[.+?\\]: )\"\n",
    "\n",
    "def preprocessTerminalLikeCode(code):    \n",
    "    pure_code = re.sub(sequence_out, '', code)\n",
    "    pure_code = re.sub(sequence_in, '', pure_code)\n",
    "    return pure_code\n",
    "\n",
    "# def preprocessTerminalLikeCode(code):    \n",
    "#     pure_code = re.sub(terminal_out_regex, '', code)\n",
    "#     return pure_code\n",
    "    \n",
    "\n",
    "def preprocessCode(code):\n",
    "    # First Method for pre-processing\n",
    "    terminalLikeCode = preprocessTerminalLikeCode(code)\n",
    "    if terminalLikeCode:\n",
    "        code = ''.join(terminalLikeCode)\n",
    "    return code\n",
    "    \n",
    "def preprocessPost(post, col):\n",
    "    strcode = str(post[col])\n",
    "    # Get the list of codes\n",
    "    post[output_col] = preprocessCode(strcode)\n",
    "    return post\n",
    "\n",
    "processed_dataset = dataset.apply(preprocessPost, axis=1, args=(input_col,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
      "\n",
      "st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
      "\n",
      "type(initialload)\n",
      "numpy.ndarray\n",
      "\n",
      "initialload.shape\n",
      "\n",
      "(4809584,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text = \"\"\"\n",
    "# In [2]: st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
    "\n",
    "# In [2]: st_time = time.time(); initialload = sm.iolib.genfromdta(\"/home/myfile.dta\"); ed_time = time.time(); print (ed_time - st_time)\n",
    "\n",
    "# In [3]: type(initialload)\n",
    "# Out[3]: numpy.ndarray\n",
    "\n",
    "# In [4]: initialload.shape\n",
    "\n",
    "# Out[4]: (4809584,)\n",
    "# \"\"\"\n",
    "\n",
    "# print(text)\n",
    "\n",
    "# print(preprocessTerminalLikeCode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-064f247c1a83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'processed_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "processed_dataset.to_pickle(output_file)\n",
    "\n",
    "if debug:\n",
    "    processed_dataset.to_csv(output_file + \".csv\", encoding='ISO-8859-1', sep=\",\", doublequote=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
