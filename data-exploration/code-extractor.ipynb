{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "\n",
    "# QUESTION/ANSWER SCORE LIMIT\n",
    "QUESTION_SCORE = 20\n",
    "ANSWER_SCORE = 10\n",
    "\n",
    "\n",
    "file = os.path.join('..','data', 'pandas-post-dataset.csv')\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(file, encoding='ISO-8859-1', error_bad_lines=False, sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# For every question\n",
    "#index, row in df.iterrows()\n",
    "# for idx, q in high_level_questions.iterrows():\n",
    "#     print('Working on the question %s' % q.Id)\n",
    "#     # Extract every answer\n",
    "#     answers = all_posts[(all_posts.ParentId == q.Id) & (all_posts.Score > ANSWER_SCORE)]\n",
    "    \n",
    "\n",
    "#     # Filter the code in the answer by using the <code> tag\n",
    "#     unformatted_codes = []\n",
    "#     for idx, a in answers.iterrows():\n",
    "#         soup = BeautifulSoup(a['Body'], \"html.parser\")\n",
    "#         unformatted_codes.extend(soup.find_all('code'))\n",
    "    \n",
    "#     # Format from HTML to text\n",
    "#     codes = [i.get_text() for i in unformatted_codes]\n",
    "    \n",
    "#     # Write it to a file\n",
    "#     file = io.open(os.path.join('..', 'data', 'extracted-code',  str(q.Id)), 'a', encoding='ISO-8859-1')\n",
    "#     for code in codes:\n",
    "#         file.write(\"%s\\n\\n------------------------------------------------------------------\\n\\n\" % code)\n",
    "#     file.close()                  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df',\n",
       " 'pandas.read_table',\n",
       " 'colA',\n",
       " 'df_greater_than10 = df[df[\"\"colA\"\"] > 10]\\n',\n",
       " 'df',\n",
       " 'colA',\n",
       " 'colB']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"\"\"\n",
    "    <p>I have a dataframe <code>df</code> in pandas that was built using <code>pandas.read_table</code> from a csv file. The dataframe has several columns and it is indexed by one of the columns (which is unique, in that each row has a unique value for that column used for indexing.) </p>\n",
    "\n",
    "<p>How can I select rows of my dataframe based on a \"\"complex\"\" filter applied to multiple columns? I can easily select out the slice of the dataframe where column <code>colA</code> is greater than 10 for example:</p>\n",
    "\n",
    "<pre><code>df_greater_than10 = df[df[\"\"colA\"\"] &gt; 10]\n",
    "</code></pre>\n",
    "\n",
    "<p>But what if I wanted a filter like: select the slice of <code>df</code> where <em>any</em> of the columns are greater than 10? </p>\n",
    "\n",
    "<p>Or where the value for <code>colA</code> is greater than 10 but the value for <code>colB</code> is less than 5?</p>\n",
    "\n",
    "<p>How are these implemented in pandas?\n",
    "Thanks.</p>\n",
    "\"\"\"\n",
    "\n",
    "def extract_tagged_code(text, tag):\n",
    "    \n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    \n",
    "    # Get the tag\n",
    "    tagged = soup.find_all(tag)\n",
    "    \n",
    "    # Remove None Objects\n",
    "#     tagged = [x for x in tagged if x is not None]\n",
    "    \n",
    "    # Format from HTML to text\n",
    "    return [i.get_text() for i in tagged]\n",
    "\n",
    "extract_tagged_code(text3, 'pre')\n",
    "extract_tagged_code(text3, 'code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  AcceptedAnswerId  AnswerCount  \\\n",
      "0  27          27            7779260.0         2.0           \n",
      "1  31          31            11617194.0        7.0           \n",
      "2  49          49            8916746.0         2.0           \n",
      "3  54          54            8997908.0         3.0           \n",
      "4  80          80            9620832.0         2.0           \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Body  \\\n",
      "0  <p>When I try to merge two dataframes by rows doing:</p>\\n\\n<pre><code>bigdata = data1.append(data2)\\n</code></pre>\\n\\n<p>I get the following error:</p>\\n\\n<blockquote>\\n<pre><code>Exception: Index cannot contain duplicate values!\\n</code></pre>\\n</blockquote>\\n\\n<p>The index of the first data frame starts from 0 to 38 and the second one from 0 to 48. I didn't understand that I have to modify the index of one of the data frame before merging, but I don't know how to.</p>\\n\\n<p>Thank you.</p>\\n\\n<p>These are the two dataframes:</p>\\n\\n<p><code>data1</code>:</p>\\n\\n<pre><code>    meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n</code></pre>\\n\\n<p><code>data2</code>:</p>\\n\\n<pre><code>    meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n</code></pre>\\n\\n<p>the first column is the index</p>\\n                                                                                                                                                                                     \n",
      "1  <p>I want to perform my own complex operations on financial data in dataframes in a sequential manner.</p>\\n\\n<p>For example I am using the following MSFT CSV file taken from <a href=\"http://finance.yahoo.com/q/hp?s=MSFT\">Yahoo Finance</a>:</p>\\n\\n<pre><code>Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n</code></pre>\\n\\n<p>I then do the following:</p>\\n\\n<pre><code>#!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n</code></pre>\\n\\n<p>Is that the most efficient way? Given the focus on speed in pandas, I would assume there must be some special function to iterate through the  values in a manner that one also retrieves the index (possibly through a generator to be memory efficient)? <code>df.iteritems</code> unfortunately only iterates column by column.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "2  <p>I have a dataframe <code>df</code> in pandas that was built using <code>pandas.read_table</code> from a csv file. The dataframe has several columns and it is indexed by one of the columns (which is unique, in that each row has a unique value for that column used for indexing.) </p>\\n\\n<p>How can I select rows of my dataframe based on a \"complex\" filter applied to multiple columns? I can easily select out the slice of the dataframe where column <code>colA</code> is greater than 10 for example:</p>\\n\\n<pre><code>df_greater_than10 = df[df[\"colA\"] &gt; 10]\\n</code></pre>\\n\\n<p>But what if I wanted a filter like: select the slice of <code>df</code> where <em>any</em> of the columns are greater than 10? </p>\\n\\n<p>Or where the value for <code>colA</code> is greater than 10 but the value for <code>colB</code> is less than 5?</p>\\n\\n<p>How are these implemented in pandas?\\nThanks.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "3  <p>I recently came across the <a href=\"http://pandas.sourceforge.net/\" rel=\"noreferrer\">pandas</a> library for python, which according to <a href=\"http://wesmckinney.com/blog/some-pandas-database-join-merge-benchmarks-vs-r-basemerge/\" rel=\"noreferrer\">this benchmark</a> performs very fast in-memory merges.  It's even faster than the <a href=\"http://cran.r-project.org/web/packages/data.table/index.html\" rel=\"noreferrer\">data.table</a> package in R (my language of choice for analysis).</p>\\n\\n<p>Why is <code>pandas</code> so much faster than <code>data.table</code>?  Is it because of an inherent speed advantage python has over R, or is there some tradeoff I'm not aware of?  Is there a way to perform inner and outer joins in <code>data.table</code> without resorting to <code>merge(X, Y, all=FALSE)</code> and <code>merge(X, Y, all=TRUE)</code>?</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/0pCvh.png\" alt=\"Comparison\"></p>\\n\\n<p>Here's the <a href=\"https://github.com/wesm/pandas/blob/master/bench/bench_merge.R\" rel=\"noreferrer\">R code</a> and the <a href=\"https://github.com/wesm/pandas/blob/master/bench/bench_merge.py\" rel=\"noreferrer\">Python code</a> used to benchmark the various packages.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "4  <p>I stumbled across <a href=\"http://pandas.pydata.org/\" rel=\"noreferrer\">pandas</a> and it looks ideal for simple calculations that I'd like to do. I have a SAS background and was thinking it'd replace proc freq -- it looks like it'll scale to what I may want to do in the future. However, I just can't seem to get my head around a simple task (I'm not sure if I'm supposed to look at <code>pivot/crosstab/indexing</code> - whether I should have a <code>Panel</code> or <code>DataFrames</code> etc...). Could someone give me some pointers on how to do the following:</p>\\n\\n<p>I have two CSV files (one for year 2010, one for year 2011 - simple transactional data) - The columns are category and amount</p>\\n\\n<p>2010:</p>\\n\\n<pre><code>AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n</code></pre>\\n\\n<p>2011:</p>\\n\\n<pre><code>AB,500.00\\nAC,250.00\\nAX,900.00\\n</code></pre>\\n\\n<p>These are loaded into separate DataFrame objects.</p>\\n\\n<p>What I'd like to do is get the category, the sum of the category, and the frequency of the category, eg:</p>\\n\\n<p>2010:</p>\\n\\n<pre><code>AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n</code></pre>\\n\\n<p>2011:</p>\\n\\n<pre><code>AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n</code></pre>\\n\\n<p>I can't work out whether I should be using <code>pivot/crosstab/groupby/an index</code>\\netc... I can get either the sum or the frequency - I can't seem to get both... It gets a bit more complex because I would like to do it on a month by month basis, but I think if someone would be so kind to point me to the right technique/direction I'll be able to go from there.</p>\\n   \n",
      "\n",
      "  ClosedDate  CommentCount CommunityOwnedDate             CreationDate  \\\n",
      "0  NaN        7             NaN                2011-10-15T08:21:17.460   \n",
      "1  NaN        3             NaN                2011-10-20T14:46:14.633   \n",
      "2  NaN        0             NaN                2012-01-18T19:41:27.017   \n",
      "3  NaN        16            NaN                2012-01-24T17:59:53.850   \n",
      "4  NaN        2             NaN                2012-03-06T17:01:47.107   \n",
      "\n",
      "   FavoriteCount  \\\n",
      "0  4.0             \n",
      "1  108.0           \n",
      "2  12.0            \n",
      "3  58.0            \n",
      "4  5.0             \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                             ...                                                                                                                                                                                                                                                                                                                                                                                                                              \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n",
      "   OwnerUserId ParentId PostTypeId Score  \\\n",
      "0  601314.0    NaN       1          25     \n",
      "1  1005409.0   NaN       1          187    \n",
      "2  248237.0    NaN       1          26     \n",
      "3  345660.0    NaN       1          134    \n",
      "4  1252759.0   NaN       1          21     \n",
      "\n",
      "                                          Tags  \\\n",
      "0  <python><pandas>                              \n",
      "1  <python><performance><for-loop><pandas>       \n",
      "2  <python><csv><numpy><tab-delimited><pandas>   \n",
      "3  <python><r><join><data.table><pandas>         \n",
      "4  <python><pandas>                              \n",
      "\n",
      "                                                                    Title  \\\n",
      "0  append two data frame with pandas                                        \n",
      "1  What is the most efficient way to loop through dataframes with pandas?   \n",
      "2  selecting across multiple columns with python pandas?                    \n",
      "3  Why are pandas merges in python faster than data.table merges in R?      \n",
      "4  Simple cross-tabulation in pandas                                        \n",
      "\n",
      "   ViewCount  \\\n",
      "0  25479.0     \n",
      "1  195364.0    \n",
      "2  19805.0     \n",
      "3  16173.0     \n",
      "4  9493.0      \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     PreCode  \\\n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n, data1,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n, data2,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]   \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n, df.iteritems]                                                                                                                                                                                                                                                                                                                       \n",
      "2  [df, pandas.read_table, colA, df_greater_than10 = df[df[\"colA\"] > 10]\\n, df, colA, colB]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "3  [pandas, data.table, data.table, merge(X, Y, all=FALSE), merge(X, Y, all=TRUE)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "4  [pivot/crosstab/indexing, Panel, DataFrames, AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n, pivot/crosstab/groupby/an index]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Code  \\\n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]   \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n]                                                                                                                                                                                                                                                                                                                       \n",
      "2  [df_greater_than10 = df[df[\"colA\"] > 10]\\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "3  []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "4  [AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     AllCode  \n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n, data1,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n, data2,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]  \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n, df.iteritems]                                                                                                                                                                                                                                                                                                                      \n",
      "2  [df, pandas.read_table, colA, df_greater_than10 = df[df[\"colA\"] > 10]\\n, df, colA, colB]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "3  [pandas, data.table, data.table, merge(X, Y, all=FALSE), merge(X, Y, all=TRUE)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "4  [pivot/crosstab/indexing, Panel, DataFrames, AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n, pivot/crosstab/groupby/an index]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  AcceptedAnswerId  AnswerCount  \\\n",
      "0  27          27            7779260.0         2.0           \n",
      "1  31          31            11617194.0        7.0           \n",
      "2  49          49            8916746.0         2.0           \n",
      "3  54          54            8997908.0         3.0           \n",
      "4  80          80            9620832.0         2.0           \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Body  \\\n",
      "0  <p>When I try to merge two dataframes by rows doing:</p>\\n\\n<pre><code>bigdata = data1.append(data2)\\n</code></pre>\\n\\n<p>I get the following error:</p>\\n\\n<blockquote>\\n<pre><code>Exception: Index cannot contain duplicate values!\\n</code></pre>\\n</blockquote>\\n\\n<p>The index of the first data frame starts from 0 to 38 and the second one from 0 to 48. I didn't understand that I have to modify the index of one of the data frame before merging, but I don't know how to.</p>\\n\\n<p>Thank you.</p>\\n\\n<p>These are the two dataframes:</p>\\n\\n<p><code>data1</code>:</p>\\n\\n<pre><code>    meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n</code></pre>\\n\\n<p><code>data2</code>:</p>\\n\\n<pre><code>    meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n</code></pre>\\n\\n<p>the first column is the index</p>\\n                                                                                                                                                                                     \n",
      "1  <p>I want to perform my own complex operations on financial data in dataframes in a sequential manner.</p>\\n\\n<p>For example I am using the following MSFT CSV file taken from <a href=\"http://finance.yahoo.com/q/hp?s=MSFT\">Yahoo Finance</a>:</p>\\n\\n<pre><code>Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n</code></pre>\\n\\n<p>I then do the following:</p>\\n\\n<pre><code>#!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n</code></pre>\\n\\n<p>Is that the most efficient way? Given the focus on speed in pandas, I would assume there must be some special function to iterate through the  values in a manner that one also retrieves the index (possibly through a generator to be memory efficient)? <code>df.iteritems</code> unfortunately only iterates column by column.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "2  <p>I have a dataframe <code>df</code> in pandas that was built using <code>pandas.read_table</code> from a csv file. The dataframe has several columns and it is indexed by one of the columns (which is unique, in that each row has a unique value for that column used for indexing.) </p>\\n\\n<p>How can I select rows of my dataframe based on a \"complex\" filter applied to multiple columns? I can easily select out the slice of the dataframe where column <code>colA</code> is greater than 10 for example:</p>\\n\\n<pre><code>df_greater_than10 = df[df[\"colA\"] &gt; 10]\\n</code></pre>\\n\\n<p>But what if I wanted a filter like: select the slice of <code>df</code> where <em>any</em> of the columns are greater than 10? </p>\\n\\n<p>Or where the value for <code>colA</code> is greater than 10 but the value for <code>colB</code> is less than 5?</p>\\n\\n<p>How are these implemented in pandas?\\nThanks.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "3  <p>I recently came across the <a href=\"http://pandas.sourceforge.net/\" rel=\"noreferrer\">pandas</a> library for python, which according to <a href=\"http://wesmckinney.com/blog/some-pandas-database-join-merge-benchmarks-vs-r-basemerge/\" rel=\"noreferrer\">this benchmark</a> performs very fast in-memory merges.  It's even faster than the <a href=\"http://cran.r-project.org/web/packages/data.table/index.html\" rel=\"noreferrer\">data.table</a> package in R (my language of choice for analysis).</p>\\n\\n<p>Why is <code>pandas</code> so much faster than <code>data.table</code>?  Is it because of an inherent speed advantage python has over R, or is there some tradeoff I'm not aware of?  Is there a way to perform inner and outer joins in <code>data.table</code> without resorting to <code>merge(X, Y, all=FALSE)</code> and <code>merge(X, Y, all=TRUE)</code>?</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/0pCvh.png\" alt=\"Comparison\"></p>\\n\\n<p>Here's the <a href=\"https://github.com/wesm/pandas/blob/master/bench/bench_merge.R\" rel=\"noreferrer\">R code</a> and the <a href=\"https://github.com/wesm/pandas/blob/master/bench/bench_merge.py\" rel=\"noreferrer\">Python code</a> used to benchmark the various packages.</p>\\n                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "4  <p>I stumbled across <a href=\"http://pandas.pydata.org/\" rel=\"noreferrer\">pandas</a> and it looks ideal for simple calculations that I'd like to do. I have a SAS background and was thinking it'd replace proc freq -- it looks like it'll scale to what I may want to do in the future. However, I just can't seem to get my head around a simple task (I'm not sure if I'm supposed to look at <code>pivot/crosstab/indexing</code> - whether I should have a <code>Panel</code> or <code>DataFrames</code> etc...). Could someone give me some pointers on how to do the following:</p>\\n\\n<p>I have two CSV files (one for year 2010, one for year 2011 - simple transactional data) - The columns are category and amount</p>\\n\\n<p>2010:</p>\\n\\n<pre><code>AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n</code></pre>\\n\\n<p>2011:</p>\\n\\n<pre><code>AB,500.00\\nAC,250.00\\nAX,900.00\\n</code></pre>\\n\\n<p>These are loaded into separate DataFrame objects.</p>\\n\\n<p>What I'd like to do is get the category, the sum of the category, and the frequency of the category, eg:</p>\\n\\n<p>2010:</p>\\n\\n<pre><code>AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n</code></pre>\\n\\n<p>2011:</p>\\n\\n<pre><code>AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n</code></pre>\\n\\n<p>I can't work out whether I should be using <code>pivot/crosstab/groupby/an index</code>\\netc... I can get either the sum or the frequency - I can't seem to get both... It gets a bit more complex because I would like to do it on a month by month basis, but I think if someone would be so kind to point me to the right technique/direction I'll be able to go from there.</p>\\n   \n",
      "\n",
      "  ClosedDate  CommentCount CommunityOwnedDate             CreationDate  \\\n",
      "0  NaN        7             NaN                2011-10-15T08:21:17.460   \n",
      "1  NaN        3             NaN                2011-10-20T14:46:14.633   \n",
      "2  NaN        0             NaN                2012-01-18T19:41:27.017   \n",
      "3  NaN        16            NaN                2012-01-24T17:59:53.850   \n",
      "4  NaN        2             NaN                2012-03-06T17:01:47.107   \n",
      "\n",
      "   FavoriteCount  \\\n",
      "0  4.0             \n",
      "1  108.0           \n",
      "2  12.0            \n",
      "3  58.0            \n",
      "4  5.0             \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                             ...                                                                                                                                                                                                                                                                                                                                                                                                                              \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n",
      "   OwnerUserId ParentId PostTypeId Score  \\\n",
      "0  601314.0    NaN       1          25     \n",
      "1  1005409.0   NaN       1          187    \n",
      "2  248237.0    NaN       1          26     \n",
      "3  345660.0    NaN       1          134    \n",
      "4  1252759.0   NaN       1          21     \n",
      "\n",
      "                                          Tags  \\\n",
      "0  <python><pandas>                              \n",
      "1  <python><performance><for-loop><pandas>       \n",
      "2  <python><csv><numpy><tab-delimited><pandas>   \n",
      "3  <python><r><join><data.table><pandas>         \n",
      "4  <python><pandas>                              \n",
      "\n",
      "                                                                    Title  \\\n",
      "0  append two data frame with pandas                                        \n",
      "1  What is the most efficient way to loop through dataframes with pandas?   \n",
      "2  selecting across multiple columns with python pandas?                    \n",
      "3  Why are pandas merges in python faster than data.table merges in R?      \n",
      "4  Simple cross-tabulation in pandas                                        \n",
      "\n",
      "   ViewCount  \\\n",
      "0  25479.0     \n",
      "1  195364.0    \n",
      "2  19805.0     \n",
      "3  16173.0     \n",
      "4  9493.0      \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     PreCode  \\\n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n, data1,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n, data2,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]   \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n, df.iteritems]                                                                                                                                                                                                                                                                                                                       \n",
      "2  [df, pandas.read_table, colA, df_greater_than10 = df[df[\"colA\"] > 10]\\n, df, colA, colB]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "3  [pandas, data.table, data.table, merge(X, Y, all=FALSE), merge(X, Y, all=TRUE)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "4  [pivot/crosstab/indexing, Panel, DataFrames, AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n, pivot/crosstab/groupby/an index]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Code  \\\n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]   \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n]                                                                                                                                                                                                                                                                                                                       \n",
      "2  [df_greater_than10 = df[df[\"colA\"] > 10]\\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "3  []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "4  [AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     AllCode  \n",
      "0  [bigdata = data1.append(data2)\\n, Exception: Index cannot contain duplicate values!\\n, data1,     meta  particle  ratio   area    type    \\n0   2     part10    1.348   0.8365  touching\\n1   2     part18    1.558   0.8244  single  \\n2   2     part2     1.893   0.894   single  \\n3   2     part37    0.6695  1.005   single  \\n....clip...\\n36  2     part23    1.051   0.8781  single  \\n37  2     part3     80.54   0.9714  nuclei  \\n38  2     part34    1.071   0.9337  single  \\n, data2,     meta  particle  ratio    area    type    \\n0   3     part10    0.4756   1.025   single  \\n1   3     part18    0.04387  1.232   dusts   \\n2   3     part2     1.132    0.8927  single  \\n...clip...\\n46  3     part46    13.71    1.001   nuclei  \\n47  3     part3     0.7439   0.9038  single  \\n48  3     part34    0.4349   0.9956  single \\n]  \n",
      "1  [Date,Open,High,Low,Close,Volume,Adj Close\\n2011-10-19,27.37,27.47,27.01,27.13,42880000,27.13\\n2011-10-18,26.94,27.40,26.80,27.31,52487900,27.31\\n2011-10-17,27.11,27.42,26.85,26.98,39433400,26.98\\n2011-10-14,27.31,27.50,27.02,27.27,50947700,27.27\\n\\n....\\n, #!/usr/bin/env python\\nfrom pandas import *\\n\\ndf = read_csv('table.csv')\\n\\nfor i, row in enumerate(df.values):\\n    date = df.index[i]\\n    open, high, low, close, adjclose = row\\n    #now perform analysis on open/close based on date, etc..\\n, df.iteritems]                                                                                                                                                                                                                                                                                                                      \n",
      "2  [df, pandas.read_table, colA, df_greater_than10 = df[df[\"colA\"] > 10]\\n, df, colA, colB]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "3  [pandas, data.table, data.table, merge(X, Y, all=FALSE), merge(X, Y, all=TRUE)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "4  [pivot/crosstab/indexing, Panel, DataFrames, AB,100.00\\nAB,200.00\\nAC,150.00\\nAD,500.00\\n, AB,500.00\\nAC,250.00\\nAX,900.00\\n, AB,300.00,2\\nAC,150.00,1\\nAD,500.00,1\\n, AB,500.00,1\\nAC,250.00,1\\nAX,900.00,1\\n, pivot/crosstab/groupby/an index]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_code(df):\n",
    "    \"\"\"\n",
    "        Extract only code with <pre><code> combined tag\n",
    "    \"\"\"\n",
    "    df['Code'] = extract_tagged_code(df['Body'], 'pre')\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_all_code(df):\n",
    "    \"\"\"\n",
    "        Extract only code with <pre><code> combined tag\n",
    "    \"\"\"\n",
    "    df['AllCode'] = extract_tagged_code(df['Body'], 'code')\n",
    "    return df\n",
    "\n",
    "# def extract_all_code(df):\n",
    "#     \"\"\"\n",
    "#         Extract every code with <code> tag\n",
    "#     \"\"\"\n",
    "#     soup = BeautifulSoup(df['Body'], \"html.parser\")\n",
    "    \n",
    "#     # Get the <code> tag\n",
    "#     unformatted_codes = soup.find_all('code')\n",
    "    \n",
    "#     # Format from HTML to text\n",
    "#     df['Code'] = [i.get_text() for i in unformatted_codes]\n",
    "#     return df\n",
    "    \n",
    "\n",
    "# Extract Code\n",
    "dataset = dataset.apply(extract_code, axis=1)\n",
    "print(dataset.head())\n",
    "dataset = dataset.apply(extract_all_code, axis=1)\n",
    "print(dataset.head())\n",
    "\n",
    "# Save to CSV\n",
    "dataset_csv = dataset[['AnswerCount',\n",
    "                                                 'CommentCount',\n",
    "                                                 'Id',\n",
    "                                                 'ParentId','PostTypeId','Score','Tags','Title', 'Body',\n",
    "                                                 'ViewCount','Code', 'AllCode']]\n",
    "\n",
    "dataset_csv.to_csv(os.path.join('..', 'data', 'pandas-code-dataset.csv'), encoding='ISO-8859-1', sep=\";\", doublequote=True)\n",
    "# #high_level_questions_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
